{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwwtn5iEQJ1M"
   },
   "source": [
    "# ProtoNN in Tensorflow\n",
    "\n",
    "This is a simple notebook that illustrates the usage of Tensorflow implementation of ProtoNN. We are using the USPS dataset. Please refer to `fetch_usps.py` for more details on downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.223951Z",
     "start_time": "2018-08-15T13:06:09.303454Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dJBVr2b7QJ1R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nadit\\anaconda3\\envs\\ProtoNN\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "#sys.path.insert(0, '../../')\n",
    "# from edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
    "# from edgeml.graph.protoNN import ProtoNN\n",
    "# import edgeml.utils as utils\n",
    "# import helpermethods as helper\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "sys.path.append(r\"D:\\programming\\practice\\research\\protoNN\\EdgeML\\examples\\tf\\ProtoNN\")\n",
    "import helpermethods as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxqvfwWQtQ-s"
   },
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cT-KokQSQiS6"
   },
   "outputs": [],
   "source": [
    "#helper methods\n",
    "sys.path.insert(0, '../')\n",
    "import argparse\n",
    "\n",
    "\n",
    "def getModelSize(matrixList, sparcityList, expected=True, bytesPerVar=4):\n",
    "    '''\n",
    "    expected: Expected size according to the parameters set. The number of\n",
    "        zeros could actually be more than that is required to satisfy the\n",
    "        sparsity constraint.\n",
    "    '''\n",
    "    nnzList, sizeList, isSparseList = [], [], []\n",
    "    hasSparse = False\n",
    "    for i in range(len(matrixList)):\n",
    "        A, s = matrixList[i], sparcityList[i]\n",
    "        assert A.ndim == 2\n",
    "        assert s >= 0\n",
    "        assert s <= 1\n",
    "        nnz, size, sparse = countnnZ(A, s, bytesPerVar=bytesPerVar)\n",
    "        nnzList.append(nnz)\n",
    "        sizeList.append(size)\n",
    "        hasSparse = (hasSparse or sparse)\n",
    "\n",
    "    totalnnZ = np.sum(nnzList)\n",
    "    totalSize = np.sum(sizeList)\n",
    "    if expected:\n",
    "        return totalnnZ, totalSize, hasSparse\n",
    "    numNonZero = 0\n",
    "    totalSize = 0\n",
    "    hasSparse = False\n",
    "    for i in range(len(matrixList)):\n",
    "        A, s = matrixList[i], sparcityList[i]\n",
    "        numNonZero_ = np.count_nonzero(A)\n",
    "        numNonZero += numNonZero_\n",
    "        hasSparse = (hasSparse or (s < 0.5))\n",
    "        if s <= 0.5:\n",
    "            totalSize += numNonZero_ * 2 * bytesPerVar\n",
    "        else:\n",
    "            totalSize += A.size * bytesPerVar\n",
    "    return numNonZero, totalSize, hasSparse\n",
    "\n",
    "\n",
    "def getGamma(gammaInit, projectionDim, dataDim, numPrototypes, x_train):\n",
    "    if gammaInit is None:\n",
    "        print(\"Using median heuristic to estimate gamma.\")\n",
    "        gamma, W, B = medianHeuristic(x_train, projectionDim,\n",
    "                                            numPrototypes)\n",
    "        print(\"Gamma estimate is: %f\" % gamma)\n",
    "        return W, B, gamma\n",
    "    return None, None, gammaInit\n",
    "\n",
    "\n",
    "def preprocessData(dataDir,w):\n",
    "    '''\n",
    "    Loads data from the dataDir and does some initial preprocessing\n",
    "    steps. Data is assumed to be contained in two files,\n",
    "    train.npy and test.npy. Each containing a 2D numpy array of dimension\n",
    "    [numberOfExamples, numberOfFeatures + 1]. The first column of each\n",
    "    matrix is assumed to contain label information.\n",
    "\n",
    "    For an N-Class problem, we assume the labels are integers from 0 through\n",
    "    N-1.\n",
    "    '''\n",
    "    # Uncomment for usual training data\n",
    "    # train = np.load(dataDir + '/train_'+str(w)+'.npy')\n",
    "    # test = np.load(dataDir + '/test_'+str(w)+'.npy')\n",
    "    # Uncomment for time domain training data\n",
    "    train = np.load(dataDir + '/ttrain_'+str(w)+'.npy')\n",
    "    test = np.load(dataDir + '/ttest_'+str(w)+'.npy')\n",
    "    # Uncomment for 1 sensordrop training data\n",
    "    # train = np.load(dataDir + '/train_'+str(w)+'.npy')\n",
    "    # test = np.load(dataDir + '/test_'+str(w)+'.npy')\n",
    "\n",
    "    dataDimension = int(train.shape[1]) - 1\n",
    "    x_train = train[:, 1:dataDimension + 1]\n",
    "    y_train_ = train[:, 0]\n",
    "    x_test = test[:, 1:dataDimension + 1]\n",
    "    y_test_ = test[:, 0]\n",
    "\n",
    "    numClasses = max(y_train_) - min(y_train_) + 1\n",
    "    numClasses = max(numClasses, max(y_test_) - min(y_test_) + 1)\n",
    "    numClasses = int(numClasses)\n",
    "\n",
    "    # mean-var\n",
    "    mean = np.mean(x_train, 0)\n",
    "    std = np.std(x_train, 0)\n",
    "    std[std[:] < 0.000001] = 1\n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "\n",
    "    # one hot y-train\n",
    "    lab = y_train_.astype('uint8')\n",
    "    lab = np.array(lab) - min(lab)\n",
    "    lab_ = np.zeros((x_train.shape[0], numClasses))\n",
    "    lab_[np.arange(x_train.shape[0]), lab] = 1\n",
    "    y_train = lab_\n",
    "\n",
    "    # one hot y-test\n",
    "    lab = y_test_.astype('uint8')\n",
    "    lab = np.array(lab) - min(lab)\n",
    "    lab_ = np.zeros((x_test.shape[0], numClasses))\n",
    "    lab_[np.arange(x_test.shape[0]), lab] = 1\n",
    "    y_test = lab_\n",
    "\n",
    "    return dataDimension, numClasses, x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "def getProtoNNArgs():\n",
    "    def checkIntPos(value):\n",
    "        ivalue = int(value)\n",
    "        if ivalue <= 0:\n",
    "            raise argparse.ArgumentTypeError(\n",
    "                \"%s is an invalid positive int value\" % value)\n",
    "        return ivalue\n",
    "\n",
    "    def checkIntNneg(value):\n",
    "        ivalue = int(value)\n",
    "        if ivalue < 0:\n",
    "            raise argparse.ArgumentTypeError(\n",
    "                \"%s is an invalid non-neg int value\" % value)\n",
    "        return ivalue\n",
    "\n",
    "    def checkFloatNneg(value):\n",
    "        fvalue = float(value)\n",
    "        if fvalue < 0:\n",
    "            raise argparse.ArgumentTypeError(\n",
    "                \"%s is an invalid non-neg float value\" % value)\n",
    "        return fvalue\n",
    "\n",
    "    def checkFloatPos(value):\n",
    "        fvalue = float(value)\n",
    "        if fvalue <= 0:\n",
    "            raise argparse.ArgumentTypeError(\n",
    "                \"%s is an invalid positive float value\" % value)\n",
    "        return fvalue\n",
    "\n",
    "    '''\n",
    "    Parse protoNN commandline arguments\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Hyperparameters for ProtoNN Algorithm')\n",
    "\n",
    "    msg = 'Data directory containing train and test data. The '\n",
    "    msg += 'data is assumed to be saved as 2-D numpy matrices with '\n",
    "    msg += 'names `train.npy` and `test.npy`, of dimensions\\n'\n",
    "    msg += '\\t[numberOfInstances, numberOfFeatures + 1].\\n'\n",
    "    msg += 'The first column of each file is assumed to contain label information.'\n",
    "    msg += ' For a N-class problem, labels are assumed to be integers from 0 to'\n",
    "    msg += ' N-1 (inclusive).'\n",
    "    parser.add_argument('-d', '--data-dir', required=True, help=msg)\n",
    "    parser.add_argument('-l', '--projection-dim', type=checkIntPos, default=10,\n",
    "                        help='Projection Dimension.')\n",
    "    parser.add_argument('-p', '--num-prototypes', type=checkIntPos, default=20,\n",
    "                        help='Number of prototypes.')\n",
    "    parser.add_argument('-g', '--gamma', type=checkFloatPos, default=None,\n",
    "                        help='Gamma for Gaussian kernel. If not provided, ' +\n",
    "                        'median heuristic will be used to estimate gamma.')\n",
    "\n",
    "    parser.add_argument('-e', '--epochs', type=checkIntPos, default=100,\n",
    "                        help='Total training epochs.')\n",
    "    parser.add_argument('-b', '--batch-size', type=checkIntPos, default=32,\n",
    "                        help='Batch size for each pass.')\n",
    "    parser.add_argument('-r', '--learning-rate', type=checkFloatPos,\n",
    "                        default=0.001,\n",
    "                        help='Initial Learning rate for ADAM Optimizer.')\n",
    "\n",
    "    parser.add_argument('-rW', type=float, default=0.000,\n",
    "                        help='Coefficient for l2 regularizer for predictor' +\n",
    "                        ' parameter W ' + '(default = 0.0).')\n",
    "    parser.add_argument('-rB', type=float, default=0.00,\n",
    "                        help='Coefficient for l2 regularizer for predictor' +\n",
    "                        ' parameter B ' + '(default = 0.0).')\n",
    "    parser.add_argument('-rZ', type=float, default=0.00,\n",
    "                        help='Coefficient for l2 regularizer for predictor' +\n",
    "                        'parameter Z ' +\n",
    "                        '(default = 0.0).')\n",
    "\n",
    "    parser.add_argument('-sW', type=float, default=1.000,\n",
    "                        help='Sparsity constraint for predictor parameter W ' +\n",
    "                        '(default = 1.0, i.e. dense matrix).')\n",
    "    parser.add_argument('-sB', type=float, default=1.00,\n",
    "                        help='Sparsity constraint for predictor parameter B ' +\n",
    "                        '(default = 1.0, i.e. dense matrix).')\n",
    "    parser.add_argument('-sZ', type=float, default=1.00,\n",
    "                        help='Sparsity constraint for predictor parameter Z ' +\n",
    "                        '(default = 1.0, i.e. dense matrix).')\n",
    "    parser.add_argument('-pS', '--print-step', type=int, default=200,\n",
    "                        help='The number of update steps between print ' +\n",
    "                        'calls to console.')\n",
    "    parser.add_argument('-vS', '--val-step', type=int, default=3,\n",
    "                        help='The number of epochs between validation' +\n",
    "                        'performance evaluation')\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ou1MfKhYtMdT"
   },
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDVo_0JiRSi9"
   },
   "outputs": [],
   "source": [
    "#utils\n",
    "import scipy.cluster\n",
    "import scipy.spatial\n",
    "import os\n",
    "\n",
    "\n",
    "def medianHeuristic(data, projectionDimension, numPrototypes, W_init=None):\n",
    "    '''\n",
    "    This method can be used to estimate gamma for ProtoNN. An approximation to\n",
    "    median heuristic is used here.\n",
    "    1. First the data is collapsed into the projectionDimension by W_init. If\n",
    "    W_init is not provided, it is initialized from a random normal(0, 1). Hence\n",
    "    data normalization is essential.\n",
    "    2. Prototype are computed by running a  k-means clustering on the projected\n",
    "    data.\n",
    "    3. The median distance is then estimated by calculating median distance\n",
    "    between prototypes and projected data points.\n",
    "\n",
    "    data needs to be [-1, numFeats]\n",
    "    If using this method to initialize gamma, please use the W and B as well.\n",
    "\n",
    "    TODO: Return estimate of Z (prototype labels) based on cluster centroids\n",
    "    andand labels\n",
    "\n",
    "    TODO: Clustering fails due to singularity error if projecting upwards\n",
    "\n",
    "    W [dxd_cap]\n",
    "    B [d_cap, m]\n",
    "    returns gamma, W, B\n",
    "    '''\n",
    "    assert data.ndim == 2\n",
    "    X = data\n",
    "    featDim = data.shape[1]\n",
    "    if projectionDimension > featDim:\n",
    "        print(\"Warning: Projection dimension > feature dimension. Gamma\")\n",
    "        print(\"\\t estimation due to median heuristic could fail.\")\n",
    "        print(\"\\tTo retain the projection dataDimension, provide\")\n",
    "        print(\"\\ta value for gamma.\")\n",
    "\n",
    "    if W_init is None:\n",
    "        W_init = np.random.normal(size=[featDim, projectionDimension])\n",
    "    W = W_init\n",
    "    XW = np.matmul(X, W)\n",
    "    assert XW.shape[1] == projectionDimension\n",
    "    assert XW.shape[0] == len(X)\n",
    "    # Requires [N x d_cap] data matrix of N observations of d_cap-dimension and\n",
    "    # the number of centroids m. Returns, [n x d_cap] centroids and\n",
    "    # elementwise center information.\n",
    "    B, centers = scipy.cluster.vq.kmeans2(XW, numPrototypes)\n",
    "    # Requires two matrices. Number of observations x dimension of observation\n",
    "    # space. Distances[i,j] is the distance between XW[i] and B[j]\n",
    "    distances = scipy.spatial.distance.cdist(XW, B, metric='euclidean')\n",
    "    distances = np.reshape(distances, [-1])\n",
    "    gamma = np.median(distances)\n",
    "    gamma = 1 / (2.5 * gamma)\n",
    "    return gamma.astype('float32'), W.astype('float32'), B.T.astype('float32')\n",
    "\n",
    "\n",
    "def multiClassHingeLoss(logits, label, batch_th):\n",
    "    '''\n",
    "    MultiClassHingeLoss to match C++ Version - No TF internal version\n",
    "    '''\n",
    "    flatLogits = tf.reshape(logits, [-1, ])\n",
    "    label_ = tf.argmax(label, 1)\n",
    "\n",
    "    correctId = tf.range(0, batch_th) * label.shape[1] + label_\n",
    "    correctLogit = tf.gather(flatLogits, correctId)\n",
    "\n",
    "    maxLabel = tf.argmax(logits, 1)\n",
    "    top2, _ = tf.nn.top_k(logits, k=2, sorted=True)\n",
    "\n",
    "    wrongMaxLogit = tf.where(\n",
    "        tf.equal(maxLabel, label_), top2[:, 1], top2[:, 0])\n",
    "\n",
    "    return tf.reduce_mean(tf.nn.relu(1. + wrongMaxLogit - correctLogit))\n",
    "\n",
    "\n",
    "def crossEntropyLoss(logits, label):\n",
    "    '''\n",
    "    Cross Entropy loss for MultiClass case in joint training for\n",
    "    faster convergence\n",
    "    '''\n",
    "    return tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                   labels=tf.stop_gradient(label)))\n",
    "\n",
    "\n",
    "def mean_absolute_error(logits, label):\n",
    "    '''\n",
    "    Function to compute the mean absolute error.\n",
    "    '''\n",
    "    return tf.reduce_mean(tf.abs(tf.subtract(logits, label)))\n",
    "\n",
    "\n",
    "def hardThreshold(A, s):\n",
    "    '''\n",
    "    Hard thresholding function on Tensor A with sparsity s\n",
    "    '''\n",
    "    A_ = np.copy(A)\n",
    "    A_ = A_.ravel()\n",
    "    if len(A_) > 0:\n",
    "        th = np.percentile(np.abs(A_), (1 - s) * 100.0, interpolation='higher')\n",
    "        A_[np.abs(A_) < th] = 0.0\n",
    "    A_ = A_.reshape(A.shape)\n",
    "    return A_\n",
    "\n",
    "\n",
    "def copySupport(src, dest):\n",
    "    '''\n",
    "    copy support of src tensor to dest tensor\n",
    "    '''\n",
    "    support = np.nonzero(src)\n",
    "    dest_ = dest\n",
    "    dest = np.zeros(dest_.shape)\n",
    "    dest[support] = dest_[support]\n",
    "    return dest\n",
    "\n",
    "\n",
    "def countnnZ(A, s, bytesPerVar=4):\n",
    "    '''\n",
    "    Returns # of non-zeros and representative size of the tensor\n",
    "    Uses dense for s >= 0.5 - 4 byte\n",
    "    Else uses sparse - 8 byte\n",
    "    '''\n",
    "    params = 1\n",
    "    hasSparse = False\n",
    "    for i in range(0, len(A.shape)):\n",
    "        params *= int(A.shape[i])\n",
    "    if s < 0.5:\n",
    "        nnZ = np.ceil(params * s)\n",
    "        hasSparse = True\n",
    "        return nnZ, nnZ * 2 * bytesPerVar, hasSparse\n",
    "    else:\n",
    "        nnZ = params\n",
    "        return nnZ, nnZ * bytesPerVar, hasSparse\n",
    "\n",
    "\n",
    "def getConfusionMatrix(predicted, target, numClasses):\n",
    "    '''\n",
    "    Returns a confusion matrix for a multiclass classification\n",
    "    problem. `predicted` is a 1-D array of integers representing\n",
    "    the predicted classes and `target` is the target classes.\n",
    "\n",
    "    confusion[i][j]: Number of elements of class j\n",
    "        predicted as class i\n",
    "    Labels are assumed to be in range(0, numClasses)\n",
    "    Use`printFormattedConfusionMatrix` to echo the confusion matrix\n",
    "    in a user friendly form.\n",
    "    '''\n",
    "    assert(predicted.ndim == 1)\n",
    "    assert(target.ndim == 1)\n",
    "    arr = np.zeros([numClasses, numClasses])\n",
    "\n",
    "    for i in range(len(predicted)):\n",
    "        arr[predicted[i]][target[i]] += 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def printFormattedConfusionMatrix(matrix):\n",
    "    '''\n",
    "    Given a 2D confusion matrix, prints it in a human readable way.\n",
    "    The confusion matrix is expected to be a 2D numpy array with\n",
    "    square dimensions\n",
    "    '''\n",
    "    assert(matrix.ndim == 2)\n",
    "    assert(matrix.shape[0] == matrix.shape[1])\n",
    "    RECALL = 'Recall'\n",
    "    PRECISION = 'PRECISION'\n",
    "    print(\"|%s|\" % ('True->'), end='')\n",
    "    for i in range(matrix.shape[0]):\n",
    "        print(\"%7d|\" % i, end='')\n",
    "    print(\"%s|\" % 'Precision')\n",
    "\n",
    "    print(\"|%s|\" % ('-' * len(RECALL)), end='')\n",
    "    for i in range(matrix.shape[0]):\n",
    "        print(\"%s|\" % ('-' * 7), end='')\n",
    "    print(\"%s|\" % ('-' * len(PRECISION)))\n",
    "\n",
    "    precisionlist = np.sum(matrix, axis=1)\n",
    "    recalllist = np.sum(matrix, axis=0)\n",
    "    precisionlist = [matrix[i][i] / x if x !=\n",
    "                     0 else -1 for i, x in enumerate(precisionlist)]\n",
    "    recalllist = [matrix[i][i] / x if x !=\n",
    "                  0 else -1 for i, x in enumerate(recalllist)]\n",
    "    for i in range(matrix.shape[0]):\n",
    "        # len recall = 6\n",
    "        print(\"|%6d|\" % (i), end='')\n",
    "        for j in range(matrix.shape[0]):\n",
    "            print(\"%7d|\" % (matrix[i][j]), end='')\n",
    "        print(\"%s\" % (\" \" * (len(PRECISION) - 7)), end='')\n",
    "        if precisionlist[i] != -1:\n",
    "            print(\"%1.5f|\" % precisionlist[i])\n",
    "        else:\n",
    "            print(\"%7s|\" % \"nan\")\n",
    "\n",
    "    print(\"|%s|\" % ('-' * len(RECALL)), end='')\n",
    "    for i in range(matrix.shape[0]):\n",
    "        print(\"%s|\" % ('-' * 7), end='')\n",
    "    print(\"%s|\" % ('-' * len(PRECISION)))\n",
    "    print(\"|%s|\" % ('Recall'), end='')\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        if recalllist[i] != -1:\n",
    "            print(\"%1.5f|\" % (recalllist[i]), end='')\n",
    "        else:\n",
    "            print(\"%7s|\" % \"nan\", end='')\n",
    "\n",
    "    print('%s|' % (' ' * len(PRECISION)))\n",
    "\n",
    "\n",
    "def getPrecisionRecall(cmatrix, label=1):\n",
    "    trueP = cmatrix[label][label]\n",
    "    denom = np.sum(cmatrix, axis=0)[label]\n",
    "    if denom == 0:\n",
    "        denom = 1\n",
    "    recall = trueP / denom\n",
    "    denom = np.sum(cmatrix, axis=1)[label]\n",
    "    if denom == 0:\n",
    "        denom = 1\n",
    "    precision = trueP / denom\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def getMacroPrecisionRecall(cmatrix):\n",
    "    # TP + FP\n",
    "    precisionlist = np.sum(cmatrix, axis=1)\n",
    "    # TP + FN\n",
    "    recalllist = np.sum(cmatrix, axis=0)\n",
    "    precisionlist__ = [cmatrix[i][i] / x if x !=\n",
    "                       0 else 0 for i, x in enumerate(precisionlist)]\n",
    "    recalllist__ = [cmatrix[i][i] / x if x !=\n",
    "                    0 else 0 for i, x in enumerate(recalllist)]\n",
    "    precision = np.sum(precisionlist__)\n",
    "    precision /= len(precisionlist__)\n",
    "    recall = np.sum(recalllist__)\n",
    "    recall /= len(recalllist__)\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def getMicroPrecisionRecall(cmatrix):\n",
    "    # TP + FP\n",
    "    precisionlist = np.sum(cmatrix, axis=1)\n",
    "    # TP + FN\n",
    "    recalllist = np.sum(cmatrix, axis=0)\n",
    "    num = 0.0\n",
    "    for i in range(len(cmatrix)):\n",
    "        num += cmatrix[i][i]\n",
    "\n",
    "    precision = num / np.sum(precisionlist)\n",
    "    recall = num / np.sum(recalllist)\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def getMacroMicroFScore(cmatrix):\n",
    "    '''\n",
    "    Returns macro and micro f-scores.\n",
    "    Refer: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.8244&rep=rep1&type=pdf\n",
    "    '''\n",
    "    precisionlist = np.sum(cmatrix, axis=1)\n",
    "    recalllist = np.sum(cmatrix, axis=0)\n",
    "    precisionlist__ = [cmatrix[i][i] / x if x !=\n",
    "                       0 else 0 for i, x in enumerate(precisionlist)]\n",
    "    recalllist__ = [cmatrix[i][i] / x if x !=\n",
    "                    0 else 0 for i, x in enumerate(recalllist)]\n",
    "    macro = 0.0\n",
    "    for i in range(len(precisionlist)):\n",
    "        denom = precisionlist__[i] + recalllist__[i]\n",
    "        numer = precisionlist__[i] * recalllist__[i] * 2\n",
    "        if denom == 0:\n",
    "            denom = 1\n",
    "        macro += numer / denom\n",
    "    macro /= len(precisionlist)\n",
    "\n",
    "    num = 0.0\n",
    "    for i in range(len(precisionlist)):\n",
    "        num += cmatrix[i][i]\n",
    "\n",
    "    denom1 = np.sum(precisionlist)\n",
    "    denom2 = np.sum(recalllist)\n",
    "    pi = num / denom1\n",
    "    rho = num / denom2\n",
    "    denom = pi + rho\n",
    "    if denom == 0:\n",
    "        denom = 1\n",
    "    micro = 2 * pi * rho / denom\n",
    "    return macro, micro\n",
    "\n",
    "\n",
    "class GraphManager:\n",
    "    '''\n",
    "    Manages saving and restoring graphs. Designed to be used with EMI-RNN\n",
    "    though is general enough to be useful otherwise as well.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def checkpointModel(self, saver, sess, modelPrefix,\n",
    "                        globalStep=1000, redirFile=None):\n",
    "        saver.save(sess, modelPrefix, global_step=globalStep)\n",
    "        print('Model saved to %s, global_step %d' % (modelPrefix, globalStep),\n",
    "              file=redirFile)\n",
    "\n",
    "    def loadCheckpoint(self, sess, modelPrefix, globalStep,\n",
    "                       redirFile=None):\n",
    "        metaname = modelPrefix + '-%d.meta' % globalStep\n",
    "        basename = os.path.basename(metaname)\n",
    "        fileList = os.listdir(os.path.dirname(modelPrefix))\n",
    "        fileList = [x for x in fileList if x.startswith(basename)]\n",
    "        assert len(fileList) > 0, 'Checkpoint file not found'\n",
    "        msg = 'Too many or too few checkpoint files for globalStep: %d' % globalStep\n",
    "        assert len(fileList) is 1, msg\n",
    "        chkpt = basename + '/' + fileList[0]\n",
    "        saver = tf.train.import_meta_graph(metaname)\n",
    "        metaname = metaname[:-5]\n",
    "        saver.restore(sess, metaname)\n",
    "        graph = tf.get_default_graph()\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAjSVSOFtFmm"
   },
   "source": [
    "# Model Trainer - ProtoNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp5dEFiZR_sy"
   },
   "outputs": [],
   "source": [
    "#Trainer\n",
    "class ProtoNNTrainer:\n",
    "    def __init__(self, protoNNObj, regW, regB, regZ,\n",
    "                 sparcityW, sparcityB, sparcityZ,\n",
    "                 learningRate, X, Y, lossType='l2'):\n",
    "        '''\n",
    "        A wrapper for the various techniques used for training ProtoNN. This\n",
    "        subsumes both the responsibility of loss graph construction and\n",
    "        performing training. The original training routine that is part of the\n",
    "        C++ implementation of EdgeML used iterative hard thresholding (IHT),\n",
    "        gamma estimation through median heuristic and other tricks for\n",
    "        training ProtoNN. This module implements the same in Tensorflow\n",
    "        and python.\n",
    "\n",
    "        protoNNObj: An instance of ProtoNN class defining the forward\n",
    "            computation graph. The loss functions and training routines will be\n",
    "            attached to this instance.\n",
    "        regW, regB, regZ: Regularization constants for W, B, and\n",
    "            Z matrices of protoNN.\n",
    "        sparcityW, sparcityB, sparcityZ: Sparsity constraints\n",
    "            for W, B and Z matrices. A value between 0 (exclusive) and 1\n",
    "            (inclusive) is expected. A value of 1 indicates dense training.\n",
    "        learningRate: Initial learning rate for ADAM optimizer.\n",
    "        X, Y : Placeholders for data and labels.\n",
    "            X [-1, featureDimension]\n",
    "            Y [-1, num Labels]\n",
    "        lossType: ['l2', 'xentropy']\n",
    "        '''\n",
    "        self.protoNNObj = protoNNObj\n",
    "        self.__regW = regW\n",
    "        self.__regB = regB\n",
    "        self.__regZ = regZ\n",
    "        self.__sW = sparcityW\n",
    "        self.__sB = sparcityB\n",
    "        self.__sZ = sparcityZ\n",
    "        self.__lR = learningRate\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.sparseTraining = True\n",
    "        if (sparcityW == 1.0) and (sparcityB == 1.0) and (sparcityZ == 1.0):\n",
    "            self.sparseTraining = False\n",
    "            print(\"Sparse training disabled.\", file=sys.stderr)\n",
    "        # Define placeholders for sparse training\n",
    "        self.W_th = None\n",
    "        self.B_th = None\n",
    "        self.Z_th = None\n",
    "        self.__lossType = lossType\n",
    "        self.__validInit = False\n",
    "        self.__validInit = self.__validateInit()\n",
    "        self.__protoNNOut = protoNNObj(X, Y)\n",
    "        self.loss = self.__lossGraph()\n",
    "        self.trainStep = self.__trainGraph()\n",
    "        self.__hthOp = self.__getHardThresholdOp()\n",
    "        self.accuracy = protoNNObj.getAccuracyOp()\n",
    "\n",
    "    def __validateInit(self):\n",
    "        self.__validInit = False\n",
    "        msg = \"Sparsity value should be between\"\n",
    "        msg += \" 0 and 1 (both inclusive).\"\n",
    "        assert self.__sW >= 0. and self.__sW <= 1., 'W:' + msg\n",
    "        assert self.__sB >= 0. and self.__sB <= 1., 'B:' + msg\n",
    "        assert self.__sZ >= 0. and self.__sZ <= 1., 'Z:' + msg\n",
    "        d, dcap, m, L, _ = self.protoNNObj.getHyperParams()\n",
    "        msg = 'Y should be of dimension [-1, num labels/classes]'\n",
    "        msg += ' specified as part of ProtoNN object.'\n",
    "        assert (len(self.Y.shape)) == 2, msg\n",
    "        assert (self.Y.shape[1] == L), msg\n",
    "        msg = 'X should be of dimension [-1, featureDimension]'\n",
    "        msg += ' specified as part of ProtoNN object.'\n",
    "        assert (len(self.X.shape) == 2), msg\n",
    "        assert (self.X.shape[1] == d), msg\n",
    "        self.__validInit = True\n",
    "        msg = 'Values can be \\'l2\\', or \\'xentropy\\''\n",
    "        if self.__lossType not in ['l2', 'xentropy']:\n",
    "            raise ValueError(msg)\n",
    "        return True\n",
    "\n",
    "    def __lossGraph(self):\n",
    "        pnnOut = self.__protoNNOut\n",
    "        l1, l2, l3 = self.__regW, self.__regB, self.__regZ\n",
    "        W, B, Z, _ = self.protoNNObj.getModelMatrices()\n",
    "        if self.__lossType == 'l2':\n",
    "            with tf.name_scope('protonn-l2-loss'):\n",
    "                loss_0 = tf.nn.l2_loss(self.Y - pnnOut)\n",
    "                reg = l1 * tf.nn.l2_loss(W) + l2 * tf.nn.l2_loss(B)\n",
    "                reg += l3 * tf.nn.l2_loss(Z)\n",
    "                loss = loss_0 + reg\n",
    "        elif self.__lossType == 'xentropy':\n",
    "            with tf.name_scope('protonn-xentropy-loss'):\n",
    "                loss_0 = tf.nn.softmax_cross_entropy_with_logits_v2(logits=pnnOut,\n",
    "                                                         labels=tf.stop_gradient(self.Y))\n",
    "                loss_0 = tf.reduce_mean(loss_0)\n",
    "                reg = l1 * tf.nn.l2_loss(W) + l2 * tf.nn.l2_loss(B)\n",
    "                reg += l3 * tf.nn.l2_loss(Z)\n",
    "                loss = loss_0 + reg\n",
    "        return loss\n",
    "\n",
    "    def __trainGraph(self):\n",
    "        with tf.name_scope('protonn-gradient-adam'):\n",
    "            trainStep = tf.train.AdamOptimizer(self.__lR)\n",
    "            trainStep = trainStep.minimize(self.loss)\n",
    "        return trainStep\n",
    "\n",
    "    def __getHardThresholdOp(self):\n",
    "        W, B, Z, _ = self.protoNNObj.getModelMatrices()\n",
    "        self.W_th = tf.placeholder(tf.float32, name='W_th')\n",
    "        self.B_th = tf.placeholder(tf.float32, name='B_th')\n",
    "        self.Z_th = tf.placeholder(tf.float32, name='Z_th')\n",
    "        with tf.name_scope('hard-threshold-assignments'):\n",
    "            hard_thrsd_W = W.assign(self.W_th)\n",
    "            hard_thrsd_B = B.assign(self.B_th)\n",
    "            hard_thrsd_Z = Z.assign(self.Z_th)\n",
    "            hard_thrsd_op = tf.group(hard_thrsd_W, hard_thrsd_B, hard_thrsd_Z)\n",
    "        return hard_thrsd_op\n",
    "\n",
    "    def train(self, batchSize, totalEpochs, sess,\n",
    "              x_train, x_val, y_train, y_val, noInit=False,\n",
    "              redirFile=None, printStep=10, valStep=3):\n",
    "        '''\n",
    "        Performs dense training of ProtoNN followed by iterative hard\n",
    "        thresholding to enforce sparsity constraints.\n",
    "\n",
    "        batchSize: Batch size per update\n",
    "        totalEpochs: The number of epochs to run training for. One epoch is\n",
    "            defined as one pass over the entire training data.\n",
    "        sess: The Tensorflow session to use for running various graph\n",
    "            operators.\n",
    "        x_train, x_val, y_train, y_val: The numpy array containing train and\n",
    "            validation data. x data is assumed to in of shape [-1,\n",
    "            featureDimension] while y should have shape [-1, numberLabels].\n",
    "        noInit: By default, all the tensors of the computation graph are\n",
    "        initialized at the start of the training session. Set noInit=False to\n",
    "        disable this behaviour.\n",
    "        printStep: Number of batches between echoing of loss and train accuracy.\n",
    "        valStep: Number of epochs between evolutions on validation set.\n",
    "        '''\n",
    "        d, d_cap, m, L, gamma = self.protoNNObj.getHyperParams()\n",
    "        assert batchSize >= 1, 'Batch size should be positive integer'\n",
    "        assert totalEpochs >= 1, 'Total epochs should be positive integer'\n",
    "        assert x_train.ndim == 2, 'Expected training data to be of rank 2'\n",
    "        assert x_train.shape[1] == d, 'Expected x_train to be [-1, %d]' % d\n",
    "        assert x_val.ndim == 2, 'Expected validation data to be of rank 2'\n",
    "        assert x_val.shape[1] == d, 'Expected x_val to be [-1, %d]' % d\n",
    "        assert y_train.ndim == 2, 'Expected training labels to be of rank 2'\n",
    "        assert y_train.shape[1] == L, 'Expected y_train to be [-1, %d]' % L\n",
    "        assert y_val.ndim == 2, 'Expected validation labels to be of rank 2'\n",
    "        assert y_val.shape[1] == L, 'Expected y_val to be [-1, %d]' % L\n",
    "\n",
    "        # Numpy will throw asserts for arrays\n",
    "        if sess is None:\n",
    "            raise ValueError('sess must be valid Tensorflow session.')\n",
    "\n",
    "        trainNumBatches = int(np.ceil(len(x_train) / batchSize))\n",
    "        valNumBatches = int(np.ceil(len(x_val) / batchSize))\n",
    "        x_train_batches = np.array_split(x_train, trainNumBatches)\n",
    "        y_train_batches = np.array_split(y_train, trainNumBatches)\n",
    "        x_val_batches = np.array_split(x_val, valNumBatches)\n",
    "        y_val_batches = np.array_split(y_val, valNumBatches)\n",
    "        if not noInit:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        X, Y = self.X, self.Y\n",
    "        W, B, Z, _ = self.protoNNObj.getModelMatrices()\n",
    "        for epoch in range(totalEpochs):\n",
    "            for i in range(len(x_train_batches)):\n",
    "                batch_x = x_train_batches[i]\n",
    "                batch_y = y_train_batches[i]\n",
    "                feed_dict = {\n",
    "                    X: batch_x,\n",
    "                    Y: batch_y\n",
    "                }\n",
    "                sess.run(self.trainStep, feed_dict=feed_dict)\n",
    "                if i % printStep == 0:\n",
    "                    loss, acc = sess.run([self.loss, self.accuracy],\n",
    "                                         feed_dict=feed_dict)\n",
    "                    msg = \"Epoch: %3d Batch: %3d\" % (epoch, i)\n",
    "                    msg += \" Loss: %3.5f Accuracy: %2.5f\" % (loss, acc)\n",
    "                    print(msg, file=redirFile)\n",
    "\n",
    "            # Perform Hard thresholding\n",
    "            if self.sparseTraining:\n",
    "                W_, B_, Z_ = sess.run([W, B, Z])\n",
    "                fd_thrsd = {\n",
    "                    self.W_th: hardThreshold(W_, self.__sW),\n",
    "                    self.B_th: hardThreshold(B_, self.__sB),\n",
    "                    self.Z_th: hardThreshold(Z_, self.__sZ)\n",
    "                }\n",
    "                sess.run(self.__hthOp, feed_dict=fd_thrsd)\n",
    "\n",
    "            if (epoch + 1) % valStep  == 0:\n",
    "                acc = 0.0\n",
    "                loss = 0.0\n",
    "                for j in range(len(x_val_batches)):\n",
    "                    batch_x = x_val_batches[j]\n",
    "                    batch_y = y_val_batches[j]\n",
    "                    feed_dict = {\n",
    "                        X: batch_x,\n",
    "                        Y: batch_y\n",
    "                    }\n",
    "                    acc_, loss_ = sess.run([self.accuracy, self.loss],\n",
    "                                           feed_dict=feed_dict)\n",
    "                    acc += acc_\n",
    "                    loss += loss_\n",
    "                acc /= len(y_val_batches)\n",
    "                loss /= len(y_val_batches)\n",
    "                print(\"Test Loss: %2.5f Accuracy: %2.5f\" % (loss, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Z6ym4k_s9pS"
   },
   "source": [
    "# Model Graph - ProtoNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRPFglKHSbu-"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ProtoNN:\n",
    "    def __init__(self, inputDimension, projectionDimension, numPrototypes,\n",
    "                 numOutputLabels, gamma,\n",
    "                 W = None, B = None, Z = None):\n",
    "        '''\n",
    "        Forward computation graph for ProtoNN.\n",
    "\n",
    "        inputDimension: Input data dimension or feature dimension.\n",
    "        projectionDimension: hyperparameter\n",
    "        numPrototypes: hyperparameter\n",
    "        numOutputLabels: The number of output labels or classes\n",
    "        W, B, Z: Numpy matrices that can be used to initialize\n",
    "            projection matrix(W), prototype matrix (B) and prototype labels\n",
    "            matrix (B).\n",
    "            Expected Dimensions:\n",
    "                W   inputDimension (d) x projectionDimension (d_cap)\n",
    "                B   projectionDimension (d_cap) x numPrototypes (m)\n",
    "                Z   numOutputLabels (L) x numPrototypes (m)\n",
    "        '''\n",
    "        with tf.name_scope('protoNN') as ns:\n",
    "            self.__nscope = ns\n",
    "        self.__d = inputDimension\n",
    "        self.__d_cap = projectionDimension\n",
    "        self.__m = numPrototypes\n",
    "        self.__L = numOutputLabels\n",
    "\n",
    "        self.__inW = W\n",
    "        self.__inB = B\n",
    "        self.__inZ = Z\n",
    "        self.__inGamma = gamma\n",
    "        self.W, self.B, self.Z = None, None, None\n",
    "        self.gamma = None\n",
    "\n",
    "        self.__validInit = False\n",
    "        self.__initWBZ()\n",
    "        self.__initGamma()\n",
    "        self.__validateInit()\n",
    "        self.protoNNOut = None\n",
    "        self.predictions = None\n",
    "        self.accuracy = None\n",
    "\n",
    "    def __validateInit(self):\n",
    "        self.__validInit = False\n",
    "        errmsg = \"Dimensions mismatch! Should be W[d, d_cap]\"\n",
    "        errmsg += \", B[d_cap, m] and Z[L, m]\"\n",
    "        d, d_cap, m, L, _ = self.getHyperParams()\n",
    "        assert self.W.shape[0] == d, errmsg\n",
    "        assert self.W.shape[1] == d_cap, errmsg\n",
    "        assert self.B.shape[0] == d_cap, errmsg\n",
    "        assert self.B.shape[1] == m, errmsg\n",
    "        assert self.Z.shape[0] == L, errmsg\n",
    "        assert self.Z.shape[1] == m, errmsg\n",
    "        self.__validInit = True\n",
    "\n",
    "    def __initWBZ(self):\n",
    "        with tf.name_scope(self.__nscope):\n",
    "            W = self.__inW\n",
    "            if W is None:\n",
    "                W = tf.random_normal_initializer()\n",
    "                W = W([self.__d, self.__d_cap])\n",
    "            self.W = tf.Variable(W, name='W', dtype=tf.float32)\n",
    "\n",
    "            B = self.__inB\n",
    "            if B is None:\n",
    "                B = tf.random_uniform_initializer()\n",
    "                B = B([self.__d_cap, self.__m])\n",
    "            self.B = tf.Variable(B, name='B', dtype=tf.float32)\n",
    "\n",
    "            Z = self.__inZ\n",
    "            if Z is None:\n",
    "                Z = tf.random_normal_initializer()\n",
    "                Z = Z([self.__L, self.__m])\n",
    "            Z = tf.Variable(Z, name='Z', dtype=tf.float32)\n",
    "            self.Z = Z\n",
    "        return self.W, self.B, self.Z\n",
    "\n",
    "    def __initGamma(self):\n",
    "        with tf.name_scope(self.__nscope):\n",
    "            gamma = self.__inGamma\n",
    "            self.gamma = tf.constant(gamma, name='gamma')\n",
    "\n",
    "    def getHyperParams(self):\n",
    "        '''\n",
    "        Returns the model hyperparameters:\n",
    "            [inputDimension, projectionDimension,\n",
    "            numPrototypes, numOutputLabels, gamma]\n",
    "        '''\n",
    "        d = self.__d\n",
    "        dcap = self.__d_cap\n",
    "        m = self.__m\n",
    "        L = self.__L\n",
    "        return d, dcap, m, L, self.gamma\n",
    "\n",
    "    def getModelMatrices(self):\n",
    "        '''\n",
    "        Returns Tensorflow tensors of the model matrices, which\n",
    "        can then be evaluated to obtain corresponding numpy arrays.\n",
    "\n",
    "        These can then be exported as part of other implementations of\n",
    "        ProtonNN, for instance a C++ implementation or pure python\n",
    "        implementation.\n",
    "        Returns\n",
    "            [ProjectionMatrix (W), prototypeMatrix (B),\n",
    "             prototypeLabelsMatrix (Z), gamma]\n",
    "        '''\n",
    "        return self.W, self.B, self.Z, self.gamma\n",
    "\n",
    "    def __call__(self, X, Y=None):\n",
    "        '''\n",
    "        This method is responsible for construction of the forward computation\n",
    "        graph. The end point of the computation graph, or in other words the\n",
    "        output operator for the forward computation is returned. Additionally,\n",
    "        if the argument Y is provided, a classification accuracy operator with\n",
    "        Y as target will also be created. For this, Y is assumed to in one-hot\n",
    "        encoded format and the class with the maximum prediction score is\n",
    "        compared to the encoded class in Y.  This accuracy operator is returned\n",
    "        by getAccuracyOp() method. If a different accuracyOp is required, it\n",
    "        can be defined by overriding the createAccOp(protoNNScoresOut, Y)\n",
    "        method.\n",
    "\n",
    "        X: Input tensor or placeholder of shape [-1, inputDimension]\n",
    "        Y: Optional tensor or placeholder for targets (labels or classes).\n",
    "            Expected shape is [-1, numOutputLabels].\n",
    "        returns: The forward computation outputs, self.protoNNOut\n",
    "        '''\n",
    "        # This should never execute\n",
    "        assert self.__validInit is True, \"Initialization failed!\"\n",
    "        if self.protoNNOut is not None:\n",
    "            return self.protoNNOut\n",
    "\n",
    "        W, B, Z, gamma = self.W, self.B, self.Z, self.gamma\n",
    "        with tf.name_scope(self.__nscope):\n",
    "            WX = tf.matmul(X, W)\n",
    "            # Convert WX to tensor so that broadcasting can work\n",
    "            dim = [-1, WX.shape.as_list()[1], 1]\n",
    "            WX = tf.reshape(WX, dim)\n",
    "            dim = [1, B.shape.as_list()[0], -1]\n",
    "            B = tf.reshape(B, dim)\n",
    "            l2sim = B - WX\n",
    "            l2sim = tf.pow(l2sim, 2)\n",
    "            l2sim = tf.reduce_sum(l2sim, 1, keepdims=True)\n",
    "            self.l2sim = l2sim\n",
    "            gammal2sim = (-1 * gamma * gamma) * l2sim\n",
    "            M = tf.exp(gammal2sim)\n",
    "            dim = [1] + Z.shape.as_list()\n",
    "            Z = tf.reshape(Z, dim)\n",
    "            y = tf.multiply(Z, M)\n",
    "            y = tf.reduce_sum(y, 2, name='protoNNScoreOut')\n",
    "            self.protoNNOut = y\n",
    "            self.predictions = tf.argmax(y, 1, name='protoNNPredictions')\n",
    "            if Y is not None:\n",
    "                self.createAccOp(self.protoNNOut, Y)\n",
    "        return y\n",
    "\n",
    "    def createAccOp(self, outputs, target):\n",
    "        '''\n",
    "        Define an accuracy operation on ProtoNN's output scores and targets.\n",
    "        Here a simple classification accuracy operator is defined. More\n",
    "        complicated operators (for multiple label problems and so forth) can be\n",
    "        defined by overriding this method\n",
    "        '''\n",
    "        assert self.predictions is not None\n",
    "        target = tf.argmax(target, 1)\n",
    "        correctPrediction = tf.equal(self.predictions, target)\n",
    "        acc = tf.reduce_mean(tf.cast(correctPrediction, tf.float32),\n",
    "                             name='protoNNAccuracy')\n",
    "        self.accuracy = acc\n",
    "\n",
    "    def getPredictionsOp(self):\n",
    "        '''\n",
    "        The predictions operator is defined as argmax(protoNNScores) for each\n",
    "        prediction.\n",
    "        '''\n",
    "        return self.predictions\n",
    "\n",
    "    def getAccuracyOp(self):\n",
    "        '''\n",
    "        returns accuracyOp as defined by createAccOp. It defaults to\n",
    "        multi-class classification accuracy.\n",
    "        '''\n",
    "        msg = \"Accuracy operator not defined in graph. Did you provide Y as an\"\n",
    "        msg += \" argument to _call_?\"\n",
    "        assert self.accuracy is not None, msg\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEBMKewPQJ1c"
   },
   "source": [
    "# Obtain Data\n",
    "\n",
    "It is assumed that the Daphnet data has already been downloaded,preprocessed and set up in subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension:  423\n",
      "Num classes:  2\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"./experiments\"\n",
    "windowLen = 'data'\n",
    "out = preprocessData(DATA_DIR,windowLen)\n",
    "dataDimension = out[0]\n",
    "numClasses = out[1]\n",
    "x_train, y_train = out[2], out[3]\n",
    "x_test, y_test = out[4], out[5]\n",
    "print(\"Feature Dimension: \", dataDimension)\n",
    "print(\"Num classes: \", numClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"./experiments\"\n",
    "train, test = np.load(DATA_DIR + '/ttrain_data.npy'), np.load(DATA_DIR + '/ttest_data.npy')\n",
    "x_train, y_train = train[:, 1:], train[:, 0]\n",
    "x_test, y_test = test[:, 1:], test[:, 0]\n",
    "\n",
    "numClasses = max(y_train) - min(y_train) + 1\n",
    "numClasses = max(numClasses, max(y_test) - min(y_test) + 1)\n",
    "numClasses = int(numClasses)\n",
    "\n",
    "y_train = helper.to_onehot(y_train, numClasses)\n",
    "y_test = helper.to_onehot(y_test, numClasses)\n",
    "dataDimension = x_train.shape[1]\n",
    "numClasses = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1u6oX8eJQJ2N"
   },
   "source": [
    "# Model Parameters\n",
    "\n",
    "Note that ProtoNN is very sensitive to the value of the hyperparameter $\\gamma$, here stored in valiable `GAMMA`. If `GAMMA` is set to `None`, median heuristic will be used to estimate a good value of $\\gamma$ through the `helper.getGamma()` method. This method also returns the corresponding `W` and `B` matrices which should be used to initialize ProtoNN (as is done here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.279204Z",
     "start_time": "2018-08-15T13:06:10.272880Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UaduZ1vJQJ2P"
   },
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 5 #d^\n",
    "NUM_PROTOTYPES = 40 #m\n",
    "REG_W = 0.000005\n",
    "REG_B = 0.0\n",
    "REG_Z = 0.00005\n",
    "SPAR_W = 1.0\n",
    "SPAR_B = 0.8\n",
    "SPAR_Z = 0.8\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 600\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.007586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.307632Z",
     "start_time": "2018-08-15T13:06:10.280955Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1003,
     "status": "ok",
     "timestamp": 1567154485603,
     "user": {
      "displayName": "Gokul Hari",
      "photoUrl": "",
      "userId": "16159457985484250305"
     },
     "user_tz": -330
    },
    "id": "teqlUPhLQJ2W",
    "outputId": "e7e7f7f2-9ddb-448b-9539-65a1a2dc1c03"
   },
   "outputs": [],
   "source": [
    "W, B, gamma = getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from functools import partial\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "def objective(trial,x_train, x_test, y_train, y_test):\n",
    "    W, B, gamma = getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)\n",
    "    # Inside the optimization function, you use the 'trial' object to suggest hyperparameters\n",
    "    REG_W = trial.suggest_float('REG_W', 2e-6, 5e-6)\n",
    "    REG_B = trial.suggest_float('REG_B', 0.0, 0.01)\n",
    "    REG_Z = trial.suggest_float('REG_Z', 2e-5, 5e-5)\n",
    "    SPAR_W = trial.suggest_float('SPAR_W', 0.5, 1.0)\n",
    "    SPAR_B = trial.suggest_float('SPAR_B', 0.5, 1.0)\n",
    "    SPAR_Z = trial.suggest_float('SPAR_Z', 0.5, 1.0)\n",
    "    LEARNING_RATE = trial.suggest_float('LEARNING_RATE', 1e-4, 1e-3)\n",
    "    NUM_EPOCHS = trial.suggest_int('NUM_EPOCHS', 200, 600)\n",
    "\n",
    "    # Set the suggested hyperparameters in the trainer\n",
    "    protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                  NUM_PROTOTYPES, numClasses,\n",
    "                  gamma, W=W, B=B)\n",
    "    trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
    "                         SPAR_W, SPAR_B, SPAR_Z,\n",
    "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
    "    # Call your ProtoNN trainer function or use it as needed\n",
    "    sess = tf.Session()\n",
    "\n",
    "    trainer.train(BATCH_SIZE, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,printStep=600, valStep=10)\n",
    "    acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "    pred = sess.run(protoNN.predictions, feed_dict={X: x_test, Y: y_test})\n",
    "    # W, B, Z are tensorflow graph nodes\n",
    "    W, B, Z, _ = protoNN.getModelMatrices()\n",
    "    matrixList = sess.run([W, B, Z])\n",
    "    sparcityList = [SPAR_W, SPAR_B, SPAR_Z]                       \n",
    "    nnz, size, sparse = getModelSize(matrixList, sparcityList)\n",
    "    y_test = np.argmax(y_test,axis=1)\n",
    "    sensitivity = confusion_matrix(y_test,pred)[1][1]/(confusion_matrix(y_test,pred)[1][1] + confusion_matrix(y_test,pred)[1][0])\n",
    "    specificity = confusion_matrix(y_test,pred)[0][0]/(confusion_matrix(y_test,pred)[0][0] + confusion_matrix(y_test,pred)[0][1])\n",
    "    return (sensitivity+specificity)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:07:07,306] A new study created in memory with name: no-name-f0231465-89ff-4f90-a3ca-24098684743e\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='maximize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.28062 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.17970 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.15184 Accuracy: 1.00000\n",
      "Epoch:   3 Batch:   0 Loss: 0.37073 Accuracy: 1.00000\n",
      "Epoch:   4 Batch:   0 Loss: 0.87558 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.34357 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.64776 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.81831 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.90185 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.93356 Accuracy: 0.00000\n",
      "Test Loss: 1.09768 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.93526 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.92006 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.89471 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.86478 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.83123 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.79649 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.76071 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.72452 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.68781 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.65009 Accuracy: 0.00000\n",
      "Test Loss: 1.05141 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.61234 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.57452 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.53662 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.49732 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.45867 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.42035 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.38243 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.34454 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.30737 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.27098 Accuracy: 0.00000\n",
      "Test Loss: 0.98368 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.23564 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.20074 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.16755 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.13565 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.10509 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.07626 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.04877 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.02279 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.99875 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.97632 Accuracy: 0.00000\n",
      "Test Loss: 0.90796 Accuracy: 0.50050\n",
      "Epoch:  40 Batch:   0 Loss: 0.95565 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.93682 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.91958 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.90391 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.88970 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.87681 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.86523 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.85486 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.84561 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.83744 Accuracy: 0.00000\n",
      "Test Loss: 0.83978 Accuracy: 0.50060\n",
      "Epoch:  50 Batch:   0 Loss: 0.83029 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.82404 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.81865 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.81439 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.81081 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.80808 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.80595 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.80448 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.80333 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.80255 Accuracy: 0.00000\n",
      "Test Loss: 0.81086 Accuracy: 0.50060\n",
      "Epoch:  60 Batch:   0 Loss: 0.80198 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.80150 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.80119 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.80090 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.80051 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.80005 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.79955 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.79894 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.79825 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.79761 Accuracy: 0.00000\n",
      "Test Loss: 0.78821 Accuracy: 0.50060\n",
      "Epoch:  70 Batch:   0 Loss: 0.79693 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.79621 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.79554 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.79494 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.79433 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.79374 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.79316 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.79264 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.79217 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.79168 Accuracy: 0.00000\n",
      "Test Loss: 0.76919 Accuracy: 0.50060\n",
      "Epoch:  80 Batch:   0 Loss: 0.79128 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.79088 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.79051 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.79018 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.78983 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.78954 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.78925 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.78897 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.78869 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.78842 Accuracy: 0.00000\n",
      "Test Loss: 0.75474 Accuracy: 0.50060\n",
      "Epoch:  90 Batch:   0 Loss: 0.78815 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.78786 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.78755 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.78724 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.78689 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.78656 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.78622 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.78584 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.78544 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.78503 Accuracy: 0.00000\n",
      "Test Loss: 0.74278 Accuracy: 0.50070\n",
      "Epoch: 100 Batch:   0 Loss: 0.78462 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.78420 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.78376 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.78330 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.78285 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.78240 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.78194 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.78147 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.78099 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.78052 Accuracy: 0.00000\n",
      "Test Loss: 0.73253 Accuracy: 0.50070\n",
      "Epoch: 110 Batch:   0 Loss: 0.78005 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.77961 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.77917 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.77874 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.77834 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.77795 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.77760 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.77724 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.77689 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.77655 Accuracy: 0.00000\n",
      "Test Loss: 0.72402 Accuracy: 0.50070\n",
      "Epoch: 120 Batch:   0 Loss: 0.77623 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.77592 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.77561 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77532 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77505 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77479 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.77455 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.77431 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.77409 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.77391 Accuracy: 0.00000\n",
      "Test Loss: 0.71704 Accuracy: 0.50070\n",
      "Epoch: 130 Batch:   0 Loss: 0.77372 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.77354 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77339 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77325 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77314 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77302 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77293 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77284 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77277 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77270 Accuracy: 0.00000\n",
      "Test Loss: 0.71130 Accuracy: 0.50070\n",
      "Epoch: 140 Batch:   0 Loss: 0.77266 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77262 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77260 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77258 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77259 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.77261 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.77264 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.77268 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.77272 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.77278 Accuracy: 0.00000\n",
      "Test Loss: 0.70668 Accuracy: 0.50070\n",
      "Epoch: 150 Batch:   0 Loss: 0.77285 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.77291 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.77298 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.77307 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.77315 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.77323 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.77332 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.77342 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.77352 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.77362 Accuracy: 0.00000\n",
      "Test Loss: 0.70282 Accuracy: 0.50070\n",
      "Epoch: 160 Batch:   0 Loss: 0.77373 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.77384 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.77396 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.77408 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.77420 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.77433 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.77445 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.77457 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.77469 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.77480 Accuracy: 0.00000\n",
      "Test Loss: 0.69949 Accuracy: 0.50070\n",
      "Epoch: 170 Batch:   0 Loss: 0.77491 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.77500 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.77508 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.77515 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.77518 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.77520 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.77519 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.77515 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.77509 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.77501 Accuracy: 0.00000\n",
      "Test Loss: 0.69616 Accuracy: 0.50070\n",
      "Epoch: 180 Batch:   0 Loss: 0.77490 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.77477 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.77464 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.77450 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.77435 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.77421 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.77407 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.77392 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.77378 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.77366 Accuracy: 0.00000\n",
      "Test Loss: 0.69286 Accuracy: 0.50070\n",
      "Epoch: 190 Batch:   0 Loss: 0.77356 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.77346 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.77341 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.77337 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.77335 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.77335 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.77338 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.77343 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.77348 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.77356 Accuracy: 0.00000\n",
      "Test Loss: 0.69021 Accuracy: 0.50060\n",
      "Epoch: 200 Batch:   0 Loss: 0.77363 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.77372 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.77381 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.77388 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.77393 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.77395 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.77392 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.77385 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.77374 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.77359 Accuracy: 0.00000\n",
      "Test Loss: 0.68769 Accuracy: 0.50060\n",
      "Epoch: 210 Batch:   0 Loss: 0.77341 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.77320 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.77297 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.77273 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.77248 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.77223 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.77198 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.77174 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.77150 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.77127 Accuracy: 0.00000\n",
      "Test Loss: 0.68550 Accuracy: 0.50060\n",
      "Epoch: 220 Batch:   0 Loss: 0.77104 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.77082 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.77060 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.77038 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.77015 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.76992 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.76967 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.76942 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.76915 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.76886 Accuracy: 0.00000\n",
      "Test Loss: 0.68401 Accuracy: 0.50070\n",
      "Epoch: 230 Batch:   0 Loss: 0.76856 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.76825 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.76792 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.76758 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.76724 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.76689 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.76653 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.76618 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.76583 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.76548 Accuracy: 0.00000\n",
      "Test Loss: 0.68289 Accuracy: 0.50070\n",
      "Epoch: 240 Batch:   0 Loss: 0.76513 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.76479 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.76446 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.76415 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.76384 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.76353 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.76323 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.76295 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.76267 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.76240 Accuracy: 0.00000\n",
      "Test Loss: 0.68237 Accuracy: 0.50070\n",
      "Epoch: 250 Batch:   0 Loss: 0.76215 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.76165 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.76120 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.76098 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.76077 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.76057 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.76037 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.76018 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:09:24,795] Trial 0 finished with value: 0.5004020908725372 and parameters: {'REG_W': 3.810381964194984e-06, 'REG_B': 0.008502786220215441, 'REG_Z': 3.65253497805578e-05, 'SPAR_W': 0.8805874465018864, 'SPAR_B': 0.6587546957396175, 'SPAR_Z': 0.5053907565086231, 'LEARNING_RATE': 0.00040739436645659944, 'NUM_EPOCHS': 260}. Best is trial 0 with value: 0.5004020908725372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.68225 Accuracy: 0.50060\n",
      "Epoch:   0 Batch:   0 Loss: 1.30456 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 4.70260 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 3.37755 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 3.04379 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.93987 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.88502 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.83778 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.78877 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.73576 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.67984 Accuracy: 0.00000\n",
      "Test Loss: 1.41102 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.62035 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.55769 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.49231 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.42448 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.35303 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.28109 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.20536 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.12666 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.04657 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.96485 Accuracy: 0.00000\n",
      "Test Loss: 1.31299 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.88399 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.80384 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.72720 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.65099 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.57685 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.50619 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.43872 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.37456 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.31398 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.25702 Accuracy: 0.00000\n",
      "Test Loss: 1.19038 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.20350 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.15390 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.10866 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.06741 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.03065 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.99818 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.97017 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.94653 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.92615 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.90803 Accuracy: 0.00000\n",
      "Test Loss: 1.02350 Accuracy: 0.50050\n",
      "Epoch:  40 Batch:   0 Loss: 0.89117 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.87524 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.85996 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.84563 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.83267 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.82124 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.81150 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.80357 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.79691 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.79164 Accuracy: 0.00000\n",
      "Test Loss: 0.89033 Accuracy: 0.50060\n",
      "Epoch:  50 Batch:   0 Loss: 0.78760 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.78439 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.78169 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.77963 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.77803 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.77678 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.77580 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.77496 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.77421 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.77362 Accuracy: 0.00000\n",
      "Test Loss: 0.82476 Accuracy: 0.50060\n",
      "Epoch:  60 Batch:   0 Loss: 0.77310 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.77269 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.77240 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.77219 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.77201 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.77192 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.77180 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.77183 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.77190 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.77202 Accuracy: 0.00000\n",
      "Test Loss: 0.78649 Accuracy: 0.50060\n",
      "Epoch:  70 Batch:   0 Loss: 0.77212 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.77225 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.77237 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.77255 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.77273 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.77287 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.77303 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.77323 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.77345 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.77365 Accuracy: 0.00000\n",
      "Test Loss: 0.76188 Accuracy: 0.50060\n",
      "Epoch:  80 Batch:   0 Loss: 0.77382 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.77405 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.77430 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.77458 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.77485 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.77516 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.77547 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.77587 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.77620 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.77658 Accuracy: 0.00000\n",
      "Test Loss: 0.74494 Accuracy: 0.50060\n",
      "Epoch:  90 Batch:   0 Loss: 0.77702 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.77746 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.77789 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.77830 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.77876 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.77920 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.77958 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.77995 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.78020 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.78040 Accuracy: 0.00000\n",
      "Test Loss: 0.73048 Accuracy: 0.50060\n",
      "Epoch: 100 Batch:   0 Loss: 0.78058 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.78076 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.78093 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.78109 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.78121 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.78124 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.78112 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.78089 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.78053 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.78009 Accuracy: 0.00000\n",
      "Test Loss: 0.71685 Accuracy: 0.50040\n",
      "Epoch: 110 Batch:   0 Loss: 0.77962 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.77912 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.77863 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.77819 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.77776 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.77731 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.77683 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.77631 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.77573 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.77506 Accuracy: 0.00000\n",
      "Test Loss: 0.70753 Accuracy: 0.50040\n",
      "Epoch: 120 Batch:   0 Loss: 0.77431 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.77352 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.77268 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77183 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77096 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77010 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.76928 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.76848 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.76771 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.76696 Accuracy: 0.00000\n",
      "Test Loss: 0.70157 Accuracy: 0.50040\n",
      "Epoch: 130 Batch:   0 Loss: 0.76626 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.76556 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.76489 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.76423 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.76363 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.76306 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.76250 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.76197 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.76147 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.76101 Accuracy: 0.00000\n",
      "Test Loss: 0.69889 Accuracy: 0.50060\n",
      "Epoch: 140 Batch:   0 Loss: 0.76056 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.76014 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 142 Batch:   0 Loss: 0.75975 Accuracy: 0.00000\n",
      "Epoch: 143 Batch:   0 Loss: 0.75937 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.75900 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.75866 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.75833 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.75801 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.75771 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.75743 Accuracy: 0.00000\n",
      "Test Loss: 0.69773 Accuracy: 0.50060\n",
      "Epoch: 150 Batch:   0 Loss: 0.75716 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.75690 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.75665 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.75640 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.75616 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.75594 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.75572 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.75552 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.75531 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.75512 Accuracy: 0.00000\n",
      "Test Loss: 0.69764 Accuracy: 0.50060\n",
      "Epoch: 160 Batch:   0 Loss: 0.75492 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.75474 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.75457 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.75440 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.75423 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.75407 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.75391 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.75376 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.75359 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.75344 Accuracy: 0.00000\n",
      "Test Loss: 0.69816 Accuracy: 0.50060\n",
      "Epoch: 170 Batch:   0 Loss: 0.75329 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.75314 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.75299 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.75285 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.75271 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.75258 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.75245 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.75232 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.75219 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.75207 Accuracy: 0.00000\n",
      "Test Loss: 0.69912 Accuracy: 0.50060\n",
      "Epoch: 180 Batch:   0 Loss: 0.75194 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.75182 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.75169 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.75157 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.75145 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.75134 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.75122 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.75110 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.75098 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.75087 Accuracy: 0.00000\n",
      "Test Loss: 0.70048 Accuracy: 0.50060\n",
      "Epoch: 190 Batch:   0 Loss: 0.75075 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.75064 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.75053 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.75041 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.75030 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.75018 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.75007 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.74997 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.74986 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.74976 Accuracy: 0.00000\n",
      "Test Loss: 0.70215 Accuracy: 0.50060\n",
      "Epoch: 200 Batch:   0 Loss: 0.74966 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.74956 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.74947 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.74936 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.74926 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.74916 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.74906 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.74896 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.74887 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.74877 Accuracy: 0.00000\n",
      "Test Loss: 0.70415 Accuracy: 0.50060\n",
      "Epoch: 210 Batch:   0 Loss: 0.74867 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.74858 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.74849 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.74839 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.74830 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.74821 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.74812 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.74803 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.74795 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.74787 Accuracy: 0.00000\n",
      "Test Loss: 0.70650 Accuracy: 0.50060\n",
      "Epoch: 220 Batch:   0 Loss: 0.74779 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.74771 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.74763 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.74755 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.74747 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.74740 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.74732 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.74724 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.74716 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.74709 Accuracy: 0.00000\n",
      "Test Loss: 0.70902 Accuracy: 0.50060\n",
      "Epoch: 230 Batch:   0 Loss: 0.74701 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.74694 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.74688 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.74681 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.74674 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.74666 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.74659 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.74652 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.74646 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.74639 Accuracy: 0.00000\n",
      "Test Loss: 0.71176 Accuracy: 0.50060\n",
      "Epoch: 240 Batch:   0 Loss: 0.74633 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.74628 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.74621 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.74615 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.74608 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.74601 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.74594 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.74589 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.74584 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.74579 Accuracy: 0.00000\n",
      "Test Loss: 0.71468 Accuracy: 0.50060\n",
      "Epoch: 250 Batch:   0 Loss: 0.74574 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.74569 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.74564 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.74559 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.74554 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.74549 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.74544 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.74539 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.74535 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.74530 Accuracy: 0.00000\n",
      "Test Loss: 0.71766 Accuracy: 0.50060\n",
      "Epoch: 260 Batch:   0 Loss: 0.74525 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.74521 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.74516 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.74511 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.74507 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.74503 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.74499 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.74495 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.74491 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.74487 Accuracy: 0.00000\n",
      "Test Loss: 0.72081 Accuracy: 0.50060\n",
      "Epoch: 270 Batch:   0 Loss: 0.74484 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.74480 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.74476 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.74473 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.74470 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.74465 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.74462 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.74458 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.74455 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.74451 Accuracy: 0.00000\n",
      "Test Loss: 0.72409 Accuracy: 0.50060\n",
      "Epoch: 280 Batch:   0 Loss: 0.74447 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.74444 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.74440 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.74437 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.74434 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 285 Batch:   0 Loss: 0.74430 Accuracy: 0.00000\n",
      "Epoch: 286 Batch:   0 Loss: 0.74428 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.74425 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.74422 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.74419 Accuracy: 0.00000\n",
      "Test Loss: 0.72742 Accuracy: 0.50060\n",
      "Epoch: 290 Batch:   0 Loss: 0.74416 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.74413 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.74410 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.74407 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.74405 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.74402 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.74399 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.74396 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.74393 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.74391 Accuracy: 0.00000\n",
      "Test Loss: 0.73081 Accuracy: 0.50070\n",
      "Epoch: 300 Batch:   0 Loss: 0.74388 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.74385 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.74383 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.74380 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.74377 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.74374 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.74372 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.74369 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.74367 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.74364 Accuracy: 0.00000\n",
      "Test Loss: 0.73431 Accuracy: 0.50070\n",
      "Epoch: 310 Batch:   0 Loss: 0.74362 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.74360 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.74357 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.74354 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.74352 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.74350 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.74348 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.74345 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.74343 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.74341 Accuracy: 0.00000\n",
      "Test Loss: 0.73784 Accuracy: 0.50070\n",
      "Epoch: 320 Batch:   0 Loss: 0.74338 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.74336 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.74333 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.74331 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.74330 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.74328 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.74326 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.74324 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.74322 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.74320 Accuracy: 0.00000\n",
      "Test Loss: 0.74134 Accuracy: 0.50070\n",
      "Epoch: 330 Batch:   0 Loss: 0.74319 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.74317 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.74316 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.74314 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.74312 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.74311 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.74309 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.74308 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.74306 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.74305 Accuracy: 0.00000\n",
      "Test Loss: 0.74481 Accuracy: 0.50070\n",
      "Epoch: 340 Batch:   0 Loss: 0.74303 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.74302 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.74301 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.74299 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.74298 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.74297 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.74296 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.74295 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.74295 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.74294 Accuracy: 0.00000\n",
      "Test Loss: 0.74830 Accuracy: 0.50070\n",
      "Epoch: 350 Batch:   0 Loss: 0.74293 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.74293 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.74291 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.74290 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.74289 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.74289 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.74288 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.74287 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.74287 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.74286 Accuracy: 0.00000\n",
      "Test Loss: 0.75185 Accuracy: 0.50080\n",
      "Epoch: 360 Batch:   0 Loss: 0.74285 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.74284 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.74283 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.74282 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.74281 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.74280 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.74280 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.74279 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.74278 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.74278 Accuracy: 0.00000\n",
      "Test Loss: 0.75540 Accuracy: 0.50080\n",
      "Epoch: 370 Batch:   0 Loss: 0.74277 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.74276 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.74275 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.74274 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.74273 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.74272 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.74272 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.74271 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.74270 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.74271 Accuracy: 0.00000\n",
      "Test Loss: 0.75911 Accuracy: 0.50080\n",
      "Epoch: 380 Batch:   0 Loss: 0.74270 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.74269 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.74267 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.74266 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.74265 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.74264 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.74263 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.74264 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.74261 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.74260 Accuracy: 0.00000\n",
      "Test Loss: 0.76286 Accuracy: 0.50080\n",
      "Epoch: 390 Batch:   0 Loss: 0.74261 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.74258 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.74256 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.74255 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.74254 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.74253 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.74256 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.74253 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.74251 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.74249 Accuracy: 0.00000\n",
      "Test Loss: 0.76598 Accuracy: 0.50080\n",
      "Epoch: 400 Batch:   0 Loss: 0.74248 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.74247 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.74246 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.74245 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.74245 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.74244 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.74243 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.74242 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.74241 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.74240 Accuracy: 0.00000\n",
      "Test Loss: 0.76918 Accuracy: 0.50080\n",
      "Epoch: 410 Batch:   0 Loss: 0.74239 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.74239 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.74238 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.74237 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.74236 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.74235 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.74234 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.74233 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.74231 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.74230 Accuracy: 0.00000\n",
      "Test Loss: 0.77235 Accuracy: 0.50080\n",
      "Epoch: 420 Batch:   0 Loss: 0.74229 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.74229 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.74228 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.74226 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.74226 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.74224 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.74223 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.74222 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 428 Batch:   0 Loss: 0.74221 Accuracy: 0.00000\n",
      "Epoch: 429 Batch:   0 Loss: 0.74220 Accuracy: 0.00000\n",
      "Test Loss: 0.77548 Accuracy: 0.50080\n",
      "Epoch: 430 Batch:   0 Loss: 0.74219 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.74218 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.74217 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.74216 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.74214 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.74213 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.74212 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.74210 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.74209 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.74208 Accuracy: 0.00000\n",
      "Test Loss: 0.77850 Accuracy: 0.50080\n",
      "Epoch: 440 Batch:   0 Loss: 0.74207 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.74205 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.74204 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.74203 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.74202 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.74201 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.74200 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.74199 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.74198 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.74197 Accuracy: 0.00000\n",
      "Test Loss: 0.78147 Accuracy: 0.50080\n",
      "Epoch: 450 Batch:   0 Loss: 0.74196 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.74195 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.74195 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.74194 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.74193 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.74192 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.74191 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.74190 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.74190 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.74189 Accuracy: 0.00000\n",
      "Test Loss: 0.78441 Accuracy: 0.50080\n",
      "Epoch: 460 Batch:   0 Loss: 0.74188 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.74188 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.74187 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.74186 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.74185 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.74185 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.74184 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.74183 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.74183 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.74182 Accuracy: 0.00000\n",
      "Test Loss: 0.78730 Accuracy: 0.50080\n",
      "Epoch: 470 Batch:   0 Loss: 0.74182 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.74181 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.74181 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.74180 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.74180 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.74179 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.74178 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.74177 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.74176 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.74176 Accuracy: 0.00000\n",
      "Test Loss: 0.79021 Accuracy: 0.50080\n",
      "Epoch: 480 Batch:   0 Loss: 0.74175 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.74174 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.74174 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.74173 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.74173 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.74172 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.74171 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.74171 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.74170 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.74169 Accuracy: 0.00000\n",
      "Test Loss: 0.79304 Accuracy: 0.50080\n",
      "Epoch: 490 Batch:   0 Loss: 0.74169 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.74168 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.74167 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.74167 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.74167 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.74166 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.74165 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.74165 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.74164 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.74164 Accuracy: 0.00000\n",
      "Test Loss: 0.79578 Accuracy: 0.50080\n",
      "Epoch: 500 Batch:   0 Loss: 0.74163 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.74162 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.74162 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.74161 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.74161 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.74160 Accuracy: 0.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.74160 Accuracy: 0.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.74159 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.74159 Accuracy: 0.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.74158 Accuracy: 0.00000\n",
      "Test Loss: 0.79829 Accuracy: 0.50080\n",
      "Epoch: 510 Batch:   0 Loss: 0.74158 Accuracy: 0.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.74157 Accuracy: 0.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.74157 Accuracy: 0.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.74156 Accuracy: 0.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.74156 Accuracy: 0.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.74155 Accuracy: 0.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.74155 Accuracy: 0.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.74154 Accuracy: 0.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.74154 Accuracy: 0.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.74154 Accuracy: 0.00000\n",
      "Test Loss: 0.80076 Accuracy: 0.50080\n",
      "Epoch: 520 Batch:   0 Loss: 0.74153 Accuracy: 0.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.74153 Accuracy: 0.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.74153 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.74152 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.74152 Accuracy: 0.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.74152 Accuracy: 0.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.74152 Accuracy: 0.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.74151 Accuracy: 0.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.74151 Accuracy: 0.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.74151 Accuracy: 0.00000\n",
      "Test Loss: 0.80312 Accuracy: 0.50080\n",
      "Epoch: 530 Batch:   0 Loss: 0.74151 Accuracy: 0.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.74150 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.74150 Accuracy: 0.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.74150 Accuracy: 0.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.74149 Accuracy: 0.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.74149 Accuracy: 0.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.74149 Accuracy: 0.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.74149 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:14:19,416] Trial 1 finished with value: 0.5006031363088058 and parameters: {'REG_W': 2.3889116573607026e-06, 'REG_B': 0.00276641635228956, 'REG_Z': 4.095409275748267e-05, 'SPAR_W': 0.8364205006053882, 'SPAR_B': 0.9623193240893757, 'SPAR_Z': 0.7706814875793248, 'LEARNING_RATE': 0.0006869908732317194, 'NUM_EPOCHS': 538}. Best is trial 1 with value: 0.5006031363088058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.09184 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.45713 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.75579 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.23665 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.37615 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.42436 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.44473 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.45385 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.45652 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.45470 Accuracy: 0.00000\n",
      "Test Loss: 1.15220 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.44929 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.44130 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.43106 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.41856 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.40382 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.38658 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.36713 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.34488 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.31973 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.29142 Accuracy: 0.00000\n",
      "Test Loss: 1.11228 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.25973 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.22480 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.18600 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.14328 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.09625 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 2.04579 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.99221 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.93557 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.87630 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.81509 Accuracy: 0.00000\n",
      "Test Loss: 1.04894 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.75211 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.68839 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.62449 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.56107 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.49852 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.43806 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.37982 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.32445 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.27189 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.22275 Accuracy: 0.00000\n",
      "Test Loss: 0.96407 Accuracy: 0.50040\n",
      "Epoch:  40 Batch:   0 Loss: 1.17707 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.13492 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.09649 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.06127 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.02937 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.00057 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.97470 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.95153 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.93091 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.91247 Accuracy: 0.00000\n",
      "Test Loss: 0.89155 Accuracy: 0.50040\n",
      "Epoch:  50 Batch:   0 Loss: 0.89593 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.88123 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.86806 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.85620 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.84558 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.83597 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.82718 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.81905 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.81158 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.80463 Accuracy: 0.00000\n",
      "Test Loss: 0.84443 Accuracy: 0.50070\n",
      "Epoch:  60 Batch:   0 Loss: 0.79833 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.79268 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.78764 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.78341 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.77990 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.77710 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.77506 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.77385 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.77322 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.77327 Accuracy: 0.00000\n",
      "Test Loss: 0.81341 Accuracy: 0.50080\n",
      "Epoch:  70 Batch:   0 Loss: 0.77381 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.77464 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.77580 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.77706 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.77833 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.77953 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.78060 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.78152 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.78232 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.78297 Accuracy: 0.00000\n",
      "Test Loss: 0.79365 Accuracy: 0.50080\n",
      "Epoch:  80 Batch:   0 Loss: 0.78346 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.78386 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.78417 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.78437 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.78454 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.78460 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.78461 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.78458 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.78454 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.78448 Accuracy: 0.00000\n",
      "Test Loss: 0.77195 Accuracy: 0.50080\n",
      "Epoch:  90 Batch:   0 Loss: 0.78440 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.78428 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.78414 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.78399 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.78382 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.78365 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.78349 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.78331 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.78316 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.78302 Accuracy: 0.00000\n",
      "Test Loss: 0.75490 Accuracy: 0.50080\n",
      "Epoch: 100 Batch:   0 Loss: 0.78286 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.78270 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.78254 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.78238 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.78224 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.78212 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.78199 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.78187 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.78175 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.78165 Accuracy: 0.00000\n",
      "Test Loss: 0.74163 Accuracy: 0.50080\n",
      "Epoch: 110 Batch:   0 Loss: 0.78153 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.78142 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.78133 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.78123 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.78113 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.78103 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.78094 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.78084 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.78073 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.78060 Accuracy: 0.00000\n",
      "Test Loss: 0.73111 Accuracy: 0.50090\n",
      "Epoch: 120 Batch:   0 Loss: 0.78047 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.78032 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.78016 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77997 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77977 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77956 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.77933 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.77906 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.77877 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.77847 Accuracy: 0.00000\n",
      "Test Loss: 0.72233 Accuracy: 0.50090\n",
      "Epoch: 130 Batch:   0 Loss: 0.77815 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.77782 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77746 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77709 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77672 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77633 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77593 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77553 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77513 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77474 Accuracy: 0.00000\n",
      "Test Loss: 0.71495 Accuracy: 0.50090\n",
      "Epoch: 140 Batch:   0 Loss: 0.77435 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77396 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77358 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77320 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77284 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.77249 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.77214 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.77181 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.77149 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.77119 Accuracy: 0.00000\n",
      "Test Loss: 0.70910 Accuracy: 0.50090\n",
      "Epoch: 150 Batch:   0 Loss: 0.77088 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.77059 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.77030 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.77003 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.76978 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.76953 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.76929 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.76907 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.76885 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.76864 Accuracy: 0.00000\n",
      "Test Loss: 0.70457 Accuracy: 0.50090\n",
      "Epoch: 160 Batch:   0 Loss: 0.76844 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.76824 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.76807 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.76790 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.76773 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.76758 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.76743 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.76729 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.76717 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.76703 Accuracy: 0.00000\n",
      "Test Loss: 0.70081 Accuracy: 0.50090\n",
      "Epoch: 170 Batch:   0 Loss: 0.76691 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.76680 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.76669 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.76658 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.76647 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.76636 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.76625 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.76614 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.76604 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.76593 Accuracy: 0.00000\n",
      "Test Loss: 0.69707 Accuracy: 0.50090\n",
      "Epoch: 180 Batch:   0 Loss: 0.76580 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.76569 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.76556 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.76543 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.76528 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.76514 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.76499 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.76484 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.76469 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.76454 Accuracy: 0.00000\n",
      "Test Loss: 0.69306 Accuracy: 0.50090\n",
      "Epoch: 190 Batch:   0 Loss: 0.76438 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.76423 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.76407 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.76391 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.76375 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.76359 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.76343 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.76327 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.76312 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.76297 Accuracy: 0.00000\n",
      "Test Loss: 0.68943 Accuracy: 0.50080\n",
      "Epoch: 200 Batch:   0 Loss: 0.76282 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.76267 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.76252 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.76237 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.76223 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.76209 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.76196 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.76184 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.76172 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.76160 Accuracy: 0.00000\n",
      "Test Loss: 0.68636 Accuracy: 0.50080\n",
      "Epoch: 210 Batch:   0 Loss: 0.76149 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.76139 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.76129 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.76120 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.76110 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.76102 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.76095 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.76088 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.76081 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.76075 Accuracy: 0.00000\n",
      "Test Loss: 0.68372 Accuracy: 0.50090\n",
      "Epoch: 220 Batch:   0 Loss: 0.76069 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.76063 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.76056 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.76049 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.76039 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.76028 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.76015 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.76000 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.75983 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.75964 Accuracy: 0.00000\n",
      "Test Loss: 0.68152 Accuracy: 0.50090\n",
      "Epoch: 230 Batch:   0 Loss: 0.75943 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.75920 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.75895 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.75869 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.75841 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.75812 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.75780 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.75748 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.75715 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.75681 Accuracy: 0.00000\n",
      "Test Loss: 0.67976 Accuracy: 0.50090\n",
      "Epoch: 240 Batch:   0 Loss: 0.75647 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.75612 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.75577 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.75542 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.75507 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.75473 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.75438 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.75405 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.75372 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.75339 Accuracy: 0.00000\n",
      "Test Loss: 0.67890 Accuracy: 0.50090\n",
      "Epoch: 250 Batch:   0 Loss: 0.75308 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.75276 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.75246 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.75216 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.75187 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.75159 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.75131 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.75104 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.75079 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.75053 Accuracy: 0.00000\n",
      "Test Loss: 0.67879 Accuracy: 0.50090\n",
      "Epoch: 260 Batch:   0 Loss: 0.75028 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.75004 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.74981 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.74959 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.74938 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.74917 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.74897 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.74877 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.74859 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.74840 Accuracy: 0.00000\n",
      "Test Loss: 0.67912 Accuracy: 0.50100\n",
      "Epoch: 270 Batch:   0 Loss: 0.74823 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.74806 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.74790 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.74774 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.74759 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.74744 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.74730 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.74716 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.74702 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.74689 Accuracy: 0.00000\n",
      "Test Loss: 0.67969 Accuracy: 0.50100\n",
      "Epoch: 280 Batch:   0 Loss: 0.74676 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.74664 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.74652 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.74640 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.74629 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.74618 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.74607 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.74597 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.74587 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.74576 Accuracy: 0.00000\n",
      "Test Loss: 0.68045 Accuracy: 0.50100\n",
      "Epoch: 290 Batch:   0 Loss: 0.74566 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.74557 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.74547 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.74538 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.74528 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.74520 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.74511 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.74502 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.74494 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.74486 Accuracy: 0.00000\n",
      "Test Loss: 0.68131 Accuracy: 0.50100\n",
      "Epoch: 300 Batch:   0 Loss: 0.74478 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.74470 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.74463 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.74455 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.74448 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.74440 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.74433 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.74426 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.74419 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.74413 Accuracy: 0.00000\n",
      "Test Loss: 0.68229 Accuracy: 0.50100\n",
      "Epoch: 310 Batch:   0 Loss: 0.74406 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.74400 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.74393 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.74387 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.74381 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.74375 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.74368 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.74362 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.74357 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.74351 Accuracy: 0.00000\n",
      "Test Loss: 0.68334 Accuracy: 0.50100\n",
      "Epoch: 320 Batch:   0 Loss: 0.74345 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.74339 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.74333 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.74327 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.74322 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.74316 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.74311 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.74306 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.74300 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.74295 Accuracy: 0.00000\n",
      "Test Loss: 0.68445 Accuracy: 0.50100\n",
      "Epoch: 330 Batch:   0 Loss: 0.74290 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.74285 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.74280 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.74275 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.74270 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.74265 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.74260 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.74255 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.74250 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.74245 Accuracy: 0.00000\n",
      "Test Loss: 0.68560 Accuracy: 0.50100\n",
      "Epoch: 340 Batch:   0 Loss: 0.74241 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.74236 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.74231 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.74226 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.74222 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.74217 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.74213 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.74208 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.74204 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.74199 Accuracy: 0.00000\n",
      "Test Loss: 0.68678 Accuracy: 0.50100\n",
      "Epoch: 350 Batch:   0 Loss: 0.74194 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.74190 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.74186 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.74181 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.74177 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.74173 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.74169 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.74165 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.74160 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.74156 Accuracy: 0.00000\n",
      "Test Loss: 0.68800 Accuracy: 0.50100\n",
      "Epoch: 360 Batch:   0 Loss: 0.74152 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.74148 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.74144 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.74140 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.74136 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.74132 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.74129 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.74125 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.74121 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.74117 Accuracy: 0.00000\n",
      "Test Loss: 0.68926 Accuracy: 0.50100\n",
      "Epoch: 370 Batch:   0 Loss: 0.74113 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.74110 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.74106 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.74102 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.74098 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.74095 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.74091 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.74087 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.74084 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.74080 Accuracy: 0.00000\n",
      "Test Loss: 0.69055 Accuracy: 0.50100\n",
      "Epoch: 380 Batch:   0 Loss: 0.74077 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.74073 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.74070 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.74066 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.74063 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.74059 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.74056 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.74052 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.74049 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.74046 Accuracy: 0.00000\n",
      "Test Loss: 0.69191 Accuracy: 0.50100\n",
      "Epoch: 390 Batch:   0 Loss: 0.74042 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.74039 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.74035 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.74032 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.74029 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.74026 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.74023 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.74020 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.74017 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.74014 Accuracy: 0.00000\n",
      "Test Loss: 0.69325 Accuracy: 0.50100\n",
      "Epoch: 400 Batch:   0 Loss: 0.74011 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.74008 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.74005 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.74002 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.73999 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.73996 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.73993 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.73990 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.73987 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.73984 Accuracy: 0.00000\n",
      "Test Loss: 0.69462 Accuracy: 0.50100\n",
      "Epoch: 410 Batch:   0 Loss: 0.73981 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.73978 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.73975 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.73973 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.73970 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.73967 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.73964 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.73961 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.73958 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.73955 Accuracy: 0.00000\n",
      "Test Loss: 0.69605 Accuracy: 0.50100\n",
      "Epoch: 420 Batch:   0 Loss: 0.73952 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.73949 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.73947 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.73944 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.73941 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.73938 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.73935 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.73933 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.73930 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.73927 Accuracy: 0.00000\n",
      "Test Loss: 0.69745 Accuracy: 0.50100\n",
      "Epoch: 430 Batch:   0 Loss: 0.73925 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.73922 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.73919 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.73917 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.73914 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.73911 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.73909 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.73906 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.73904 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.73901 Accuracy: 0.00000\n",
      "Test Loss: 0.69887 Accuracy: 0.50100\n",
      "Epoch: 440 Batch:   0 Loss: 0.73899 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.73896 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.73893 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.73891 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.73888 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.73886 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.73883 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.73881 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.73879 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.73876 Accuracy: 0.00000\n",
      "Test Loss: 0.70028 Accuracy: 0.50100\n",
      "Epoch: 450 Batch:   0 Loss: 0.73874 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.73872 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.73869 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.73867 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.73865 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.73863 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.73860 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.73858 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.73856 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.73854 Accuracy: 0.00000\n",
      "Test Loss: 0.70170 Accuracy: 0.50100\n",
      "Epoch: 460 Batch:   0 Loss: 0.73851 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.73849 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.73847 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.73845 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.73850 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.73843 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.73839 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.73835 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.73840 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.73833 Accuracy: 0.00000\n",
      "Test Loss: 0.70345 Accuracy: 0.50100\n",
      "Epoch: 470 Batch:   0 Loss: 0.73829 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.73825 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.73823 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.73820 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.73818 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.73816 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.73814 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.73812 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.73810 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.73808 Accuracy: 0.00000\n",
      "Test Loss: 0.70457 Accuracy: 0.50100\n",
      "Epoch: 480 Batch:   0 Loss: 0.73806 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.73804 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.73802 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.73800 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.73797 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.73795 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.73794 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.73792 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.73790 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.73788 Accuracy: 0.00000\n",
      "Test Loss: 0.70587 Accuracy: 0.50100\n",
      "Epoch: 490 Batch:   0 Loss: 0.73786 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.73784 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.73782 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.73780 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.73778 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.73776 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.73774 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.73772 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.73770 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.73768 Accuracy: 0.00000\n",
      "Test Loss: 0.70715 Accuracy: 0.50100\n",
      "Epoch: 500 Batch:   0 Loss: 0.73766 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.73764 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.73762 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.73760 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.73758 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.73756 Accuracy: 0.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.73754 Accuracy: 0.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.73752 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.73750 Accuracy: 0.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.73748 Accuracy: 0.00000\n",
      "Test Loss: 0.70845 Accuracy: 0.50100\n",
      "Epoch: 510 Batch:   0 Loss: 0.73746 Accuracy: 0.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.73745 Accuracy: 0.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.73743 Accuracy: 0.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.73741 Accuracy: 0.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.73739 Accuracy: 0.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.73737 Accuracy: 0.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.73736 Accuracy: 0.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.73734 Accuracy: 0.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.73732 Accuracy: 0.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.73730 Accuracy: 0.00000\n",
      "Test Loss: 0.70971 Accuracy: 0.50100\n",
      "Epoch: 520 Batch:   0 Loss: 0.73729 Accuracy: 0.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.73727 Accuracy: 0.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.73725 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.73723 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.73722 Accuracy: 0.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.73720 Accuracy: 0.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.73718 Accuracy: 0.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.73717 Accuracy: 0.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.73715 Accuracy: 0.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.73713 Accuracy: 0.00000\n",
      "Test Loss: 0.71096 Accuracy: 0.50100\n",
      "Epoch: 530 Batch:   0 Loss: 0.73712 Accuracy: 0.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.73710 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.73709 Accuracy: 0.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.73707 Accuracy: 0.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.73706 Accuracy: 0.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.73704 Accuracy: 0.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.73702 Accuracy: 0.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.73700 Accuracy: 0.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.73699 Accuracy: 0.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.73697 Accuracy: 0.00000\n",
      "Test Loss: 0.71218 Accuracy: 0.50100\n",
      "Epoch: 540 Batch:   0 Loss: 0.73696 Accuracy: 0.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.73694 Accuracy: 0.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.73693 Accuracy: 0.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.73692 Accuracy: 0.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.73690 Accuracy: 0.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.73688 Accuracy: 0.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.73687 Accuracy: 0.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.73685 Accuracy: 0.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.73684 Accuracy: 0.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.73683 Accuracy: 0.00000\n",
      "Test Loss: 0.71343 Accuracy: 0.50100\n",
      "Epoch: 550 Batch:   0 Loss: 0.73681 Accuracy: 0.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.73680 Accuracy: 0.00000\n",
      "Epoch: 552 Batch:   0 Loss: 0.73678 Accuracy: 0.00000\n",
      "Epoch: 553 Batch:   0 Loss: 0.73677 Accuracy: 0.00000\n",
      "Epoch: 554 Batch:   0 Loss: 0.73675 Accuracy: 0.00000\n",
      "Epoch: 555 Batch:   0 Loss: 0.73674 Accuracy: 0.00000\n",
      "Epoch: 556 Batch:   0 Loss: 0.73673 Accuracy: 0.00000\n",
      "Epoch: 557 Batch:   0 Loss: 0.73673 Accuracy: 0.00000\n",
      "Epoch: 558 Batch:   0 Loss: 0.73671 Accuracy: 0.00000\n",
      "Epoch: 559 Batch:   0 Loss: 0.73669 Accuracy: 0.00000\n",
      "Test Loss: 0.71467 Accuracy: 0.50111\n",
      "Epoch: 560 Batch:   0 Loss: 0.73667 Accuracy: 0.00000\n",
      "Epoch: 561 Batch:   0 Loss: 0.73666 Accuracy: 0.00000\n",
      "Epoch: 562 Batch:   0 Loss: 0.73665 Accuracy: 0.00000\n",
      "Epoch: 563 Batch:   0 Loss: 0.73663 Accuracy: 0.00000\n",
      "Epoch: 564 Batch:   0 Loss: 0.73662 Accuracy: 0.00000\n",
      "Epoch: 565 Batch:   0 Loss: 0.73661 Accuracy: 0.00000\n",
      "Epoch: 566 Batch:   0 Loss: 0.73660 Accuracy: 0.00000\n",
      "Epoch: 567 Batch:   0 Loss: 0.73658 Accuracy: 0.00000\n",
      "Epoch: 568 Batch:   0 Loss: 0.73657 Accuracy: 0.00000\n",
      "Epoch: 569 Batch:   0 Loss: 0.73656 Accuracy: 0.00000\n",
      "Test Loss: 0.71577 Accuracy: 0.50111\n",
      "Epoch: 570 Batch:   0 Loss: 0.73655 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 571 Batch:   0 Loss: 0.73653 Accuracy: 0.00000\n",
      "Epoch: 572 Batch:   0 Loss: 0.73652 Accuracy: 0.00000\n",
      "Epoch: 573 Batch:   0 Loss: 0.73651 Accuracy: 0.00000\n",
      "Epoch: 574 Batch:   0 Loss: 0.73651 Accuracy: 0.00000\n",
      "Epoch: 575 Batch:   0 Loss: 0.73649 Accuracy: 0.00000\n",
      "Epoch: 576 Batch:   0 Loss: 0.73648 Accuracy: 0.00000\n",
      "Epoch: 577 Batch:   0 Loss: 0.73647 Accuracy: 0.00000\n",
      "Epoch: 578 Batch:   0 Loss: 0.73646 Accuracy: 0.00000\n",
      "Epoch: 579 Batch:   0 Loss: 0.73645 Accuracy: 0.00000\n",
      "Test Loss: 0.71692 Accuracy: 0.50111\n",
      "Epoch: 580 Batch:   0 Loss: 0.73644 Accuracy: 0.00000\n",
      "Epoch: 581 Batch:   0 Loss: 0.73643 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:22:38,343] Trial 2 finished with value: 0.5009047044632087 and parameters: {'REG_W': 2.3811746750267102e-06, 'REG_B': 0.002946692532198456, 'REG_Z': 4.828542175111063e-05, 'SPAR_W': 0.953388755074015, 'SPAR_B': 0.7181145448240711, 'SPAR_Z': 0.8185762503600094, 'LEARNING_RATE': 0.00048259573711175347, 'NUM_EPOCHS': 582}. Best is trial 2 with value: 0.5009047044632087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.20565 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 3.78336 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 3.03371 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.78009 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.71030 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.70523 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.71731 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.72878 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.73408 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.73241 Accuracy: 0.00000\n",
      "Test Loss: 1.42221 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.72461 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.71158 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.69480 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.67436 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.65119 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.62527 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.59770 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.56775 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.53451 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.50013 Accuracy: 0.00000\n",
      "Test Loss: 1.41174 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.46317 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.42359 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.38149 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.33881 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.29224 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 2.24339 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 2.19273 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 2.13914 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 2.08362 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 2.02698 Accuracy: 0.00000\n",
      "Test Loss: 1.35878 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.97077 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.91191 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.85207 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.79125 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.72892 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.66770 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.60642 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.54682 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.48728 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.42892 Accuracy: 0.00000\n",
      "Test Loss: 1.26056 Accuracy: 0.50030\n",
      "Epoch:  40 Batch:   0 Loss: 1.37111 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.31679 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.26250 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.21014 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.16081 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.11552 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.07345 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.03372 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.99774 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.96558 Accuracy: 0.00000\n",
      "Test Loss: 1.11117 Accuracy: 0.50040\n",
      "Epoch:  50 Batch:   0 Loss: 0.93661 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.91115 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.88840 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.86868 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.85165 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.83646 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.82351 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.81219 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.80232 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.79387 Accuracy: 0.00000\n",
      "Test Loss: 0.98124 Accuracy: 0.50060\n",
      "Epoch:  60 Batch:   0 Loss: 0.78662 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.78032 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.77494 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.77031 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.76629 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.76293 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.76019 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.75796 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.75622 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.75490 Accuracy: 0.00000\n",
      "Test Loss: 0.89009 Accuracy: 0.50060\n",
      "Epoch:  70 Batch:   0 Loss: 0.75394 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.75349 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.75332 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.75329 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.75348 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.75385 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.75435 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.75491 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.75557 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.75632 Accuracy: 0.00000\n",
      "Test Loss: 0.84892 Accuracy: 0.50060\n",
      "Epoch:  80 Batch:   0 Loss: 0.75705 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.75778 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.75853 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.75923 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.75995 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.76065 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.76138 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.76201 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.76258 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.76314 Accuracy: 0.00000\n",
      "Test Loss: 0.81611 Accuracy: 0.50060\n",
      "Epoch:  90 Batch:   0 Loss: 0.76369 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.76419 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.76470 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.76517 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.76566 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.76604 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.76647 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.76680 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.76712 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.76741 Accuracy: 0.00000\n",
      "Test Loss: 0.79020 Accuracy: 0.50060\n",
      "Epoch: 100 Batch:   0 Loss: 0.76770 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.76798 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.76827 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.76856 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.76885 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.76914 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.76948 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.76978 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.77008 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.77035 Accuracy: 0.00000\n",
      "Test Loss: 0.77283 Accuracy: 0.50060\n",
      "Epoch: 110 Batch:   0 Loss: 0.77060 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.77087 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.77109 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.77137 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.77159 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.77179 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.77200 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.77216 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.77232 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.77244 Accuracy: 0.00000\n",
      "Test Loss: 0.76107 Accuracy: 0.50060\n",
      "Epoch: 120 Batch:   0 Loss: 0.77255 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.77264 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.77273 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77280 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77292 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77302 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.77304 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.77310 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.77314 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.77316 Accuracy: 0.00000\n",
      "Test Loss: 0.75309 Accuracy: 0.50060\n",
      "Epoch: 130 Batch:   0 Loss: 0.77316 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.77313 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77314 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77302 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77290 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77282 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77265 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77251 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77238 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77222 Accuracy: 0.00000\n",
      "Test Loss: 0.74665 Accuracy: 0.50060\n",
      "Epoch: 140 Batch:   0 Loss: 0.77205 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77187 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77165 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77140 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77117 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.77094 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.77071 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.77048 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.77025 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.77005 Accuracy: 0.00000\n",
      "Test Loss: 0.74199 Accuracy: 0.50060\n",
      "Epoch: 150 Batch:   0 Loss: 0.76986 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.76967 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.76949 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.76930 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.76915 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.76899 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.76882 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.76864 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.76848 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.76832 Accuracy: 0.00000\n",
      "Test Loss: 0.73827 Accuracy: 0.50060\n",
      "Epoch: 160 Batch:   0 Loss: 0.76817 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.76798 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.76781 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.76766 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.76751 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.76737 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.76721 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.76703 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.76689 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.76676 Accuracy: 0.00000\n",
      "Test Loss: 0.73519 Accuracy: 0.50060\n",
      "Epoch: 170 Batch:   0 Loss: 0.76663 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.76652 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.76638 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.76625 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.76612 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.76598 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.76585 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.76572 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.76560 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.76548 Accuracy: 0.00000\n",
      "Test Loss: 0.73262 Accuracy: 0.50060\n",
      "Epoch: 180 Batch:   0 Loss: 0.76535 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.76522 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.76511 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.76499 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.76488 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.76476 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.76465 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.76453 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.76440 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.76429 Accuracy: 0.00000\n",
      "Test Loss: 0.73052 Accuracy: 0.50060\n",
      "Epoch: 190 Batch:   0 Loss: 0.76417 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.76406 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.76394 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.76382 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.76370 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.76360 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.76349 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.76336 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.76323 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.76313 Accuracy: 0.00000\n",
      "Test Loss: 0.72874 Accuracy: 0.50060\n",
      "Epoch: 200 Batch:   0 Loss: 0.76303 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.76293 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.76283 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.76273 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.76264 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.76256 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.76246 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.76238 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.76228 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.76222 Accuracy: 0.00000\n",
      "Test Loss: 0.72706 Accuracy: 0.50060\n",
      "Epoch: 210 Batch:   0 Loss: 0.76214 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.76207 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.76199 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:25:42,449] Trial 3 finished with value: 0.5004020908725372 and parameters: {'REG_W': 2.5413170126742132e-06, 'REG_B': 0.006482346810895375, 'REG_Z': 3.838850424544486e-05, 'SPAR_W': 0.5495479131542118, 'SPAR_B': 0.7076576660375489, 'SPAR_Z': 0.56169644186905, 'LEARNING_RATE': 0.0006389569712456179, 'NUM_EPOCHS': 213}. Best is trial 2 with value: 0.5009047044632087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.12429 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.08299 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.09090 Accuracy: 1.00000\n",
      "Epoch:   3 Batch:   0 Loss: 0.34594 Accuracy: 1.00000\n",
      "Epoch:   4 Batch:   0 Loss: 0.89466 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.37802 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.68166 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.85007 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.93602 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.97600 Accuracy: 0.00000\n",
      "Test Loss: 1.11332 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.99065 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.99188 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.98578 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.97543 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.96269 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.94865 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.93381 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.91830 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.90226 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.88572 Accuracy: 0.00000\n",
      "Test Loss: 1.10295 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.86874 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.85142 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.83312 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.81510 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.79635 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.77695 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.75756 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.73771 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.71744 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.69639 Accuracy: 0.00000\n",
      "Test Loss: 1.07361 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.67515 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.65377 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.63170 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.60932 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.58672 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.56390 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.54032 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.51682 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.49279 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.46843 Accuracy: 0.00000\n",
      "Test Loss: 1.04170 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.44415 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.42015 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.39645 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.37273 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.34915 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.32550 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.30177 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.27814 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.25524 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.23236 Accuracy: 0.00000\n",
      "Test Loss: 1.00450 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.20982 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.18725 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.16598 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.14507 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.12448 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.10444 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.08489 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.06600 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.04792 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.03042 Accuracy: 0.00000\n",
      "Test Loss: 0.96134 Accuracy: 0.50040\n",
      "Epoch:  60 Batch:   0 Loss: 1.01356 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.99713 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.98134 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.96635 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.95197 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.93815 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.92512 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.91263 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.90068 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.88934 Accuracy: 0.00000\n",
      "Test Loss: 0.91983 Accuracy: 0.50060\n",
      "Epoch:  70 Batch:   0 Loss: 0.87858 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.86840 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.85896 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.84991 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.84157 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.83361 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.82616 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.81910 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.81248 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.80625 Accuracy: 0.00000\n",
      "Test Loss: 0.88892 Accuracy: 0.50060\n",
      "Epoch:  80 Batch:   0 Loss: 0.80041 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.79496 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.78982 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.78504 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.78062 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.77643 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.77262 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.76908 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.76574 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.76273 Accuracy: 0.00000\n",
      "Test Loss: 0.86347 Accuracy: 0.50060\n",
      "Epoch:  90 Batch:   0 Loss: 0.75996 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.75739 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.75501 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.75294 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.75105 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.74936 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.74794 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.74669 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.74565 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.74486 Accuracy: 0.00000\n",
      "Test Loss: 0.84157 Accuracy: 0.50060\n",
      "Epoch: 100 Batch:   0 Loss: 0.74420 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.74379 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.74354 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.74344 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.74347 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.74362 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.74383 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.74412 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.74448 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.74490 Accuracy: 0.00000\n",
      "Test Loss: 0.82973 Accuracy: 0.50060\n",
      "Epoch: 110 Batch:   0 Loss: 0.74536 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.74586 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.74639 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.74692 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.74748 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.74804 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.74859 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.74915 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.74972 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.75028 Accuracy: 0.00000\n",
      "Test Loss: 0.81465 Accuracy: 0.50070\n",
      "Epoch: 120 Batch:   0 Loss: 0.75086 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.75146 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.75209 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.75267 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.75325 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.75380 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.75435 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.75491 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.75540 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.75592 Accuracy: 0.00000\n",
      "Test Loss: 0.79827 Accuracy: 0.50070\n",
      "Epoch: 130 Batch:   0 Loss: 0.75645 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.75697 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.75749 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.75800 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.75854 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.75909 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.75966 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.76022 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.76081 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.76135 Accuracy: 0.00000\n",
      "Test Loss: 0.78391 Accuracy: 0.50070\n",
      "Epoch: 140 Batch:   0 Loss: 0.76189 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.76244 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.76298 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.76358 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.76415 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.76470 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.76529 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.76585 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.76642 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.76700 Accuracy: 0.00000\n",
      "Test Loss: 0.77201 Accuracy: 0.50070\n",
      "Epoch: 150 Batch:   0 Loss: 0.76759 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.76818 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.76877 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.76937 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.76997 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.77055 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.77113 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.77170 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.77228 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.77286 Accuracy: 0.00000\n",
      "Test Loss: 0.76189 Accuracy: 0.50070\n",
      "Epoch: 160 Batch:   0 Loss: 0.77343 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.77400 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.77456 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.77513 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.77570 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.77625 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.77678 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.77731 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.77784 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.77835 Accuracy: 0.00000\n",
      "Test Loss: 0.75315 Accuracy: 0.50070\n",
      "Epoch: 170 Batch:   0 Loss: 0.77886 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.77936 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.77984 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.78032 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.78079 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.78125 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.78168 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.78212 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.78254 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.78296 Accuracy: 0.00000\n",
      "Test Loss: 0.74528 Accuracy: 0.50070\n",
      "Epoch: 180 Batch:   0 Loss: 0.78331 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.78365 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.78397 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.78426 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.78453 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.78479 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.78504 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.78527 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.78548 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.78567 Accuracy: 0.00000\n",
      "Test Loss: 0.73830 Accuracy: 0.50070\n",
      "Epoch: 190 Batch:   0 Loss: 0.78585 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.78600 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.78609 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.78617 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.78624 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.78627 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.78629 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.78626 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.78622 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.78613 Accuracy: 0.00000\n",
      "Test Loss: 0.73192 Accuracy: 0.50080\n",
      "Epoch: 200 Batch:   0 Loss: 0.78596 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.78579 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.78560 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.78538 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.78516 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.78494 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.78472 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.78448 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.78427 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.78409 Accuracy: 0.00000\n",
      "Test Loss: 0.72612 Accuracy: 0.50080\n",
      "Epoch: 210 Batch:   0 Loss: 0.78384 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.78358 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.78333 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.78307 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.78276 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.78247 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.78217 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.78187 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.78158 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.78128 Accuracy: 0.00000\n",
      "Test Loss: 0.72081 Accuracy: 0.50080\n",
      "Epoch: 220 Batch:   0 Loss: 0.78099 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.78070 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.78038 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.78007 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.77977 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.77942 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.77907 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.77873 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.77838 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.77802 Accuracy: 0.00000\n",
      "Test Loss: 0.71612 Accuracy: 0.50080\n",
      "Epoch: 230 Batch:   0 Loss: 0.77768 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.77736 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.77704 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.77673 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.77641 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.77608 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.77575 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.77544 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.77513 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.77482 Accuracy: 0.00000\n",
      "Test Loss: 0.71209 Accuracy: 0.50080\n",
      "Epoch: 240 Batch:   0 Loss: 0.77455 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.77428 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.77400 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.77376 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.77349 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.77323 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.77298 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.77273 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.77248 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.77223 Accuracy: 0.00000\n",
      "Test Loss: 0.70861 Accuracy: 0.50090\n",
      "Epoch: 250 Batch:   0 Loss: 0.77199 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.77173 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.77151 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.77127 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.77104 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.77082 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.77060 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.77038 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.77017 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.76996 Accuracy: 0.00000\n",
      "Test Loss: 0.70556 Accuracy: 0.50090\n",
      "Epoch: 260 Batch:   0 Loss: 0.76975 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.76955 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.76934 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.76914 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.76895 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.76878 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.76860 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.76844 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.76826 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.76809 Accuracy: 0.00000\n",
      "Test Loss: 0.70299 Accuracy: 0.50090\n",
      "Epoch: 270 Batch:   0 Loss: 0.76792 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.76775 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.76758 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.76743 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.76728 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.76712 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.76697 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.76682 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.76667 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.76653 Accuracy: 0.00000\n",
      "Test Loss: 0.70082 Accuracy: 0.50090\n",
      "Epoch: 280 Batch:   0 Loss: 0.76639 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.76625 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.76611 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.76597 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.76582 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.76567 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.76553 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.76538 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.76523 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.76508 Accuracy: 0.00000\n",
      "Test Loss: 0.69891 Accuracy: 0.50090\n",
      "Epoch: 290 Batch:   0 Loss: 0.76493 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.76478 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.76462 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.76447 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.76432 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.76417 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.76402 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.76386 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.76370 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.76354 Accuracy: 0.00000\n",
      "Test Loss: 0.69733 Accuracy: 0.50090\n",
      "Epoch: 300 Batch:   0 Loss: 0.76339 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.76323 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.76308 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.76293 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.76279 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.76264 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.76250 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.76234 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.76220 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.76205 Accuracy: 0.00000\n",
      "Test Loss: 0.69602 Accuracy: 0.50090\n",
      "Epoch: 310 Batch:   0 Loss: 0.76191 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.76176 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.76163 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.76149 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.76136 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.76123 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.76111 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.76099 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.76087 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.76075 Accuracy: 0.00000\n",
      "Test Loss: 0.69497 Accuracy: 0.50090\n",
      "Epoch: 320 Batch:   0 Loss: 0.76063 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.76051 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.76038 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.76026 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.76013 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.76001 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.75990 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.75978 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.75966 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.75953 Accuracy: 0.00000\n",
      "Test Loss: 0.69427 Accuracy: 0.50090\n",
      "Epoch: 330 Batch:   0 Loss: 0.75941 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.75928 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.75916 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.75904 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.75892 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.75880 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.75869 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.75857 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.75846 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.75835 Accuracy: 0.00000\n",
      "Test Loss: 0.69378 Accuracy: 0.50090\n",
      "Epoch: 340 Batch:   0 Loss: 0.75823 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.75814 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.75802 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.75791 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.75780 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.75770 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.75760 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.75749 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.75739 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.75729 Accuracy: 0.00000\n",
      "Test Loss: 0.69348 Accuracy: 0.50090\n",
      "Epoch: 350 Batch:   0 Loss: 0.75719 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.75711 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.75703 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.75694 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.75685 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.75676 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.75667 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.75658 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.75649 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.75640 Accuracy: 0.00000\n",
      "Test Loss: 0.69347 Accuracy: 0.50090\n",
      "Epoch: 360 Batch:   0 Loss: 0.75630 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.75620 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.75610 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.75600 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.75590 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.75581 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.75571 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.75563 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.75554 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.75544 Accuracy: 0.00000\n",
      "Test Loss: 0.69352 Accuracy: 0.50090\n",
      "Epoch: 370 Batch:   0 Loss: 0.75535 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.75526 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.75517 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.75509 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.75499 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.75490 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.75481 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.75471 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.75462 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.75453 Accuracy: 0.00000\n",
      "Test Loss: 0.69366 Accuracy: 0.50090\n",
      "Epoch: 380 Batch:   0 Loss: 0.75445 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.75436 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.75428 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.75419 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.75411 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.75402 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.75394 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.75386 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.75378 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.75369 Accuracy: 0.00000\n",
      "Test Loss: 0.69389 Accuracy: 0.50090\n",
      "Epoch: 390 Batch:   0 Loss: 0.75362 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.75354 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.75346 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.75338 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.75330 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.75322 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.75314 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.75306 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.75298 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.75290 Accuracy: 0.00000\n",
      "Test Loss: 0.69425 Accuracy: 0.50090\n",
      "Epoch: 400 Batch:   0 Loss: 0.75281 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.75273 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.75265 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.75257 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.75249 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.75240 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.75232 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.75224 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.75216 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.75208 Accuracy: 0.00000\n",
      "Test Loss: 0.69461 Accuracy: 0.50090\n",
      "Epoch: 410 Batch:   0 Loss: 0.75200 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.75192 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.75183 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.75175 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.75168 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.75160 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.75152 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.75144 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.75136 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.75129 Accuracy: 0.00000\n",
      "Test Loss: 0.69509 Accuracy: 0.50080\n",
      "Epoch: 420 Batch:   0 Loss: 0.75121 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.75113 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.75106 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.75099 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.75091 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.75084 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.75077 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.75070 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.75063 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.75056 Accuracy: 0.00000\n",
      "Test Loss: 0.69560 Accuracy: 0.50080\n",
      "Epoch: 430 Batch:   0 Loss: 0.75049 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.75042 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.75035 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.75028 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.75021 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.75015 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.75008 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.75001 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.74995 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.74989 Accuracy: 0.00000\n",
      "Test Loss: 0.69620 Accuracy: 0.50080\n",
      "Epoch: 440 Batch:   0 Loss: 0.74983 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.74977 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.74973 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.74968 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.74963 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.74958 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.74953 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.74949 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.74945 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.74942 Accuracy: 0.00000\n",
      "Test Loss: 0.69684 Accuracy: 0.50080\n",
      "Epoch: 450 Batch:   0 Loss: 0.74938 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.74934 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.74931 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.74928 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.74925 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.74922 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.74919 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.74917 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.74915 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.74913 Accuracy: 0.00000\n",
      "Test Loss: 0.69741 Accuracy: 0.50080\n",
      "Epoch: 460 Batch:   0 Loss: 0.74911 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.74910 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.74908 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.74906 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.74905 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.74904 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.74903 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.74902 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.74901 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.74899 Accuracy: 0.00000\n",
      "Test Loss: 0.69779 Accuracy: 0.50080\n",
      "Epoch: 470 Batch:   0 Loss: 0.74898 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.74897 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.74895 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.74894 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.74891 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.74889 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.74886 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.74882 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.74878 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.74874 Accuracy: 0.00000\n",
      "Test Loss: 0.69766 Accuracy: 0.50080\n",
      "Epoch: 480 Batch:   0 Loss: 0.74870 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.74865 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.74860 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.74854 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.74848 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.74842 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.74836 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.74829 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.74822 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.74815 Accuracy: 0.00000\n",
      "Test Loss: 0.69713 Accuracy: 0.50080\n",
      "Epoch: 490 Batch:   0 Loss: 0.74808 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.74801 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.74794 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.74788 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.74782 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.74776 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.74770 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.74764 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.74758 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.74753 Accuracy: 0.00000\n",
      "Test Loss: 0.69639 Accuracy: 0.50080\n",
      "Epoch: 500 Batch:   0 Loss: 0.74748 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.74743 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.74738 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.74734 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.74731 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.74728 Accuracy: 0.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.74725 Accuracy: 0.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.74723 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.74721 Accuracy: 0.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.74720 Accuracy: 0.00000\n",
      "Test Loss: 0.69566 Accuracy: 0.50080\n",
      "Epoch: 510 Batch:   0 Loss: 0.74720 Accuracy: 0.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.74719 Accuracy: 0.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.74719 Accuracy: 0.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.74720 Accuracy: 0.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.74722 Accuracy: 0.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.74723 Accuracy: 0.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.74727 Accuracy: 0.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.74730 Accuracy: 0.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.74735 Accuracy: 0.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.74741 Accuracy: 0.00000\n",
      "Test Loss: 0.69452 Accuracy: 0.50070\n",
      "Epoch: 520 Batch:   0 Loss: 0.74748 Accuracy: 0.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.74757 Accuracy: 0.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.74766 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.74777 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.74790 Accuracy: 0.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.74803 Accuracy: 0.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.74816 Accuracy: 0.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.74831 Accuracy: 0.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.74847 Accuracy: 0.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.74863 Accuracy: 0.00000\n",
      "Test Loss: 0.69299 Accuracy: 0.50070\n",
      "Epoch: 530 Batch:   0 Loss: 0.74879 Accuracy: 0.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.74894 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.74908 Accuracy: 0.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.74920 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:33:55,791] Trial 4 finished with value: 0.5005026135906715 and parameters: {'REG_W': 2.106554995596043e-06, 'REG_B': 0.0035354041069576925, 'REG_Z': 4.577970493534107e-05, 'SPAR_W': 0.5637900188025731, 'SPAR_B': 0.6363861051363228, 'SPAR_Z': 0.5125862107227793, 'LEARNING_RATE': 0.00040531390559979413, 'NUM_EPOCHS': 534}. Best is trial 2 with value: 0.5009047044632087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 8.82441 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 3.40938 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.32924 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.08432 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.05501 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.07401 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.09765 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.11767 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.13282 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.14410 Accuracy: 0.00000\n",
      "Test Loss: 1.06641 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.15193 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.15684 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.15966 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.16079 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.16063 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.15937 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.15708 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.15389 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.14983 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.14495 Accuracy: 0.00000\n",
      "Test Loss: 1.06699 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.13923 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.13265 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.12486 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.11636 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.10651 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 2.09655 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 2.08546 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 2.07334 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 2.05964 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 2.04516 Accuracy: 0.00000\n",
      "Test Loss: 1.04707 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 2.02947 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 2.01242 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.99351 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.97309 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.95135 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.92760 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.90227 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.87478 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.84570 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.81405 Accuracy: 0.00000\n",
      "Test Loss: 1.01825 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.78091 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.74636 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.70971 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.67111 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.63122 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.59090 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.55032 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.50826 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.46592 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.42480 Accuracy: 0.00000\n",
      "Test Loss: 0.97405 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.38497 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.34594 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.30796 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.27168 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.23692 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.20431 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.17295 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.14364 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.11617 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.09079 Accuracy: 0.00000\n",
      "Test Loss: 0.91746 Accuracy: 0.50040\n",
      "Epoch:  60 Batch:   0 Loss: 1.06649 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.04380 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.02266 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.00277 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.98425 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.96725 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.95116 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.93669 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.92348 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.91148 Accuracy: 0.00000\n",
      "Test Loss: 0.85773 Accuracy: 0.50070\n",
      "Epoch:  70 Batch:   0 Loss: 0.90103 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.89175 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.88374 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.87679 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.87081 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.86587 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.86178 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.85829 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.85542 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.85323 Accuracy: 0.00000\n",
      "Test Loss: 0.82068 Accuracy: 0.50070\n",
      "Epoch:  80 Batch:   0 Loss: 0.85152 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.85023 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.84924 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.84852 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.84800 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.84753 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.84713 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.84683 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.84651 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.84614 Accuracy: 0.00000\n",
      "Test Loss: 0.79852 Accuracy: 0.50070\n",
      "Epoch:  90 Batch:   0 Loss: 0.84570 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.84521 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.84471 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.84407 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.84345 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.84279 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.84207 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.84123 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.84037 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.83948 Accuracy: 0.00000\n",
      "Test Loss: 0.77745 Accuracy: 0.50070\n",
      "Epoch: 100 Batch:   0 Loss: 0.83852 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.83754 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.83648 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.83545 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.83434 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.83322 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.83205 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.83086 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.82971 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.82862 Accuracy: 0.00000\n",
      "Test Loss: 0.75989 Accuracy: 0.50070\n",
      "Epoch: 110 Batch:   0 Loss: 0.82754 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.82645 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.82540 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.82436 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.82331 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.82231 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.82133 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.82034 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.81933 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.81832 Accuracy: 0.00000\n",
      "Test Loss: 0.74531 Accuracy: 0.50070\n",
      "Epoch: 120 Batch:   0 Loss: 0.81734 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.81640 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.81554 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.81470 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.81388 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.81307 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.81228 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.81149 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.81069 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.80989 Accuracy: 0.00000\n",
      "Test Loss: 0.73325 Accuracy: 0.50070\n",
      "Epoch: 130 Batch:   0 Loss: 0.80914 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.80841 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.80772 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.80706 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.80642 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.80579 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.80519 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.80460 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.80404 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.80350 Accuracy: 0.00000\n",
      "Test Loss: 0.72358 Accuracy: 0.50070\n",
      "Epoch: 140 Batch:   0 Loss: 0.80298 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.80249 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.80202 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.80158 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.80115 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.80074 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.80036 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.79999 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.79963 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.79929 Accuracy: 0.00000\n",
      "Test Loss: 0.71568 Accuracy: 0.50080\n",
      "Epoch: 150 Batch:   0 Loss: 0.79895 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.79867 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.79837 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.79809 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.79783 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.79760 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.79738 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.79717 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.79698 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.79680 Accuracy: 0.00000\n",
      "Test Loss: 0.70921 Accuracy: 0.50080\n",
      "Epoch: 160 Batch:   0 Loss: 0.79665 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.79651 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.79638 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.79629 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.79622 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.79616 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.79612 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.79609 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.79607 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.79606 Accuracy: 0.00000\n",
      "Test Loss: 0.70389 Accuracy: 0.50080\n",
      "Epoch: 170 Batch:   0 Loss: 0.79608 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.79615 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.79622 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.79629 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.79633 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.79639 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.79646 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.79652 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.79657 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.79660 Accuracy: 0.00000\n",
      "Test Loss: 0.69922 Accuracy: 0.50080\n",
      "Epoch: 180 Batch:   0 Loss: 0.79661 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.79659 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.79655 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.79649 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.79642 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.79633 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.79625 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.79615 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.79606 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.79596 Accuracy: 0.00000\n",
      "Test Loss: 0.69460 Accuracy: 0.50080\n",
      "Epoch: 190 Batch:   0 Loss: 0.79586 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.79571 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.79556 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.79543 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.79530 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.79516 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.79504 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.79490 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.79476 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.79463 Accuracy: 0.00000\n",
      "Test Loss: 0.69061 Accuracy: 0.50080\n",
      "Epoch: 200 Batch:   0 Loss: 0.79448 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.79432 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.79415 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.79398 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:37:08,848] Trial 5 finished with value: 0.5006031363088058 and parameters: {'REG_W': 2.0116378258662663e-06, 'REG_B': 0.004867608452905099, 'REG_Z': 4.359075766970931e-05, 'SPAR_W': 0.69839053336034, 'SPAR_B': 0.5014467537488719, 'SPAR_Z': 0.7461619806724386, 'LEARNING_RATE': 0.0003850109092687232, 'NUM_EPOCHS': 204}. Best is trial 2 with value: 0.5009047044632087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 14.61238 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 8.29134 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 3.19560 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.20260 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.11150 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.13666 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.16771 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.19142 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.20799 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.21890 Accuracy: 0.00000\n",
      "Test Loss: 1.10526 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.22530 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.22768 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.22660 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.22253 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.21582 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.20675 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.19556 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.18244 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.16727 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.15027 Accuracy: 0.00000\n",
      "Test Loss: 1.10938 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.13110 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.10973 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.08601 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.05979 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.03141 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 2.00097 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.96899 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.93416 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.89773 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.85999 Accuracy: 0.00000\n",
      "Test Loss: 1.07070 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.81991 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.77664 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.73216 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.68670 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.64020 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.59305 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.54551 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.49776 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.44984 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.40208 Accuracy: 0.00000\n",
      "Test Loss: 1.00178 Accuracy: 0.50040\n",
      "Epoch:  40 Batch:   0 Loss: 1.35452 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.30842 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.26444 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.22213 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.18209 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.14449 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.10856 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.07520 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.04425 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.01570 Accuracy: 0.00000\n",
      "Test Loss: 0.91734 Accuracy: 0.50050\n",
      "Epoch:  50 Batch:   0 Loss: 0.98990 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.96648 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.94530 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.92619 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.90911 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.89399 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.88108 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.86951 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.85970 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.85123 Accuracy: 0.00000\n",
      "Test Loss: 0.84375 Accuracy: 0.50060\n",
      "Epoch:  60 Batch:   0 Loss: 0.84411 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.83812 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.83325 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.82923 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.82606 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.82360 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.82165 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.81996 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.81858 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.81727 Accuracy: 0.00000\n",
      "Test Loss: 0.80184 Accuracy: 0.50070\n",
      "Epoch:  70 Batch:   0 Loss: 0.81625 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.81520 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.81434 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.81358 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.81281 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.81209 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.81151 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.81092 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.81031 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.80975 Accuracy: 0.00000\n",
      "Test Loss: 0.77112 Accuracy: 0.50070\n",
      "Epoch:  80 Batch:   0 Loss: 0.80926 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.80881 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.80835 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.80792 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.80743 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.80696 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.80656 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.80617 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.80581 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.80550 Accuracy: 0.00000\n",
      "Test Loss: 0.74973 Accuracy: 0.50080\n",
      "Epoch:  90 Batch:   0 Loss: 0.80526 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.80498 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.80481 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.80466 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.80459 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.80453 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.80447 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.80443 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.80442 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.80444 Accuracy: 0.00000\n",
      "Test Loss: 0.73484 Accuracy: 0.50080\n",
      "Epoch: 100 Batch:   0 Loss: 0.80447 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.80450 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.80453 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.80458 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.80461 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.80462 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.80466 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.80469 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.80469 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.80462 Accuracy: 0.00000\n",
      "Test Loss: 0.72400 Accuracy: 0.50080\n",
      "Epoch: 110 Batch:   0 Loss: 0.80464 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.80460 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.80457 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.80453 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.80446 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.80441 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.80432 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.80422 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.80413 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.80403 Accuracy: 0.00000\n",
      "Test Loss: 0.71543 Accuracy: 0.50070\n",
      "Epoch: 120 Batch:   0 Loss: 0.80391 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.80374 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.80360 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.80344 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.80328 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.80309 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.80291 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.80272 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.80255 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.80237 Accuracy: 0.00000\n",
      "Test Loss: 0.70834 Accuracy: 0.50070\n",
      "Epoch: 130 Batch:   0 Loss: 0.80220 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.80203 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.80186 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.80169 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.80152 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.80136 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.80119 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.80104 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.80087 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.80068 Accuracy: 0.00000\n",
      "Test Loss: 0.70231 Accuracy: 0.50070\n",
      "Epoch: 140 Batch:   0 Loss: 0.80050 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.80033 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.80015 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.79998 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.79982 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.79966 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.79948 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.79930 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.79914 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.79897 Accuracy: 0.00000\n",
      "Test Loss: 0.69714 Accuracy: 0.50070\n",
      "Epoch: 150 Batch:   0 Loss: 0.79880 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.79865 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.79850 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.79836 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.79824 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.79812 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.79801 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.79793 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.79785 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.79777 Accuracy: 0.00000\n",
      "Test Loss: 0.69255 Accuracy: 0.50070\n",
      "Epoch: 160 Batch:   0 Loss: 0.79769 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.79762 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.79754 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.79747 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.79739 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.79733 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.79727 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.79722 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.79716 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.79710 Accuracy: 0.00000\n",
      "Test Loss: 0.68859 Accuracy: 0.50070\n",
      "Epoch: 170 Batch:   0 Loss: 0.79704 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.79699 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.79694 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.79690 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.79687 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.79685 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.79683 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.79683 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.79684 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.79687 Accuracy: 0.00000\n",
      "Test Loss: 0.68514 Accuracy: 0.50070\n",
      "Epoch: 180 Batch:   0 Loss: 0.79690 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.79694 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.79700 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.79707 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.79716 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.79726 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.79737 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.79749 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.79764 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.79779 Accuracy: 0.00000\n",
      "Test Loss: 0.68222 Accuracy: 0.50070\n",
      "Epoch: 190 Batch:   0 Loss: 0.79796 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.79815 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.79837 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.79860 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.79885 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.79914 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.79945 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.79980 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.80018 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.80058 Accuracy: 0.00000\n",
      "Test Loss: 0.67983 Accuracy: 0.50080\n",
      "Epoch: 200 Batch:   0 Loss: 0.80101 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.80145 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.80192 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.80235 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.80276 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.80314 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.80347 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.80376 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.80396 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.80410 Accuracy: 0.00000\n",
      "Test Loss: 0.67754 Accuracy: 0.50080\n",
      "Epoch: 210 Batch:   0 Loss: 0.80415 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.80416 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.80411 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.80400 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.80384 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.80364 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.80341 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.80315 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.80284 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.80252 Accuracy: 0.00000\n",
      "Test Loss: 0.67501 Accuracy: 0.50090\n",
      "Epoch: 220 Batch:   0 Loss: 0.80215 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.80176 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.80137 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.80095 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.80055 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.80015 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.79974 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.79931 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.79889 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.79847 Accuracy: 0.00000\n",
      "Test Loss: 0.67293 Accuracy: 0.50090\n",
      "Epoch: 230 Batch:   0 Loss: 0.79805 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.79766 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.79724 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.79683 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.79643 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.79605 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.79568 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.79532 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.79498 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.79465 Accuracy: 0.00000\n",
      "Test Loss: 0.67129 Accuracy: 0.50090\n",
      "Epoch: 240 Batch:   0 Loss: 0.79434 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.79402 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.79372 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.79342 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.79313 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.79284 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.79256 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.79229 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.79202 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.79174 Accuracy: 0.00000\n",
      "Test Loss: 0.67004 Accuracy: 0.50090\n",
      "Epoch: 250 Batch:   0 Loss: 0.79147 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.79119 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.79090 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.79061 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.79034 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.79005 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.78976 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.78948 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.78921 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.78894 Accuracy: 0.00000\n",
      "Test Loss: 0.66888 Accuracy: 0.50090\n",
      "Epoch: 260 Batch:   0 Loss: 0.78869 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.78845 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.78824 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.78804 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.78785 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.78771 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.78760 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.78753 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.78750 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.78750 Accuracy: 0.00000\n",
      "Test Loss: 0.66817 Accuracy: 0.50090\n",
      "Epoch: 270 Batch:   0 Loss: 0.78753 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.78759 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.78766 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.78771 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.78775 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.78772 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.78763 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.78747 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.78721 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.78686 Accuracy: 0.00000\n",
      "Test Loss: 0.66761 Accuracy: 0.50090\n",
      "Epoch: 280 Batch:   0 Loss: 0.78646 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.78600 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.78550 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.78495 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.78438 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.78381 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.78323 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.78266 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.78209 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.78154 Accuracy: 0.00000\n",
      "Test Loss: 0.66690 Accuracy: 0.50090\n",
      "Epoch: 290 Batch:   0 Loss: 0.78101 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.78049 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.77998 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.77949 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.77901 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.77854 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.77808 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.77763 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.77720 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.77679 Accuracy: 0.00000\n",
      "Test Loss: 0.66672 Accuracy: 0.50090\n",
      "Epoch: 300 Batch:   0 Loss: 0.77638 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.77599 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.77562 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.77525 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.77489 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.77455 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.77422 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.77388 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.77356 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.77325 Accuracy: 0.00000\n",
      "Test Loss: 0.66687 Accuracy: 0.50090\n",
      "Epoch: 310 Batch:   0 Loss: 0.77294 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.77265 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.77237 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.77209 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.77183 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.77157 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.77131 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.77106 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.77082 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.77058 Accuracy: 0.00000\n",
      "Test Loss: 0.66735 Accuracy: 0.50060\n",
      "Epoch: 320 Batch:   0 Loss: 0.77035 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.77013 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.76991 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.76971 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.76951 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.76931 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.76913 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.76894 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.76877 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.76860 Accuracy: 0.00000\n",
      "Test Loss: 0.66802 Accuracy: 0.50060\n",
      "Epoch: 330 Batch:   0 Loss: 0.76846 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.76831 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.76818 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.76804 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.76791 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.76777 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.76764 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.76751 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.76738 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.76726 Accuracy: 0.00000\n",
      "Test Loss: 0.66887 Accuracy: 0.50060\n",
      "Epoch: 340 Batch:   0 Loss: 0.76714 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.76702 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:41:41,445] Trial 6 finished with value: 0.5004020908725372 and parameters: {'REG_W': 4.121217309324934e-06, 'REG_B': 0.008181582116268727, 'REG_Z': 2.371372933028167e-05, 'SPAR_W': 0.7798664321781542, 'SPAR_B': 0.5633915948914334, 'SPAR_Z': 0.877669365611784, 'LEARNING_RATE': 0.0004288571397523209, 'NUM_EPOCHS': 342}. Best is trial 2 with value: 0.5009047044632087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.11542 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.74523 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.79806 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 3.09930 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 3.18378 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 3.20157 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 3.19225 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 3.16788 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 3.13110 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 3.08805 Accuracy: 0.00000\n",
      "Test Loss: 1.57659 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 3.03720 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.97933 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.91423 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.84168 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.76352 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.67659 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.58036 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.47720 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.36964 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.25749 Accuracy: 0.00000\n",
      "Test Loss: 1.49914 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.14323 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.02562 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.90820 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.79501 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.68568 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.58138 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.48423 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.39245 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.30618 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.22712 Accuracy: 0.00000\n",
      "Test Loss: 1.31674 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.15523 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.09155 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.03507 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.98556 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.94367 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.90819 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.87885 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.85523 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.83613 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.82089 Accuracy: 0.00000\n",
      "Test Loss: 1.02631 Accuracy: 0.50050\n",
      "Epoch:  40 Batch:   0 Loss: 0.80833 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.79794 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.78903 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.78157 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.77558 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.77091 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.76749 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.76544 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.76455 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.76451 Accuracy: 0.00000\n",
      "Test Loss: 0.85848 Accuracy: 0.50060\n",
      "Epoch:  50 Batch:   0 Loss: 0.76520 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.76623 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.76760 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.76898 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.77034 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.77170 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.77295 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.77417 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.77529 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.77634 Accuracy: 0.00000\n",
      "Test Loss: 0.80694 Accuracy: 0.50050\n",
      "Epoch:  60 Batch:   0 Loss: 0.77723 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.77811 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.77888 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.77970 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.78035 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.78084 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.78130 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.78177 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.78211 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.78240 Accuracy: 0.00000\n",
      "Test Loss: 0.77672 Accuracy: 0.50060\n",
      "Epoch:  70 Batch:   0 Loss: 0.78263 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.78286 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.78298 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.78310 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.78317 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.78325 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.78326 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.78329 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.78329 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.78326 Accuracy: 0.00000\n",
      "Test Loss: 0.75462 Accuracy: 0.50060\n",
      "Epoch:  80 Batch:   0 Loss: 0.78323 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.78320 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.78316 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.78313 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.78312 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.78312 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.78314 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.78318 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.78327 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.78341 Accuracy: 0.00000\n",
      "Test Loss: 0.73848 Accuracy: 0.50060\n",
      "Epoch:  90 Batch:   0 Loss: 0.78356 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.78378 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.78402 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.78438 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.78476 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.78525 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.78585 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.78656 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.78735 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.78831 Accuracy: 0.00000\n",
      "Test Loss: 0.72663 Accuracy: 0.50060\n",
      "Epoch: 100 Batch:   0 Loss: 0.78941 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.79057 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.79176 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.79280 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.79364 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.79426 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.79471 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.79505 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.79525 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.79547 Accuracy: 0.00000\n",
      "Test Loss: 0.71545 Accuracy: 0.50060\n",
      "Epoch: 110 Batch:   0 Loss: 0.79577 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.79614 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.79651 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.79686 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.79709 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.79724 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.79718 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.79706 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.79671 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.79614 Accuracy: 0.00000\n",
      "Test Loss: 0.70558 Accuracy: 0.50060\n",
      "Epoch: 120 Batch:   0 Loss: 0.79546 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.79476 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.79406 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.79323 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.79239 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.79149 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.79052 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.78938 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.78820 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.78691 Accuracy: 0.00000\n",
      "Test Loss: 0.69871 Accuracy: 0.50040\n",
      "Epoch: 130 Batch:   0 Loss: 0.78562 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.78434 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.78306 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.78184 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.78066 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77952 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77845 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77745 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77650 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77559 Accuracy: 0.00000\n",
      "Test Loss: 0.69523 Accuracy: 0.50040\n",
      "Epoch: 140 Batch:   0 Loss: 0.77474 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77395 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77321 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77252 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77189 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.77131 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.77075 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.77023 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.76975 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.76929 Accuracy: 0.00000\n",
      "Test Loss: 0.69433 Accuracy: 0.50050\n",
      "Epoch: 150 Batch:   0 Loss: 0.76887 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.76844 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.76802 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.76764 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.76727 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.76690 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.76657 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.76624 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.76592 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.76564 Accuracy: 0.00000\n",
      "Test Loss: 0.69451 Accuracy: 0.50050\n",
      "Epoch: 160 Batch:   0 Loss: 0.76536 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.76509 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.76482 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.76457 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.76433 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.76408 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.76384 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.76361 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.76339 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.76318 Accuracy: 0.00000\n",
      "Test Loss: 0.69531 Accuracy: 0.50050\n",
      "Epoch: 170 Batch:   0 Loss: 0.76296 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.76277 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.76259 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.76242 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.76227 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.76212 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.76197 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.76182 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.76168 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.76153 Accuracy: 0.00000\n",
      "Test Loss: 0.69664 Accuracy: 0.50050\n",
      "Epoch: 180 Batch:   0 Loss: 0.76139 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.76126 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.76113 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.76100 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.76088 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.76075 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.76064 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.76053 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.76042 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.76032 Accuracy: 0.00000\n",
      "Test Loss: 0.69831 Accuracy: 0.50050\n",
      "Epoch: 190 Batch:   0 Loss: 0.76022 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.76012 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.76002 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.75993 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.75984 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.75974 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.75966 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.75957 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.75949 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.75941 Accuracy: 0.00000\n",
      "Test Loss: 0.70030 Accuracy: 0.50050\n",
      "Epoch: 200 Batch:   0 Loss: 0.75933 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.75926 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.75920 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.75915 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.75909 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.75903 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.75896 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.75889 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.75882 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.75876 Accuracy: 0.00000\n",
      "Test Loss: 0.70228 Accuracy: 0.50060\n",
      "Epoch: 210 Batch:   0 Loss: 0.75871 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.75865 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.75860 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.75855 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.75850 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.75844 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.75839 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.75834 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.75829 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.75825 Accuracy: 0.00000\n",
      "Test Loss: 0.70445 Accuracy: 0.50060\n",
      "Epoch: 220 Batch:   0 Loss: 0.75821 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.75816 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.75811 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.75807 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.75801 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.75796 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.75792 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.75789 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.75784 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.75780 Accuracy: 0.00000\n",
      "Test Loss: 0.70674 Accuracy: 0.50060\n",
      "Epoch: 230 Batch:   0 Loss: 0.75776 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.75772 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.75768 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.75764 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.75760 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.75755 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.75751 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.75746 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.75742 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.75738 Accuracy: 0.00000\n",
      "Test Loss: 0.70899 Accuracy: 0.50060\n",
      "Epoch: 240 Batch:   0 Loss: 0.75734 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.75730 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.75726 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.75723 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.75719 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.75716 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.75711 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.75708 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.75704 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.75700 Accuracy: 0.00000\n",
      "Test Loss: 0.71110 Accuracy: 0.50060\n",
      "Epoch: 250 Batch:   0 Loss: 0.75695 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.75693 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.75689 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.75687 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.75684 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.75681 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.75679 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.75676 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.75674 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.75672 Accuracy: 0.00000\n",
      "Test Loss: 0.71320 Accuracy: 0.50060\n",
      "Epoch: 260 Batch:   0 Loss: 0.75670 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.75667 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.75665 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.75662 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.75660 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.75657 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.75655 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.75652 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.75649 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.75647 Accuracy: 0.00000\n",
      "Test Loss: 0.71517 Accuracy: 0.50060\n",
      "Epoch: 270 Batch:   0 Loss: 0.75644 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.75642 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.75640 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.75637 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.75634 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.75631 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.75629 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.75626 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.75624 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.75621 Accuracy: 0.00000\n",
      "Test Loss: 0.71714 Accuracy: 0.50070\n",
      "Epoch: 280 Batch:   0 Loss: 0.75619 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.75617 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.75614 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.75612 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.75611 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.75609 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.75607 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.75605 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.75604 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.75602 Accuracy: 0.00000\n",
      "Test Loss: 0.71916 Accuracy: 0.50070\n",
      "Epoch: 290 Batch:   0 Loss: 0.75601 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.75600 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.75599 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.75597 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.75596 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.75595 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.75593 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.75592 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.75591 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.75590 Accuracy: 0.00000\n",
      "Test Loss: 0.72120 Accuracy: 0.50070\n",
      "Epoch: 300 Batch:   0 Loss: 0.75589 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.75588 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.75587 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.75587 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.75586 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.75585 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.75585 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.75584 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.75583 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.75582 Accuracy: 0.00000\n",
      "Test Loss: 0.72333 Accuracy: 0.50070\n",
      "Epoch: 310 Batch:   0 Loss: 0.75582 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.75581 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.75580 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.75579 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.75577 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.75576 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.75575 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.75574 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.75572 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.75570 Accuracy: 0.00000\n",
      "Test Loss: 0.72554 Accuracy: 0.50070\n",
      "Epoch: 320 Batch:   0 Loss: 0.75569 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.75568 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.75567 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.75566 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.75565 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.75564 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.75563 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.75562 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.75561 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.75560 Accuracy: 0.00000\n",
      "Test Loss: 0.72789 Accuracy: 0.50070\n",
      "Epoch: 330 Batch:   0 Loss: 0.75559 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.75559 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.75558 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.75557 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.75557 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.75556 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.75556 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.75555 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.75555 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.75554 Accuracy: 0.00000\n",
      "Test Loss: 0.73019 Accuracy: 0.50070\n",
      "Epoch: 340 Batch:   0 Loss: 0.75553 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.75553 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.75552 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.75551 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.75551 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.75550 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.75550 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.75550 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.75550 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.75549 Accuracy: 0.00000\n",
      "Test Loss: 0.73251 Accuracy: 0.50070\n",
      "Epoch: 350 Batch:   0 Loss: 0.75549 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.75547 Accuracy: 0.00000\n",
      "Test Loss: 0.73480 Accuracy: 0.50070\n",
      "Epoch: 360 Batch:   0 Loss: 0.75547 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.75547 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.75547 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.75547 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.75547 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.75547 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Test Loss: 0.73709 Accuracy: 0.50070\n",
      "Epoch: 370 Batch:   0 Loss: 0.75549 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.75549 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.75549 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.75549 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.75550 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.75550 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.75551 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.75552 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.75552 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.75553 Accuracy: 0.00000\n",
      "Test Loss: 0.73937 Accuracy: 0.50070\n",
      "Epoch: 380 Batch:   0 Loss: 0.75553 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.75554 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.75555 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.75555 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:46:02,427] Trial 7 finished with value: 0.5005026135906715 and parameters: {'REG_W': 4.412697676135592e-06, 'REG_B': 0.003198383489368524, 'REG_Z': 3.552689934474277e-05, 'SPAR_W': 0.7978297845104647, 'SPAR_B': 0.84924161136927, 'SPAR_Z': 0.8079038266929486, 'LEARNING_RATE': 0.0008210480292785842, 'NUM_EPOCHS': 384}. Best is trial 2 with value: 0.5009047044632087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 5.75914 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 2.83749 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.86660 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.92428 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.95118 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.95749 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.95039 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.93410 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.91105 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.88296 Accuracy: 0.00000\n",
      "Test Loss: 1.43994 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.84909 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.81210 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.76845 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.72043 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.66657 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.60484 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.53730 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.46276 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.37964 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.29276 Accuracy: 0.00000\n",
      "Test Loss: 1.36705 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 2.19771 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.10166 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.00481 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.90771 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.80960 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.71348 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.62021 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.52991 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.44411 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.36268 Accuracy: 0.00000\n",
      "Test Loss: 1.22780 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.28607 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.21491 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.15108 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.09420 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.04418 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.00080 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.96376 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.93255 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.90632 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.88407 Accuracy: 0.00000\n",
      "Test Loss: 1.02540 Accuracy: 0.50060\n",
      "Epoch:  40 Batch:   0 Loss: 0.86489 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.84825 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.83305 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.81980 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.80834 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.79855 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.79005 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.78323 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.77784 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.77388 Accuracy: 0.00000\n",
      "Test Loss: 0.88857 Accuracy: 0.50080\n",
      "Epoch:  50 Batch:   0 Loss: 0.77100 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.76920 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.76835 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.76812 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.76840 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.76899 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.76974 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.77053 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.77135 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.77206 Accuracy: 0.00000\n",
      "Test Loss: 0.83804 Accuracy: 0.50070\n",
      "Epoch:  60 Batch:   0 Loss: 0.77276 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.77348 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.77421 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.77477 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.77525 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.77571 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.77613 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.77666 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.77713 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.77757 Accuracy: 0.00000\n",
      "Test Loss: 0.79793 Accuracy: 0.50070\n",
      "Epoch:  70 Batch:   0 Loss: 0.77792 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.77826 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.77853 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.77881 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.77897 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.77912 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.77917 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.77916 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.77908 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.77897 Accuracy: 0.00000\n",
      "Test Loss: 0.76722 Accuracy: 0.50070\n",
      "Epoch:  80 Batch:   0 Loss: 0.77881 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.77860 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.77834 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.77805 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.77775 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.77740 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.77706 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.77674 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.77641 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.77610 Accuracy: 0.00000\n",
      "Test Loss: 0.74495 Accuracy: 0.50070\n",
      "Epoch:  90 Batch:   0 Loss: 0.77581 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.77554 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.77528 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.77502 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.77479 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.77457 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.77436 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.77421 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.77405 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.77392 Accuracy: 0.00000\n",
      "Test Loss: 0.72980 Accuracy: 0.50070\n",
      "Epoch: 100 Batch:   0 Loss: 0.77379 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.77370 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.77366 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.77362 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.77358 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.77345 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.77333 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.77327 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.77320 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.77319 Accuracy: 0.00000\n",
      "Test Loss: 0.71946 Accuracy: 0.50070\n",
      "Epoch: 110 Batch:   0 Loss: 0.77315 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.77313 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.77312 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.77310 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.77308 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.77308 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.77308 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.77309 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.77309 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.77306 Accuracy: 0.00000\n",
      "Test Loss: 0.71222 Accuracy: 0.50080\n",
      "Epoch: 120 Batch:   0 Loss: 0.77307 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.77308 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.77309 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77310 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77308 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77309 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.77306 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.77298 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.77290 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.77284 Accuracy: 0.00000\n",
      "Test Loss: 0.70680 Accuracy: 0.50090\n",
      "Epoch: 130 Batch:   0 Loss: 0.77278 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.77273 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77269 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77266 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77263 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77261 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77258 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77257 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77255 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77253 Accuracy: 0.00000\n",
      "Test Loss: 0.70242 Accuracy: 0.50111\n",
      "Epoch: 140 Batch:   0 Loss: 0.77248 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77241 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77229 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77212 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77189 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.77160 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.77125 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.77087 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.77044 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.76999 Accuracy: 0.00000\n",
      "Test Loss: 0.69696 Accuracy: 0.50111\n",
      "Epoch: 150 Batch:   0 Loss: 0.76953 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.76905 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.76855 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.76803 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.76750 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.76698 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.76645 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.76591 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.76539 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.76488 Accuracy: 0.00000\n",
      "Test Loss: 0.69199 Accuracy: 0.50111\n",
      "Epoch: 160 Batch:   0 Loss: 0.76439 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.76393 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.76350 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.76313 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.76277 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.76247 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.76223 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.76205 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.76194 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Test Loss: 0.68933 Accuracy: 0.50100\n",
      "Epoch: 170 Batch:   0 Loss: 0.76188 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.76188 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.76187 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.76179 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.76170 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.76161 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.76155 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.76151 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.76121 Accuracy: 0.00000\n",
      "Test Loss: 0.68820 Accuracy: 0.50100\n",
      "Epoch: 180 Batch:   0 Loss: 0.76083 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.76028 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.75962 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.75885 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.75805 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.75724 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.75647 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.75572 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.75501 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.75437 Accuracy: 0.00000\n",
      "Test Loss: 0.68812 Accuracy: 0.50100\n",
      "Epoch: 190 Batch:   0 Loss: 0.75377 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.75321 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.75267 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.75218 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.75172 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.75129 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.75088 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.75050 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.75013 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.74978 Accuracy: 0.00000\n",
      "Test Loss: 0.68998 Accuracy: 0.50100\n",
      "Epoch: 200 Batch:   0 Loss: 0.74946 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.74916 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.74886 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.74858 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.74832 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.74806 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.74781 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.74757 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.74734 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.74712 Accuracy: 0.00000\n",
      "Test Loss: 0.69239 Accuracy: 0.50100\n",
      "Epoch: 210 Batch:   0 Loss: 0.74691 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.74670 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.74650 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.74631 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.74613 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.74595 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.74577 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.74561 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.74544 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.74529 Accuracy: 0.00000\n",
      "Test Loss: 0.69503 Accuracy: 0.50100\n",
      "Epoch: 220 Batch:   0 Loss: 0.74514 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.74499 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.74484 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.74471 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.74457 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.74444 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.74432 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.74420 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.74409 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.74398 Accuracy: 0.00000\n",
      "Test Loss: 0.69782 Accuracy: 0.50100\n",
      "Epoch: 230 Batch:   0 Loss: 0.74388 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.74377 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.74367 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.74357 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.74347 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.74337 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.74328 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.74318 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.74309 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.74300 Accuracy: 0.00000\n",
      "Test Loss: 0.70064 Accuracy: 0.50100\n",
      "Epoch: 240 Batch:   0 Loss: 0.74293 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.74284 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.74276 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.74268 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.74261 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.74253 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.74245 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.74238 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.74230 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.74223 Accuracy: 0.00000\n",
      "Test Loss: 0.70338 Accuracy: 0.50100\n",
      "Epoch: 250 Batch:   0 Loss: 0.74215 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.74208 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.74201 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.74194 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.74187 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.74181 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.74174 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.74168 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.74161 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.74154 Accuracy: 0.00000\n",
      "Test Loss: 0.70613 Accuracy: 0.50090\n",
      "Epoch: 260 Batch:   0 Loss: 0.74148 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.74142 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.74135 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.74129 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.74124 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.74118 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.74112 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.74106 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.74100 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.74094 Accuracy: 0.00000\n",
      "Test Loss: 0.70888 Accuracy: 0.50090\n",
      "Epoch: 270 Batch:   0 Loss: 0.74089 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.74083 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.74078 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.74073 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.74068 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.74064 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.74059 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.74055 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.74051 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.74047 Accuracy: 0.00000\n",
      "Test Loss: 0.71167 Accuracy: 0.50090\n",
      "Epoch: 280 Batch:   0 Loss: 0.74043 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.74039 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.74035 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.74030 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.74026 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.74022 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.74019 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.74015 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.74012 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.74008 Accuracy: 0.00000\n",
      "Test Loss: 0.71432 Accuracy: 0.50090\n",
      "Epoch: 290 Batch:   0 Loss: 0.74005 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.74003 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.74000 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.73998 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.73995 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.73992 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.73989 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.73987 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.73984 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.73981 Accuracy: 0.00000\n",
      "Test Loss: 0.71690 Accuracy: 0.50090\n",
      "Epoch: 300 Batch:   0 Loss: 0.73979 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.73976 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.73974 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.73972 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.73969 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.73966 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.73963 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.73961 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.73960 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.73957 Accuracy: 0.00000\n",
      "Test Loss: 0.71942 Accuracy: 0.50090\n",
      "Epoch: 310 Batch:   0 Loss: 0.73956 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.73954 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.73952 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.73951 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.73949 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.73947 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.73945 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.73943 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.73941 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.73940 Accuracy: 0.00000\n",
      "Test Loss: 0.72196 Accuracy: 0.50090\n",
      "Epoch: 320 Batch:   0 Loss: 0.73938 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.73936 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.73935 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.73934 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.73932 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.73931 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.73929 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.73928 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.73927 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.73926 Accuracy: 0.00000\n",
      "Test Loss: 0.72451 Accuracy: 0.50090\n",
      "Epoch: 330 Batch:   0 Loss: 0.73924 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.73922 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.73921 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.73920 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.73919 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.73917 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.73916 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.73915 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.73914 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.73913 Accuracy: 0.00000\n",
      "Test Loss: 0.72704 Accuracy: 0.50090\n",
      "Epoch: 340 Batch:   0 Loss: 0.73911 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.73910 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.73909 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.73907 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.73906 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.73905 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.73904 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.73902 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.73901 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.73900 Accuracy: 0.00000\n",
      "Test Loss: 0.72956 Accuracy: 0.50090\n",
      "Epoch: 350 Batch:   0 Loss: 0.73898 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.73897 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.73895 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.73894 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.73893 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.73891 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.73890 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.73888 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.73887 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.73885 Accuracy: 0.00000\n",
      "Test Loss: 0.73199 Accuracy: 0.50090\n",
      "Epoch: 360 Batch:   0 Loss: 0.73883 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.73881 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.73880 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.73878 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.73876 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.73875 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.73873 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.73871 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.73869 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.73868 Accuracy: 0.00000\n",
      "Test Loss: 0.73440 Accuracy: 0.50090\n",
      "Epoch: 370 Batch:   0 Loss: 0.73866 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.73865 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.73863 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.73862 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.73860 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.73859 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.73857 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.73855 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.73853 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.73851 Accuracy: 0.00000\n",
      "Test Loss: 0.73682 Accuracy: 0.50090\n",
      "Epoch: 380 Batch:   0 Loss: 0.73850 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:50:17,343] Trial 8 finished with value: 0.5007036590269401 and parameters: {'REG_W': 2.2931800644736617e-06, 'REG_B': 0.006665022716907156, 'REG_Z': 4.5094551587690154e-05, 'SPAR_W': 0.7593484805210193, 'SPAR_B': 0.6159196429129663, 'SPAR_Z': 0.8862216677271006, 'LEARNING_RATE': 0.0007529488504011111, 'NUM_EPOCHS': 381}. Best is trial 2 with value: 0.5009047044632087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.66041 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.17187 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.64755 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.89058 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.98747 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.01348 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.00963 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.99545 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.97919 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.96393 Accuracy: 0.00000\n",
      "Test Loss: 1.02673 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.95033 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.93822 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.92728 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.91701 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.90715 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.89737 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.88757 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.87761 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.86746 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.85706 Accuracy: 0.00000\n",
      "Test Loss: 0.99950 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.84636 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.83537 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.82403 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.81233 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.80024 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.78772 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.77468 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.76135 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.74761 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.73325 Accuracy: 0.00000\n",
      "Test Loss: 0.97044 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.71848 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.70324 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.68712 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.67098 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.65455 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.63771 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.62049 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.60308 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.58538 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.56708 Accuracy: 0.00000\n",
      "Test Loss: 0.93716 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.54795 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.52860 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.50842 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.48811 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.46728 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.44628 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.42499 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.40329 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.38113 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.35902 Accuracy: 0.00000\n",
      "Test Loss: 0.90163 Accuracy: 0.50030\n",
      "Epoch:  50 Batch:   0 Loss: 1.33658 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.31454 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.29260 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.27072 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.24863 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.22743 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.20641 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.18546 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.16509 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.14536 Accuracy: 0.00000\n",
      "Test Loss: 0.86435 Accuracy: 0.50030\n",
      "Epoch:  60 Batch:   0 Loss: 1.12628 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.10814 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.09004 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.07364 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 1.05796 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 1.04336 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 1.02932 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 1.01619 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 1.00379 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.99221 Accuracy: 0.00000\n",
      "Test Loss: 0.82842 Accuracy: 0.50040\n",
      "Epoch:  70 Batch:   0 Loss: 0.98123 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.97092 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.96108 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.95197 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.94344 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.93541 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.92785 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.92081 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.91426 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.90817 Accuracy: 0.00000\n",
      "Test Loss: 0.79464 Accuracy: 0.50040\n",
      "Epoch:  80 Batch:   0 Loss: 0.90276 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.89796 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.89367 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.88979 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.88642 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.88341 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.88078 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.87845 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.87638 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.87459 Accuracy: 0.00000\n",
      "Test Loss: 0.77109 Accuracy: 0.50040\n",
      "Epoch:  90 Batch:   0 Loss: 0.87302 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.87158 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.87029 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.86907 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.86798 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.86693 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.86591 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.86501 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.86413 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.86340 Accuracy: 0.00000\n",
      "Test Loss: 0.75371 Accuracy: 0.50040\n",
      "Epoch: 100 Batch:   0 Loss: 0.86252 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.86170 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.86091 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.86013 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.85930 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.85845 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.85758 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.85665 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.85571 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.85473 Accuracy: 0.00000\n",
      "Test Loss: 0.73913 Accuracy: 0.50040\n",
      "Epoch: 110 Batch:   0 Loss: 0.85372 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.85271 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.85164 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.85056 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.84947 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.84837 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.84728 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.84617 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.84507 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.84394 Accuracy: 0.00000\n",
      "Test Loss: 0.72758 Accuracy: 0.50050\n",
      "Epoch: 120 Batch:   0 Loss: 0.84286 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.84175 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.84064 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.83956 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.83849 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.83739 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.83630 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.83516 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.83415 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.83314 Accuracy: 0.00000\n",
      "Test Loss: 0.71854 Accuracy: 0.50040\n",
      "Epoch: 130 Batch:   0 Loss: 0.83218 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.83121 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.83031 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.82941 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.82853 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.82763 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.82674 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.82587 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.82502 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.82420 Accuracy: 0.00000\n",
      "Test Loss: 0.71129 Accuracy: 0.50050\n",
      "Epoch: 140 Batch:   0 Loss: 0.82339 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.82260 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.82183 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.82107 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.82033 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.81960 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.81887 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.81815 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.81744 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.81673 Accuracy: 0.00000\n",
      "Test Loss: 0.70508 Accuracy: 0.50050\n",
      "Epoch: 150 Batch:   0 Loss: 0.81602 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.81533 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.81464 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.81399 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.81329 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.81266 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.81204 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.81143 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.81081 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.81020 Accuracy: 0.00000\n",
      "Test Loss: 0.69969 Accuracy: 0.50060\n",
      "Epoch: 160 Batch:   0 Loss: 0.80960 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.80900 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.80839 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.80781 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.80723 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.80668 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.80613 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.80558 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.80501 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.80448 Accuracy: 0.00000\n",
      "Test Loss: 0.69497 Accuracy: 0.50060\n",
      "Epoch: 170 Batch:   0 Loss: 0.80395 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.80343 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.80288 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.80234 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.80187 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.80138 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.80094 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.80051 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.80009 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.79968 Accuracy: 0.00000\n",
      "Test Loss: 0.69075 Accuracy: 0.50060\n",
      "Epoch: 180 Batch:   0 Loss: 0.79927 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.79886 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.79846 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.79807 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.79769 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.79731 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.79696 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.79661 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.79625 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.79594 Accuracy: 0.00000\n",
      "Test Loss: 0.68686 Accuracy: 0.50060\n",
      "Epoch: 190 Batch:   0 Loss: 0.79563 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.79533 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.79504 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.79475 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.79447 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.79420 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.79393 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.79368 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.79342 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.79317 Accuracy: 0.00000\n",
      "Test Loss: 0.68320 Accuracy: 0.50060\n",
      "Epoch: 200 Batch:   0 Loss: 0.79293 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.79269 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.79246 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.79224 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.79203 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.79182 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.79165 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.79148 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.79132 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.79118 Accuracy: 0.00000\n",
      "Test Loss: 0.67981 Accuracy: 0.50060\n",
      "Epoch: 210 Batch:   0 Loss: 0.79104 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.79091 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.79079 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.79069 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.79058 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.79048 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.79041 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.79033 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.79026 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.79018 Accuracy: 0.00000\n",
      "Test Loss: 0.67663 Accuracy: 0.50060\n",
      "Epoch: 220 Batch:   0 Loss: 0.79011 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.79004 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.78998 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.78993 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.78988 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.78984 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.78980 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.78979 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.78979 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.78978 Accuracy: 0.00000\n",
      "Test Loss: 0.67370 Accuracy: 0.50060\n",
      "Epoch: 230 Batch:   0 Loss: 0.78978 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.78979 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.78980 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.78983 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.78986 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.78991 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.78997 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.79003 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.79011 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.79019 Accuracy: 0.00000\n",
      "Test Loss: 0.67106 Accuracy: 0.50060\n",
      "Epoch: 240 Batch:   0 Loss: 0.79028 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.79039 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.79051 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.79064 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.79078 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.79092 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.79108 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.79125 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.79143 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.79161 Accuracy: 0.00000\n",
      "Test Loss: 0.66869 Accuracy: 0.50070\n",
      "Epoch: 250 Batch:   0 Loss: 0.79181 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.79200 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.79220 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.79241 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.79261 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.79285 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.79313 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.79336 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.79359 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.79381 Accuracy: 0.00000\n",
      "Test Loss: 0.66662 Accuracy: 0.50070\n",
      "Epoch: 260 Batch:   0 Loss: 0.79402 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.79423 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.79442 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.79456 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.79469 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.79480 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.79489 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.79498 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.79504 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.79508 Accuracy: 0.00000\n",
      "Test Loss: 0.66452 Accuracy: 0.50070\n",
      "Epoch: 270 Batch:   0 Loss: 0.79510 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.79510 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.79508 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.79505 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.79500 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.79491 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.79480 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.79469 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.79457 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.79441 Accuracy: 0.00000\n",
      "Test Loss: 0.66260 Accuracy: 0.50070\n",
      "Epoch: 280 Batch:   0 Loss: 0.79428 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.79417 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.79404 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.79393 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.79379 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.79364 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.79349 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.79337 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.79326 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.79315 Accuracy: 0.00000\n",
      "Test Loss: 0.66098 Accuracy: 0.50070\n",
      "Epoch: 290 Batch:   0 Loss: 0.79305 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.79296 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.79287 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.79280 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.79275 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.79271 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.79267 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.79264 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.79262 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.79262 Accuracy: 0.00000\n",
      "Test Loss: 0.65957 Accuracy: 0.50070\n",
      "Epoch: 300 Batch:   0 Loss: 0.79262 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.79263 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.79263 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.79263 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.79262 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.79261 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.79256 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.79251 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.79246 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.79237 Accuracy: 0.00000\n",
      "Test Loss: 0.65823 Accuracy: 0.50070\n",
      "Epoch: 310 Batch:   0 Loss: 0.79228 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.79218 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.79207 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.79195 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.79183 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.79169 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.79153 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.79136 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.79118 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.79101 Accuracy: 0.00000\n",
      "Test Loss: 0.65701 Accuracy: 0.50060\n",
      "Epoch: 320 Batch:   0 Loss: 0.79083 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.79063 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.79044 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.79024 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.79003 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.78980 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.78958 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.78935 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.78911 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.78885 Accuracy: 0.00000\n",
      "Test Loss: 0.65596 Accuracy: 0.50060\n",
      "Epoch: 330 Batch:   0 Loss: 0.78858 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.78831 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.78803 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.78774 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.78744 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.78714 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.78684 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.78654 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.78622 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.78589 Accuracy: 0.00000\n",
      "Test Loss: 0.65498 Accuracy: 0.50060\n",
      "Epoch: 340 Batch:   0 Loss: 0.78556 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.78522 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.78488 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.78454 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.78420 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.78386 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.78351 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.78316 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.78279 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.78242 Accuracy: 0.00000\n",
      "Test Loss: 0.65410 Accuracy: 0.50060\n",
      "Epoch: 350 Batch:   0 Loss: 0.78205 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.78167 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.78130 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.78093 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.78056 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.78019 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.77982 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.77945 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.77907 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.77870 Accuracy: 0.00000\n",
      "Test Loss: 0.65348 Accuracy: 0.50060\n",
      "Epoch: 360 Batch:   0 Loss: 0.77834 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.77798 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.77762 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.77727 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.77692 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.77657 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.77623 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.77589 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.77553 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.77520 Accuracy: 0.00000\n",
      "Test Loss: 0.65315 Accuracy: 0.50060\n",
      "Epoch: 370 Batch:   0 Loss: 0.77487 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.77455 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.77423 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.77391 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.77360 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.77330 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.77299 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.77269 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.77240 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.77210 Accuracy: 0.00000\n",
      "Test Loss: 0.65310 Accuracy: 0.50060\n",
      "Epoch: 380 Batch:   0 Loss: 0.77178 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.77150 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.77122 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.77094 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.77067 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.77040 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.77014 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.76988 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.76963 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.76938 Accuracy: 0.00000\n",
      "Test Loss: 0.65330 Accuracy: 0.50060\n",
      "Epoch: 390 Batch:   0 Loss: 0.76914 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.76891 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.76867 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.76843 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.76820 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.76798 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.76776 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.76754 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.76733 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.76712 Accuracy: 0.00000\n",
      "Test Loss: 0.65368 Accuracy: 0.50060\n",
      "Epoch: 400 Batch:   0 Loss: 0.76691 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.76671 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.76651 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.76632 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.76613 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.76594 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.76576 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.76558 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.76541 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.76524 Accuracy: 0.00000\n",
      "Test Loss: 0.65425 Accuracy: 0.50060\n",
      "Epoch: 410 Batch:   0 Loss: 0.76507 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.76491 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.76475 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.76460 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.76443 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.76427 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.76412 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.76396 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.76381 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.76366 Accuracy: 0.00000\n",
      "Test Loss: 0.65499 Accuracy: 0.50060\n",
      "Epoch: 420 Batch:   0 Loss: 0.76352 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.76337 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.76324 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.76310 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.76296 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.76283 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.76270 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.76257 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.76244 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.76232 Accuracy: 0.00000\n",
      "Test Loss: 0.65583 Accuracy: 0.50060\n",
      "Epoch: 430 Batch:   0 Loss: 0.76219 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.76207 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.76193 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.76180 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.76166 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.76153 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.76141 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.76128 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.76117 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.76105 Accuracy: 0.00000\n",
      "Test Loss: 0.65671 Accuracy: 0.50060\n",
      "Epoch: 440 Batch:   0 Loss: 0.76094 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.76083 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.76072 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.76061 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.76051 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.76040 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.76030 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.76020 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.76009 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.76000 Accuracy: 0.00000\n",
      "Test Loss: 0.65761 Accuracy: 0.50060\n",
      "Epoch: 450 Batch:   0 Loss: 0.75991 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.75982 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.75972 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.75963 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.75954 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.75946 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.75937 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.75928 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.75919 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.75911 Accuracy: 0.00000\n",
      "Test Loss: 0.65860 Accuracy: 0.50060\n",
      "Epoch: 460 Batch:   0 Loss: 0.75902 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.75894 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.75885 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.75877 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.75868 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.75859 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.75851 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.75842 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.75834 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.75825 Accuracy: 0.00000\n",
      "Test Loss: 0.65967 Accuracy: 0.50060\n",
      "Epoch: 470 Batch:   0 Loss: 0.75817 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.75808 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.75800 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.75791 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.75783 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.75774 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.75766 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.75758 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.75750 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.75742 Accuracy: 0.00000\n",
      "Test Loss: 0.66081 Accuracy: 0.50060\n",
      "Epoch: 480 Batch:   0 Loss: 0.75734 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.75726 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.75718 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.75710 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.75703 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.75695 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.75687 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.75679 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.75672 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.75664 Accuracy: 0.00000\n",
      "Test Loss: 0.66195 Accuracy: 0.50060\n",
      "Epoch: 490 Batch:   0 Loss: 0.75656 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.75649 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.75641 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.75634 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.75626 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.75619 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.75611 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.75604 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.75596 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.75589 Accuracy: 0.00000\n",
      "Test Loss: 0.66310 Accuracy: 0.50060\n",
      "Epoch: 500 Batch:   0 Loss: 0.75582 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.75575 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.75567 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.75559 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.75551 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.75543 Accuracy: 0.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.75535 Accuracy: 0.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.75527 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.75519 Accuracy: 0.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.75511 Accuracy: 0.00000\n",
      "Test Loss: 0.66427 Accuracy: 0.50060\n",
      "Epoch: 510 Batch:   0 Loss: 0.75502 Accuracy: 0.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.75495 Accuracy: 0.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.75486 Accuracy: 0.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.75478 Accuracy: 0.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.75470 Accuracy: 0.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.75462 Accuracy: 0.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.75454 Accuracy: 0.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.75447 Accuracy: 0.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.75439 Accuracy: 0.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.75431 Accuracy: 0.00000\n",
      "Test Loss: 0.66546 Accuracy: 0.50060\n",
      "Epoch: 520 Batch:   0 Loss: 0.75424 Accuracy: 0.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.75417 Accuracy: 0.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.75409 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.75402 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.75395 Accuracy: 0.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.75388 Accuracy: 0.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.75381 Accuracy: 0.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.75374 Accuracy: 0.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.75367 Accuracy: 0.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.75360 Accuracy: 0.00000\n",
      "Test Loss: 0.66668 Accuracy: 0.50060\n",
      "Epoch: 530 Batch:   0 Loss: 0.75353 Accuracy: 0.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.75346 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.75339 Accuracy: 0.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.75332 Accuracy: 0.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.75325 Accuracy: 0.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.75318 Accuracy: 0.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.75311 Accuracy: 0.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.75303 Accuracy: 0.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.75296 Accuracy: 0.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.75288 Accuracy: 0.00000\n",
      "Test Loss: 0.66796 Accuracy: 0.50060\n",
      "Epoch: 540 Batch:   0 Loss: 0.75281 Accuracy: 0.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.75273 Accuracy: 0.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.75266 Accuracy: 0.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.75259 Accuracy: 0.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.75252 Accuracy: 0.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.75245 Accuracy: 0.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.75238 Accuracy: 0.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.75231 Accuracy: 0.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.75224 Accuracy: 0.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.75217 Accuracy: 0.00000\n",
      "Test Loss: 0.66926 Accuracy: 0.50060\n",
      "Epoch: 550 Batch:   0 Loss: 0.75210 Accuracy: 0.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.75203 Accuracy: 0.00000\n",
      "Epoch: 552 Batch:   0 Loss: 0.75196 Accuracy: 0.00000\n",
      "Epoch: 553 Batch:   0 Loss: 0.75189 Accuracy: 0.00000\n",
      "Epoch: 554 Batch:   0 Loss: 0.75182 Accuracy: 0.00000\n",
      "Epoch: 555 Batch:   0 Loss: 0.75176 Accuracy: 0.00000\n",
      "Epoch: 556 Batch:   0 Loss: 0.75169 Accuracy: 0.00000\n",
      "Epoch: 557 Batch:   0 Loss: 0.75163 Accuracy: 0.00000\n",
      "Epoch: 558 Batch:   0 Loss: 0.75156 Accuracy: 0.00000\n",
      "Epoch: 559 Batch:   0 Loss: 0.75149 Accuracy: 0.00000\n",
      "Test Loss: 0.67054 Accuracy: 0.50060\n",
      "Epoch: 560 Batch:   0 Loss: 0.75142 Accuracy: 0.00000\n",
      "Epoch: 561 Batch:   0 Loss: 0.75135 Accuracy: 0.00000\n",
      "Epoch: 562 Batch:   0 Loss: 0.75128 Accuracy: 0.00000\n",
      "Epoch: 563 Batch:   0 Loss: 0.75121 Accuracy: 0.00000\n",
      "Epoch: 564 Batch:   0 Loss: 0.75114 Accuracy: 0.00000\n",
      "Epoch: 565 Batch:   0 Loss: 0.75108 Accuracy: 0.00000\n",
      "Epoch: 566 Batch:   0 Loss: 0.75101 Accuracy: 0.00000\n",
      "Epoch: 567 Batch:   0 Loss: 0.75095 Accuracy: 0.00000\n",
      "Epoch: 568 Batch:   0 Loss: 0.75088 Accuracy: 0.00000\n",
      "Epoch: 569 Batch:   0 Loss: 0.75082 Accuracy: 0.00000\n",
      "Test Loss: 0.67180 Accuracy: 0.50060\n",
      "Epoch: 570 Batch:   0 Loss: 0.75075 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 571 Batch:   0 Loss: 0.75069 Accuracy: 0.00000\n",
      "Epoch: 572 Batch:   0 Loss: 0.75063 Accuracy: 0.00000\n",
      "Epoch: 573 Batch:   0 Loss: 0.75056 Accuracy: 0.00000\n",
      "Epoch: 574 Batch:   0 Loss: 0.75050 Accuracy: 0.00000\n",
      "Epoch: 575 Batch:   0 Loss: 0.75044 Accuracy: 0.00000\n",
      "Epoch: 576 Batch:   0 Loss: 0.75038 Accuracy: 0.00000\n",
      "Epoch: 577 Batch:   0 Loss: 0.75032 Accuracy: 0.00000\n",
      "Epoch: 578 Batch:   0 Loss: 0.75026 Accuracy: 0.00000\n",
      "Epoch: 579 Batch:   0 Loss: 0.75020 Accuracy: 0.00000\n",
      "Test Loss: 0.67309 Accuracy: 0.50060\n",
      "Epoch: 580 Batch:   0 Loss: 0.75014 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 13:58:41,307] Trial 9 finished with value: 0.5004020908725372 and parameters: {'REG_W': 2.4810859452802976e-06, 'REG_B': 0.00988922374826537, 'REG_Z': 3.261693080385779e-05, 'SPAR_W': 0.6028177136949872, 'SPAR_B': 0.7005312263694913, 'SPAR_Z': 0.5302911886348941, 'LEARNING_RATE': 0.00031652384749609113, 'NUM_EPOCHS': 581}. Best is trial 2 with value: 0.5009047044632087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.00596 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.00624 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.01096 Accuracy: 1.00000\n",
      "Epoch:   3 Batch:   0 Loss: 0.05319 Accuracy: 1.00000\n",
      "Epoch:   4 Batch:   0 Loss: 0.27952 Accuracy: 1.00000\n",
      "Epoch:   5 Batch:   0 Loss: 0.67344 Accuracy: 1.00000\n",
      "Epoch:   6 Batch:   0 Loss: 0.91267 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.00609 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.04003 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.05301 Accuracy: 0.00000\n",
      "Test Loss: 0.73942 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.05820 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.05956 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.05875 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.05629 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.05258 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.04788 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.04236 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.03613 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.02933 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.02191 Accuracy: 0.00000\n",
      "Test Loss: 0.73212 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.01432 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.00670 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 0.99909 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 0.99180 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 0.98446 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 0.97734 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 0.97019 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 0.96287 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 0.95561 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 0.94853 Accuracy: 0.00000\n",
      "Test Loss: 0.71812 Accuracy: 0.50060\n",
      "Epoch:  30 Batch:   0 Loss: 0.94144 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 0.93459 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 0.92775 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.92097 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.91401 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.90716 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.90054 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.89386 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.88700 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.87999 Accuracy: 0.00000\n",
      "Test Loss: 0.70151 Accuracy: 0.52854\n",
      "Epoch:  40 Batch:   0 Loss: 0.87308 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.86600 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.85894 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.85171 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.84419 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.83660 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.82881 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.82104 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.81318 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.80528 Accuracy: 0.00000\n",
      "Test Loss: 0.67998 Accuracy: 0.56953\n",
      "Epoch:  50 Batch:   0 Loss: 0.79719 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.78906 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.78096 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.77282 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.76465 Accuracy: 0.03125\n",
      "Epoch:  55 Batch:   0 Loss: 0.75648 Accuracy: 0.06250\n",
      "Epoch:  56 Batch:   0 Loss: 0.74828 Accuracy: 0.09375\n",
      "Epoch:  57 Batch:   0 Loss: 0.74008 Accuracy: 0.15625\n",
      "Epoch:  58 Batch:   0 Loss: 0.73191 Accuracy: 0.21875\n",
      "Epoch:  59 Batch:   0 Loss: 0.72375 Accuracy: 0.34375\n",
      "Test Loss: 0.65598 Accuracy: 0.61273\n",
      "Epoch:  60 Batch:   0 Loss: 0.71559 Accuracy: 0.40625\n",
      "Epoch:  61 Batch:   0 Loss: 0.70742 Accuracy: 0.53125\n",
      "Epoch:  62 Batch:   0 Loss: 0.69926 Accuracy: 0.56250\n",
      "Epoch:  63 Batch:   0 Loss: 0.69103 Accuracy: 0.62500\n",
      "Epoch:  64 Batch:   0 Loss: 0.68290 Accuracy: 0.75000\n",
      "Epoch:  65 Batch:   0 Loss: 0.67483 Accuracy: 0.75000\n",
      "Epoch:  66 Batch:   0 Loss: 0.66682 Accuracy: 0.78125\n",
      "Epoch:  67 Batch:   0 Loss: 0.65883 Accuracy: 0.84375\n",
      "Epoch:  68 Batch:   0 Loss: 0.65088 Accuracy: 0.87500\n",
      "Epoch:  69 Batch:   0 Loss: 0.64300 Accuracy: 0.90625\n",
      "Test Loss: 0.63213 Accuracy: 0.65222\n",
      "Epoch:  70 Batch:   0 Loss: 0.63518 Accuracy: 0.90625\n",
      "Epoch:  71 Batch:   0 Loss: 0.62744 Accuracy: 0.90625\n",
      "Epoch:  72 Batch:   0 Loss: 0.61960 Accuracy: 0.93750\n",
      "Epoch:  73 Batch:   0 Loss: 0.61170 Accuracy: 0.93750\n",
      "Epoch:  74 Batch:   0 Loss: 0.60414 Accuracy: 1.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.59669 Accuracy: 1.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.58933 Accuracy: 1.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.58205 Accuracy: 1.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.57484 Accuracy: 1.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.56773 Accuracy: 1.00000\n",
      "Test Loss: 0.61035 Accuracy: 0.68517\n",
      "Epoch:  80 Batch:   0 Loss: 0.56071 Accuracy: 1.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.55375 Accuracy: 1.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.54687 Accuracy: 1.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.54008 Accuracy: 1.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.53338 Accuracy: 1.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.52677 Accuracy: 1.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.52023 Accuracy: 1.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.51376 Accuracy: 1.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.50738 Accuracy: 1.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.50106 Accuracy: 1.00000\n",
      "Test Loss: 0.59197 Accuracy: 0.71260\n",
      "Epoch:  90 Batch:   0 Loss: 0.49484 Accuracy: 1.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.48872 Accuracy: 1.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.48268 Accuracy: 1.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.47675 Accuracy: 1.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.47087 Accuracy: 1.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.46510 Accuracy: 1.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.45942 Accuracy: 1.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.45385 Accuracy: 1.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.44835 Accuracy: 1.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.44294 Accuracy: 1.00000\n",
      "Test Loss: 0.57713 Accuracy: 0.72766\n",
      "Epoch: 100 Batch:   0 Loss: 0.43761 Accuracy: 1.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.43237 Accuracy: 1.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.42723 Accuracy: 1.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.42217 Accuracy: 1.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.41720 Accuracy: 1.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.41232 Accuracy: 1.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.40752 Accuracy: 1.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.40284 Accuracy: 1.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.39826 Accuracy: 1.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.39374 Accuracy: 1.00000\n",
      "Test Loss: 0.56568 Accuracy: 0.73922\n",
      "Epoch: 110 Batch:   0 Loss: 0.38931 Accuracy: 1.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.38496 Accuracy: 1.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.38069 Accuracy: 1.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.37649 Accuracy: 1.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.37237 Accuracy: 1.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.36834 Accuracy: 1.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.36438 Accuracy: 1.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.36050 Accuracy: 1.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.35669 Accuracy: 1.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.35295 Accuracy: 1.00000\n",
      "Test Loss: 0.55713 Accuracy: 0.74645\n",
      "Epoch: 120 Batch:   0 Loss: 0.34928 Accuracy: 1.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.34568 Accuracy: 1.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.34216 Accuracy: 1.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.33871 Accuracy: 1.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.33532 Accuracy: 1.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.33200 Accuracy: 1.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.32874 Accuracy: 1.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.32555 Accuracy: 1.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.32242 Accuracy: 1.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.31935 Accuracy: 1.00000\n",
      "Test Loss: 0.55076 Accuracy: 0.75218\n",
      "Epoch: 130 Batch:   0 Loss: 0.31636 Accuracy: 1.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.31342 Accuracy: 1.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.31054 Accuracy: 1.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.30772 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.30496 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.30225 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.29960 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.29701 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.29447 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.29198 Accuracy: 1.00000\n",
      "Test Loss: 0.54606 Accuracy: 0.75629\n",
      "Epoch: 140 Batch:   0 Loss: 0.28955 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.28717 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.28484 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.28256 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.28033 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.27816 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.27602 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.27394 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.27190 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.26990 Accuracy: 1.00000\n",
      "Test Loss: 0.54259 Accuracy: 0.75730\n",
      "Epoch: 150 Batch:   0 Loss: 0.26795 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.26603 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.26417 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.26235 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.26056 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.25881 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.25710 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.25543 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.25378 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.25219 Accuracy: 1.00000\n",
      "Test Loss: 0.54002 Accuracy: 0.75881\n",
      "Epoch: 160 Batch:   0 Loss: 0.25063 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.24910 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.24760 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.24614 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.24470 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.24330 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.24193 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.24059 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.23928 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.23800 Accuracy: 1.00000\n",
      "Test Loss: 0.53803 Accuracy: 0.76132\n",
      "Epoch: 170 Batch:   0 Loss: 0.23674 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.23552 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.23432 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.23314 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.23200 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.23087 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.22978 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.22870 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.22766 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.22663 Accuracy: 1.00000\n",
      "Test Loss: 0.53645 Accuracy: 0.76303\n",
      "Epoch: 180 Batch:   0 Loss: 0.22563 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.22466 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.22370 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.22277 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.22185 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.22096 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.22008 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.21923 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.21839 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.21758 Accuracy: 1.00000\n",
      "Test Loss: 0.53521 Accuracy: 0.76564\n",
      "Epoch: 190 Batch:   0 Loss: 0.21678 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.21599 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.21523 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.21449 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.21375 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.21303 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.21233 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.21164 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.21097 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.21031 Accuracy: 1.00000\n",
      "Test Loss: 0.53421 Accuracy: 0.76685\n",
      "Epoch: 200 Batch:   0 Loss: 0.20967 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.20904 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.20842 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.20782 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.20723 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.20666 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.20610 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.20555 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.20501 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.20449 Accuracy: 1.00000\n",
      "Test Loss: 0.53339 Accuracy: 0.76905\n",
      "Epoch: 210 Batch:   0 Loss: 0.20397 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.20346 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.20298 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.20249 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.20202 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.20157 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.20112 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.20068 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.20033 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.19983 Accuracy: 1.00000\n",
      "Test Loss: 0.53270 Accuracy: 0.77036\n",
      "Epoch: 220 Batch:   0 Loss: 0.19940 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.19900 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.19860 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.19822 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.19784 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.19747 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.19711 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.19676 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.19642 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.19608 Accuracy: 1.00000\n",
      "Test Loss: 0.53211 Accuracy: 0.77186\n",
      "Epoch: 230 Batch:   0 Loss: 0.19575 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.19542 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.19510 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.19479 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.19449 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.19418 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.19388 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.19360 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.19332 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.19305 Accuracy: 1.00000\n",
      "Test Loss: 0.53160 Accuracy: 0.77387\n",
      "Epoch: 240 Batch:   0 Loss: 0.19279 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.19252 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.19228 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.19202 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.19177 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.19153 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.19129 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.19106 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.19084 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.19062 Accuracy: 1.00000\n",
      "Test Loss: 0.53118 Accuracy: 0.77578\n",
      "Epoch: 250 Batch:   0 Loss: 0.19040 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.19019 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.18999 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.18987 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.18969 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.18949 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.18930 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.18911 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.18893 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.18875 Accuracy: 1.00000\n",
      "Test Loss: 0.53087 Accuracy: 0.77678\n",
      "Epoch: 260 Batch:   0 Loss: 0.18857 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.18840 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.18823 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.18807 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.18791 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.18775 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.18759 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.18744 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.18730 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.18714 Accuracy: 1.00000\n",
      "Test Loss: 0.53058 Accuracy: 0.77718\n",
      "Epoch: 270 Batch:   0 Loss: 0.18700 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.18686 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.18673 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.18659 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.18646 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.18633 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.18621 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.18608 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.18596 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.18584 Accuracy: 1.00000\n",
      "Test Loss: 0.53036 Accuracy: 0.77698\n",
      "Epoch: 280 Batch:   0 Loss: 0.18572 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.18561 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.18550 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.18539 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.18528 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.18518 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.18507 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.18497 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.18481 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.18475 Accuracy: 1.00000\n",
      "Test Loss: 0.53022 Accuracy: 0.77718\n",
      "Epoch: 290 Batch:   0 Loss: 0.18466 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.18457 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.18448 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.18439 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.18430 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.18421 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.18413 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.18404 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.18396 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.18389 Accuracy: 1.00000\n",
      "Test Loss: 0.53016 Accuracy: 0.77889\n",
      "Epoch: 300 Batch:   0 Loss: 0.18380 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.18372 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.18364 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.18357 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.18349 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.18342 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.18335 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.18328 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.18321 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.18314 Accuracy: 1.00000\n",
      "Test Loss: 0.53019 Accuracy: 0.77969\n",
      "Epoch: 310 Batch:   0 Loss: 0.18307 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.18301 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.18294 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.18288 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.18282 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.18276 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.18269 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.18263 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.18257 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.18251 Accuracy: 1.00000\n",
      "Test Loss: 0.53029 Accuracy: 0.78049\n",
      "Epoch: 320 Batch:   0 Loss: 0.18246 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.18240 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.18235 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.18230 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.18224 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.18219 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.18214 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.18209 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.18204 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.18199 Accuracy: 1.00000\n",
      "Test Loss: 0.53048 Accuracy: 0.78029\n",
      "Epoch: 330 Batch:   0 Loss: 0.18194 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.18189 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.18184 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.18179 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.18174 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.18170 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.18165 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.18161 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.18157 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.18152 Accuracy: 1.00000\n",
      "Test Loss: 0.53075 Accuracy: 0.78140\n",
      "Epoch: 340 Batch:   0 Loss: 0.18148 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.18144 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.18140 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.18135 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.18132 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.18127 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.18124 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.18120 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.18116 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.18112 Accuracy: 1.00000\n",
      "Test Loss: 0.53109 Accuracy: 0.78210\n",
      "Epoch: 350 Batch:   0 Loss: 0.18108 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.18104 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.18100 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.18097 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.18093 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.18089 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.18086 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.18083 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.18079 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.18076 Accuracy: 1.00000\n",
      "Test Loss: 0.53152 Accuracy: 0.78220\n",
      "Epoch: 360 Batch:   0 Loss: 0.18072 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.18069 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.18065 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.18062 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.18059 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.18056 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.18053 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.18050 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.18047 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.18044 Accuracy: 1.00000\n",
      "Test Loss: 0.53201 Accuracy: 0.78250\n",
      "Epoch: 370 Batch:   0 Loss: 0.18041 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.18038 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.18035 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.18032 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.18029 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.18026 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.18023 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.18020 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.18017 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.18014 Accuracy: 1.00000\n",
      "Test Loss: 0.53256 Accuracy: 0.78250\n",
      "Epoch: 380 Batch:   0 Loss: 0.18011 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.18009 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.18006 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.18003 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.18000 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.17997 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.17994 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.17991 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.17988 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.17985 Accuracy: 1.00000\n",
      "Test Loss: 0.53319 Accuracy: 0.78290\n",
      "Epoch: 390 Batch:   0 Loss: 0.17982 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.17979 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.17976 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.17973 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.17970 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.17968 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.17965 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.17962 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.17959 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.17956 Accuracy: 1.00000\n",
      "Test Loss: 0.53387 Accuracy: 0.78320\n",
      "Epoch: 400 Batch:   0 Loss: 0.17953 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.17950 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.17947 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.17944 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.17941 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.17938 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.17935 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.17932 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.17930 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.17927 Accuracy: 1.00000\n",
      "Test Loss: 0.53461 Accuracy: 0.78310\n",
      "Epoch: 410 Batch:   0 Loss: 0.17924 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.17921 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.17918 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.17915 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.17913 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.17910 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.17907 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.17905 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.17902 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.17900 Accuracy: 1.00000\n",
      "Test Loss: 0.53543 Accuracy: 0.78360\n",
      "Epoch: 420 Batch:   0 Loss: 0.17896 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.17893 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.17890 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.17888 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.17885 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.17882 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.17879 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.17876 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.17873 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.17870 Accuracy: 1.00000\n",
      "Test Loss: 0.53629 Accuracy: 0.78320\n",
      "Epoch: 430 Batch:   0 Loss: 0.17867 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.17864 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.17861 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.17858 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.17855 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.17852 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.17849 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.17846 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.17843 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.17840 Accuracy: 1.00000\n",
      "Test Loss: 0.53721 Accuracy: 0.78340\n",
      "Epoch: 440 Batch:   0 Loss: 0.17837 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.17834 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.17830 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.17827 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.17824 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.17821 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.17818 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.17815 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.17811 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.17808 Accuracy: 1.00000\n",
      "Test Loss: 0.53817 Accuracy: 0.78260\n",
      "Epoch: 450 Batch:   0 Loss: 0.17805 Accuracy: 1.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.17802 Accuracy: 1.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.17799 Accuracy: 1.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.17795 Accuracy: 1.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.17792 Accuracy: 1.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.17789 Accuracy: 1.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.17786 Accuracy: 1.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.17783 Accuracy: 1.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.17779 Accuracy: 1.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.17776 Accuracy: 1.00000\n",
      "Test Loss: 0.53916 Accuracy: 0.78260\n",
      "Epoch: 460 Batch:   0 Loss: 0.17773 Accuracy: 1.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.17770 Accuracy: 1.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.17767 Accuracy: 1.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.17763 Accuracy: 1.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.17760 Accuracy: 1.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.17757 Accuracy: 1.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.17753 Accuracy: 1.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.17750 Accuracy: 1.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.17746 Accuracy: 1.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.17743 Accuracy: 1.00000\n",
      "Test Loss: 0.54019 Accuracy: 0.78290\n",
      "Epoch: 470 Batch:   0 Loss: 0.17740 Accuracy: 1.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.17736 Accuracy: 1.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.17733 Accuracy: 1.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.17730 Accuracy: 1.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.17726 Accuracy: 1.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.17723 Accuracy: 1.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.17719 Accuracy: 1.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.17716 Accuracy: 1.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.17713 Accuracy: 1.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.17709 Accuracy: 1.00000\n",
      "Test Loss: 0.54126 Accuracy: 0.78330\n",
      "Epoch: 480 Batch:   0 Loss: 0.17706 Accuracy: 1.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.17703 Accuracy: 1.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.17699 Accuracy: 1.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.17696 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:04:12,448] Trial 10 finished with value: 0.7833735424205871 and parameters: {'REG_W': 3.1651209759814418e-06, 'REG_B': 1.5029243127284535e-05, 'REG_Z': 4.9678837029664995e-05, 'SPAR_W': 0.9694619549595722, 'SPAR_B': 0.8063620879846112, 'SPAR_Z': 0.9979067852308309, 'LEARNING_RATE': 0.0001202698283373907, 'NUM_EPOCHS': 484}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 20.02424 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 18.53956 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 16.66841 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 14.76781 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 12.84827 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 10.89393 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 8.94775 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 7.02891 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 5.15114 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 3.38570 Accuracy: 0.00000\n",
      "Test Loss: 0.99467 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.05309 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.41565 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.18329 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.11014 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.09162 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.09011 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.09277 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.09561 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.09762 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.09870 Accuracy: 0.00000\n",
      "Test Loss: 0.73183 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.09898 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.09863 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.09776 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.09646 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.09478 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.09268 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.09039 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.08783 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.08499 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.08188 Accuracy: 0.00000\n",
      "Test Loss: 0.72323 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.07845 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.07485 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.07119 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.06731 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.06334 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.05934 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.05524 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.05116 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.04698 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.04283 Accuracy: 0.00000\n",
      "Test Loss: 0.71378 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.03859 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.03436 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.03010 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.02574 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.02122 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.01670 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.01222 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.00773 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.00318 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.99856 Accuracy: 0.00000\n",
      "Test Loss: 0.71041 Accuracy: 0.50543\n",
      "Epoch:  50 Batch:   0 Loss: 0.99391 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.98935 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.98462 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.98008 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.97551 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.97089 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.96629 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.96167 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.95705 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.95238 Accuracy: 0.00000\n",
      "Test Loss: 0.70990 Accuracy: 0.54512\n",
      "Epoch:  60 Batch:   0 Loss: 0.94769 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.94294 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.93812 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.93329 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.92843 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.92351 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.91852 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.91347 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.90841 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.90332 Accuracy: 0.00000\n",
      "Test Loss: 0.70937 Accuracy: 0.56330\n",
      "Epoch:  70 Batch:   0 Loss: 0.89820 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.89301 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.88781 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.88257 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.87732 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.87204 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.86674 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.86145 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.85614 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.85083 Accuracy: 0.00000\n",
      "Test Loss: 0.70681 Accuracy: 0.58611\n",
      "Epoch:  80 Batch:   0 Loss: 0.84554 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.84026 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.83500 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.82978 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.82458 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.81942 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.81431 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.80923 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.80421 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.79923 Accuracy: 0.00000\n",
      "Test Loss: 0.70092 Accuracy: 0.59908\n",
      "Epoch:  90 Batch:   0 Loss: 0.79431 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.78943 Accuracy: 0.03125\n",
      "Epoch:  92 Batch:   0 Loss: 0.78464 Accuracy: 0.03125\n",
      "Epoch:  93 Batch:   0 Loss: 0.77990 Accuracy: 0.03125\n",
      "Epoch:  94 Batch:   0 Loss: 0.77522 Accuracy: 0.03125\n",
      "Epoch:  95 Batch:   0 Loss: 0.77061 Accuracy: 0.09375\n",
      "Epoch:  96 Batch:   0 Loss: 0.76605 Accuracy: 0.15625\n",
      "Epoch:  97 Batch:   0 Loss: 0.76156 Accuracy: 0.15625\n",
      "Epoch:  98 Batch:   0 Loss: 0.75713 Accuracy: 0.18750\n",
      "Epoch:  99 Batch:   0 Loss: 0.75278 Accuracy: 0.31250\n",
      "Test Loss: 0.69271 Accuracy: 0.60993\n",
      "Epoch: 100 Batch:   0 Loss: 0.74848 Accuracy: 0.37500\n",
      "Epoch: 101 Batch:   0 Loss: 0.74424 Accuracy: 0.46875\n",
      "Epoch: 102 Batch:   0 Loss: 0.74004 Accuracy: 0.53125\n",
      "Epoch: 103 Batch:   0 Loss: 0.73591 Accuracy: 0.62500\n",
      "Epoch: 104 Batch:   0 Loss: 0.73184 Accuracy: 0.62500\n",
      "Epoch: 105 Batch:   0 Loss: 0.72782 Accuracy: 0.65625\n",
      "Epoch: 106 Batch:   0 Loss: 0.72386 Accuracy: 0.65625\n",
      "Epoch: 107 Batch:   0 Loss: 0.71997 Accuracy: 0.65625\n",
      "Epoch: 108 Batch:   0 Loss: 0.71616 Accuracy: 0.65625\n",
      "Epoch: 109 Batch:   0 Loss: 0.71257 Accuracy: 0.65625\n",
      "Test Loss: 0.68459 Accuracy: 0.62279\n",
      "Epoch: 110 Batch:   0 Loss: 0.70888 Accuracy: 0.68750\n",
      "Epoch: 111 Batch:   0 Loss: 0.70519 Accuracy: 0.71875\n",
      "Epoch: 112 Batch:   0 Loss: 0.70155 Accuracy: 0.71875\n",
      "Epoch: 113 Batch:   0 Loss: 0.69797 Accuracy: 0.71875\n",
      "Epoch: 114 Batch:   0 Loss: 0.69443 Accuracy: 0.75000\n",
      "Epoch: 115 Batch:   0 Loss: 0.69093 Accuracy: 0.75000\n",
      "Epoch: 116 Batch:   0 Loss: 0.68749 Accuracy: 0.75000\n",
      "Epoch: 117 Batch:   0 Loss: 0.68409 Accuracy: 0.84375\n",
      "Epoch: 118 Batch:   0 Loss: 0.68075 Accuracy: 0.90625\n",
      "Epoch: 119 Batch:   0 Loss: 0.67747 Accuracy: 0.96875\n",
      "Test Loss: 0.67740 Accuracy: 0.64438\n",
      "Epoch: 120 Batch:   0 Loss: 0.67423 Accuracy: 0.96875\n",
      "Epoch: 121 Batch:   0 Loss: 0.67103 Accuracy: 0.96875\n",
      "Epoch: 122 Batch:   0 Loss: 0.66789 Accuracy: 0.96875\n",
      "Epoch: 123 Batch:   0 Loss: 0.66479 Accuracy: 1.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.66173 Accuracy: 1.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.65872 Accuracy: 1.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.65577 Accuracy: 1.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.65286 Accuracy: 1.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.65000 Accuracy: 1.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.64719 Accuracy: 1.00000\n",
      "Test Loss: 0.67143 Accuracy: 0.66508\n",
      "Epoch: 130 Batch:   0 Loss: 0.64443 Accuracy: 1.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.64171 Accuracy: 1.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.63904 Accuracy: 1.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.63642 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.63383 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.63129 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.62880 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.62635 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.62393 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.62155 Accuracy: 1.00000\n",
      "Test Loss: 0.66671 Accuracy: 0.68165\n",
      "Epoch: 140 Batch:   0 Loss: 0.61921 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.61691 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.61465 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.61245 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.61028 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.60814 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.60604 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.60398 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.60195 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.59996 Accuracy: 1.00000\n",
      "Test Loss: 0.66309 Accuracy: 0.69732\n",
      "Epoch: 150 Batch:   0 Loss: 0.59801 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.59608 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.59419 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.59232 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.59049 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.58869 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.58693 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.58519 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.58348 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.58180 Accuracy: 1.00000\n",
      "Test Loss: 0.66035 Accuracy: 0.70626\n",
      "Epoch: 160 Batch:   0 Loss: 0.58014 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.57851 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.57691 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.57534 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.57379 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.57227 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.57077 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.56930 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.56784 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.56642 Accuracy: 1.00000\n",
      "Test Loss: 0.65825 Accuracy: 0.71139\n",
      "Epoch: 170 Batch:   0 Loss: 0.56502 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.56363 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.56227 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.56093 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.55961 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.55832 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.55703 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.55578 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.55454 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.55331 Accuracy: 1.00000\n",
      "Test Loss: 0.65658 Accuracy: 0.71340\n",
      "Epoch: 180 Batch:   0 Loss: 0.55211 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.55092 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.54975 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.54860 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.54747 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.54635 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.54525 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.54416 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.54301 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.54173 Accuracy: 1.00000\n",
      "Test Loss: 0.65511 Accuracy: 0.71903\n",
      "Epoch: 190 Batch:   0 Loss: 0.54064 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.53960 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.53858 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.53758 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.53659 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.53563 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.53467 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.53371 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.53278 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.53185 Accuracy: 1.00000\n",
      "Test Loss: 0.65391 Accuracy: 0.72194\n",
      "Epoch: 200 Batch:   0 Loss: 0.53094 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.53004 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.52914 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.52826 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.52740 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.52654 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.52569 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.52485 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.52402 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.52321 Accuracy: 1.00000\n",
      "Test Loss: 0.65284 Accuracy: 0.72505\n",
      "Epoch: 210 Batch:   0 Loss: 0.52240 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.52160 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.52081 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.52003 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.51926 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.51850 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.51774 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.51700 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.51626 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.51553 Accuracy: 1.00000\n",
      "Test Loss: 0.65185 Accuracy: 0.72817\n",
      "Epoch: 220 Batch:   0 Loss: 0.51481 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.51410 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.51339 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.51269 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.51200 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.51132 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.51064 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.50997 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.50931 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.50865 Accuracy: 1.00000\n",
      "Test Loss: 0.65090 Accuracy: 0.73028\n",
      "Epoch: 230 Batch:   0 Loss: 0.50800 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.50735 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.50671 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.50608 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.50545 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.50483 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.50421 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.50360 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.50300 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.50240 Accuracy: 1.00000\n",
      "Test Loss: 0.64997 Accuracy: 0.73138\n",
      "Epoch: 240 Batch:   0 Loss: 0.50180 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.50122 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.50064 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.50006 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.49949 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.49892 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.49836 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.49780 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.49725 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.49671 Accuracy: 1.00000\n",
      "Test Loss: 0.64907 Accuracy: 0.73429\n",
      "Epoch: 250 Batch:   0 Loss: 0.49617 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.49563 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.49510 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.49457 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.49405 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.49353 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.49302 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.49251 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.49200 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.49150 Accuracy: 1.00000\n",
      "Test Loss: 0.64820 Accuracy: 0.73670\n",
      "Epoch: 260 Batch:   0 Loss: 0.49101 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.49051 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.49003 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.48955 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.48906 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.48855 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.48803 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.48752 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.48702 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.48652 Accuracy: 1.00000\n",
      "Test Loss: 0.64732 Accuracy: 0.73871\n",
      "Epoch: 270 Batch:   0 Loss: 0.48602 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.48553 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.48504 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.48456 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.48407 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.48360 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.48312 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.48265 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.48219 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.48173 Accuracy: 1.00000\n",
      "Test Loss: 0.64645 Accuracy: 0.74061\n",
      "Epoch: 280 Batch:   0 Loss: 0.48127 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.48082 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.48037 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.47992 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.47948 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.47904 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.47860 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.47817 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.47774 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.47732 Accuracy: 1.00000\n",
      "Test Loss: 0.64563 Accuracy: 0.74262\n",
      "Epoch: 290 Batch:   0 Loss: 0.47689 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.47647 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.47606 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.47564 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.47523 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.47478 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.47433 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.47387 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.47343 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.47298 Accuracy: 1.00000\n",
      "Test Loss: 0.64480 Accuracy: 0.74413\n",
      "Epoch: 300 Batch:   0 Loss: 0.47254 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.47211 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.47168 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.47125 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.47083 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.47041 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.46999 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.46958 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.46917 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.46876 Accuracy: 1.00000\n",
      "Test Loss: 0.64399 Accuracy: 0.74574\n",
      "Epoch: 310 Batch:   0 Loss: 0.46836 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.46796 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.46756 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.46717 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.46678 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.46639 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.46600 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.46576 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.46521 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.46479 Accuracy: 1.00000\n",
      "Test Loss: 0.64320 Accuracy: 0.74765\n",
      "Epoch: 320 Batch:   0 Loss: 0.46441 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.46405 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.46368 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.46332 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.46297 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.46261 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.46226 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.46190 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.46156 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.46121 Accuracy: 1.00000\n",
      "Test Loss: 0.64247 Accuracy: 0.74915\n",
      "Epoch: 330 Batch:   0 Loss: 0.46086 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.46052 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.46018 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.45984 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.45950 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.45917 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.45884 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.45851 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.45818 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.45786 Accuracy: 1.00000\n",
      "Test Loss: 0.64176 Accuracy: 0.75026\n",
      "Epoch: 340 Batch:   0 Loss: 0.45754 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.45722 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.45690 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.45658 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.45627 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.45595 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.45564 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.45533 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.45503 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.45472 Accuracy: 1.00000\n",
      "Test Loss: 0.64108 Accuracy: 0.75217\n",
      "Epoch: 350 Batch:   0 Loss: 0.45442 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.45412 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.45382 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.45352 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.45322 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.45293 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.45264 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.45234 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.45205 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.45177 Accuracy: 1.00000\n",
      "Test Loss: 0.64041 Accuracy: 0.75337\n",
      "Epoch: 360 Batch:   0 Loss: 0.45148 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.45119 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.45091 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.45063 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.45035 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.45007 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.44979 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.44951 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.44924 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.44895 Accuracy: 1.00000\n",
      "Test Loss: 0.63975 Accuracy: 0.75388\n",
      "Epoch: 370 Batch:   0 Loss: 0.44867 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.44839 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.44811 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.44784 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.44756 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.44729 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.44702 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.44675 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.44648 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.44621 Accuracy: 1.00000\n",
      "Test Loss: 0.63910 Accuracy: 0.75468\n",
      "Epoch: 380 Batch:   0 Loss: 0.44595 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.44569 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.44543 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.44516 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.44490 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.44465 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.44439 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.44413 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.44388 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.44363 Accuracy: 1.00000\n",
      "Test Loss: 0.63846 Accuracy: 0.75599\n",
      "Epoch: 390 Batch:   0 Loss: 0.44337 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.44312 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.44287 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.44262 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.44237 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.44212 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.44187 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.44163 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.44138 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.44114 Accuracy: 1.00000\n",
      "Test Loss: 0.63783 Accuracy: 0.75770\n",
      "Epoch: 400 Batch:   0 Loss: 0.44089 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.44065 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.44061 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.44027 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.44000 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.43975 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.43950 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.43926 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.43902 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.43878 Accuracy: 1.00000\n",
      "Test Loss: 0.63722 Accuracy: 0.75850\n",
      "Epoch: 410 Batch:   0 Loss: 0.43854 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.43830 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.43806 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.43782 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.43758 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.43735 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.43711 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.43688 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.43664 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.43641 Accuracy: 1.00000\n",
      "Test Loss: 0.63659 Accuracy: 0.75970\n",
      "Epoch: 420 Batch:   0 Loss: 0.43618 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.43595 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.43572 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.43549 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.43526 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.43503 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.43480 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.43457 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.43434 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.43412 Accuracy: 1.00000\n",
      "Test Loss: 0.63596 Accuracy: 0.76081\n",
      "Epoch: 430 Batch:   0 Loss: 0.43389 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.43367 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.43344 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.43322 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.43299 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.43277 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.43255 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.43233 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.43211 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.43189 Accuracy: 1.00000\n",
      "Test Loss: 0.63534 Accuracy: 0.76212\n",
      "Epoch: 440 Batch:   0 Loss: 0.43167 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.43145 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.43123 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.43101 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.43079 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.43057 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.43036 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.43014 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.42993 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.42971 Accuracy: 1.00000\n",
      "Test Loss: 0.63472 Accuracy: 0.76231\n",
      "Epoch: 450 Batch:   0 Loss: 0.42950 Accuracy: 1.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.42928 Accuracy: 1.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.42907 Accuracy: 1.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.42886 Accuracy: 1.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.42865 Accuracy: 1.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.42844 Accuracy: 1.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.42823 Accuracy: 1.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.42801 Accuracy: 1.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.42780 Accuracy: 1.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.42759 Accuracy: 1.00000\n",
      "Test Loss: 0.63412 Accuracy: 0.76322\n",
      "Epoch: 460 Batch:   0 Loss: 0.42739 Accuracy: 1.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.42718 Accuracy: 1.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.42697 Accuracy: 1.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.42676 Accuracy: 1.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.42655 Accuracy: 1.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.42635 Accuracy: 1.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.42614 Accuracy: 1.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.42593 Accuracy: 1.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.42573 Accuracy: 1.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.42552 Accuracy: 1.00000\n",
      "Test Loss: 0.63352 Accuracy: 0.76402\n",
      "Epoch: 470 Batch:   0 Loss: 0.42532 Accuracy: 1.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.42512 Accuracy: 1.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.42491 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:09:29,082] Trial 11 finished with value: 0.764173703256936 and parameters: {'REG_W': 3.2395899592085873e-06, 'REG_B': 0.0003664057333160444, 'REG_Z': 4.973956832128323e-05, 'SPAR_W': 0.9837845128293876, 'SPAR_B': 0.7837171297182737, 'SPAR_Z': 0.988068899370609, 'LEARNING_RATE': 0.0001012807558511427, 'NUM_EPOCHS': 473}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 4.40007 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 3.03392 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.88292 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.35881 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.18530 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.13539 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.12351 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.12198 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.12246 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.12269 Accuracy: 0.00000\n",
      "Test Loss: 0.74729 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.12206 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.12062 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.11843 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.11544 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.11167 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.10702 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.10166 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.09554 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.08883 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.08160 Accuracy: 0.00000\n",
      "Test Loss: 0.73037 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 1.07396 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.06587 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.05739 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.04881 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.04018 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.03140 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.02255 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.01380 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.00495 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 0.99615 Accuracy: 0.00000\n",
      "Test Loss: 0.71587 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 0.98736 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 0.97851 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 0.96994 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.96131 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.95268 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.94421 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.93596 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.92771 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.91947 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.91137 Accuracy: 0.00000\n",
      "Test Loss: 0.70527 Accuracy: 0.53919\n",
      "Epoch:  40 Batch:   0 Loss: 0.90344 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.89562 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.88790 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.88031 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.87283 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.86544 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.85818 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.85102 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.84395 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.83700 Accuracy: 0.00000\n",
      "Test Loss: 0.69358 Accuracy: 0.58863\n",
      "Epoch:  50 Batch:   0 Loss: 0.83016 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.82345 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.81684 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.81034 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.80391 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.79758 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.79141 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.78538 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.77948 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.77367 Accuracy: 0.03125\n",
      "Test Loss: 0.68232 Accuracy: 0.61214\n",
      "Epoch:  60 Batch:   0 Loss: 0.76799 Accuracy: 0.06250\n",
      "Epoch:  61 Batch:   0 Loss: 0.76241 Accuracy: 0.12500\n",
      "Epoch:  62 Batch:   0 Loss: 0.75695 Accuracy: 0.12500\n",
      "Epoch:  63 Batch:   0 Loss: 0.75157 Accuracy: 0.21875\n",
      "Epoch:  64 Batch:   0 Loss: 0.74630 Accuracy: 0.31250\n",
      "Epoch:  65 Batch:   0 Loss: 0.74111 Accuracy: 0.40625\n",
      "Epoch:  66 Batch:   0 Loss: 0.73608 Accuracy: 0.40625\n",
      "Epoch:  67 Batch:   0 Loss: 0.73111 Accuracy: 0.59375\n",
      "Epoch:  68 Batch:   0 Loss: 0.72627 Accuracy: 0.68750\n",
      "Epoch:  69 Batch:   0 Loss: 0.72153 Accuracy: 0.75000\n",
      "Test Loss: 0.67272 Accuracy: 0.64268\n",
      "Epoch:  70 Batch:   0 Loss: 0.71688 Accuracy: 0.78125\n",
      "Epoch:  71 Batch:   0 Loss: 0.71231 Accuracy: 0.78125\n",
      "Epoch:  72 Batch:   0 Loss: 0.70781 Accuracy: 0.84375\n",
      "Epoch:  73 Batch:   0 Loss: 0.70337 Accuracy: 0.87500\n",
      "Epoch:  74 Batch:   0 Loss: 0.69906 Accuracy: 0.90625\n",
      "Epoch:  75 Batch:   0 Loss: 0.69482 Accuracy: 0.90625\n",
      "Epoch:  76 Batch:   0 Loss: 0.69066 Accuracy: 0.96875\n",
      "Epoch:  77 Batch:   0 Loss: 0.68659 Accuracy: 0.96875\n",
      "Epoch:  78 Batch:   0 Loss: 0.68261 Accuracy: 0.96875\n",
      "Epoch:  79 Batch:   0 Loss: 0.67871 Accuracy: 0.96875\n",
      "Test Loss: 0.66520 Accuracy: 0.66810\n",
      "Epoch:  80 Batch:   0 Loss: 0.67490 Accuracy: 0.96875\n",
      "Epoch:  81 Batch:   0 Loss: 0.67116 Accuracy: 0.96875\n",
      "Epoch:  82 Batch:   0 Loss: 0.66750 Accuracy: 0.96875\n",
      "Epoch:  83 Batch:   0 Loss: 0.66391 Accuracy: 0.96875\n",
      "Epoch:  84 Batch:   0 Loss: 0.66040 Accuracy: 0.96875\n",
      "Epoch:  85 Batch:   0 Loss: 0.65696 Accuracy: 0.96875\n",
      "Epoch:  86 Batch:   0 Loss: 0.65359 Accuracy: 1.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.65030 Accuracy: 1.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.64707 Accuracy: 1.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.64392 Accuracy: 1.00000\n",
      "Test Loss: 0.65970 Accuracy: 0.69261\n",
      "Epoch:  90 Batch:   0 Loss: 0.64076 Accuracy: 1.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.63764 Accuracy: 1.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.63460 Accuracy: 1.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.63160 Accuracy: 1.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.62868 Accuracy: 1.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.62581 Accuracy: 1.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.62300 Accuracy: 1.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.62026 Accuracy: 1.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.61757 Accuracy: 1.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.61494 Accuracy: 1.00000\n",
      "Test Loss: 0.65565 Accuracy: 0.71190\n",
      "Epoch: 100 Batch:   0 Loss: 0.61237 Accuracy: 1.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.60986 Accuracy: 1.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.60738 Accuracy: 1.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.60497 Accuracy: 1.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.60262 Accuracy: 1.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.60030 Accuracy: 1.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.59805 Accuracy: 1.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.59585 Accuracy: 1.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.59368 Accuracy: 1.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.59156 Accuracy: 1.00000\n",
      "Test Loss: 0.65296 Accuracy: 0.72134\n",
      "Epoch: 110 Batch:   0 Loss: 0.58951 Accuracy: 1.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.58749 Accuracy: 1.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.58550 Accuracy: 1.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.58356 Accuracy: 1.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.58166 Accuracy: 1.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.57980 Accuracy: 1.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.57798 Accuracy: 1.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.57620 Accuracy: 1.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.57445 Accuracy: 1.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.57274 Accuracy: 1.00000\n",
      "Test Loss: 0.65118 Accuracy: 0.72727\n",
      "Epoch: 120 Batch:   0 Loss: 0.57106 Accuracy: 1.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.56943 Accuracy: 1.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.56782 Accuracy: 1.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.56625 Accuracy: 1.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.56470 Accuracy: 1.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.56319 Accuracy: 1.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.56171 Accuracy: 1.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.56026 Accuracy: 1.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.55884 Accuracy: 1.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.55744 Accuracy: 1.00000\n",
      "Test Loss: 0.64999 Accuracy: 0.72837\n",
      "Epoch: 130 Batch:   0 Loss: 0.55607 Accuracy: 1.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.55474 Accuracy: 1.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.55343 Accuracy: 1.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.55214 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.55088 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.54964 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.54843 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.54724 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.54607 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.54492 Accuracy: 1.00000\n",
      "Test Loss: 0.64916 Accuracy: 0.73259\n",
      "Epoch: 140 Batch:   0 Loss: 0.54380 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.54269 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.54160 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.54054 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.53949 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.53846 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.53745 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.53645 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.53548 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.53452 Accuracy: 1.00000\n",
      "Test Loss: 0.64857 Accuracy: 0.73269\n",
      "Epoch: 150 Batch:   0 Loss: 0.53358 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.53265 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.53174 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.53085 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.52997 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.52910 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.52825 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.52741 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.52659 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.52579 Accuracy: 1.00000\n",
      "Test Loss: 0.64810 Accuracy: 0.73389\n",
      "Epoch: 160 Batch:   0 Loss: 0.52499 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.52421 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.52344 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.52268 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.52193 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.52119 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.52047 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.51975 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.51905 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.51836 Accuracy: 1.00000\n",
      "Test Loss: 0.64771 Accuracy: 0.73560\n",
      "Epoch: 170 Batch:   0 Loss: 0.51768 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.51700 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.51634 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.51569 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.51505 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.51441 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.51379 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.51318 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.51257 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.51197 Accuracy: 1.00000\n",
      "Test Loss: 0.64736 Accuracy: 0.73730\n",
      "Epoch: 180 Batch:   0 Loss: 0.51137 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.51079 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.51022 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.50965 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.50909 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.50853 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.50798 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.50744 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.50691 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.50638 Accuracy: 1.00000\n",
      "Test Loss: 0.64703 Accuracy: 0.73821\n",
      "Epoch: 190 Batch:   0 Loss: 0.50586 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.50535 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.50484 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.50434 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.50384 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.50336 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.50289 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.50240 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.50194 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.50147 Accuracy: 1.00000\n",
      "Test Loss: 0.64671 Accuracy: 0.73972\n",
      "Epoch: 200 Batch:   0 Loss: 0.50102 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.50056 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.50010 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.49966 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.49921 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.49878 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.49835 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.49792 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.49750 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.49708 Accuracy: 1.00000\n",
      "Test Loss: 0.64638 Accuracy: 0.74223\n",
      "Epoch: 210 Batch:   0 Loss: 0.49667 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.49626 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.49585 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.49545 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.49506 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.49467 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.49428 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.49389 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.49351 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.49313 Accuracy: 1.00000\n",
      "Test Loss: 0.64603 Accuracy: 0.74353\n",
      "Epoch: 220 Batch:   0 Loss: 0.49276 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.49239 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.49202 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.49166 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.49130 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.49094 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.49059 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.49024 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.48989 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.48954 Accuracy: 1.00000\n",
      "Test Loss: 0.64568 Accuracy: 0.74514\n",
      "Epoch: 230 Batch:   0 Loss: 0.48920 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.48886 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.48852 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.48819 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.48786 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.48753 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.48721 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.48689 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.48657 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.48625 Accuracy: 1.00000\n",
      "Test Loss: 0.64532 Accuracy: 0.74725\n",
      "Epoch: 240 Batch:   0 Loss: 0.48593 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.48562 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.48531 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.48500 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.48470 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.48440 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.48410 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.48380 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.48350 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.48321 Accuracy: 1.00000\n",
      "Test Loss: 0.64494 Accuracy: 0.74926\n",
      "Epoch: 250 Batch:   0 Loss: 0.48292 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.48263 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.48234 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.48206 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.48178 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.48149 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.48121 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.48094 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.48066 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.48039 Accuracy: 1.00000\n",
      "Test Loss: 0.64456 Accuracy: 0.74926\n",
      "Epoch: 260 Batch:   0 Loss: 0.48011 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.47984 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.47957 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.47930 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.47904 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.47877 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.47851 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.47825 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.47799 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.47773 Accuracy: 1.00000\n",
      "Test Loss: 0.64417 Accuracy: 0.75056\n",
      "Epoch: 270 Batch:   0 Loss: 0.47748 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.47722 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.47697 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.47672 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.47647 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.47622 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.47597 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.47572 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.47548 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.47524 Accuracy: 1.00000\n",
      "Test Loss: 0.64377 Accuracy: 0.75177\n",
      "Epoch: 280 Batch:   0 Loss: 0.47500 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.47476 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.47452 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.47428 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.47404 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.47381 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.47358 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.47335 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.47311 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.47288 Accuracy: 1.00000\n",
      "Test Loss: 0.64336 Accuracy: 0.75267\n",
      "Epoch: 290 Batch:   0 Loss: 0.47265 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.47243 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.47220 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.47198 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.47175 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.47153 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.47131 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.47109 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.47087 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.47065 Accuracy: 1.00000\n",
      "Test Loss: 0.64293 Accuracy: 0.75318\n",
      "Epoch: 300 Batch:   0 Loss: 0.47040 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.47016 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.46992 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.46967 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.46944 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.46920 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.46896 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.46873 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.46850 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.46828 Accuracy: 1.00000\n",
      "Test Loss: 0.64244 Accuracy: 0.75428\n",
      "Epoch: 310 Batch:   0 Loss: 0.46805 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.46783 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.46760 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.46738 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.46716 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.46695 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.46673 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.46651 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.46630 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.46609 Accuracy: 1.00000\n",
      "Test Loss: 0.64197 Accuracy: 0.75589\n",
      "Epoch: 320 Batch:   0 Loss: 0.46588 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.46568 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.46547 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.46527 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.46506 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.46486 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.46464 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.46441 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.46419 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.46397 Accuracy: 1.00000\n",
      "Test Loss: 0.64147 Accuracy: 0.75689\n",
      "Epoch: 330 Batch:   0 Loss: 0.46375 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.46353 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.46332 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.46311 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.46290 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.46269 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.46249 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.46229 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.46208 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.46188 Accuracy: 1.00000\n",
      "Test Loss: 0.64096 Accuracy: 0.75720\n",
      "Epoch: 340 Batch:   0 Loss: 0.46169 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.46149 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.46129 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.46110 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.46091 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.46071 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.46052 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.46034 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.46015 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.45996 Accuracy: 1.00000\n",
      "Test Loss: 0.64044 Accuracy: 0.75850\n",
      "Epoch: 350 Batch:   0 Loss: 0.45977 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.45958 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.45940 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.45922 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.45903 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.45885 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.45867 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.45849 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.45831 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.45813 Accuracy: 1.00000\n",
      "Test Loss: 0.63992 Accuracy: 0.75951\n",
      "Epoch: 360 Batch:   0 Loss: 0.45796 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.45778 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.45760 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.45743 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.45725 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.45708 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.45690 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.45673 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.45656 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.45639 Accuracy: 1.00000\n",
      "Test Loss: 0.63941 Accuracy: 0.76001\n",
      "Epoch: 370 Batch:   0 Loss: 0.45622 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.45606 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.45589 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.45573 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.45556 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.45540 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.45523 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.45507 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.45491 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.45474 Accuracy: 1.00000\n",
      "Test Loss: 0.63892 Accuracy: 0.76011\n",
      "Epoch: 380 Batch:   0 Loss: 0.45459 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.45443 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.45427 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.45411 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.45395 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.45379 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.45363 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.45347 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.45332 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.45316 Accuracy: 1.00000\n",
      "Test Loss: 0.63844 Accuracy: 0.76041\n",
      "Epoch: 390 Batch:   0 Loss: 0.45300 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.45284 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.45269 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.45253 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.45238 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.45222 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.45207 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.45191 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.45176 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.45160 Accuracy: 1.00000\n",
      "Test Loss: 0.63797 Accuracy: 0.76141\n",
      "Epoch: 400 Batch:   0 Loss: 0.45145 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.45130 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.45114 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.45099 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.45083 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.45068 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.45053 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.45038 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.45023 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.45007 Accuracy: 1.00000\n",
      "Test Loss: 0.63753 Accuracy: 0.76262\n",
      "Epoch: 410 Batch:   0 Loss: 0.44992 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.44976 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.44961 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.44946 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.44931 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.44915 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.44900 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.44885 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.44870 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.44855 Accuracy: 1.00000\n",
      "Test Loss: 0.63709 Accuracy: 0.76352\n",
      "Epoch: 420 Batch:   0 Loss: 0.44840 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.44825 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.44810 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.44795 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.44780 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.44765 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.44750 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.44735 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.44720 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.44705 Accuracy: 1.00000\n",
      "Test Loss: 0.63666 Accuracy: 0.76322\n",
      "Epoch: 430 Batch:   0 Loss: 0.44690 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.44676 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.44661 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.44646 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.44631 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.44616 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.44601 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.44586 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.44571 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.44556 Accuracy: 1.00000\n",
      "Test Loss: 0.63624 Accuracy: 0.76372\n",
      "Epoch: 440 Batch:   0 Loss: 0.44542 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.44527 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.44512 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.44497 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.44483 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.44468 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.44453 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.44439 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.44424 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.44409 Accuracy: 1.00000\n",
      "Test Loss: 0.63583 Accuracy: 0.76453\n",
      "Epoch: 450 Batch:   0 Loss: 0.44395 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:14:51,984] Trial 12 finished with value: 0.7646763168476076 and parameters: {'REG_W': 3.220491817791798e-06, 'REG_B': 0.0005350984518690573, 'REG_Z': 4.898567836971721e-05, 'SPAR_W': 0.9871943753190696, 'SPAR_B': 0.7865101139326912, 'SPAR_Z': 0.9854272311827109, 'LEARNING_RATE': 0.00010566103743412826, 'NUM_EPOCHS': 451}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 1.96295 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.43166 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.17168 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.09669 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.07652 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.07033 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.06668 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.06263 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.05761 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.05168 Accuracy: 0.00000\n",
      "Test Loss: 0.72899 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.04509 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.03776 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.02999 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.02203 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.01411 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.00595 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 0.99780 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 0.98988 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 0.98199 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 0.97370 Accuracy: 0.00000\n",
      "Test Loss: 0.70824 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 0.96546 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 0.95742 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 0.94955 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 0.94168 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 0.93364 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 0.92557 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 0.91768 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 0.90962 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 0.90153 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 0.89336 Accuracy: 0.00000\n",
      "Test Loss: 0.68889 Accuracy: 0.54190\n",
      "Epoch:  30 Batch:   0 Loss: 0.88504 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 0.87669 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 0.86802 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.85934 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.85062 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.84169 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.83273 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.82359 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.81433 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.80514 Accuracy: 0.00000\n",
      "Test Loss: 0.66583 Accuracy: 0.59374\n",
      "Epoch:  40 Batch:   0 Loss: 0.79592 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.78643 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.77704 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.76762 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.75812 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.74864 Accuracy: 0.06250\n",
      "Epoch:  46 Batch:   0 Loss: 0.73896 Accuracy: 0.09375\n",
      "Epoch:  47 Batch:   0 Loss: 0.72939 Accuracy: 0.18750\n",
      "Epoch:  48 Batch:   0 Loss: 0.71988 Accuracy: 0.21875\n",
      "Epoch:  49 Batch:   0 Loss: 0.71039 Accuracy: 0.31250\n",
      "Test Loss: 0.64118 Accuracy: 0.63785\n",
      "Epoch:  50 Batch:   0 Loss: 0.70094 Accuracy: 0.56250\n",
      "Epoch:  51 Batch:   0 Loss: 0.69153 Accuracy: 0.62500\n",
      "Epoch:  52 Batch:   0 Loss: 0.68216 Accuracy: 0.71875\n",
      "Epoch:  53 Batch:   0 Loss: 0.67285 Accuracy: 0.84375\n",
      "Epoch:  54 Batch:   0 Loss: 0.66363 Accuracy: 0.87500\n",
      "Epoch:  55 Batch:   0 Loss: 0.65444 Accuracy: 0.87500\n",
      "Epoch:  56 Batch:   0 Loss: 0.64534 Accuracy: 0.90625\n",
      "Epoch:  57 Batch:   0 Loss: 0.63635 Accuracy: 0.93750\n",
      "Epoch:  58 Batch:   0 Loss: 0.62744 Accuracy: 1.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.61863 Accuracy: 1.00000\n",
      "Test Loss: 0.61766 Accuracy: 0.67684\n",
      "Epoch:  60 Batch:   0 Loss: 0.60987 Accuracy: 1.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.60122 Accuracy: 1.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.59267 Accuracy: 1.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.58422 Accuracy: 1.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.57583 Accuracy: 1.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.56759 Accuracy: 1.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.55945 Accuracy: 1.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.55141 Accuracy: 1.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.54348 Accuracy: 1.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.53564 Accuracy: 1.00000\n",
      "Test Loss: 0.59681 Accuracy: 0.70697\n",
      "Epoch:  70 Batch:   0 Loss: 0.52791 Accuracy: 1.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.52028 Accuracy: 1.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.51278 Accuracy: 1.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.50538 Accuracy: 1.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.49809 Accuracy: 1.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.49093 Accuracy: 1.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.48388 Accuracy: 1.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.47695 Accuracy: 1.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.47012 Accuracy: 1.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.46343 Accuracy: 1.00000\n",
      "Test Loss: 0.57929 Accuracy: 0.71852\n",
      "Epoch:  80 Batch:   0 Loss: 0.45684 Accuracy: 1.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.45035 Accuracy: 1.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.44399 Accuracy: 1.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.43773 Accuracy: 1.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.43158 Accuracy: 1.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.42555 Accuracy: 1.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.41962 Accuracy: 1.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.41379 Accuracy: 1.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.40808 Accuracy: 1.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.40245 Accuracy: 1.00000\n",
      "Test Loss: 0.56527 Accuracy: 0.72916\n",
      "Epoch:  90 Batch:   0 Loss: 0.39693 Accuracy: 1.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.39152 Accuracy: 1.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.38621 Accuracy: 1.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.38100 Accuracy: 1.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.37589 Accuracy: 1.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.37088 Accuracy: 1.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.36595 Accuracy: 1.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.36111 Accuracy: 1.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.35638 Accuracy: 1.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.35173 Accuracy: 1.00000\n",
      "Test Loss: 0.55445 Accuracy: 0.73567\n",
      "Epoch: 100 Batch:   0 Loss: 0.34717 Accuracy: 1.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.34271 Accuracy: 1.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.33833 Accuracy: 1.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.33403 Accuracy: 1.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.32983 Accuracy: 1.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.32569 Accuracy: 1.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.32165 Accuracy: 1.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.31768 Accuracy: 1.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.31381 Accuracy: 1.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.31001 Accuracy: 1.00000\n",
      "Test Loss: 0.54635 Accuracy: 0.74069\n",
      "Epoch: 110 Batch:   0 Loss: 0.30630 Accuracy: 1.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.30266 Accuracy: 1.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.29909 Accuracy: 1.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.29559 Accuracy: 1.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.29217 Accuracy: 1.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.28881 Accuracy: 1.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.28552 Accuracy: 1.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.28230 Accuracy: 1.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.27914 Accuracy: 1.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.27606 Accuracy: 1.00000\n",
      "Test Loss: 0.54045 Accuracy: 0.74280\n",
      "Epoch: 120 Batch:   0 Loss: 0.27305 Accuracy: 1.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.27009 Accuracy: 1.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.26718 Accuracy: 1.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.26436 Accuracy: 1.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.26157 Accuracy: 1.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.25884 Accuracy: 1.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.25617 Accuracy: 1.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.25355 Accuracy: 1.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.25098 Accuracy: 1.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.24847 Accuracy: 1.00000\n",
      "Test Loss: 0.53630 Accuracy: 0.74441\n",
      "Epoch: 130 Batch:   0 Loss: 0.24602 Accuracy: 1.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.24362 Accuracy: 1.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.24128 Accuracy: 1.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.23898 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.23673 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.23452 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.23236 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.23025 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.22817 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.22614 Accuracy: 1.00000\n",
      "Test Loss: 0.53343 Accuracy: 0.74672\n",
      "Epoch: 140 Batch:   0 Loss: 0.22415 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.22220 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.22031 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.21845 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.21662 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.21484 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.21310 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.21140 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.20974 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.20811 Accuracy: 1.00000\n",
      "Test Loss: 0.53152 Accuracy: 0.75043\n",
      "Epoch: 150 Batch:   0 Loss: 0.20652 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.20495 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.20342 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.20192 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.20045 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.19902 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.19761 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.19623 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.19488 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.19356 Accuracy: 1.00000\n",
      "Test Loss: 0.53026 Accuracy: 0.75244\n",
      "Epoch: 160 Batch:   0 Loss: 0.19227 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.19100 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.18976 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.18855 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.18737 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.18620 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.18507 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.18396 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.18285 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.18170 Accuracy: 1.00000\n",
      "Test Loss: 0.52941 Accuracy: 0.75546\n",
      "Epoch: 170 Batch:   0 Loss: 0.18062 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.17959 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.17859 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.17761 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.17665 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.17571 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.17478 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.17388 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.17299 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.17213 Accuracy: 1.00000\n",
      "Test Loss: 0.52885 Accuracy: 0.75877\n",
      "Epoch: 180 Batch:   0 Loss: 0.17128 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.17045 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.16963 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.16883 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.16804 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.16727 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.16652 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.16578 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.16505 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.16434 Accuracy: 1.00000\n",
      "Test Loss: 0.52841 Accuracy: 0.76108\n",
      "Epoch: 190 Batch:   0 Loss: 0.16364 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.16295 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.16229 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.16164 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.16100 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.16037 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.15975 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.15915 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.15856 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.15804 Accuracy: 1.00000\n",
      "Test Loss: 0.52810 Accuracy: 0.76098\n",
      "Epoch: 200 Batch:   0 Loss: 0.15749 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.15693 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.15638 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.15584 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.15531 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.15479 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.15429 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.15379 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.15330 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.15283 Accuracy: 1.00000\n",
      "Test Loss: 0.52784 Accuracy: 0.76218\n",
      "Epoch: 210 Batch:   0 Loss: 0.15236 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.15190 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.15145 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.15101 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.15058 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.15015 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.14974 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.14933 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.14893 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.14853 Accuracy: 1.00000\n",
      "Test Loss: 0.52761 Accuracy: 0.76339\n",
      "Epoch: 220 Batch:   0 Loss: 0.14815 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.14778 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.14740 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.14704 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.14668 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.14633 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.14598 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.14565 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.14532 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.14500 Accuracy: 1.00000\n",
      "Test Loss: 0.52737 Accuracy: 0.76500\n",
      "Epoch: 230 Batch:   0 Loss: 0.14468 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.14436 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.14405 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.14375 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.14346 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.14317 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.14288 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.14261 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.14233 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.14206 Accuracy: 1.00000\n",
      "Test Loss: 0.52712 Accuracy: 0.76651\n",
      "Epoch: 240 Batch:   0 Loss: 0.14179 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.14152 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.14127 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.14102 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.14077 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.14054 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.14030 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.14007 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.13985 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.13964 Accuracy: 1.00000\n",
      "Test Loss: 0.52686 Accuracy: 0.76771\n",
      "Epoch: 250 Batch:   0 Loss: 0.13942 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.13921 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.13896 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.13874 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.13855 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.13836 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.13817 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.13799 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.13781 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.13763 Accuracy: 1.00000\n",
      "Test Loss: 0.52655 Accuracy: 0.76882\n",
      "Epoch: 260 Batch:   0 Loss: 0.13746 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.13729 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.13712 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.13696 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.13680 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.13664 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.13649 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.13633 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.13618 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.13604 Accuracy: 1.00000\n",
      "Test Loss: 0.52624 Accuracy: 0.76942\n",
      "Epoch: 270 Batch:   0 Loss: 0.13589 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.13575 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.13561 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.13547 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.13534 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.13521 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.13508 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.13496 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.13483 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.13471 Accuracy: 1.00000\n",
      "Test Loss: 0.52597 Accuracy: 0.77113\n",
      "Epoch: 280 Batch:   0 Loss: 0.13460 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.13448 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.13437 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.13426 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.13415 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.13405 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.13394 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.13384 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.13375 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.13365 Accuracy: 1.00000\n",
      "Test Loss: 0.52572 Accuracy: 0.77193\n",
      "Epoch: 290 Batch:   0 Loss: 0.13356 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.13347 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.13338 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.13329 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.13321 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.13312 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.13303 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.13296 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.13288 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.13281 Accuracy: 1.00000\n",
      "Test Loss: 0.52549 Accuracy: 0.77203\n",
      "Epoch: 300 Batch:   0 Loss: 0.13274 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.13267 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.13260 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.13253 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.13246 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.13240 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.13233 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.13227 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.13221 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.13215 Accuracy: 1.00000\n",
      "Test Loss: 0.52532 Accuracy: 0.77344\n",
      "Epoch: 310 Batch:   0 Loss: 0.13209 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.13203 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.13198 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.13192 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.13187 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.13181 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.13176 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.13171 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.13166 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.13161 Accuracy: 1.00000\n",
      "Test Loss: 0.52520 Accuracy: 0.77474\n",
      "Epoch: 320 Batch:   0 Loss: 0.13157 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.13152 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.13148 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.13143 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.13139 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.13135 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.13131 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.13127 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.13123 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.13119 Accuracy: 1.00000\n",
      "Test Loss: 0.52511 Accuracy: 0.77635\n",
      "Epoch: 330 Batch:   0 Loss: 0.13114 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.13111 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.13107 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.13103 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.13100 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.13096 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.13093 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.13089 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.13086 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.13084 Accuracy: 1.00000\n",
      "Test Loss: 0.52509 Accuracy: 0.77655\n",
      "Epoch: 340 Batch:   0 Loss: 0.13081 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.13078 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.13076 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.13073 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.13070 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.13067 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.13065 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.13062 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.13060 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.13057 Accuracy: 1.00000\n",
      "Test Loss: 0.52510 Accuracy: 0.77746\n",
      "Epoch: 350 Batch:   0 Loss: 0.13055 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.13053 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.13050 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.13048 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.13046 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.13044 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.13041 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.13040 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.13037 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.13035 Accuracy: 1.00000\n",
      "Test Loss: 0.52515 Accuracy: 0.77776\n",
      "Epoch: 360 Batch:   0 Loss: 0.13034 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.13032 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.13031 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.13030 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.13028 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.13027 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.13026 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.13024 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.13023 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.13022 Accuracy: 1.00000\n",
      "Test Loss: 0.52524 Accuracy: 0.77917\n",
      "Epoch: 370 Batch:   0 Loss: 0.13020 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.13019 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.13018 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.13017 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.13015 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.13014 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.13013 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.13011 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.13010 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.13009 Accuracy: 1.00000\n",
      "Test Loss: 0.52539 Accuracy: 0.78027\n",
      "Epoch: 380 Batch:   0 Loss: 0.13008 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.13007 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.13006 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.13005 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.13004 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.13003 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.13002 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.13002 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.13001 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.13000 Accuracy: 1.00000\n",
      "Test Loss: 0.52558 Accuracy: 0.78047\n",
      "Epoch: 390 Batch:   0 Loss: 0.12999 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.12999 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.12998 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.12997 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.12996 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.12995 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.12994 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.12993 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.12992 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.12991 Accuracy: 1.00000\n",
      "Test Loss: 0.52581 Accuracy: 0.78107\n",
      "Epoch: 400 Batch:   0 Loss: 0.12991 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.12990 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.12989 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.12988 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.12988 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.12987 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.12987 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.12986 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.12985 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.12985 Accuracy: 1.00000\n",
      "Test Loss: 0.52609 Accuracy: 0.78157\n",
      "Epoch: 410 Batch:   0 Loss: 0.12984 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.12984 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.12983 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.12983 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.12982 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.12982 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.12981 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.12981 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.12980 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.12980 Accuracy: 1.00000\n",
      "Test Loss: 0.52642 Accuracy: 0.78217\n",
      "Epoch: 420 Batch:   0 Loss: 0.12979 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.12977 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.12976 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.12975 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.12974 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.12974 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.12973 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.12973 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.12972 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.12971 Accuracy: 1.00000\n",
      "Test Loss: 0.52681 Accuracy: 0.78298\n",
      "Epoch: 430 Batch:   0 Loss: 0.12971 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.12970 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.12970 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.12969 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.12969 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.12968 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.12967 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.12967 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.12967 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.12966 Accuracy: 1.00000\n",
      "Test Loss: 0.52723 Accuracy: 0.78358\n",
      "Epoch: 440 Batch:   0 Loss: 0.12965 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.12964 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:19:25,821] Trial 13 finished with value: 0.783373542420587 and parameters: {'REG_W': 3.2463815718835868e-06, 'REG_B': 3.572113501268689e-06, 'REG_Z': 4.9983371351560104e-05, 'SPAR_W': 0.9243469318758182, 'SPAR_B': 0.8076493738250382, 'SPAR_Z': 0.99383634206201, 'LEARNING_RATE': 0.0001038928417897229, 'NUM_EPOCHS': 442}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 3.46925 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.85211 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.61304 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.62114 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.63809 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.64711 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.64986 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.64857 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.64366 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.63586 Accuracy: 0.00000\n",
      "Test Loss: 0.86037 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.62592 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.61415 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.60080 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.58615 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.57044 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.55370 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.53636 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.51819 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.49942 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.48005 Accuracy: 0.00000\n",
      "Test Loss: 0.82881 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 1.46051 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.44069 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.42021 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.40006 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.37853 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.35698 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.33584 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.31483 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.29332 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.27259 Accuracy: 0.00000\n",
      "Test Loss: 0.80946 Accuracy: 0.50764\n",
      "Epoch:  30 Batch:   0 Loss: 1.25187 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.23134 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.21093 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.19095 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.17099 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.15171 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.13284 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.11444 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.09638 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.07860 Accuracy: 0.00000\n",
      "Test Loss: 0.78710 Accuracy: 0.53808\n",
      "Epoch:  40 Batch:   0 Loss: 1.06093 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.04403 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.02758 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.01142 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.99525 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.97988 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.96517 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.95075 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.93686 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.92325 Accuracy: 0.00000\n",
      "Test Loss: 0.76301 Accuracy: 0.55938\n",
      "Epoch:  50 Batch:   0 Loss: 0.91007 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.89724 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.88469 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.87263 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.86099 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.84964 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.83860 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.82791 Accuracy: 0.03125\n",
      "Epoch:  58 Batch:   0 Loss: 0.81758 Accuracy: 0.03125\n",
      "Epoch:  59 Batch:   0 Loss: 0.80749 Accuracy: 0.06250\n",
      "Test Loss: 0.74420 Accuracy: 0.59937\n",
      "Epoch:  60 Batch:   0 Loss: 0.79776 Accuracy: 0.12500\n",
      "Epoch:  61 Batch:   0 Loss: 0.78823 Accuracy: 0.21875\n",
      "Epoch:  62 Batch:   0 Loss: 0.77902 Accuracy: 0.21875\n",
      "Epoch:  63 Batch:   0 Loss: 0.77012 Accuracy: 0.34375\n",
      "Epoch:  64 Batch:   0 Loss: 0.76148 Accuracy: 0.40625\n",
      "Epoch:  65 Batch:   0 Loss: 0.75309 Accuracy: 0.46875\n",
      "Epoch:  66 Batch:   0 Loss: 0.74496 Accuracy: 0.56250\n",
      "Epoch:  67 Batch:   0 Loss: 0.73704 Accuracy: 0.65625\n",
      "Epoch:  68 Batch:   0 Loss: 0.72936 Accuracy: 0.75000\n",
      "Epoch:  69 Batch:   0 Loss: 0.72192 Accuracy: 0.81250\n",
      "Test Loss: 0.73154 Accuracy: 0.63735\n",
      "Epoch:  70 Batch:   0 Loss: 0.71471 Accuracy: 0.87500\n",
      "Epoch:  71 Batch:   0 Loss: 0.70776 Accuracy: 0.90625\n",
      "Epoch:  72 Batch:   0 Loss: 0.70109 Accuracy: 0.93750\n",
      "Epoch:  73 Batch:   0 Loss: 0.69463 Accuracy: 0.96875\n",
      "Epoch:  74 Batch:   0 Loss: 0.68837 Accuracy: 1.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.68229 Accuracy: 1.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.67640 Accuracy: 1.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.67069 Accuracy: 1.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.66520 Accuracy: 1.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.66002 Accuracy: 1.00000\n",
      "Test Loss: 0.72420 Accuracy: 0.66710\n",
      "Epoch:  80 Batch:   0 Loss: 0.65529 Accuracy: 1.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.65030 Accuracy: 1.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.64540 Accuracy: 1.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.64070 Accuracy: 1.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.63611 Accuracy: 1.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.63168 Accuracy: 1.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.62739 Accuracy: 1.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.62324 Accuracy: 1.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.61921 Accuracy: 1.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.61533 Accuracy: 1.00000\n",
      "Test Loss: 0.71926 Accuracy: 0.68378\n",
      "Epoch:  90 Batch:   0 Loss: 0.61158 Accuracy: 1.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.60791 Accuracy: 1.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.60431 Accuracy: 1.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.60085 Accuracy: 1.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.59752 Accuracy: 1.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.59428 Accuracy: 1.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.59113 Accuracy: 1.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.58807 Accuracy: 1.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.58506 Accuracy: 1.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.58216 Accuracy: 1.00000\n",
      "Test Loss: 0.71563 Accuracy: 0.69734\n",
      "Epoch: 100 Batch:   0 Loss: 0.57931 Accuracy: 1.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.57654 Accuracy: 1.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.57386 Accuracy: 1.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.57126 Accuracy: 1.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.56873 Accuracy: 1.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.56624 Accuracy: 1.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.56384 Accuracy: 1.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.56152 Accuracy: 1.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.55924 Accuracy: 1.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.55703 Accuracy: 1.00000\n",
      "Test Loss: 0.71258 Accuracy: 0.70809\n",
      "Epoch: 110 Batch:   0 Loss: 0.55485 Accuracy: 1.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.55275 Accuracy: 1.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.55071 Accuracy: 1.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.54871 Accuracy: 1.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.54675 Accuracy: 1.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.54483 Accuracy: 1.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.54294 Accuracy: 1.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.54115 Accuracy: 1.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.53942 Accuracy: 1.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.53770 Accuracy: 1.00000\n",
      "Test Loss: 0.70970 Accuracy: 0.71401\n",
      "Epoch: 120 Batch:   0 Loss: 0.53603 Accuracy: 1.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.53435 Accuracy: 1.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.53246 Accuracy: 1.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.53089 Accuracy: 1.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.52937 Accuracy: 1.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.52788 Accuracy: 1.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.52641 Accuracy: 1.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.52496 Accuracy: 1.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.52353 Accuracy: 1.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.52222 Accuracy: 1.00000\n",
      "Test Loss: 0.70685 Accuracy: 0.71893\n",
      "Epoch: 130 Batch:   0 Loss: 0.52099 Accuracy: 1.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.51962 Accuracy: 1.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.51826 Accuracy: 1.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.51695 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.51567 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.51440 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.51315 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.51178 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.51085 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.50969 Accuracy: 1.00000\n",
      "Test Loss: 0.70418 Accuracy: 0.72295\n",
      "Epoch: 140 Batch:   0 Loss: 0.50854 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.50740 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.50629 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.50519 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.50412 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.50303 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.50197 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.50094 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.49993 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.49895 Accuracy: 1.00000\n",
      "Test Loss: 0.70160 Accuracy: 0.72687\n",
      "Epoch: 150 Batch:   0 Loss: 0.49798 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.49704 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.49610 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.49519 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.49429 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.49340 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.49253 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.49167 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.49082 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.48998 Accuracy: 1.00000\n",
      "Test Loss: 0.69905 Accuracy: 0.72878\n",
      "Epoch: 160 Batch:   0 Loss: 0.48914 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.48830 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.48749 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.48668 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.48588 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.48510 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.48433 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.48357 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.48281 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.48207 Accuracy: 1.00000\n",
      "Test Loss: 0.69654 Accuracy: 0.73159\n",
      "Epoch: 170 Batch:   0 Loss: 0.48135 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.48065 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.47995 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.47926 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.47857 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.47790 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.47723 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.47657 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.47591 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.47527 Accuracy: 1.00000\n",
      "Test Loss: 0.69408 Accuracy: 0.73380\n",
      "Epoch: 180 Batch:   0 Loss: 0.47463 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.47399 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.47336 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.47274 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.47199 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.47172 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.47091 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.47030 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.46969 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.46910 Accuracy: 1.00000\n",
      "Test Loss: 0.69172 Accuracy: 0.73661\n",
      "Epoch: 190 Batch:   0 Loss: 0.46851 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.46793 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.46734 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.46676 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.46619 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.46562 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.46506 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.46451 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.46395 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.46340 Accuracy: 1.00000\n",
      "Test Loss: 0.68948 Accuracy: 0.73862\n",
      "Epoch: 200 Batch:   0 Loss: 0.46286 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.46232 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.46178 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.46125 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.46072 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.46019 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.45967 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.45915 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.45863 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.45811 Accuracy: 1.00000\n",
      "Test Loss: 0.68733 Accuracy: 0.73963\n",
      "Epoch: 210 Batch:   0 Loss: 0.45761 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.45709 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.45658 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.45607 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.45557 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.45507 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.45458 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.45410 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.45361 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.45313 Accuracy: 1.00000\n",
      "Test Loss: 0.68522 Accuracy: 0.74234\n",
      "Epoch: 220 Batch:   0 Loss: 0.45265 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.45218 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.45170 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.45123 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.45076 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.45029 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.44982 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.44935 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.44889 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.44843 Accuracy: 1.00000\n",
      "Test Loss: 0.68308 Accuracy: 0.74334\n",
      "Epoch: 230 Batch:   0 Loss: 0.44799 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.44752 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.44706 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.44661 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.44616 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.44572 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.44528 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.44483 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.44440 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.44397 Accuracy: 1.00000\n",
      "Test Loss: 0.68098 Accuracy: 0.74535\n",
      "Epoch: 240 Batch:   0 Loss: 0.44354 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.44312 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.44270 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.44227 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.44185 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.44144 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.44103 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.44062 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.44021 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.43981 Accuracy: 1.00000\n",
      "Test Loss: 0.67909 Accuracy: 0.74686\n",
      "Epoch: 250 Batch:   0 Loss: 0.43940 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.43899 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.43859 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.43818 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.43778 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.43738 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.43699 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.43659 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.43619 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.43579 Accuracy: 1.00000\n",
      "Test Loss: 0.67733 Accuracy: 0.74937\n",
      "Epoch: 260 Batch:   0 Loss: 0.43541 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.43502 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.43463 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.43424 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.43385 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.43347 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.43308 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.43269 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.43199 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.43181 Accuracy: 1.00000\n",
      "Test Loss: 0.67560 Accuracy: 0.75148\n",
      "Epoch: 270 Batch:   0 Loss: 0.43143 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.43105 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.43067 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.43029 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.42990 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.42952 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.42914 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.42876 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.42838 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.42800 Accuracy: 1.00000\n",
      "Test Loss: 0.67403 Accuracy: 0.75329\n",
      "Epoch: 280 Batch:   0 Loss: 0.42763 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.42726 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.42689 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.42652 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.42616 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.42579 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.42543 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.42507 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.42470 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.42434 Accuracy: 1.00000\n",
      "Test Loss: 0.67255 Accuracy: 0.75470\n",
      "Epoch: 290 Batch:   0 Loss: 0.42398 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.42362 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.42326 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.42290 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.42255 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.42220 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.42185 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.42150 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.42114 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.42079 Accuracy: 1.00000\n",
      "Test Loss: 0.67112 Accuracy: 0.75560\n",
      "Epoch: 300 Batch:   0 Loss: 0.42045 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.42010 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.41975 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.41941 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.41907 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.41873 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.41829 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.41810 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.41770 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.41735 Accuracy: 1.00000\n",
      "Test Loss: 0.66980 Accuracy: 0.75630\n",
      "Epoch: 310 Batch:   0 Loss: 0.41701 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.41667 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.41633 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.41599 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.41566 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.41533 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.41500 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.41467 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.41433 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.41400 Accuracy: 1.00000\n",
      "Test Loss: 0.66858 Accuracy: 0.75751\n",
      "Epoch: 320 Batch:   0 Loss: 0.41366 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.41333 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.41300 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.41267 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.41234 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.41201 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.41169 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.41137 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.41104 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.41072 Accuracy: 1.00000\n",
      "Test Loss: 0.66745 Accuracy: 0.75801\n",
      "Epoch: 330 Batch:   0 Loss: 0.41040 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.41008 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.40976 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.40944 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.40912 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.40880 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.40848 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.40815 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.40783 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.40751 Accuracy: 1.00000\n",
      "Test Loss: 0.66638 Accuracy: 0.75851\n",
      "Epoch: 340 Batch:   0 Loss: 0.40719 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.40687 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.40655 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.40623 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.40592 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.40561 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.40529 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.40498 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.40467 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.40435 Accuracy: 1.00000\n",
      "Test Loss: 0.66539 Accuracy: 0.75931\n",
      "Epoch: 350 Batch:   0 Loss: 0.40404 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.40374 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.40343 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.40312 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.40281 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.40250 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.40219 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.40188 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.40158 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.40127 Accuracy: 1.00000\n",
      "Test Loss: 0.66448 Accuracy: 0.76002\n",
      "Epoch: 360 Batch:   0 Loss: 0.40097 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.40066 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.40035 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.40005 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.39975 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.39945 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.39915 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.39885 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.39855 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.39824 Accuracy: 1.00000\n",
      "Test Loss: 0.66364 Accuracy: 0.75971\n",
      "Epoch: 370 Batch:   0 Loss: 0.39793 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.39762 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.39732 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.39701 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.39672 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.39641 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.39610 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.39580 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.39550 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.39520 Accuracy: 1.00000\n",
      "Test Loss: 0.66287 Accuracy: 0.76112\n",
      "Epoch: 380 Batch:   0 Loss: 0.39491 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.39461 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.39431 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.39402 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.39372 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.39343 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.39313 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.39284 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.39255 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.39226 Accuracy: 1.00000\n",
      "Test Loss: 0.66213 Accuracy: 0.76152\n",
      "Epoch: 390 Batch:   0 Loss: 0.39197 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.39167 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.39138 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.39109 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.39081 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.39052 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.39023 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.38994 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.38965 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.38936 Accuracy: 1.00000\n",
      "Test Loss: 0.66143 Accuracy: 0.76223\n",
      "Epoch: 400 Batch:   0 Loss: 0.38908 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.38879 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.38851 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.38822 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.38793 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.38765 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.38736 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.38708 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.38680 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.38651 Accuracy: 1.00000\n",
      "Test Loss: 0.66076 Accuracy: 0.76293\n",
      "Epoch: 410 Batch:   0 Loss: 0.38623 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.38595 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.38568 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.38539 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.38511 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.38483 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.38455 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.38427 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.38400 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.38372 Accuracy: 1.00000\n",
      "Test Loss: 0.66014 Accuracy: 0.76313\n",
      "Epoch: 420 Batch:   0 Loss: 0.38345 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.38317 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.38290 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.38263 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.38236 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.38208 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.38180 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.38153 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.38126 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.38098 Accuracy: 1.00000\n",
      "Test Loss: 0.65956 Accuracy: 0.76393\n",
      "Epoch: 430 Batch:   0 Loss: 0.38071 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.38044 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.38016 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.37989 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.37962 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.37935 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.37908 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.37881 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.37854 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.37827 Accuracy: 1.00000\n",
      "Test Loss: 0.65900 Accuracy: 0.76424\n",
      "Epoch: 440 Batch:   0 Loss: 0.37801 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.37773 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.37746 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.37720 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.37693 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.37667 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.37641 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.37615 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.37589 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.37564 Accuracy: 1.00000\n",
      "Test Loss: 0.65847 Accuracy: 0.76454\n",
      "Epoch: 450 Batch:   0 Loss: 0.37538 Accuracy: 1.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.37512 Accuracy: 1.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.37487 Accuracy: 1.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.37461 Accuracy: 1.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.37435 Accuracy: 1.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.37410 Accuracy: 1.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.37384 Accuracy: 1.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.37358 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:24:30,245] Trial 14 finished with value: 0.7647768395657419 and parameters: {'REG_W': 4.9443223762717384e-06, 'REG_B': 0.00023673683599163402, 'REG_Z': 4.9885120979036455e-05, 'SPAR_W': 0.8947625074756174, 'SPAR_B': 0.8462338809988931, 'SPAR_Z': 0.9883925840878015, 'LEARNING_RATE': 0.00023019529772352665, 'NUM_EPOCHS': 458}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 5.33966 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 2.49974 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.62745 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.51148 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.51585 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.52937 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.53747 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.54032 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.53911 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.53498 Accuracy: 0.00000\n",
      "Test Loss: 0.88718 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.52861 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.52052 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.51116 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.50097 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.49036 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.47944 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.46821 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.45714 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.44603 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.43505 Accuracy: 0.00000\n",
      "Test Loss: 0.85961 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.42419 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.41354 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.40293 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.39237 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.38190 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.37139 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.36098 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.35065 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.34027 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.32992 Accuracy: 0.00000\n",
      "Test Loss: 0.85070 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.31952 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.30903 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.29848 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.28798 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.27749 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.26698 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.25649 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.24602 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.23557 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.22518 Accuracy: 0.00000\n",
      "Test Loss: 0.84691 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.21474 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.20453 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.19436 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.18434 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.17444 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.16463 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.15480 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.14513 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.13559 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.12616 Accuracy: 0.00000\n",
      "Test Loss: 0.84260 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.11694 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.10784 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.09886 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.09012 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.08150 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.07308 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.06479 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.05674 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.04890 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.04124 Accuracy: 0.00000\n",
      "Test Loss: 0.83744 Accuracy: 0.50131\n",
      "Epoch:  60 Batch:   0 Loss: 1.03376 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.02644 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.01930 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.01228 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 1.00546 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.99885 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.99236 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.98608 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.97994 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.97400 Accuracy: 0.00000\n",
      "Test Loss: 0.83197 Accuracy: 0.50281\n",
      "Epoch:  70 Batch:   0 Loss: 0.96818 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.96257 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.95707 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.95172 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.94654 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.94146 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.93656 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.93181 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.92722 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.92271 Accuracy: 0.00000\n",
      "Test Loss: 0.82644 Accuracy: 0.50342\n",
      "Epoch:  80 Batch:   0 Loss: 0.91833 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.91408 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.90994 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.90592 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.90199 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.89817 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.89446 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.89087 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.88738 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.88399 Accuracy: 0.00000\n",
      "Test Loss: 0.82095 Accuracy: 0.50342\n",
      "Epoch:  90 Batch:   0 Loss: 0.88070 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.87747 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.87435 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.87132 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.86837 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.86549 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.86269 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.85993 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.85724 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.85463 Accuracy: 0.00000\n",
      "Test Loss: 0.81552 Accuracy: 0.50281\n",
      "Epoch: 100 Batch:   0 Loss: 0.85209 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.84961 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.84720 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.84486 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.84256 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.84035 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.83814 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.83599 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.83391 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.83188 Accuracy: 0.00000\n",
      "Test Loss: 0.80996 Accuracy: 0.50121\n",
      "Epoch: 110 Batch:   0 Loss: 0.82993 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.82801 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.82613 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.82431 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.82255 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.82084 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.81918 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.81758 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.81602 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.81452 Accuracy: 0.00000\n",
      "Test Loss: 0.80407 Accuracy: 0.50070\n",
      "Epoch: 120 Batch:   0 Loss: 0.81308 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.81167 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.81030 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.80900 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.80779 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.80662 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.80548 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.80442 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.80339 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.80245 Accuracy: 0.00000\n",
      "Test Loss: 0.79716 Accuracy: 0.50060\n",
      "Epoch: 130 Batch:   0 Loss: 0.80158 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.80072 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.79990 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.79912 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.79837 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.79766 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.79698 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.79632 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.79571 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.79513 Accuracy: 0.00000\n",
      "Test Loss: 0.78703 Accuracy: 0.50050\n",
      "Epoch: 140 Batch:   0 Loss: 0.79458 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.79406 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.79358 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.79314 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.79274 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.79237 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.79205 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.79174 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.79148 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.79121 Accuracy: 0.00000\n",
      "Test Loss: 0.77117 Accuracy: 0.50040\n",
      "Epoch: 150 Batch:   0 Loss: 0.79100 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.79081 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.79063 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.79044 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.79027 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.79008 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.78989 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.78970 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.78950 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.78928 Accuracy: 0.00000\n",
      "Test Loss: 0.75255 Accuracy: 0.50050\n",
      "Epoch: 160 Batch:   0 Loss: 0.78906 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.78881 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.78856 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.78831 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.78802 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.78772 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.78741 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.78709 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.78676 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.78641 Accuracy: 0.00000\n",
      "Test Loss: 0.73690 Accuracy: 0.50050\n",
      "Epoch: 170 Batch:   0 Loss: 0.78605 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.78571 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.78537 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.78501 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.78464 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.78428 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.78393 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.78355 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.78319 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.78283 Accuracy: 0.00000\n",
      "Test Loss: 0.72379 Accuracy: 0.50050\n",
      "Epoch: 180 Batch:   0 Loss: 0.78248 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.78210 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.78177 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.78145 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.78113 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.78081 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.78050 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.78019 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.77989 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.77959 Accuracy: 0.00000\n",
      "Test Loss: 0.71217 Accuracy: 0.50050\n",
      "Epoch: 190 Batch:   0 Loss: 0.77931 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.77904 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.77877 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.77851 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.77826 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.77803 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.77780 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.77758 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.77736 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.77716 Accuracy: 0.00000\n",
      "Test Loss: 0.70217 Accuracy: 0.50060\n",
      "Epoch: 200 Batch:   0 Loss: 0.77696 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.77678 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.77661 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.77644 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.77628 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.77615 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.77603 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.77591 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.77581 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.77572 Accuracy: 0.00000\n",
      "Test Loss: 0.69371 Accuracy: 0.50070\n",
      "Epoch: 210 Batch:   0 Loss: 0.77563 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.77556 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.77549 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.77544 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.77541 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.77539 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.77537 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.77537 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.77538 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.77540 Accuracy: 0.00000\n",
      "Test Loss: 0.68664 Accuracy: 0.50070\n",
      "Epoch: 220 Batch:   0 Loss: 0.77543 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.77547 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.77553 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.77558 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.77566 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.77575 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.77586 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.77599 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.77613 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.77627 Accuracy: 0.00000\n",
      "Test Loss: 0.68075 Accuracy: 0.50070\n",
      "Epoch: 230 Batch:   0 Loss: 0.77643 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.77660 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.77677 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.77696 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.77716 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.77736 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.77755 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.77776 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.77798 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.77819 Accuracy: 0.00000\n",
      "Test Loss: 0.67577 Accuracy: 0.50070\n",
      "Epoch: 240 Batch:   0 Loss: 0.77841 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.77861 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.77880 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.77899 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.77916 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.77932 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.77946 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.77959 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.77971 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.77981 Accuracy: 0.00000\n",
      "Test Loss: 0.67135 Accuracy: 0.50070\n",
      "Epoch: 250 Batch:   0 Loss: 0.77990 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.77998 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.78005 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.78011 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.78016 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.78020 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.78024 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.78027 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.78029 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.78031 Accuracy: 0.00000\n",
      "Test Loss: 0.66749 Accuracy: 0.50070\n",
      "Epoch: 260 Batch:   0 Loss: 0.78033 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.78034 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.78037 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.78039 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.78041 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.78043 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.78045 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.78048 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.78051 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.78054 Accuracy: 0.00000\n",
      "Test Loss: 0.66441 Accuracy: 0.50070\n",
      "Epoch: 270 Batch:   0 Loss: 0.78056 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.78059 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.78062 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.78066 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.78070 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.78074 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.78079 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.78083 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.78088 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.78092 Accuracy: 0.00000\n",
      "Test Loss: 0.66196 Accuracy: 0.50060\n",
      "Epoch: 280 Batch:   0 Loss: 0.78095 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.78098 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.78099 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.78099 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.78097 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.78092 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.78083 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.78072 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.78058 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.78041 Accuracy: 0.00000\n",
      "Test Loss: 0.65984 Accuracy: 0.50060\n",
      "Epoch: 290 Batch:   0 Loss: 0.78021 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.77997 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.77971 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.77943 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.77912 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.77878 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.77843 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.77806 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.77768 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.77728 Accuracy: 0.00000\n",
      "Test Loss: 0.65792 Accuracy: 0.50060\n",
      "Epoch: 300 Batch:   0 Loss: 0.77688 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.77647 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.77605 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.77564 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.77522 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.77481 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.77439 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.77398 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.77357 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.77317 Accuracy: 0.00000\n",
      "Test Loss: 0.65636 Accuracy: 0.50070\n",
      "Epoch: 310 Batch:   0 Loss: 0.77277 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:27:54,413] Trial 15 finished with value: 0.5005026135906715 and parameters: {'REG_W': 2.9817944061172906e-06, 'REG_B': 0.0015764948468564553, 'REG_Z': 4.2455140492222395e-05, 'SPAR_W': 0.9216345594073406, 'SPAR_B': 0.8740899737578733, 'SPAR_Z': 0.9224633223709945, 'LEARNING_RATE': 0.0002329813134211586, 'NUM_EPOCHS': 311}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 4.09905 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 3.22776 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 3.46697 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 3.50745 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 3.49307 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 3.45398 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 3.39392 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 3.31812 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 3.22441 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 3.11006 Accuracy: 0.00000\n",
      "Test Loss: 1.72716 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.97928 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.83617 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.68179 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.51929 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.35450 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.18927 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.02767 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.87293 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.72970 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.59528 Accuracy: 0.00000\n",
      "Test Loss: 1.62673 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 1.47328 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.36477 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.26792 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.18308 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.10755 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.04181 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 0.98582 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 0.93770 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 0.89668 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 0.86281 Accuracy: 0.00000\n",
      "Test Loss: 1.33790 Accuracy: 0.50060\n",
      "Epoch:  30 Batch:   0 Loss: 0.83503 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 0.81287 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 0.79573 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.78246 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.77203 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.76362 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.75672 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.75085 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.74576 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.74143 Accuracy: 0.00000\n",
      "Test Loss: 1.03485 Accuracy: 0.50070\n",
      "Epoch:  40 Batch:   0 Loss: 0.73785 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.73495 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.73279 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.73142 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.73074 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.73076 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.73147 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.73277 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.73454 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.73661 Accuracy: 0.00000\n",
      "Test Loss: 0.89724 Accuracy: 0.50070\n",
      "Epoch:  50 Batch:   0 Loss: 0.73889 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.74125 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.74369 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.74602 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.74837 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.75066 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.75281 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.75485 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.75675 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.75852 Accuracy: 0.00000\n",
      "Test Loss: 0.84283 Accuracy: 0.50080\n",
      "Epoch:  60 Batch:   0 Loss: 0.76006 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.76143 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.76259 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.76348 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.76416 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.76470 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.76517 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.76558 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.76590 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.76612 Accuracy: 0.00000\n",
      "Test Loss: 0.80589 Accuracy: 0.50090\n",
      "Epoch:  70 Batch:   0 Loss: 0.76635 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.76651 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.76664 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.76678 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.76696 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.76714 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.76732 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.76749 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.76767 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.76789 Accuracy: 0.00000\n",
      "Test Loss: 0.78436 Accuracy: 0.50090\n",
      "Epoch:  80 Batch:   0 Loss: 0.76809 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.76831 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.76858 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.76884 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.76911 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.76936 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.76961 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.76991 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.77023 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.77057 Accuracy: 0.00000\n",
      "Test Loss: 0.77207 Accuracy: 0.50080\n",
      "Epoch:  90 Batch:   0 Loss: 0.77091 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.77125 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.77155 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.77187 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.77219 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.77252 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.77288 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.77320 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.77351 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.77381 Accuracy: 0.00000\n",
      "Test Loss: 0.76457 Accuracy: 0.50090\n",
      "Epoch: 100 Batch:   0 Loss: 0.77413 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.77443 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.77473 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.77501 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.77527 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.77554 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.77575 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.77591 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.77605 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.77618 Accuracy: 0.00000\n",
      "Test Loss: 0.75982 Accuracy: 0.50090\n",
      "Epoch: 110 Batch:   0 Loss: 0.77626 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.77632 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.77638 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.77643 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.77646 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.77649 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.77654 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.77659 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.77662 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.77663 Accuracy: 0.00000\n",
      "Test Loss: 0.75627 Accuracy: 0.50080\n",
      "Epoch: 120 Batch:   0 Loss: 0.77661 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.77660 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.77652 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77633 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77598 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77553 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.77495 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.77433 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.77366 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.77301 Accuracy: 0.00000\n",
      "Test Loss: 0.75004 Accuracy: 0.50070\n",
      "Epoch: 130 Batch:   0 Loss: 0.77239 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.77184 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77138 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77102 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77075 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77063 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77067 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77092 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77130 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77169 Accuracy: 0.00000\n",
      "Test Loss: 0.74505 Accuracy: 0.50050\n",
      "Epoch: 140 Batch:   0 Loss: 0.77190 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77188 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77157 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77098 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77022 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.76940 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.76863 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.76792 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.76725 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.76652 Accuracy: 0.00000\n",
      "Test Loss: 0.73979 Accuracy: 0.50050\n",
      "Epoch: 150 Batch:   0 Loss: 0.76567 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.76475 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.76380 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.76288 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.76199 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.76117 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.76043 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.75976 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.75915 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.75859 Accuracy: 0.00000\n",
      "Test Loss: 0.73837 Accuracy: 0.50050\n",
      "Epoch: 160 Batch:   0 Loss: 0.75810 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.75766 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.75726 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.75690 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.75657 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.75627 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.75600 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.75575 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.75552 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.75531 Accuracy: 0.00000\n",
      "Test Loss: 0.74001 Accuracy: 0.50050\n",
      "Epoch: 170 Batch:   0 Loss: 0.75511 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.75494 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.75478 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.75462 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.75449 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.75436 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.75424 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.75412 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.75401 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.75391 Accuracy: 0.00000\n",
      "Test Loss: 0.74251 Accuracy: 0.50050\n",
      "Epoch: 180 Batch:   0 Loss: 0.75379 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.75369 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.75359 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.75349 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.75339 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.75331 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.75323 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.75315 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.75306 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.75299 Accuracy: 0.00000\n",
      "Test Loss: 0.74535 Accuracy: 0.50060\n",
      "Epoch: 190 Batch:   0 Loss: 0.75293 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.75285 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.75278 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.75272 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.75266 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.75261 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.75254 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.75247 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.75241 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.75235 Accuracy: 0.00000\n",
      "Test Loss: 0.74818 Accuracy: 0.50070\n",
      "Epoch: 200 Batch:   0 Loss: 0.75230 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.75224 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.75219 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.75214 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.75209 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.75204 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.75200 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.75196 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.75193 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.75189 Accuracy: 0.00000\n",
      "Test Loss: 0.75114 Accuracy: 0.50070\n",
      "Epoch: 210 Batch:   0 Loss: 0.75186 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.75183 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.75180 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.75177 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.75173 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.75170 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.75167 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.75164 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.75161 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.75158 Accuracy: 0.00000\n",
      "Test Loss: 0.75423 Accuracy: 0.50070\n",
      "Epoch: 220 Batch:   0 Loss: 0.75155 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.75154 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.75152 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.75150 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.75148 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.75146 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.75145 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.75143 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.75142 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.75142 Accuracy: 0.00000\n",
      "Test Loss: 0.75739 Accuracy: 0.50070\n",
      "Epoch: 230 Batch:   0 Loss: 0.75140 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.75139 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.75136 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.75135 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.75134 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.75133 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.75133 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.75132 Accuracy: 0.00000\n",
      "Test Loss: 0.76062 Accuracy: 0.50070\n",
      "Epoch: 240 Batch:   0 Loss: 0.75131 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.75131 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.75130 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.75129 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.75128 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.75128 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.75128 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.75128 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.75127 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.75128 Accuracy: 0.00000\n",
      "Test Loss: 0.76399 Accuracy: 0.50070\n",
      "Epoch: 250 Batch:   0 Loss: 0.75127 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.75127 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.75125 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.75127 Accuracy: 0.00000\n",
      "Test Loss: 0.76703 Accuracy: 0.50080\n",
      "Epoch: 260 Batch:   0 Loss: 0.75127 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.75127 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.75128 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.75129 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.75130 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.75130 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.75131 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.75132 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.75132 Accuracy: 0.00000\n",
      "Test Loss: 0.77012 Accuracy: 0.50080\n",
      "Epoch: 270 Batch:   0 Loss: 0.75133 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.75133 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.75134 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.75134 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.75134 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.75135 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.75135 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.75136 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.75136 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Test Loss: 0.77315 Accuracy: 0.50080\n",
      "Epoch: 280 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.75139 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Test Loss: 0.77610 Accuracy: 0.50080\n",
      "Epoch: 290 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Test Loss: 0.77909 Accuracy: 0.50080\n",
      "Epoch: 300 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.75138 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.75139 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.75139 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.75139 Accuracy: 0.00000\n",
      "Test Loss: 0.78211 Accuracy: 0.50080\n",
      "Epoch: 310 Batch:   0 Loss: 0.75140 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.75140 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Test Loss: 0.78501 Accuracy: 0.50080\n",
      "Epoch: 320 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.75140 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.75142 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.75142 Accuracy: 0.00000\n",
      "Test Loss: 0.78774 Accuracy: 0.50080\n",
      "Epoch: 330 Batch:   0 Loss: 0.75143 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.75143 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.75144 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.75145 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.75146 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.75146 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.75147 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.75147 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.75148 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.75149 Accuracy: 0.00000\n",
      "Test Loss: 0.79033 Accuracy: 0.50080\n",
      "Epoch: 340 Batch:   0 Loss: 0.75150 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.75150 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.75151 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.75151 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.75152 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.75152 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.75153 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.75154 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.75155 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.75155 Accuracy: 0.00000\n",
      "Test Loss: 0.79295 Accuracy: 0.50080\n",
      "Epoch: 350 Batch:   0 Loss: 0.75156 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.75157 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.75155 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.75155 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.75155 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.75156 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.75156 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.75156 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.75158 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.75158 Accuracy: 0.00000\n",
      "Test Loss: 0.79524 Accuracy: 0.50090\n",
      "Epoch: 360 Batch:   0 Loss: 0.75159 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.75159 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.75159 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.75160 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.75161 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.75161 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.75162 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.75165 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.75163 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.75163 Accuracy: 0.00000\n",
      "Test Loss: 0.79745 Accuracy: 0.50090\n",
      "Epoch: 370 Batch:   0 Loss: 0.75164 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.75165 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.75170 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.75167 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.75167 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.75168 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.75169 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.75170 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.75171 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.75172 Accuracy: 0.00000\n",
      "Test Loss: 0.79952 Accuracy: 0.50090\n",
      "Epoch: 380 Batch:   0 Loss: 0.75173 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.75174 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.75175 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.75177 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.75178 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.75179 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.75180 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.75181 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.75182 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.75183 Accuracy: 0.00000\n",
      "Test Loss: 0.80149 Accuracy: 0.50090\n",
      "Epoch: 390 Batch:   0 Loss: 0.75185 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.75186 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.75187 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.75189 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.75190 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.75191 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.75192 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.75193 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.75194 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.75195 Accuracy: 0.00000\n",
      "Test Loss: 0.80330 Accuracy: 0.50090\n",
      "Epoch: 400 Batch:   0 Loss: 0.75196 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.75197 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.75198 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.75199 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.75200 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.75201 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.75203 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.75204 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.75205 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.75206 Accuracy: 0.00000\n",
      "Test Loss: 0.80507 Accuracy: 0.50090\n",
      "Epoch: 410 Batch:   0 Loss: 0.75207 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.75208 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.75209 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.75210 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.75210 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.75211 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.75212 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.75213 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.75214 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.75215 Accuracy: 0.00000\n",
      "Test Loss: 0.80682 Accuracy: 0.50090\n",
      "Epoch: 420 Batch:   0 Loss: 0.75216 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.75217 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.75217 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.75218 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.75218 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.75219 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.75219 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.75220 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.75221 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.75221 Accuracy: 0.00000\n",
      "Test Loss: 0.80848 Accuracy: 0.50090\n",
      "Epoch: 430 Batch:   0 Loss: 0.75222 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.75223 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.75223 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.75224 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.75225 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.75226 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.75227 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.75227 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.75228 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.75229 Accuracy: 0.00000\n",
      "Test Loss: 0.80999 Accuracy: 0.50090\n",
      "Epoch: 440 Batch:   0 Loss: 0.75230 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.75231 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.75232 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.75233 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.75235 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.75236 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.75237 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.75238 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.75239 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.75240 Accuracy: 0.00000\n",
      "Test Loss: 0.81152 Accuracy: 0.50090\n",
      "Epoch: 450 Batch:   0 Loss: 0.75241 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.75242 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.75243 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.75244 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.75245 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.75247 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.75247 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.75248 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.75249 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.75250 Accuracy: 0.00000\n",
      "Test Loss: 0.81284 Accuracy: 0.50090\n",
      "Epoch: 460 Batch:   0 Loss: 0.75251 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.75252 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.75252 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.75253 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.75254 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.75255 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.75255 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.75256 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.75257 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.75258 Accuracy: 0.00000\n",
      "Test Loss: 0.81397 Accuracy: 0.50090\n",
      "Epoch: 470 Batch:   0 Loss: 0.75259 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.75260 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.75260 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.75261 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.75262 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.75263 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.75263 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.75264 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.75265 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.75266 Accuracy: 0.00000\n",
      "Test Loss: 0.81503 Accuracy: 0.50090\n",
      "Epoch: 480 Batch:   0 Loss: 0.75267 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.75268 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.75268 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.75269 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.75270 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.75271 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.75272 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.75273 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.75274 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.75274 Accuracy: 0.00000\n",
      "Test Loss: 0.81610 Accuracy: 0.50090\n",
      "Epoch: 490 Batch:   0 Loss: 0.75275 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.75276 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.75276 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.75277 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.75278 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.75279 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.75279 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.75281 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.75282 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.75282 Accuracy: 0.00000\n",
      "Test Loss: 0.81718 Accuracy: 0.50090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:34:31,309] Trial 16 finished with value: 0.5007036590269401 and parameters: {'REG_W': 3.563427719034845e-06, 'REG_B': 0.001817478468648327, 'REG_Z': 4.590243215292866e-05, 'SPAR_W': 0.864984424398386, 'SPAR_B': 0.770681142610384, 'SPAR_Z': 0.9182472389817082, 'LEARNING_RATE': 0.0009987435328399474, 'NUM_EPOCHS': 500}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.01813 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.22860 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.05089 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.37349 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.44603 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.46450 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.46861 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.46582 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.45860 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.44818 Accuracy: 0.00000\n",
      "Test Loss: 0.82225 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.43534 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.42049 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.40457 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.38785 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.37064 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.35345 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.33600 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.31862 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.30180 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.28474 Accuracy: 0.00000\n",
      "Test Loss: 0.78941 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 1.26781 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.25132 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.23476 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.21850 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.20213 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.18545 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.16889 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.15201 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.13562 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.11912 Accuracy: 0.00000\n",
      "Test Loss: 0.76160 Accuracy: 0.52633\n",
      "Epoch:  30 Batch:   0 Loss: 1.10227 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.08560 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.06878 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.05224 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.03560 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.01894 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.00223 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.98560 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.96904 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.95255 Accuracy: 0.00000\n",
      "Test Loss: 0.72815 Accuracy: 0.56099\n",
      "Epoch:  40 Batch:   0 Loss: 0.93614 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.91984 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.90376 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.88796 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.87236 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.85691 Accuracy: 0.03125\n",
      "Epoch:  46 Batch:   0 Loss: 0.84169 Accuracy: 0.06250\n",
      "Epoch:  47 Batch:   0 Loss: 0.82668 Accuracy: 0.06250\n",
      "Epoch:  48 Batch:   0 Loss: 0.81193 Accuracy: 0.09375\n",
      "Epoch:  49 Batch:   0 Loss: 0.79744 Accuracy: 0.09375\n",
      "Test Loss: 0.69643 Accuracy: 0.61695\n",
      "Epoch:  50 Batch:   0 Loss: 0.78310 Accuracy: 0.15625\n",
      "Epoch:  51 Batch:   0 Loss: 0.76910 Accuracy: 0.25000\n",
      "Epoch:  52 Batch:   0 Loss: 0.75543 Accuracy: 0.28125\n",
      "Epoch:  53 Batch:   0 Loss: 0.74201 Accuracy: 0.37500\n",
      "Epoch:  54 Batch:   0 Loss: 0.72888 Accuracy: 0.50000\n",
      "Epoch:  55 Batch:   0 Loss: 0.71605 Accuracy: 0.56250\n",
      "Epoch:  56 Batch:   0 Loss: 0.70345 Accuracy: 0.59375\n",
      "Epoch:  57 Batch:   0 Loss: 0.69113 Accuracy: 0.71875\n",
      "Epoch:  58 Batch:   0 Loss: 0.67912 Accuracy: 0.81250\n",
      "Epoch:  59 Batch:   0 Loss: 0.66747 Accuracy: 0.84375\n",
      "Test Loss: 0.67230 Accuracy: 0.66458\n",
      "Epoch:  60 Batch:   0 Loss: 0.65618 Accuracy: 0.93750\n",
      "Epoch:  61 Batch:   0 Loss: 0.64521 Accuracy: 0.93750\n",
      "Epoch:  62 Batch:   0 Loss: 0.63455 Accuracy: 0.93750\n",
      "Epoch:  63 Batch:   0 Loss: 0.62421 Accuracy: 0.96875\n",
      "Epoch:  64 Batch:   0 Loss: 0.61420 Accuracy: 0.96875\n",
      "Epoch:  65 Batch:   0 Loss: 0.60449 Accuracy: 1.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.59509 Accuracy: 1.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.58602 Accuracy: 1.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.57726 Accuracy: 1.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.56880 Accuracy: 1.00000\n",
      "Test Loss: 0.65639 Accuracy: 0.69845\n",
      "Epoch:  70 Batch:   0 Loss: 0.56061 Accuracy: 1.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.55271 Accuracy: 1.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.54504 Accuracy: 1.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.53766 Accuracy: 1.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.53054 Accuracy: 1.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.52367 Accuracy: 1.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.51708 Accuracy: 1.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.51071 Accuracy: 1.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.50456 Accuracy: 1.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.49864 Accuracy: 1.00000\n",
      "Test Loss: 0.64618 Accuracy: 0.71844\n",
      "Epoch:  80 Batch:   0 Loss: 0.49293 Accuracy: 1.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.48742 Accuracy: 1.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.48209 Accuracy: 1.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.47695 Accuracy: 1.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.47199 Accuracy: 1.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.46721 Accuracy: 1.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.46261 Accuracy: 1.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.45818 Accuracy: 1.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.45390 Accuracy: 1.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.44977 Accuracy: 1.00000\n",
      "Test Loss: 0.63922 Accuracy: 0.72878\n",
      "Epoch:  90 Batch:   0 Loss: 0.44581 Accuracy: 1.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.44198 Accuracy: 1.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.43828 Accuracy: 1.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.43470 Accuracy: 1.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.43125 Accuracy: 1.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.42792 Accuracy: 1.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.42470 Accuracy: 1.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.42161 Accuracy: 1.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.41862 Accuracy: 1.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.41572 Accuracy: 1.00000\n",
      "Test Loss: 0.63393 Accuracy: 0.73541\n",
      "Epoch: 100 Batch:   0 Loss: 0.41293 Accuracy: 1.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.41022 Accuracy: 1.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.40762 Accuracy: 1.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.40510 Accuracy: 1.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.40266 Accuracy: 1.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.40030 Accuracy: 1.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.39802 Accuracy: 1.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.39582 Accuracy: 1.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.39341 Accuracy: 1.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.39112 Accuracy: 1.00000\n",
      "Test Loss: 0.62919 Accuracy: 0.74053\n",
      "Epoch: 110 Batch:   0 Loss: 0.38913 Accuracy: 1.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.38723 Accuracy: 1.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.38539 Accuracy: 1.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.38361 Accuracy: 1.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.38187 Accuracy: 1.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.38020 Accuracy: 1.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.37857 Accuracy: 1.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.37698 Accuracy: 1.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.37545 Accuracy: 1.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.37395 Accuracy: 1.00000\n",
      "Test Loss: 0.62528 Accuracy: 0.74435\n",
      "Epoch: 120 Batch:   0 Loss: 0.37250 Accuracy: 1.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.37110 Accuracy: 1.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.36972 Accuracy: 1.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.36841 Accuracy: 1.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.36711 Accuracy: 1.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.36586 Accuracy: 1.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.36463 Accuracy: 1.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.36344 Accuracy: 1.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.36229 Accuracy: 1.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.36117 Accuracy: 1.00000\n",
      "Test Loss: 0.62171 Accuracy: 0.74756\n",
      "Epoch: 130 Batch:   0 Loss: 0.36008 Accuracy: 1.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.35901 Accuracy: 1.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.35798 Accuracy: 1.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.35698 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.35600 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.35505 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.35413 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.35322 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.35232 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.35145 Accuracy: 1.00000\n",
      "Test Loss: 0.61844 Accuracy: 0.75279\n",
      "Epoch: 140 Batch:   0 Loss: 0.35060 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.34977 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.34895 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.34817 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.34740 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.34666 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.34593 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.34523 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.34452 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.34383 Accuracy: 1.00000\n",
      "Test Loss: 0.61546 Accuracy: 0.75500\n",
      "Epoch: 150 Batch:   0 Loss: 0.34316 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.34249 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.34184 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.34120 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.34058 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.33996 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.33936 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.33878 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.33820 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.33764 Accuracy: 1.00000\n",
      "Test Loss: 0.61275 Accuracy: 0.75681\n",
      "Epoch: 160 Batch:   0 Loss: 0.33709 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.33654 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.33603 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.33550 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.33498 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.33447 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.33398 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.33350 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.33302 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.33255 Accuracy: 1.00000\n",
      "Test Loss: 0.61030 Accuracy: 0.75821\n",
      "Epoch: 170 Batch:   0 Loss: 0.33208 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.33162 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.33116 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.33072 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.33028 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.32985 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.32944 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.32902 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.32861 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.32821 Accuracy: 1.00000\n",
      "Test Loss: 0.60813 Accuracy: 0.76032\n",
      "Epoch: 180 Batch:   0 Loss: 0.32781 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.32742 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.32705 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.32667 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.32630 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.32593 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.32557 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.32521 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.32485 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.32449 Accuracy: 1.00000\n",
      "Test Loss: 0.60623 Accuracy: 0.76324\n",
      "Epoch: 190 Batch:   0 Loss: 0.32415 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.32380 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.32345 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.32312 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.32278 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.32245 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.32212 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.32179 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.32147 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.32116 Accuracy: 1.00000\n",
      "Test Loss: 0.60457 Accuracy: 0.76514\n",
      "Epoch: 200 Batch:   0 Loss: 0.32085 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.32055 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.32024 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.31994 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.31964 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.31934 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.31905 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.31875 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.31846 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.31849 Accuracy: 1.00000\n",
      "Test Loss: 0.60316 Accuracy: 0.76675\n",
      "Epoch: 210 Batch:   0 Loss: 0.31797 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.31764 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.31734 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.31704 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.31676 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.31647 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.31617 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.31589 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.31560 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.31532 Accuracy: 1.00000\n",
      "Test Loss: 0.60179 Accuracy: 0.76796\n",
      "Epoch: 220 Batch:   0 Loss: 0.31503 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.31475 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.31447 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.31419 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.31391 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.31363 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.31336 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.31309 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.31282 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.31254 Accuracy: 1.00000\n",
      "Test Loss: 0.60035 Accuracy: 0.76977\n",
      "Epoch: 230 Batch:   0 Loss: 0.31227 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.31200 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.31172 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.31145 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.31118 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.31092 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.31066 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.31040 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.31014 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.30990 Accuracy: 1.00000\n",
      "Test Loss: 0.59890 Accuracy: 0.77087\n",
      "Epoch: 240 Batch:   0 Loss: 0.30965 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.30941 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.30920 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.30912 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.30888 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.30863 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.30838 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.30813 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.30787 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.30762 Accuracy: 1.00000\n",
      "Test Loss: 0.59813 Accuracy: 0.77288\n",
      "Epoch: 250 Batch:   0 Loss: 0.30738 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.30713 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.30689 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.30665 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.30641 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.30617 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.30593 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.30570 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.30540 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.30525 Accuracy: 1.00000\n",
      "Test Loss: 0.59749 Accuracy: 0.77248\n",
      "Epoch: 260 Batch:   0 Loss: 0.30503 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.30480 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.30456 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.30433 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.30410 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.30386 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.30363 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.30341 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.30318 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.30297 Accuracy: 1.00000\n",
      "Test Loss: 0.59684 Accuracy: 0.77348\n",
      "Epoch: 270 Batch:   0 Loss: 0.30275 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.30253 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.30231 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.30209 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.30188 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.30166 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.30143 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.30122 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.30100 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.30078 Accuracy: 1.00000\n",
      "Test Loss: 0.59655 Accuracy: 0.77388\n",
      "Epoch: 280 Batch:   0 Loss: 0.30057 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.30035 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.30012 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.29990 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.29968 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.29946 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.29923 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.29901 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.29879 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.29856 Accuracy: 1.00000\n",
      "Test Loss: 0.59643 Accuracy: 0.77367\n",
      "Epoch: 290 Batch:   0 Loss: 0.29834 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.29812 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.29789 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.29766 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.29743 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.29721 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.29699 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.29676 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.29653 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.29631 Accuracy: 1.00000\n",
      "Test Loss: 0.59641 Accuracy: 0.77478\n",
      "Epoch: 300 Batch:   0 Loss: 0.29608 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.29585 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.29562 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.29538 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.29516 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.29493 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.29470 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.29447 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.29424 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.29401 Accuracy: 1.00000\n",
      "Test Loss: 0.59651 Accuracy: 0.77558\n",
      "Epoch: 310 Batch:   0 Loss: 0.29379 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.29356 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.29334 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.29311 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.29289 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.29266 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.29244 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.29222 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.29200 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.29178 Accuracy: 1.00000\n",
      "Test Loss: 0.59669 Accuracy: 0.77598\n",
      "Epoch: 320 Batch:   0 Loss: 0.29156 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.29133 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.29112 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.29090 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.29068 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.29046 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.29024 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.29003 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.28981 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.28959 Accuracy: 1.00000\n",
      "Test Loss: 0.59695 Accuracy: 0.77638\n",
      "Epoch: 330 Batch:   0 Loss: 0.28938 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.28917 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.28896 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.28875 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.28853 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.28833 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.28813 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.28792 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.28772 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.28752 Accuracy: 1.00000\n",
      "Test Loss: 0.59730 Accuracy: 0.77638\n",
      "Epoch: 340 Batch:   0 Loss: 0.28731 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.28710 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.28691 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.28671 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.28651 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.28630 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.28609 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.28588 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.28567 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.28547 Accuracy: 1.00000\n",
      "Test Loss: 0.59773 Accuracy: 0.77618\n",
      "Epoch: 350 Batch:   0 Loss: 0.28527 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.28506 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.28486 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.28467 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.28446 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.28426 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.28406 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.28387 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.28367 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.28347 Accuracy: 1.00000\n",
      "Test Loss: 0.59818 Accuracy: 0.77598\n",
      "Epoch: 360 Batch:   0 Loss: 0.28327 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.28307 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.28287 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.28268 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.28248 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.28229 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.28209 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.28190 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.28170 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.28150 Accuracy: 1.00000\n",
      "Test Loss: 0.59866 Accuracy: 0.77638\n",
      "Epoch: 370 Batch:   0 Loss: 0.28131 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.28111 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.28092 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.28072 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.28053 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.28020 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.28010 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.27992 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.27973 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.27954 Accuracy: 1.00000\n",
      "Test Loss: 0.59911 Accuracy: 0.77688\n",
      "Epoch: 380 Batch:   0 Loss: 0.27935 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.27916 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.27897 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.27878 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.27859 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.27840 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.27822 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.27804 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.27786 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.27767 Accuracy: 1.00000\n",
      "Test Loss: 0.59960 Accuracy: 0.77678\n",
      "Epoch: 390 Batch:   0 Loss: 0.27749 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.27730 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.27712 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.27694 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.27676 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.27658 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.27639 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.27621 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.27603 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.27586 Accuracy: 1.00000\n",
      "Test Loss: 0.60011 Accuracy: 0.77698\n",
      "Epoch: 400 Batch:   0 Loss: 0.27568 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.27550 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.27532 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.27515 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.27497 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.27480 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.27462 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.27445 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.27427 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.27410 Accuracy: 1.00000\n",
      "Test Loss: 0.60063 Accuracy: 0.77719\n",
      "Epoch: 410 Batch:   0 Loss: 0.27392 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.27375 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.27357 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.27339 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.27314 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.27306 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.27289 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.27272 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.27254 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.27236 Accuracy: 1.00000\n",
      "Test Loss: 0.60118 Accuracy: 0.77719\n",
      "Epoch: 420 Batch:   0 Loss: 0.27219 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.27202 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.27185 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.27168 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.27152 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.27135 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:41:08,471] Trial 17 finished with value: 0.7770406111781263 and parameters: {'REG_W': 2.987979066384924e-06, 'REG_B': 7.777710356943696e-05, 'REG_Z': 4.161294467229353e-05, 'SPAR_W': 0.9368568088782723, 'SPAR_B': 0.9440713822183731, 'SPAR_Z': 0.9447121506984012, 'LEARNING_RATE': 0.0002062157637362075, 'NUM_EPOCHS': 426}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.50034 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 2.36514 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.70076 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.68985 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.64494 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.60123 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.55941 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.51721 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.47312 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.42613 Accuracy: 0.00000\n",
      "Test Loss: 1.26310 Accuracy: 0.50030\n",
      "Epoch:  10 Batch:   0 Loss: 2.37555 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.32113 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.26289 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.20084 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.13524 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.06662 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.99528 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.92181 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.84686 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.77105 Accuracy: 0.00000\n",
      "Test Loss: 1.16195 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 1.69525 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.62023 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.54672 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.47543 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.40693 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.34183 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.28051 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.22331 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.17042 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.12188 Accuracy: 0.00000\n",
      "Test Loss: 1.05337 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.07771 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.03782 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.00207 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.97027 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.94218 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.91748 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.89586 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.87697 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.86049 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.84609 Accuracy: 0.00000\n",
      "Test Loss: 0.95198 Accuracy: 0.50060\n",
      "Epoch:  40 Batch:   0 Loss: 0.83345 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.82236 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.81257 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.80400 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.79657 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.79025 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.78506 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.78096 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.77797 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.77593 Accuracy: 0.00000\n",
      "Test Loss: 0.86384 Accuracy: 0.50070\n",
      "Epoch:  50 Batch:   0 Loss: 0.77472 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.77416 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.77402 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.77411 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.77433 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.77457 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.77480 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.77501 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.77519 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.77532 Accuracy: 0.00000\n",
      "Test Loss: 0.81341 Accuracy: 0.50070\n",
      "Epoch:  60 Batch:   0 Loss: 0.77540 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.77545 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.77548 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.77546 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.77543 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.77539 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.77534 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.77529 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.77525 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.77520 Accuracy: 0.00000\n",
      "Test Loss: 0.77749 Accuracy: 0.50070\n",
      "Epoch:  70 Batch:   0 Loss: 0.77513 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.77510 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.77510 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.77510 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.77512 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.77513 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.77516 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.77518 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.77522 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.77524 Accuracy: 0.00000\n",
      "Test Loss: 0.75521 Accuracy: 0.50070\n",
      "Epoch:  80 Batch:   0 Loss: 0.77527 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.77531 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.77533 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.77535 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.77535 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.77534 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.77533 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.77529 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.77524 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.77518 Accuracy: 0.00000\n",
      "Test Loss: 0.74013 Accuracy: 0.50070\n",
      "Epoch:  90 Batch:   0 Loss: 0.77509 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.77500 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.77489 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.77477 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.77464 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.77450 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.77435 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.77420 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.77405 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.77389 Accuracy: 0.00000\n",
      "Test Loss: 0.72945 Accuracy: 0.50080\n",
      "Epoch: 100 Batch:   0 Loss: 0.77374 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.77358 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.77343 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.77327 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.77313 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.77299 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.77286 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.77273 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.77261 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.77250 Accuracy: 0.00000\n",
      "Test Loss: 0.72191 Accuracy: 0.50080\n",
      "Epoch: 110 Batch:   0 Loss: 0.77240 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.77231 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.77223 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.77216 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.77210 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.77205 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.77201 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.77197 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.77195 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.77193 Accuracy: 0.00000\n",
      "Test Loss: 0.71648 Accuracy: 0.50080\n",
      "Epoch: 120 Batch:   0 Loss: 0.77192 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.77193 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.77194 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77196 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77199 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77202 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.77207 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.77212 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.77219 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.77227 Accuracy: 0.00000\n",
      "Test Loss: 0.71235 Accuracy: 0.50090\n",
      "Epoch: 130 Batch:   0 Loss: 0.77236 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.77246 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77259 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77273 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77289 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77307 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77326 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77344 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77362 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77377 Accuracy: 0.00000\n",
      "Test Loss: 0.70870 Accuracy: 0.50100\n",
      "Epoch: 140 Batch:   0 Loss: 0.77387 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77392 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77391 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77382 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77366 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.77345 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.77320 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.77292 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.77261 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.77229 Accuracy: 0.00000\n",
      "Test Loss: 0.70409 Accuracy: 0.50100\n",
      "Epoch: 150 Batch:   0 Loss: 0.77197 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.77166 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.77135 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.77106 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.77080 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.77055 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.77032 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.77012 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.76992 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.76973 Accuracy: 0.00000\n",
      "Test Loss: 0.70054 Accuracy: 0.50100\n",
      "Epoch: 160 Batch:   0 Loss: 0.76953 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.76933 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.76913 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.76891 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.76870 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.76847 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.76825 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.76802 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.76780 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.76760 Accuracy: 0.00000\n",
      "Test Loss: 0.69779 Accuracy: 0.50100\n",
      "Epoch: 170 Batch:   0 Loss: 0.76741 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.76725 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.76711 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.76701 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.76694 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.76691 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.76692 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.76697 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.76705 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.76716 Accuracy: 0.00000\n",
      "Test Loss: 0.69641 Accuracy: 0.50090\n",
      "Epoch: 180 Batch:   0 Loss: 0.76727 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.76738 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.76745 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.76744 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.76732 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.76708 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.76672 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.76626 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.76572 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.76513 Accuracy: 0.00000\n",
      "Test Loss: 0.69479 Accuracy: 0.50090\n",
      "Epoch: 190 Batch:   0 Loss: 0.76452 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.76389 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.76326 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.76263 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.76202 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.76084 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.76027 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.75973 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.75921 Accuracy: 0.00000\n",
      "Test Loss: 0.69434 Accuracy: 0.50090\n",
      "Epoch: 200 Batch:   0 Loss: 0.75871 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.75824 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.75779 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.75736 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.75694 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.75654 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.75616 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.75580 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.75545 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.75511 Accuracy: 0.00000\n",
      "Test Loss: 0.69486 Accuracy: 0.50090\n",
      "Epoch: 210 Batch:   0 Loss: 0.75479 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.75449 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.75419 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.75391 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.75364 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.75338 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.75313 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.75288 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.75265 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.75242 Accuracy: 0.00000\n",
      "Test Loss: 0.69588 Accuracy: 0.50080\n",
      "Epoch: 220 Batch:   0 Loss: 0.75220 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.75199 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.75179 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.75159 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.75140 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.75121 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.75103 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.75086 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.75069 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.75052 Accuracy: 0.00000\n",
      "Test Loss: 0.69720 Accuracy: 0.50080\n",
      "Epoch: 230 Batch:   0 Loss: 0.75036 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.75021 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.75005 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.74991 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.74976 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.74962 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.74948 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.74935 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.74922 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.74909 Accuracy: 0.00000\n",
      "Test Loss: 0.69871 Accuracy: 0.50080\n",
      "Epoch: 240 Batch:   0 Loss: 0.74897 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.74885 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.74872 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.74861 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.74849 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.74838 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.74827 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.74816 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.74805 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.74795 Accuracy: 0.00000\n",
      "Test Loss: 0.70038 Accuracy: 0.50080\n",
      "Epoch: 250 Batch:   0 Loss: 0.74785 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.74775 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.74765 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.74755 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.74745 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.74736 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.74727 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.74718 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.74709 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.74701 Accuracy: 0.00000\n",
      "Test Loss: 0.70212 Accuracy: 0.50080\n",
      "Epoch: 260 Batch:   0 Loss: 0.74692 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.74683 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.74674 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.74666 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.74657 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.74649 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.74641 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.74633 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.74625 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.74618 Accuracy: 0.00000\n",
      "Test Loss: 0.70393 Accuracy: 0.50080\n",
      "Epoch: 270 Batch:   0 Loss: 0.74610 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.74603 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.74596 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.74588 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.74581 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.74574 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.74567 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.74560 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.74553 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.74546 Accuracy: 0.00000\n",
      "Test Loss: 0.70577 Accuracy: 0.50080\n",
      "Epoch: 280 Batch:   0 Loss: 0.74539 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.74533 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.74526 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.74520 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.74513 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.74507 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.74500 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.74494 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.74488 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.74482 Accuracy: 0.00000\n",
      "Test Loss: 0.70765 Accuracy: 0.50080\n",
      "Epoch: 290 Batch:   0 Loss: 0.74476 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.74470 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.74464 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.74458 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.74452 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.74446 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.74441 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.74435 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.74429 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.74424 Accuracy: 0.00000\n",
      "Test Loss: 0.70953 Accuracy: 0.50080\n",
      "Epoch: 300 Batch:   0 Loss: 0.74419 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.74413 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.74408 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.74403 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.74397 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.74392 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.74387 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.74382 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.74377 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.74371 Accuracy: 0.00000\n",
      "Test Loss: 0.71139 Accuracy: 0.50080\n",
      "Epoch: 310 Batch:   0 Loss: 0.74366 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.74361 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.74356 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.74352 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.74347 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.74342 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.74337 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.74332 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.74328 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.74323 Accuracy: 0.00000\n",
      "Test Loss: 0.71321 Accuracy: 0.50080\n",
      "Epoch: 320 Batch:   0 Loss: 0.74318 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.74314 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.74309 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.74305 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.74300 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.74296 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.74292 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.74287 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.74283 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.74279 Accuracy: 0.00000\n",
      "Test Loss: 0.71500 Accuracy: 0.50080\n",
      "Epoch: 330 Batch:   0 Loss: 0.74275 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.74271 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.74267 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.74262 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.74259 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.74254 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.74250 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.74246 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.74242 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.74238 Accuracy: 0.00000\n",
      "Test Loss: 0.71669 Accuracy: 0.50080\n",
      "Epoch: 340 Batch:   0 Loss: 0.74234 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.74230 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.74226 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.74223 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.74219 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.74215 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.74211 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.74208 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.74204 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.74200 Accuracy: 0.00000\n",
      "Test Loss: 0.71834 Accuracy: 0.50080\n",
      "Epoch: 350 Batch:   0 Loss: 0.74197 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.74193 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.74189 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.74186 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.74182 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.74179 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.74175 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.74172 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.74169 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.74165 Accuracy: 0.00000\n",
      "Test Loss: 0.71994 Accuracy: 0.50080\n",
      "Epoch: 360 Batch:   0 Loss: 0.74162 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.74159 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.74155 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.74152 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.74149 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.74145 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.74142 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.74139 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.74136 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.74133 Accuracy: 0.00000\n",
      "Test Loss: 0.72148 Accuracy: 0.50080\n",
      "Epoch: 370 Batch:   0 Loss: 0.74130 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.74127 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.74124 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.74121 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.74118 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.74115 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.74112 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.74109 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.74106 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.74103 Accuracy: 0.00000\n",
      "Test Loss: 0.72295 Accuracy: 0.50090\n",
      "Epoch: 380 Batch:   0 Loss: 0.74100 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.74097 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.74094 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.74091 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.74089 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.74086 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.74083 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.74080 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.74078 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.74075 Accuracy: 0.00000\n",
      "Test Loss: 0.72439 Accuracy: 0.50090\n",
      "Epoch: 390 Batch:   0 Loss: 0.74072 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.74070 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.74067 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.74064 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.74062 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.74059 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.74057 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.74054 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.74052 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.74049 Accuracy: 0.00000\n",
      "Test Loss: 0.72578 Accuracy: 0.50100\n",
      "Epoch: 400 Batch:   0 Loss: 0.74047 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.74044 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.74042 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.74040 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.74037 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.74035 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.74033 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.74030 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.74028 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.74026 Accuracy: 0.00000\n",
      "Test Loss: 0.72715 Accuracy: 0.50100\n",
      "Epoch: 410 Batch:   0 Loss: 0.74023 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.74021 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.74019 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.74017 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.74015 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.74013 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.74011 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.74009 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.74007 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.74004 Accuracy: 0.00000\n",
      "Test Loss: 0.72849 Accuracy: 0.50100\n",
      "Epoch: 420 Batch:   0 Loss: 0.74002 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.74000 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.73998 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.73996 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.73994 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.73992 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.73990 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.73989 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.73987 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.73985 Accuracy: 0.00000\n",
      "Test Loss: 0.72978 Accuracy: 0.50100\n",
      "Epoch: 430 Batch:   0 Loss: 0.73983 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.73981 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.73979 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.73977 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.73976 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.73974 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.73972 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.73970 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.73968 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.73967 Accuracy: 0.00000\n",
      "Test Loss: 0.73106 Accuracy: 0.50100\n",
      "Epoch: 440 Batch:   0 Loss: 0.73965 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.73963 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.73962 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.73960 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.73958 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.73956 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.73955 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.73953 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.73952 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.73950 Accuracy: 0.00000\n",
      "Test Loss: 0.73232 Accuracy: 0.50100\n",
      "Epoch: 450 Batch:   0 Loss: 0.73948 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.73947 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.73945 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.73943 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.73942 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.73940 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.73939 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.73937 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.73936 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.73934 Accuracy: 0.00000\n",
      "Test Loss: 0.73356 Accuracy: 0.50100\n",
      "Epoch: 460 Batch:   0 Loss: 0.73933 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.73931 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.73929 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.73928 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.73926 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.73925 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.73924 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.73922 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.73921 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.73920 Accuracy: 0.00000\n",
      "Test Loss: 0.73485 Accuracy: 0.50100\n",
      "Epoch: 470 Batch:   0 Loss: 0.73918 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.73917 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.73915 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.73914 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.73912 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.73912 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.73910 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.73908 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.73906 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.73905 Accuracy: 0.00000\n",
      "Test Loss: 0.73611 Accuracy: 0.50100\n",
      "Epoch: 480 Batch:   0 Loss: 0.73904 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.73904 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.73901 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.73900 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.73898 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.73897 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.73895 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.73894 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.73892 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.73891 Accuracy: 0.00000\n",
      "Test Loss: 0.73733 Accuracy: 0.50100\n",
      "Epoch: 490 Batch:   0 Loss: 0.73890 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.73889 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.73887 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.73886 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.73885 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.73884 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.73882 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.73881 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.73880 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.73879 Accuracy: 0.00000\n",
      "Test Loss: 0.73854 Accuracy: 0.50100\n",
      "Epoch: 500 Batch:   0 Loss: 0.73878 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.73876 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.73875 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.73874 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.73873 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:46:03,644] Trial 18 finished with value: 0.5008041817450744 and parameters: {'REG_W': 2.7986508078728687e-06, 'REG_B': 0.0016520481634988342, 'REG_Z': 4.701659115784846e-05, 'SPAR_W': 0.9952675904405462, 'SPAR_B': 0.899331900603328, 'SPAR_Z': 0.8610259893007911, 'LEARNING_RATE': 0.0005469267034550651, 'NUM_EPOCHS': 505}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.05067 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.04223 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.36415 Accuracy: 1.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.36094 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.59576 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.64890 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.67048 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.67943 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.68064 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.67594 Accuracy: 0.00000\n",
      "Test Loss: 0.95305 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.66648 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.65380 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.63879 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.62171 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.60405 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.58575 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.56746 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.54984 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.53237 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.51547 Accuracy: 0.00000\n",
      "Test Loss: 0.93748 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.49894 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.48278 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.46668 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.45087 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.43499 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.41940 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.40386 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.38845 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.37318 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.35794 Accuracy: 0.00000\n",
      "Test Loss: 0.93446 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.34289 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.32796 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.31337 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.29890 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.28465 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.27064 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.25685 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.24350 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.23031 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.21759 Accuracy: 0.00000\n",
      "Test Loss: 0.92763 Accuracy: 0.50241\n",
      "Epoch:  40 Batch:   0 Loss: 1.20523 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.19324 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.18176 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.17070 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.16012 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.15001 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.14031 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.13089 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.12197 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.11337 Accuracy: 0.00000\n",
      "Test Loss: 0.91883 Accuracy: 0.51829\n",
      "Epoch:  50 Batch:   0 Loss: 1.10515 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.09721 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.08957 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.08226 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.07526 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.06851 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.06214 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.05601 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.05008 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.04442 Accuracy: 0.00000\n",
      "Test Loss: 0.91019 Accuracy: 0.52271\n",
      "Epoch:  60 Batch:   0 Loss: 1.03898 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.03365 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.02850 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.02352 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 1.01865 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 1.01397 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 1.00940 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 1.00493 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 1.00059 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.99633 Accuracy: 0.00000\n",
      "Test Loss: 0.90234 Accuracy: 0.52371\n",
      "Epoch:  70 Batch:   0 Loss: 0.99216 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.98809 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.98411 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.98022 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.97640 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.97268 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.96902 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.96547 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.96201 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.95861 Accuracy: 0.00000\n",
      "Test Loss: 0.89546 Accuracy: 0.52422\n",
      "Epoch:  80 Batch:   0 Loss: 0.95526 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.95201 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.94886 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.94578 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.94279 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.93987 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.93704 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.93430 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.93163 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.92903 Accuracy: 0.00000\n",
      "Test Loss: 0.88961 Accuracy: 0.52472\n",
      "Epoch:  90 Batch:   0 Loss: 0.92650 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.92405 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.92166 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.91934 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.91708 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.91489 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.91277 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.91071 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.90872 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.90679 Accuracy: 0.00000\n",
      "Test Loss: 0.88462 Accuracy: 0.52532\n",
      "Epoch: 100 Batch:   0 Loss: 0.90489 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.90303 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.90124 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.89952 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.89783 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.89619 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.89460 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.89306 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.89155 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.89009 Accuracy: 0.00000\n",
      "Test Loss: 0.88037 Accuracy: 0.52552\n",
      "Epoch: 110 Batch:   0 Loss: 0.88867 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.88729 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.88594 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.88462 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.88334 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.88210 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.88088 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.87970 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.87854 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.87741 Accuracy: 0.00000\n",
      "Test Loss: 0.87675 Accuracy: 0.52582\n",
      "Epoch: 120 Batch:   0 Loss: 0.87632 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.87525 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.87420 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.87318 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.87219 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.87121 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.87025 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.86930 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.86836 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.86746 Accuracy: 0.00000\n",
      "Test Loss: 0.87370 Accuracy: 0.52633\n",
      "Epoch: 130 Batch:   0 Loss: 0.86658 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.86572 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.86488 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.86407 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.86327 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.86249 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.86172 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.86099 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.86025 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.85954 Accuracy: 0.00000\n",
      "Test Loss: 0.87117 Accuracy: 0.52693\n",
      "Epoch: 140 Batch:   0 Loss: 0.85885 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.85817 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.85751 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.85687 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.85624 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.85563 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.85503 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.85443 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.85386 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.85329 Accuracy: 0.00000\n",
      "Test Loss: 0.86910 Accuracy: 0.52814\n",
      "Epoch: 150 Batch:   0 Loss: 0.85274 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.85220 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.85167 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.85115 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.85065 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.85017 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.84969 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.84922 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.84876 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.84831 Accuracy: 0.00000\n",
      "Test Loss: 0.86741 Accuracy: 0.52863\n",
      "Epoch: 160 Batch:   0 Loss: 0.84787 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.84744 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.84701 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.84659 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.84618 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.84578 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.84538 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.84500 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.84462 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.84425 Accuracy: 0.00000\n",
      "Test Loss: 0.86604 Accuracy: 0.52873\n",
      "Epoch: 170 Batch:   0 Loss: 0.84387 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.84352 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.84317 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.84283 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.84249 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.84215 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.84183 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.84151 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.84119 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.84087 Accuracy: 0.00000\n",
      "Test Loss: 0.86499 Accuracy: 0.52984\n",
      "Epoch: 180 Batch:   0 Loss: 0.84056 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.84026 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.83995 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.83966 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.83937 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.83908 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.83879 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.83852 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.83823 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.83795 Accuracy: 0.00000\n",
      "Test Loss: 0.86422 Accuracy: 0.53165\n",
      "Epoch: 190 Batch:   0 Loss: 0.83768 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.83741 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.83714 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.83687 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.83661 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.83635 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.83610 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.83585 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.83559 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.83534 Accuracy: 0.00000\n",
      "Test Loss: 0.86366 Accuracy: 0.53275\n",
      "Epoch: 200 Batch:   0 Loss: 0.83510 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.83485 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.83462 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.83437 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.83414 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.83390 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.83366 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.83343 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.83318 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.83294 Accuracy: 0.00000\n",
      "Test Loss: 0.86334 Accuracy: 0.53406\n",
      "Epoch: 210 Batch:   0 Loss: 0.83271 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.83248 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.83225 Accuracy: 0.03125\n",
      "Epoch: 213 Batch:   0 Loss: 0.83202 Accuracy: 0.03125\n",
      "Epoch: 214 Batch:   0 Loss: 0.83180 Accuracy: 0.03125\n",
      "Epoch: 215 Batch:   0 Loss: 0.83156 Accuracy: 0.03125\n",
      "Epoch: 216 Batch:   0 Loss: 0.83133 Accuracy: 0.03125\n",
      "Epoch: 217 Batch:   0 Loss: 0.83111 Accuracy: 0.03125\n",
      "Epoch: 218 Batch:   0 Loss: 0.83088 Accuracy: 0.03125\n",
      "Epoch: 219 Batch:   0 Loss: 0.83064 Accuracy: 0.03125\n",
      "Test Loss: 0.86313 Accuracy: 0.53637\n",
      "Epoch: 220 Batch:   0 Loss: 0.83043 Accuracy: 0.03125\n",
      "Epoch: 221 Batch:   0 Loss: 0.83021 Accuracy: 0.03125\n",
      "Epoch: 222 Batch:   0 Loss: 0.82998 Accuracy: 0.03125\n",
      "Epoch: 223 Batch:   0 Loss: 0.82976 Accuracy: 0.03125\n",
      "Epoch: 224 Batch:   0 Loss: 0.82954 Accuracy: 0.03125\n",
      "Epoch: 225 Batch:   0 Loss: 0.82932 Accuracy: 0.03125\n",
      "Epoch: 226 Batch:   0 Loss: 0.82910 Accuracy: 0.03125\n",
      "Epoch: 227 Batch:   0 Loss: 0.82887 Accuracy: 0.03125\n",
      "Epoch: 228 Batch:   0 Loss: 0.82865 Accuracy: 0.03125\n",
      "Epoch: 229 Batch:   0 Loss: 0.82843 Accuracy: 0.03125\n",
      "Test Loss: 0.86301 Accuracy: 0.53777\n",
      "Epoch: 230 Batch:   0 Loss: 0.82821 Accuracy: 0.03125\n",
      "Epoch: 231 Batch:   0 Loss: 0.82798 Accuracy: 0.03125\n",
      "Epoch: 232 Batch:   0 Loss: 0.82776 Accuracy: 0.03125\n",
      "Epoch: 233 Batch:   0 Loss: 0.82754 Accuracy: 0.03125\n",
      "Epoch: 234 Batch:   0 Loss: 0.82731 Accuracy: 0.03125\n",
      "Epoch: 235 Batch:   0 Loss: 0.82709 Accuracy: 0.03125\n",
      "Epoch: 236 Batch:   0 Loss: 0.82686 Accuracy: 0.03125\n",
      "Epoch: 237 Batch:   0 Loss: 0.82664 Accuracy: 0.03125\n",
      "Epoch: 238 Batch:   0 Loss: 0.82641 Accuracy: 0.03125\n",
      "Epoch: 239 Batch:   0 Loss: 0.82619 Accuracy: 0.03125\n",
      "Test Loss: 0.86292 Accuracy: 0.54009\n",
      "Epoch: 240 Batch:   0 Loss: 0.82596 Accuracy: 0.03125\n",
      "Epoch: 241 Batch:   0 Loss: 0.82574 Accuracy: 0.03125\n",
      "Epoch: 242 Batch:   0 Loss: 0.82552 Accuracy: 0.03125\n",
      "Epoch: 243 Batch:   0 Loss: 0.82529 Accuracy: 0.03125\n",
      "Epoch: 244 Batch:   0 Loss: 0.82507 Accuracy: 0.03125\n",
      "Epoch: 245 Batch:   0 Loss: 0.82484 Accuracy: 0.03125\n",
      "Epoch: 246 Batch:   0 Loss: 0.82462 Accuracy: 0.03125\n",
      "Epoch: 247 Batch:   0 Loss: 0.82439 Accuracy: 0.03125\n",
      "Epoch: 248 Batch:   0 Loss: 0.82416 Accuracy: 0.03125\n",
      "Epoch: 249 Batch:   0 Loss: 0.82394 Accuracy: 0.03125\n",
      "Test Loss: 0.86278 Accuracy: 0.54240\n",
      "Epoch: 250 Batch:   0 Loss: 0.82371 Accuracy: 0.03125\n",
      "Epoch: 251 Batch:   0 Loss: 0.82349 Accuracy: 0.03125\n",
      "Epoch: 252 Batch:   0 Loss: 0.82327 Accuracy: 0.03125\n",
      "Epoch: 253 Batch:   0 Loss: 0.82303 Accuracy: 0.03125\n",
      "Epoch: 254 Batch:   0 Loss: 0.82281 Accuracy: 0.03125\n",
      "Epoch: 255 Batch:   0 Loss: 0.82247 Accuracy: 0.03125\n",
      "Epoch: 256 Batch:   0 Loss: 0.82204 Accuracy: 0.06250\n",
      "Epoch: 257 Batch:   0 Loss: 0.82181 Accuracy: 0.06250\n",
      "Epoch: 258 Batch:   0 Loss: 0.82159 Accuracy: 0.06250\n",
      "Epoch: 259 Batch:   0 Loss: 0.82136 Accuracy: 0.09375\n",
      "Test Loss: 0.86218 Accuracy: 0.54451\n",
      "Epoch: 260 Batch:   0 Loss: 0.82112 Accuracy: 0.09375\n",
      "Epoch: 261 Batch:   0 Loss: 0.82088 Accuracy: 0.09375\n",
      "Epoch: 262 Batch:   0 Loss: 0.82062 Accuracy: 0.09375\n",
      "Epoch: 263 Batch:   0 Loss: 0.82037 Accuracy: 0.09375\n",
      "Epoch: 264 Batch:   0 Loss: 0.82011 Accuracy: 0.09375\n",
      "Epoch: 265 Batch:   0 Loss: 0.81986 Accuracy: 0.09375\n",
      "Epoch: 266 Batch:   0 Loss: 0.81960 Accuracy: 0.09375\n",
      "Epoch: 267 Batch:   0 Loss: 0.81933 Accuracy: 0.09375\n",
      "Epoch: 268 Batch:   0 Loss: 0.81906 Accuracy: 0.09375\n",
      "Epoch: 269 Batch:   0 Loss: 0.81879 Accuracy: 0.09375\n",
      "Test Loss: 0.86184 Accuracy: 0.54642\n",
      "Epoch: 270 Batch:   0 Loss: 0.81851 Accuracy: 0.09375\n",
      "Epoch: 271 Batch:   0 Loss: 0.81823 Accuracy: 0.09375\n",
      "Epoch: 272 Batch:   0 Loss: 0.81796 Accuracy: 0.09375\n",
      "Epoch: 273 Batch:   0 Loss: 0.81768 Accuracy: 0.09375\n",
      "Epoch: 274 Batch:   0 Loss: 0.81739 Accuracy: 0.12500\n",
      "Epoch: 275 Batch:   0 Loss: 0.81712 Accuracy: 0.12500\n",
      "Epoch: 276 Batch:   0 Loss: 0.81684 Accuracy: 0.12500\n",
      "Epoch: 277 Batch:   0 Loss: 0.81656 Accuracy: 0.15625\n",
      "Epoch: 278 Batch:   0 Loss: 0.81628 Accuracy: 0.15625\n",
      "Epoch: 279 Batch:   0 Loss: 0.81601 Accuracy: 0.15625\n",
      "Test Loss: 0.86136 Accuracy: 0.54873\n",
      "Epoch: 280 Batch:   0 Loss: 0.81572 Accuracy: 0.15625\n",
      "Epoch: 281 Batch:   0 Loss: 0.81543 Accuracy: 0.15625\n",
      "Epoch: 282 Batch:   0 Loss: 0.81515 Accuracy: 0.15625\n",
      "Epoch: 283 Batch:   0 Loss: 0.81488 Accuracy: 0.15625\n",
      "Epoch: 284 Batch:   0 Loss: 0.81460 Accuracy: 0.15625\n",
      "Epoch: 285 Batch:   0 Loss: 0.81432 Accuracy: 0.15625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.81405 Accuracy: 0.18750\n",
      "Epoch: 287 Batch:   0 Loss: 0.81376 Accuracy: 0.18750\n",
      "Epoch: 288 Batch:   0 Loss: 0.81348 Accuracy: 0.18750\n",
      "Epoch: 289 Batch:   0 Loss: 0.81319 Accuracy: 0.21875\n",
      "Test Loss: 0.86072 Accuracy: 0.55124\n",
      "Epoch: 290 Batch:   0 Loss: 0.81291 Accuracy: 0.21875\n",
      "Epoch: 291 Batch:   0 Loss: 0.81262 Accuracy: 0.21875\n",
      "Epoch: 292 Batch:   0 Loss: 0.81233 Accuracy: 0.21875\n",
      "Epoch: 293 Batch:   0 Loss: 0.81204 Accuracy: 0.25000\n",
      "Epoch: 294 Batch:   0 Loss: 0.81175 Accuracy: 0.25000\n",
      "Epoch: 295 Batch:   0 Loss: 0.81146 Accuracy: 0.25000\n",
      "Epoch: 296 Batch:   0 Loss: 0.81116 Accuracy: 0.25000\n",
      "Epoch: 297 Batch:   0 Loss: 0.81087 Accuracy: 0.25000\n",
      "Epoch: 298 Batch:   0 Loss: 0.81057 Accuracy: 0.28125\n",
      "Epoch: 299 Batch:   0 Loss: 0.81028 Accuracy: 0.28125\n",
      "Test Loss: 0.85991 Accuracy: 0.55445\n",
      "Epoch: 300 Batch:   0 Loss: 0.80998 Accuracy: 0.28125\n",
      "Epoch: 301 Batch:   0 Loss: 0.80968 Accuracy: 0.28125\n",
      "Epoch: 302 Batch:   0 Loss: 0.80939 Accuracy: 0.28125\n",
      "Epoch: 303 Batch:   0 Loss: 0.80909 Accuracy: 0.28125\n",
      "Epoch: 304 Batch:   0 Loss: 0.80879 Accuracy: 0.28125\n",
      "Epoch: 305 Batch:   0 Loss: 0.80849 Accuracy: 0.31250\n",
      "Epoch: 306 Batch:   0 Loss: 0.80818 Accuracy: 0.31250\n",
      "Epoch: 307 Batch:   0 Loss: 0.80787 Accuracy: 0.31250\n",
      "Epoch: 308 Batch:   0 Loss: 0.80757 Accuracy: 0.31250\n",
      "Epoch: 309 Batch:   0 Loss: 0.80726 Accuracy: 0.31250\n",
      "Test Loss: 0.85891 Accuracy: 0.55697\n",
      "Epoch: 310 Batch:   0 Loss: 0.80695 Accuracy: 0.31250\n",
      "Epoch: 311 Batch:   0 Loss: 0.80664 Accuracy: 0.31250\n",
      "Epoch: 312 Batch:   0 Loss: 0.80631 Accuracy: 0.31250\n",
      "Epoch: 313 Batch:   0 Loss: 0.80600 Accuracy: 0.31250\n",
      "Epoch: 314 Batch:   0 Loss: 0.80569 Accuracy: 0.31250\n",
      "Epoch: 315 Batch:   0 Loss: 0.80537 Accuracy: 0.31250\n",
      "Epoch: 316 Batch:   0 Loss: 0.80506 Accuracy: 0.31250\n",
      "Epoch: 317 Batch:   0 Loss: 0.80473 Accuracy: 0.31250\n",
      "Epoch: 318 Batch:   0 Loss: 0.80441 Accuracy: 0.34375\n",
      "Epoch: 319 Batch:   0 Loss: 0.80409 Accuracy: 0.34375\n",
      "Test Loss: 0.85773 Accuracy: 0.55958\n",
      "Epoch: 320 Batch:   0 Loss: 0.80377 Accuracy: 0.34375\n",
      "Epoch: 321 Batch:   0 Loss: 0.80345 Accuracy: 0.34375\n",
      "Epoch: 322 Batch:   0 Loss: 0.80312 Accuracy: 0.34375\n",
      "Epoch: 323 Batch:   0 Loss: 0.80279 Accuracy: 0.34375\n",
      "Epoch: 324 Batch:   0 Loss: 0.80247 Accuracy: 0.34375\n",
      "Epoch: 325 Batch:   0 Loss: 0.80214 Accuracy: 0.37500\n",
      "Epoch: 326 Batch:   0 Loss: 0.80181 Accuracy: 0.37500\n",
      "Epoch: 327 Batch:   0 Loss: 0.80148 Accuracy: 0.40625\n",
      "Epoch: 328 Batch:   0 Loss: 0.80115 Accuracy: 0.40625\n",
      "Epoch: 329 Batch:   0 Loss: 0.80082 Accuracy: 0.40625\n",
      "Test Loss: 0.85638 Accuracy: 0.56229\n",
      "Epoch: 330 Batch:   0 Loss: 0.80048 Accuracy: 0.40625\n",
      "Epoch: 331 Batch:   0 Loss: 0.80015 Accuracy: 0.40625\n",
      "Epoch: 332 Batch:   0 Loss: 0.79982 Accuracy: 0.40625\n",
      "Epoch: 333 Batch:   0 Loss: 0.79949 Accuracy: 0.40625\n",
      "Epoch: 334 Batch:   0 Loss: 0.79915 Accuracy: 0.40625\n",
      "Epoch: 335 Batch:   0 Loss: 0.79881 Accuracy: 0.43750\n",
      "Epoch: 336 Batch:   0 Loss: 0.79847 Accuracy: 0.43750\n",
      "Epoch: 337 Batch:   0 Loss: 0.79813 Accuracy: 0.43750\n",
      "Epoch: 338 Batch:   0 Loss: 0.79779 Accuracy: 0.46875\n",
      "Epoch: 339 Batch:   0 Loss: 0.79745 Accuracy: 0.46875\n",
      "Test Loss: 0.85490 Accuracy: 0.56501\n",
      "Epoch: 340 Batch:   0 Loss: 0.79711 Accuracy: 0.46875\n",
      "Epoch: 341 Batch:   0 Loss: 0.79677 Accuracy: 0.46875\n",
      "Epoch: 342 Batch:   0 Loss: 0.79642 Accuracy: 0.46875\n",
      "Epoch: 343 Batch:   0 Loss: 0.79608 Accuracy: 0.46875\n",
      "Epoch: 344 Batch:   0 Loss: 0.79573 Accuracy: 0.46875\n",
      "Epoch: 345 Batch:   0 Loss: 0.79539 Accuracy: 0.50000\n",
      "Epoch: 346 Batch:   0 Loss: 0.79504 Accuracy: 0.50000\n",
      "Epoch: 347 Batch:   0 Loss: 0.79469 Accuracy: 0.50000\n",
      "Epoch: 348 Batch:   0 Loss: 0.79434 Accuracy: 0.50000\n",
      "Epoch: 349 Batch:   0 Loss: 0.79399 Accuracy: 0.53125\n",
      "Test Loss: 0.85330 Accuracy: 0.56832\n",
      "Epoch: 350 Batch:   0 Loss: 0.79364 Accuracy: 0.56250\n",
      "Epoch: 351 Batch:   0 Loss: 0.79329 Accuracy: 0.59375\n",
      "Epoch: 352 Batch:   0 Loss: 0.79294 Accuracy: 0.59375\n",
      "Epoch: 353 Batch:   0 Loss: 0.79259 Accuracy: 0.59375\n",
      "Epoch: 354 Batch:   0 Loss: 0.79224 Accuracy: 0.59375\n",
      "Epoch: 355 Batch:   0 Loss: 0.79188 Accuracy: 0.59375\n",
      "Epoch: 356 Batch:   0 Loss: 0.79153 Accuracy: 0.59375\n",
      "Epoch: 357 Batch:   0 Loss: 0.79117 Accuracy: 0.59375\n",
      "Epoch: 358 Batch:   0 Loss: 0.79081 Accuracy: 0.59375\n",
      "Epoch: 359 Batch:   0 Loss: 0.79045 Accuracy: 0.59375\n",
      "Test Loss: 0.85161 Accuracy: 0.57184\n",
      "Epoch: 360 Batch:   0 Loss: 0.79009 Accuracy: 0.59375\n",
      "Epoch: 361 Batch:   0 Loss: 0.78973 Accuracy: 0.59375\n",
      "Epoch: 362 Batch:   0 Loss: 0.78938 Accuracy: 0.59375\n",
      "Epoch: 363 Batch:   0 Loss: 0.78902 Accuracy: 0.59375\n",
      "Epoch: 364 Batch:   0 Loss: 0.78866 Accuracy: 0.59375\n",
      "Epoch: 365 Batch:   0 Loss: 0.78831 Accuracy: 0.59375\n",
      "Epoch: 366 Batch:   0 Loss: 0.78795 Accuracy: 0.59375\n",
      "Epoch: 367 Batch:   0 Loss: 0.78759 Accuracy: 0.62500\n",
      "Epoch: 368 Batch:   0 Loss: 0.78722 Accuracy: 0.62500\n",
      "Epoch: 369 Batch:   0 Loss: 0.78686 Accuracy: 0.62500\n",
      "Test Loss: 0.84986 Accuracy: 0.57465\n",
      "Epoch: 370 Batch:   0 Loss: 0.78650 Accuracy: 0.62500\n",
      "Epoch: 371 Batch:   0 Loss: 0.78614 Accuracy: 0.62500\n",
      "Epoch: 372 Batch:   0 Loss: 0.78577 Accuracy: 0.62500\n",
      "Epoch: 373 Batch:   0 Loss: 0.78540 Accuracy: 0.62500\n",
      "Epoch: 374 Batch:   0 Loss: 0.78503 Accuracy: 0.62500\n",
      "Epoch: 375 Batch:   0 Loss: 0.78466 Accuracy: 0.62500\n",
      "Epoch: 376 Batch:   0 Loss: 0.78428 Accuracy: 0.62500\n",
      "Epoch: 377 Batch:   0 Loss: 0.78391 Accuracy: 0.62500\n",
      "Epoch: 378 Batch:   0 Loss: 0.78354 Accuracy: 0.62500\n",
      "Epoch: 379 Batch:   0 Loss: 0.78316 Accuracy: 0.62500\n",
      "Test Loss: 0.84807 Accuracy: 0.57787\n",
      "Epoch: 380 Batch:   0 Loss: 0.78279 Accuracy: 0.62500\n",
      "Epoch: 381 Batch:   0 Loss: 0.78242 Accuracy: 0.62500\n",
      "Epoch: 382 Batch:   0 Loss: 0.78203 Accuracy: 0.62500\n",
      "Epoch: 383 Batch:   0 Loss: 0.78166 Accuracy: 0.62500\n",
      "Epoch: 384 Batch:   0 Loss: 0.78128 Accuracy: 0.62500\n",
      "Epoch: 385 Batch:   0 Loss: 0.78090 Accuracy: 0.62500\n",
      "Epoch: 386 Batch:   0 Loss: 0.78052 Accuracy: 0.62500\n",
      "Epoch: 387 Batch:   0 Loss: 0.78014 Accuracy: 0.62500\n",
      "Epoch: 388 Batch:   0 Loss: 0.77976 Accuracy: 0.62500\n",
      "Epoch: 389 Batch:   0 Loss: 0.77938 Accuracy: 0.62500\n",
      "Test Loss: 0.84625 Accuracy: 0.58189\n",
      "Epoch: 390 Batch:   0 Loss: 0.77900 Accuracy: 0.62500\n",
      "Epoch: 391 Batch:   0 Loss: 0.77862 Accuracy: 0.62500\n",
      "Epoch: 392 Batch:   0 Loss: 0.77823 Accuracy: 0.62500\n",
      "Epoch: 393 Batch:   0 Loss: 0.77786 Accuracy: 0.65625\n",
      "Epoch: 394 Batch:   0 Loss: 0.77746 Accuracy: 0.65625\n",
      "Epoch: 395 Batch:   0 Loss: 0.77708 Accuracy: 0.65625\n",
      "Epoch: 396 Batch:   0 Loss: 0.77669 Accuracy: 0.65625\n",
      "Epoch: 397 Batch:   0 Loss: 0.77630 Accuracy: 0.68750\n",
      "Epoch: 398 Batch:   0 Loss: 0.77591 Accuracy: 0.68750\n",
      "Epoch: 399 Batch:   0 Loss: 0.77552 Accuracy: 0.68750\n",
      "Test Loss: 0.84439 Accuracy: 0.58540\n",
      "Epoch: 400 Batch:   0 Loss: 0.77513 Accuracy: 0.68750\n",
      "Epoch: 401 Batch:   0 Loss: 0.77474 Accuracy: 0.68750\n",
      "Epoch: 402 Batch:   0 Loss: 0.77436 Accuracy: 0.68750\n",
      "Epoch: 403 Batch:   0 Loss: 0.77397 Accuracy: 0.68750\n",
      "Epoch: 404 Batch:   0 Loss: 0.77357 Accuracy: 0.68750\n",
      "Epoch: 405 Batch:   0 Loss: 0.77319 Accuracy: 0.68750\n",
      "Epoch: 406 Batch:   0 Loss: 0.77280 Accuracy: 0.68750\n",
      "Epoch: 407 Batch:   0 Loss: 0.77241 Accuracy: 0.68750\n",
      "Epoch: 408 Batch:   0 Loss: 0.77202 Accuracy: 0.68750\n",
      "Epoch: 409 Batch:   0 Loss: 0.77163 Accuracy: 0.68750\n",
      "Test Loss: 0.84251 Accuracy: 0.58952\n",
      "Epoch: 410 Batch:   0 Loss: 0.77124 Accuracy: 0.68750\n",
      "Epoch: 411 Batch:   0 Loss: 0.77085 Accuracy: 0.68750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 14:51:23,448] Trial 19 finished with value: 0.5906714917571371 and parameters: {'REG_W': 3.4256544426719675e-06, 'REG_B': 0.0012195362651619677, 'REG_Z': 4.640666946458155e-05, 'SPAR_W': 0.9249592321637052, 'SPAR_B': 0.8062760865390182, 'SPAR_Z': 0.9531998601449847, 'LEARNING_RATE': 0.0002936820967518912, 'NUM_EPOCHS': 412}. Best is trial 10 with value: 0.7833735424205871.\n"
     ]
    }
   ],
   "source": [
    "op_fun = partial(objective,x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)\n",
    "study.optimize(op_fun,n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=10, state=TrialState.COMPLETE, values=[0.7833735424205871], datetime_start=datetime.datetime(2023, 11, 17, 13, 58, 41, 309742), datetime_complete=datetime.datetime(2023, 11, 17, 14, 4, 12, 447046), params={'REG_W': 3.1651209759814418e-06, 'REG_B': 1.5029243127284535e-05, 'REG_Z': 4.9678837029664995e-05, 'SPAR_W': 0.9694619549595722, 'SPAR_B': 0.8063620879846112, 'SPAR_Z': 0.9979067852308309, 'LEARNING_RATE': 0.0001202698283373907, 'NUM_EPOCHS': 484}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'REG_W': FloatDistribution(high=5e-06, log=False, low=2e-06, step=None), 'REG_B': FloatDistribution(high=0.01, log=False, low=0.0, step=None), 'REG_Z': FloatDistribution(high=5e-05, log=False, low=2e-05, step=None), 'SPAR_W': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'SPAR_B': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'SPAR_Z': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'LEARNING_RATE': FloatDistribution(high=0.001, log=False, low=0.0001, step=None), 'NUM_EPOCHS': IntDistribution(high=600, log=False, low=200, step=1)}, trial_id=10, value=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 5 #d^\n",
    "NUM_PROTOTYPES = 40 #m\n",
    "REG_W = 3.1545272147130644e-06\n",
    "REG_B = 0.00025738817748430687\n",
    "REG_Z = 3.534809578054365e-05\n",
    "SPAR_W = 0.6622823978261199\n",
    "SPAR_B = 0.651918182305612\n",
    "SPAR_Z = 0.6197401480486052\n",
    "LEARNING_RATE = 0.00029791501581002825\n",
    "NUM_EPOCHS = 595\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.007586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJwO4MXatk9G"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:07:22.641991Z",
     "start_time": "2018-08-15T13:06:10.309353Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98358,
     "status": "ok",
     "timestamp": 1567154584840,
     "user": {
      "displayName": "Gokul Hari",
      "photoUrl": "",
      "userId": "16159457985484250305"
     },
     "user_tz": -330
    },
    "id": "MrKAP5_RQJ2b",
    "outputId": "2fb982af-47ae-4867-c5e5-b2ecc2b9dfc4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 1.96731 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 2.25109 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.97812 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.88018 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.84649 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.83512 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.83033 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.82631 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.82104 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.81396 Accuracy: 0.00000\n",
      "Test Loss: 0.96558 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.80509 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.79451 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.78257 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.76965 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.75536 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.74069 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.72541 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.70923 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.69198 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.67404 Accuracy: 0.00000\n",
      "Test Loss: 0.93259 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.65502 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.63551 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.61491 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.59488 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.57470 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.55422 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.53394 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.51294 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.49131 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.46985 Accuracy: 0.00000\n",
      "Test Loss: 0.90941 Accuracy: 0.50593\n",
      "Epoch:  30 Batch:   0 Loss: 1.44859 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.42733 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.40626 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.38529 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.36363 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.34242 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.32187 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.30164 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.28187 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.26257 Accuracy: 0.00000\n",
      "Test Loss: 0.88508 Accuracy: 0.52713\n",
      "Epoch:  40 Batch:   0 Loss: 1.24360 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.22537 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.20766 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.19040 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.17349 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.15700 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.14089 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.12524 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.10996 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.09510 Accuracy: 0.00000\n",
      "Test Loss: 0.85848 Accuracy: 0.54109\n",
      "Epoch:  50 Batch:   0 Loss: 1.08061 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.06651 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.05287 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.03967 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.02657 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.01407 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.00186 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.98999 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.97833 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.96704 Accuracy: 0.00000\n",
      "Test Loss: 0.83463 Accuracy: 0.55637\n",
      "Epoch:  60 Batch:   0 Loss: 0.95606 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.94542 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.93497 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.92483 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.91450 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.90411 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.89383 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.88382 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.87430 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.86505 Accuracy: 0.00000\n",
      "Test Loss: 0.81549 Accuracy: 0.56983\n",
      "Epoch:  70 Batch:   0 Loss: 0.85617 Accuracy: 0.03125\n",
      "Epoch:  71 Batch:   0 Loss: 0.84753 Accuracy: 0.03125\n",
      "Epoch:  72 Batch:   0 Loss: 0.83918 Accuracy: 0.03125\n",
      "Epoch:  73 Batch:   0 Loss: 0.83109 Accuracy: 0.06250\n",
      "Epoch:  74 Batch:   0 Loss: 0.82329 Accuracy: 0.09375\n",
      "Epoch:  75 Batch:   0 Loss: 0.81566 Accuracy: 0.18750\n",
      "Epoch:  76 Batch:   0 Loss: 0.80829 Accuracy: 0.31250\n",
      "Epoch:  77 Batch:   0 Loss: 0.80118 Accuracy: 0.34375\n",
      "Epoch:  78 Batch:   0 Loss: 0.79426 Accuracy: 0.40625\n",
      "Epoch:  79 Batch:   0 Loss: 0.78754 Accuracy: 0.46875\n",
      "Test Loss: 0.80179 Accuracy: 0.59264\n",
      "Epoch:  80 Batch:   0 Loss: 0.78102 Accuracy: 0.46875\n",
      "Epoch:  81 Batch:   0 Loss: 0.77477 Accuracy: 0.46875\n",
      "Epoch:  82 Batch:   0 Loss: 0.76873 Accuracy: 0.53125\n",
      "Epoch:  83 Batch:   0 Loss: 0.76285 Accuracy: 0.56250\n",
      "Epoch:  84 Batch:   0 Loss: 0.75719 Accuracy: 0.62500\n",
      "Epoch:  85 Batch:   0 Loss: 0.75171 Accuracy: 0.65625\n",
      "Epoch:  86 Batch:   0 Loss: 0.74637 Accuracy: 0.71875\n",
      "Epoch:  87 Batch:   0 Loss: 0.74119 Accuracy: 0.78125\n",
      "Epoch:  88 Batch:   0 Loss: 0.73615 Accuracy: 0.81250\n",
      "Epoch:  89 Batch:   0 Loss: 0.73130 Accuracy: 0.81250\n",
      "Test Loss: 0.79239 Accuracy: 0.61143\n",
      "Epoch:  90 Batch:   0 Loss: 0.72660 Accuracy: 0.81250\n",
      "Epoch:  91 Batch:   0 Loss: 0.72209 Accuracy: 0.84375\n",
      "Epoch:  92 Batch:   0 Loss: 0.71765 Accuracy: 0.90625\n",
      "Epoch:  93 Batch:   0 Loss: 0.71331 Accuracy: 0.90625\n",
      "Epoch:  94 Batch:   0 Loss: 0.70903 Accuracy: 0.90625\n",
      "Epoch:  95 Batch:   0 Loss: 0.70497 Accuracy: 0.90625\n",
      "Epoch:  96 Batch:   0 Loss: 0.70097 Accuracy: 0.90625\n",
      "Epoch:  97 Batch:   0 Loss: 0.69710 Accuracy: 0.93750\n",
      "Epoch:  98 Batch:   0 Loss: 0.69343 Accuracy: 0.93750\n",
      "Epoch:  99 Batch:   0 Loss: 0.68988 Accuracy: 0.93750\n",
      "Test Loss: 0.78565 Accuracy: 0.62720\n",
      "Epoch: 100 Batch:   0 Loss: 0.68639 Accuracy: 0.93750\n",
      "Epoch: 101 Batch:   0 Loss: 0.68306 Accuracy: 0.93750\n",
      "Epoch: 102 Batch:   0 Loss: 0.67986 Accuracy: 0.93750\n",
      "Epoch: 103 Batch:   0 Loss: 0.67662 Accuracy: 0.93750\n",
      "Epoch: 104 Batch:   0 Loss: 0.67342 Accuracy: 0.93750\n",
      "Epoch: 105 Batch:   0 Loss: 0.67008 Accuracy: 0.96875\n",
      "Epoch: 106 Batch:   0 Loss: 0.66673 Accuracy: 1.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.66345 Accuracy: 1.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.66029 Accuracy: 1.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.65719 Accuracy: 1.00000\n",
      "Test Loss: 0.77961 Accuracy: 0.64328\n",
      "Epoch: 110 Batch:   0 Loss: 0.65425 Accuracy: 1.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.65140 Accuracy: 1.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.64865 Accuracy: 1.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.64598 Accuracy: 1.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.64341 Accuracy: 1.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.64092 Accuracy: 1.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.63851 Accuracy: 1.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.63616 Accuracy: 1.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.63387 Accuracy: 1.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.63165 Accuracy: 1.00000\n",
      "Test Loss: 0.77464 Accuracy: 0.65513\n",
      "Epoch: 120 Batch:   0 Loss: 0.62954 Accuracy: 1.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.62744 Accuracy: 1.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.62544 Accuracy: 1.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.62348 Accuracy: 1.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.62158 Accuracy: 1.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.61971 Accuracy: 1.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.61794 Accuracy: 1.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.61621 Accuracy: 1.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.61451 Accuracy: 1.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.61279 Accuracy: 1.00000\n",
      "Test Loss: 0.77064 Accuracy: 0.66408\n",
      "Epoch: 130 Batch:   0 Loss: 0.61111 Accuracy: 1.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.60950 Accuracy: 1.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.60793 Accuracy: 1.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.60639 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.60491 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.60341 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.60193 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.60049 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.59913 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.59780 Accuracy: 1.00000\n",
      "Test Loss: 0.76722 Accuracy: 0.67091\n",
      "Epoch: 140 Batch:   0 Loss: 0.59649 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.59520 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.59389 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.59260 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.59133 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.59007 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.58889 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.58771 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.58655 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.58539 Accuracy: 1.00000\n",
      "Test Loss: 0.76412 Accuracy: 0.67794\n",
      "Epoch: 150 Batch:   0 Loss: 0.58414 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.58292 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.58173 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.58055 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.57940 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.57824 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.57713 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.57601 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.57492 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.57382 Accuracy: 1.00000\n",
      "Test Loss: 0.76141 Accuracy: 0.68317\n",
      "Epoch: 160 Batch:   0 Loss: 0.57274 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.57162 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.57052 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.56941 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.56834 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.56731 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.56629 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.56528 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.56429 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.56325 Accuracy: 1.00000\n",
      "Test Loss: 0.75861 Accuracy: 0.68578\n",
      "Epoch: 170 Batch:   0 Loss: 0.56223 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.56123 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.56018 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.55916 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.55812 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.55712 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.55607 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.55506 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.55406 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.55310 Accuracy: 1.00000\n",
      "Test Loss: 0.75567 Accuracy: 0.69060\n",
      "Epoch: 180 Batch:   0 Loss: 0.55216 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.55124 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.55034 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.54945 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.54857 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.54774 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.54684 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.54602 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.54519 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.54432 Accuracy: 1.00000\n",
      "Test Loss: 0.75299 Accuracy: 0.69462\n",
      "Epoch: 190 Batch:   0 Loss: 0.54347 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.54263 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.54180 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.54098 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.54017 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.53936 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.53857 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.53779 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.53702 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.53627 Accuracy: 1.00000\n",
      "Test Loss: 0.75042 Accuracy: 0.69954\n",
      "Epoch: 200 Batch:   0 Loss: 0.53552 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.53481 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.53404 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.53330 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.53256 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.53183 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.53111 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.53041 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.52971 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.52897 Accuracy: 1.00000\n",
      "Test Loss: 0.74801 Accuracy: 0.70165\n",
      "Epoch: 210 Batch:   0 Loss: 0.52827 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.52757 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.52688 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.52622 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.52553 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.52486 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.52419 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.52353 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.52288 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.52223 Accuracy: 1.00000\n",
      "Test Loss: 0.74595 Accuracy: 0.70467\n",
      "Epoch: 220 Batch:   0 Loss: 0.52159 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.52095 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.52032 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.51967 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.51902 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.51838 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.51774 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.51713 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.51652 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.51588 Accuracy: 1.00000\n",
      "Test Loss: 0.74403 Accuracy: 0.70828\n",
      "Epoch: 230 Batch:   0 Loss: 0.51526 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.51462 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.51400 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.51339 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.51277 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.51218 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.51159 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.51100 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.51038 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.50979 Accuracy: 1.00000\n",
      "Test Loss: 0.74212 Accuracy: 0.71100\n",
      "Epoch: 240 Batch:   0 Loss: 0.50920 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.50863 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.50806 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.50750 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.50695 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.50638 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.50582 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.50525 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.50470 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.50415 Accuracy: 1.00000\n",
      "Test Loss: 0.74030 Accuracy: 0.71311\n",
      "Epoch: 250 Batch:   0 Loss: 0.50359 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.50303 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.50246 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.50188 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.50130 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.50072 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.50015 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.49958 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.49901 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.49845 Accuracy: 1.00000\n",
      "Test Loss: 0.73851 Accuracy: 0.71652\n",
      "Epoch: 260 Batch:   0 Loss: 0.49784 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.49729 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.49673 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.49618 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.49563 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.49509 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.49456 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.49402 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.49349 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.49296 Accuracy: 1.00000\n",
      "Test Loss: 0.73665 Accuracy: 0.71913\n",
      "Epoch: 270 Batch:   0 Loss: 0.49243 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.49191 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.49138 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.49082 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.49027 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.48972 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.48918 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.48865 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.48812 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.48761 Accuracy: 1.00000\n",
      "Test Loss: 0.73474 Accuracy: 0.72104\n",
      "Epoch: 280 Batch:   0 Loss: 0.48709 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.48657 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.48606 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.48555 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.48500 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.48448 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.48397 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.48346 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.48295 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.48245 Accuracy: 1.00000\n",
      "Test Loss: 0.73289 Accuracy: 0.72416\n",
      "Epoch: 290 Batch:   0 Loss: 0.48194 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.48146 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.48093 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.48042 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.47992 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.47937 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.47885 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.47834 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.47782 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.47732 Accuracy: 1.00000\n",
      "Test Loss: 0.73106 Accuracy: 0.72586\n",
      "Epoch: 300 Batch:   0 Loss: 0.47683 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.47636 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.47588 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.47541 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.47495 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.47449 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.47404 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.47359 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.47314 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.47270 Accuracy: 1.00000\n",
      "Test Loss: 0.72929 Accuracy: 0.72797\n",
      "Epoch: 310 Batch:   0 Loss: 0.47227 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.47183 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.47139 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.47096 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.47053 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.47010 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.46968 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.46928 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.46887 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.46846 Accuracy: 1.00000\n",
      "Test Loss: 0.72749 Accuracy: 0.72988\n",
      "Epoch: 320 Batch:   0 Loss: 0.46805 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.46764 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.46723 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.46681 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.46641 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.46598 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.46555 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.46512 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.46469 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.46422 Accuracy: 1.00000\n",
      "Test Loss: 0.72566 Accuracy: 0.73119\n",
      "Epoch: 330 Batch:   0 Loss: 0.46377 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.46332 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.46288 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.46245 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.46201 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.46158 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.46116 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.46073 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.46031 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.45989 Accuracy: 1.00000\n",
      "Test Loss: 0.72388 Accuracy: 0.73260\n",
      "Epoch: 340 Batch:   0 Loss: 0.45947 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.45905 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.45864 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.45824 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.45781 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.45738 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.45696 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.45655 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.45613 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.45572 Accuracy: 1.00000\n",
      "Test Loss: 0.72217 Accuracy: 0.73451\n",
      "Epoch: 350 Batch:   0 Loss: 0.45531 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.45490 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.45449 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.45407 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.45364 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.45321 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.45280 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.45238 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.45196 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.45152 Accuracy: 1.00000\n",
      "Test Loss: 0.72055 Accuracy: 0.73601\n",
      "Epoch: 360 Batch:   0 Loss: 0.45109 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.45067 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.45025 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.44983 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.44941 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.44899 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.44858 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.44815 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.44773 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.44732 Accuracy: 1.00000\n",
      "Test Loss: 0.71901 Accuracy: 0.73692\n",
      "Epoch: 370 Batch:   0 Loss: 0.44691 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.44651 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.44610 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.44571 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.44530 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.44493 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.44456 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.44418 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.44381 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.44343 Accuracy: 1.00000\n",
      "Test Loss: 0.71756 Accuracy: 0.73843\n",
      "Epoch: 380 Batch:   0 Loss: 0.44306 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.44268 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.44231 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.44193 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.44156 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.44119 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.44083 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.44046 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.44012 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.43978 Accuracy: 1.00000\n",
      "Test Loss: 0.71619 Accuracy: 0.74033\n",
      "Epoch: 390 Batch:   0 Loss: 0.43942 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.43909 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.43876 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.43842 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.43806 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.43771 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.43736 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.43702 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.43667 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.43634 Accuracy: 1.00000\n",
      "Test Loss: 0.71487 Accuracy: 0.74194\n",
      "Epoch: 400 Batch:   0 Loss: 0.43600 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.43567 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.43532 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.43497 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.43463 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.43429 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.43395 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.43361 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.43328 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.43294 Accuracy: 1.00000\n",
      "Test Loss: 0.71359 Accuracy: 0.74254\n",
      "Epoch: 410 Batch:   0 Loss: 0.43260 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.43227 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.43193 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.43159 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.43125 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.43092 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.43058 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.43025 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.42991 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.42957 Accuracy: 1.00000\n",
      "Test Loss: 0.71235 Accuracy: 0.74314\n",
      "Epoch: 420 Batch:   0 Loss: 0.42924 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.42891 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.42857 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.42823 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.42791 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.42759 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.42726 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.42693 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.42661 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.42628 Accuracy: 1.00000\n",
      "Test Loss: 0.71115 Accuracy: 0.74384\n",
      "Epoch: 430 Batch:   0 Loss: 0.42595 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.42562 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.42528 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.42495 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.42465 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.42431 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.42396 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.42363 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.42330 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.42296 Accuracy: 1.00000\n",
      "Test Loss: 0.70998 Accuracy: 0.74505\n",
      "Epoch: 440 Batch:   0 Loss: 0.42264 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.42231 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.42198 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.42165 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.42133 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.42100 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.42068 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.42036 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.42004 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.41972 Accuracy: 1.00000\n",
      "Test Loss: 0.70887 Accuracy: 0.74495\n",
      "Epoch: 450 Batch:   0 Loss: 0.41940 Accuracy: 1.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.41908 Accuracy: 1.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.41876 Accuracy: 1.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.41844 Accuracy: 1.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.41812 Accuracy: 1.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.41781 Accuracy: 1.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.41749 Accuracy: 1.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.41718 Accuracy: 1.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.41685 Accuracy: 1.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.41654 Accuracy: 1.00000\n",
      "Test Loss: 0.70780 Accuracy: 0.74646\n",
      "Epoch: 460 Batch:   0 Loss: 0.41622 Accuracy: 1.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.41591 Accuracy: 1.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.41559 Accuracy: 1.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.41527 Accuracy: 1.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.41497 Accuracy: 1.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.41466 Accuracy: 1.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.41436 Accuracy: 1.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.41405 Accuracy: 1.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.41329 Accuracy: 1.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.41326 Accuracy: 1.00000\n",
      "Test Loss: 0.70673 Accuracy: 0.74746\n",
      "Epoch: 470 Batch:   0 Loss: 0.41307 Accuracy: 1.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.41281 Accuracy: 1.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.41252 Accuracy: 1.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.41223 Accuracy: 1.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.41192 Accuracy: 1.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.41162 Accuracy: 1.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.41131 Accuracy: 1.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.41101 Accuracy: 1.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.41071 Accuracy: 1.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.41042 Accuracy: 1.00000\n",
      "Test Loss: 0.70579 Accuracy: 0.74786\n",
      "Epoch: 480 Batch:   0 Loss: 0.41012 Accuracy: 1.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.40982 Accuracy: 1.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.40952 Accuracy: 1.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.40923 Accuracy: 1.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.40893 Accuracy: 1.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.40864 Accuracy: 1.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.40834 Accuracy: 1.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.40804 Accuracy: 1.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.40775 Accuracy: 1.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.40745 Accuracy: 1.00000\n",
      "Test Loss: 0.70487 Accuracy: 0.74836\n",
      "Epoch: 490 Batch:   0 Loss: 0.40715 Accuracy: 1.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.40686 Accuracy: 1.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.40657 Accuracy: 1.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.40628 Accuracy: 1.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.40599 Accuracy: 1.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.40570 Accuracy: 1.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.40541 Accuracy: 1.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.40512 Accuracy: 1.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.40484 Accuracy: 1.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.40455 Accuracy: 1.00000\n",
      "Test Loss: 0.70398 Accuracy: 0.74937\n",
      "Epoch: 500 Batch:   0 Loss: 0.40428 Accuracy: 1.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.40345 Accuracy: 1.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.40342 Accuracy: 1.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.40323 Accuracy: 1.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.40298 Accuracy: 1.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.40271 Accuracy: 1.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.40244 Accuracy: 1.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.40216 Accuracy: 1.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.40187 Accuracy: 1.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.40158 Accuracy: 1.00000\n",
      "Test Loss: 0.70302 Accuracy: 0.75027\n",
      "Epoch: 510 Batch:   0 Loss: 0.40129 Accuracy: 1.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.40100 Accuracy: 1.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.40072 Accuracy: 1.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.40044 Accuracy: 1.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.40016 Accuracy: 1.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.39987 Accuracy: 1.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.39959 Accuracy: 1.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.39931 Accuracy: 1.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.39904 Accuracy: 1.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.39876 Accuracy: 1.00000\n",
      "Test Loss: 0.70219 Accuracy: 0.75057\n",
      "Epoch: 520 Batch:   0 Loss: 0.39849 Accuracy: 1.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.39821 Accuracy: 1.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.39793 Accuracy: 1.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.39766 Accuracy: 1.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.39738 Accuracy: 1.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.39710 Accuracy: 1.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.39683 Accuracy: 1.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.39655 Accuracy: 1.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.39626 Accuracy: 1.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.39599 Accuracy: 1.00000\n",
      "Test Loss: 0.70138 Accuracy: 0.75188\n",
      "Epoch: 530 Batch:   0 Loss: 0.39571 Accuracy: 1.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.39543 Accuracy: 1.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.39515 Accuracy: 1.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.39486 Accuracy: 1.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.39458 Accuracy: 1.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.39430 Accuracy: 1.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.39402 Accuracy: 1.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.39373 Accuracy: 1.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.39346 Accuracy: 1.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.39319 Accuracy: 1.00000\n",
      "Test Loss: 0.70062 Accuracy: 0.75248\n",
      "Epoch: 540 Batch:   0 Loss: 0.39291 Accuracy: 1.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.39264 Accuracy: 1.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.39237 Accuracy: 1.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.39211 Accuracy: 1.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.39183 Accuracy: 1.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.39155 Accuracy: 1.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.39128 Accuracy: 1.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.39100 Accuracy: 1.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.39073 Accuracy: 1.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.39046 Accuracy: 1.00000\n",
      "Test Loss: 0.69987 Accuracy: 0.75228\n",
      "Epoch: 550 Batch:   0 Loss: 0.39018 Accuracy: 1.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.38991 Accuracy: 1.00000\n",
      "Epoch: 552 Batch:   0 Loss: 0.38964 Accuracy: 1.00000\n",
      "Epoch: 553 Batch:   0 Loss: 0.38937 Accuracy: 1.00000\n",
      "Epoch: 554 Batch:   0 Loss: 0.38910 Accuracy: 1.00000\n",
      "Epoch: 555 Batch:   0 Loss: 0.38883 Accuracy: 1.00000\n",
      "Epoch: 556 Batch:   0 Loss: 0.38856 Accuracy: 1.00000\n",
      "Epoch: 557 Batch:   0 Loss: 0.38829 Accuracy: 1.00000\n",
      "Epoch: 558 Batch:   0 Loss: 0.38803 Accuracy: 1.00000\n",
      "Epoch: 559 Batch:   0 Loss: 0.38776 Accuracy: 1.00000\n",
      "Test Loss: 0.69912 Accuracy: 0.75338\n",
      "Epoch: 560 Batch:   0 Loss: 0.38749 Accuracy: 1.00000\n",
      "Epoch: 561 Batch:   0 Loss: 0.38721 Accuracy: 1.00000\n",
      "Epoch: 562 Batch:   0 Loss: 0.38694 Accuracy: 1.00000\n",
      "Epoch: 563 Batch:   0 Loss: 0.38668 Accuracy: 1.00000\n",
      "Epoch: 564 Batch:   0 Loss: 0.38642 Accuracy: 1.00000\n",
      "Epoch: 565 Batch:   0 Loss: 0.38615 Accuracy: 1.00000\n",
      "Epoch: 566 Batch:   0 Loss: 0.38588 Accuracy: 1.00000\n",
      "Epoch: 567 Batch:   0 Loss: 0.38561 Accuracy: 1.00000\n",
      "Epoch: 568 Batch:   0 Loss: 0.38535 Accuracy: 1.00000\n",
      "Epoch: 569 Batch:   0 Loss: 0.38509 Accuracy: 1.00000\n",
      "Test Loss: 0.69836 Accuracy: 0.75348\n",
      "Epoch: 570 Batch:   0 Loss: 0.38482 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 571 Batch:   0 Loss: 0.38455 Accuracy: 1.00000\n",
      "Epoch: 572 Batch:   0 Loss: 0.38429 Accuracy: 1.00000\n",
      "Epoch: 573 Batch:   0 Loss: 0.38402 Accuracy: 1.00000\n",
      "Epoch: 574 Batch:   0 Loss: 0.38377 Accuracy: 1.00000\n",
      "Epoch: 575 Batch:   0 Loss: 0.38351 Accuracy: 1.00000\n",
      "Epoch: 576 Batch:   0 Loss: 0.38325 Accuracy: 1.00000\n",
      "Epoch: 577 Batch:   0 Loss: 0.38299 Accuracy: 1.00000\n",
      "Epoch: 578 Batch:   0 Loss: 0.38274 Accuracy: 1.00000\n",
      "Epoch: 579 Batch:   0 Loss: 0.38248 Accuracy: 1.00000\n",
      "Test Loss: 0.69762 Accuracy: 0.75399\n",
      "Epoch: 580 Batch:   0 Loss: 0.38223 Accuracy: 1.00000\n",
      "Epoch: 581 Batch:   0 Loss: 0.38197 Accuracy: 1.00000\n",
      "Epoch: 582 Batch:   0 Loss: 0.38172 Accuracy: 1.00000\n",
      "Epoch: 583 Batch:   0 Loss: 0.38147 Accuracy: 1.00000\n",
      "Epoch: 584 Batch:   0 Loss: 0.38121 Accuracy: 1.00000\n",
      "Epoch: 585 Batch:   0 Loss: 0.38096 Accuracy: 1.00000\n",
      "Epoch: 586 Batch:   0 Loss: 0.38071 Accuracy: 1.00000\n",
      "Epoch: 587 Batch:   0 Loss: 0.38046 Accuracy: 1.00000\n",
      "Epoch: 588 Batch:   0 Loss: 0.38020 Accuracy: 1.00000\n",
      "Epoch: 589 Batch:   0 Loss: 0.37995 Accuracy: 1.00000\n",
      "Test Loss: 0.69691 Accuracy: 0.75449\n",
      "Epoch: 590 Batch:   0 Loss: 0.37970 Accuracy: 1.00000\n",
      "Epoch: 591 Batch:   0 Loss: 0.37945 Accuracy: 1.00000\n",
      "Epoch: 592 Batch:   0 Loss: 0.37921 Accuracy: 1.00000\n",
      "Epoch: 593 Batch:   0 Loss: 0.37895 Accuracy: 1.00000\n",
      "Epoch: 594 Batch:   0 Loss: 0.37870 Accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup input and train protoNN\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                  NUM_PROTOTYPES, numClasses,\n",
    "                  gamma, W=W, B=B)\n",
    "trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
    "                         SPAR_W, SPAR_B, SPAR_Z,\n",
    "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
    "sess = tf.Session()\n",
    "\n",
    "trainer.train(BATCH_SIZE, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,\n",
    "              printStep=600, valStep=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uypXmz1QJ2h"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:07:22.671507Z",
     "start_time": "2018-08-15T13:07:22.645050Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 96103,
     "status": "ok",
     "timestamp": 1567154584845,
     "user": {
      "displayName": "Gokul Hari",
      "photoUrl": "",
      "userId": "16159457985484250305"
     },
     "user_tz": -330
    },
    "id": "VYxefAD3QJ2j",
    "outputId": "f8b711a1-bae4-4bf5-9a62-935838844601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.7552272\n",
      "Model size constraint (Bytes):  9580\n",
      "Number of non-zeros:  2395\n"
     ]
    }
   ],
   "source": [
    "acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "pred = sess.run(protoNN.predictions, feed_dict={X: x_test, Y: y_test})\n",
    "# W, B, Z are tensorflow graph nodes\n",
    "W, B, Z, _ = protoNN.getModelMatrices()\n",
    "matrixList = sess.run([W, B, Z])\n",
    "sparcityList = [SPAR_W, SPAR_B, SPAR_Z]                       \n",
    "nnz, size, sparse = getModelSize(matrixList, sparcityList)\n",
    "print(\"Final test accuracy\", acc)\n",
    "print(\"Model size constraint (Bytes): \", size)\n",
    "print(\"Number of non-zeros: \", nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 91542,
     "status": "ok",
     "timestamp": 1567154584848,
     "user": {
      "displayName": "Gokul Hari",
      "photoUrl": "",
      "userId": "16159457985484250305"
     },
     "user_tz": -330
    },
    "id": "yJM9puhcQJ2t",
    "outputId": "d8e743e0-1068-4681-e3bc-3b650ab66a3c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2946 2028]\n",
      " [ 407 4567]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.87862   0.59228   0.70758      4974\n",
      "           1    0.69249   0.91817   0.78952      4974\n",
      "\n",
      "    accuracy                        0.75523      9948\n",
      "   macro avg    0.78556   0.75523   0.74855      9948\n",
      "weighted avg    0.78556   0.75523   0.74855      9948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "y_test = np.argmax(y_test,axis=1)\n",
    "print (confusion_matrix(y_test,pred))\n",
    "print (classification_report(y_test,pred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9181745074386811"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = confusion_matrix(y_test,pred)[1][1]/(confusion_matrix(y_test,pred)[1][1] + confusion_matrix(y_test,pred)[1][0])\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5922798552472859"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity = confusion_matrix(y_test,pred)[0][0]/(confusion_matrix(y_test,pred)[0][0] + confusion_matrix(y_test,pred)[0][1])\n",
    "specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = (TP + TN) / (TP + TN + FP + FN) \n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)\n",
    "# sensitivity = TP / (TP + FN) \n",
    "# specificity = TN / (TN + FP) \n",
    "# positive predictive value (PPV) = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "protoNN_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ProtoNN",
   "language": "python",
   "name": "protonn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
