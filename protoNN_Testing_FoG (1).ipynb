{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwwtn5iEQJ1M"
   },
   "source": [
    "# ProtoNN in Tensorflow\n",
    "\n",
    "This is a simple notebook that illustrates the usage of Tensorflow implementation of ProtoNN. We are using the USPS dataset. Please refer to `fetch_usps.py` for more details on downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.223951Z",
     "start_time": "2018-08-15T13:06:09.303454Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dJBVr2b7QJ1R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nadit\\anaconda3\\envs\\ProtoNN\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "#sys.path.insert(0, '../../')\n",
    "# from edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
    "# from edgeml.graph.protoNN import ProtoNN\n",
    "# import edgeml.utils as utils\n",
    "# import helpermethods as helper\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "sys.path.append(r\"D:\\programming\\practice\\research\\protoNN\\EdgeML\\examples\\tf\\ProtoNN\")\n",
    "import helpermethods as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxqvfwWQtQ-s"
   },
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cT-KokQSQiS6"
   },
   "outputs": [],
   "source": [
    "#helper methods\n",
    "sys.path.insert(0, '../')\n",
    "import argparse\n",
    "\n",
    "\n",
    "def getModelSize(matrixList, sparcityList, expected=True, bytesPerVar=4):\n",
    "    '''\n",
    "    expected: Expected size according to the parameters set. The number of\n",
    "        zeros could actually be more than that is required to satisfy the\n",
    "        sparsity constraint.\n",
    "    '''\n",
    "    nnzList, sizeList, isSparseList = [], [], []\n",
    "    hasSparse = False\n",
    "    for i in range(len(matrixList)):\n",
    "        A, s = matrixList[i], sparcityList[i]\n",
    "        assert A.ndim == 2\n",
    "        assert s >= 0\n",
    "        assert s <= 1\n",
    "        nnz, size, sparse = countnnZ(A, s, bytesPerVar=bytesPerVar)\n",
    "        nnzList.append(nnz)\n",
    "        sizeList.append(size)\n",
    "        hasSparse = (hasSparse or sparse)\n",
    "\n",
    "    totalnnZ = np.sum(nnzList)\n",
    "    totalSize = np.sum(sizeList)\n",
    "    if expected:\n",
    "        return totalnnZ, totalSize, hasSparse\n",
    "    numNonZero = 0\n",
    "    totalSize = 0\n",
    "    hasSparse = False\n",
    "    for i in range(len(matrixList)):\n",
    "        A, s = matrixList[i], sparcityList[i]\n",
    "        numNonZero_ = np.count_nonzero(A)\n",
    "        numNonZero += numNonZero_\n",
    "        hasSparse = (hasSparse or (s < 0.5))\n",
    "        if s <= 0.5:\n",
    "            totalSize += numNonZero_ * 2 * bytesPerVar\n",
    "        else:\n",
    "            totalSize += A.size * bytesPerVar\n",
    "    return numNonZero, totalSize, hasSparse\n",
    "\n",
    "\n",
    "def getGamma(gammaInit, projectionDim, dataDim, numPrototypes, x_train):\n",
    "    if gammaInit is None:\n",
    "        print(\"Using median heuristic to estimate gamma.\")\n",
    "        gamma, W, B = medianHeuristic(x_train, projectionDim,\n",
    "                                            numPrototypes)\n",
    "        print(\"Gamma estimate is: %f\" % gamma)\n",
    "        return W, B, gamma\n",
    "    return None, None, gammaInit\n",
    "\n",
    "\n",
    "def preprocessData(dataDir,w):\n",
    "    '''\n",
    "    Loads data from the dataDir and does some initial preprocessing\n",
    "    steps. Data is assumed to be contained in two files,\n",
    "    train.npy and test.npy. Each containing a 2D numpy array of dimension\n",
    "    [numberOfExamples, numberOfFeatures + 1]. The first column of each\n",
    "    matrix is assumed to contain label information.\n",
    "\n",
    "    For an N-Class problem, we assume the labels are integers from 0 through\n",
    "    N-1.\n",
    "    '''\n",
    "    # Uncomment for usual training data\n",
    "    # train = np.load(dataDir + '/train_'+str(w)+'.npy')\n",
    "    # test = np.load(dataDir + '/test_'+str(w)+'.npy')\n",
    "    # Uncomment for time domain training data\n",
    "    train = np.load(dataDir + '/ttrain_'+str(w)+'.npy')\n",
    "    test = np.load(dataDir + '/ttest_'+str(w)+'.npy')\n",
    "    # Uncomment for 1 sensordrop training data\n",
    "    # train = np.load(dataDir + '/train_'+str(w)+'.npy')\n",
    "    # test = np.load(dataDir + '/test_'+str(w)+'.npy')\n",
    "\n",
    "    dataDimension = int(train.shape[1]) - 1\n",
    "    x_train = train[:, 1:dataDimension + 1]\n",
    "    y_train_ = train[:, 0]\n",
    "    x_test = test[:, 1:dataDimension + 1]\n",
    "    y_test_ = test[:, 0]\n",
    "\n",
    "    numClasses = max(y_train_) - min(y_train_) + 1\n",
    "    numClasses = max(numClasses, max(y_test_) - min(y_test_) + 1)\n",
    "    numClasses = int(numClasses)\n",
    "\n",
    "    # mean-var\n",
    "    mean = np.mean(x_train, 0)\n",
    "    std = np.std(x_train, 0)\n",
    "    std[std[:] < 0.000001] = 1\n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "\n",
    "    # one hot y-train\n",
    "    lab = y_train_.astype('uint8')\n",
    "    lab = np.array(lab) - min(lab)\n",
    "    lab_ = np.zeros((x_train.shape[0], numClasses))\n",
    "    lab_[np.arange(x_train.shape[0]), lab] = 1\n",
    "    y_train = lab_\n",
    "\n",
    "    # one hot y-test\n",
    "    lab = y_test_.astype('uint8')\n",
    "    lab = np.array(lab) - min(lab)\n",
    "    lab_ = np.zeros((x_test.shape[0], numClasses))\n",
    "    lab_[np.arange(x_test.shape[0]), lab] = 1\n",
    "    y_test = lab_\n",
    "\n",
    "    return dataDimension, numClasses, x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "def getProtoNNArgs():\n",
    "    def checkIntPos(value):\n",
    "        ivalue = int(value)\n",
    "        if ivalue <= 0:\n",
    "            raise argparse.ArgumentTypeError(\n",
    "                \"%s is an invalid positive int value\" % value)\n",
    "        return ivalue\n",
    "\n",
    "    def checkIntNneg(value):\n",
    "        ivalue = int(value)\n",
    "        if ivalue < 0:\n",
    "            raise argparse.ArgumentTypeError(\n",
    "                \"%s is an invalid non-neg int value\" % value)\n",
    "        return ivalue\n",
    "\n",
    "    def checkFloatNneg(value):\n",
    "        fvalue = float(value)\n",
    "        if fvalue < 0:\n",
    "            raise argparse.ArgumentTypeError(\n",
    "                \"%s is an invalid non-neg float value\" % value)\n",
    "        return fvalue\n",
    "\n",
    "    def checkFloatPos(value):\n",
    "        fvalue = float(value)\n",
    "        if fvalue <= 0:\n",
    "            raise argparse.ArgumentTypeError(\n",
    "                \"%s is an invalid positive float value\" % value)\n",
    "        return fvalue\n",
    "\n",
    "    '''\n",
    "    Parse protoNN commandline arguments\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Hyperparameters for ProtoNN Algorithm')\n",
    "\n",
    "    msg = 'Data directory containing train and test data. The '\n",
    "    msg += 'data is assumed to be saved as 2-D numpy matrices with '\n",
    "    msg += 'names `train.npy` and `test.npy`, of dimensions\\n'\n",
    "    msg += '\\t[numberOfInstances, numberOfFeatures + 1].\\n'\n",
    "    msg += 'The first column of each file is assumed to contain label information.'\n",
    "    msg += ' For a N-class problem, labels are assumed to be integers from 0 to'\n",
    "    msg += ' N-1 (inclusive).'\n",
    "    parser.add_argument('-d', '--data-dir', required=True, help=msg)\n",
    "    parser.add_argument('-l', '--projection-dim', type=checkIntPos, default=10,\n",
    "                        help='Projection Dimension.')\n",
    "    parser.add_argument('-p', '--num-prototypes', type=checkIntPos, default=20,\n",
    "                        help='Number of prototypes.')\n",
    "    parser.add_argument('-g', '--gamma', type=checkFloatPos, default=None,\n",
    "                        help='Gamma for Gaussian kernel. If not provided, ' +\n",
    "                        'median heuristic will be used to estimate gamma.')\n",
    "\n",
    "    parser.add_argument('-e', '--epochs', type=checkIntPos, default=100,\n",
    "                        help='Total training epochs.')\n",
    "    parser.add_argument('-b', '--batch-size', type=checkIntPos, default=32,\n",
    "                        help='Batch size for each pass.')\n",
    "    parser.add_argument('-r', '--learning-rate', type=checkFloatPos,\n",
    "                        default=0.001,\n",
    "                        help='Initial Learning rate for ADAM Optimizer.')\n",
    "\n",
    "    parser.add_argument('-rW', type=float, default=0.000,\n",
    "                        help='Coefficient for l2 regularizer for predictor' +\n",
    "                        ' parameter W ' + '(default = 0.0).')\n",
    "    parser.add_argument('-rB', type=float, default=0.00,\n",
    "                        help='Coefficient for l2 regularizer for predictor' +\n",
    "                        ' parameter B ' + '(default = 0.0).')\n",
    "    parser.add_argument('-rZ', type=float, default=0.00,\n",
    "                        help='Coefficient for l2 regularizer for predictor' +\n",
    "                        'parameter Z ' +\n",
    "                        '(default = 0.0).')\n",
    "\n",
    "    parser.add_argument('-sW', type=float, default=1.000,\n",
    "                        help='Sparsity constraint for predictor parameter W ' +\n",
    "                        '(default = 1.0, i.e. dense matrix).')\n",
    "    parser.add_argument('-sB', type=float, default=1.00,\n",
    "                        help='Sparsity constraint for predictor parameter B ' +\n",
    "                        '(default = 1.0, i.e. dense matrix).')\n",
    "    parser.add_argument('-sZ', type=float, default=1.00,\n",
    "                        help='Sparsity constraint for predictor parameter Z ' +\n",
    "                        '(default = 1.0, i.e. dense matrix).')\n",
    "    parser.add_argument('-pS', '--print-step', type=int, default=200,\n",
    "                        help='The number of update steps between print ' +\n",
    "                        'calls to console.')\n",
    "    parser.add_argument('-vS', '--val-step', type=int, default=3,\n",
    "                        help='The number of epochs between validation' +\n",
    "                        'performance evaluation')\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ou1MfKhYtMdT"
   },
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDVo_0JiRSi9"
   },
   "outputs": [],
   "source": [
    "#utils\n",
    "import scipy.cluster\n",
    "import scipy.spatial\n",
    "import os\n",
    "\n",
    "\n",
    "def medianHeuristic(data, projectionDimension, numPrototypes, W_init=None):\n",
    "    '''\n",
    "    This method can be used to estimate gamma for ProtoNN. An approximation to\n",
    "    median heuristic is used here.\n",
    "    1. First the data is collapsed into the projectionDimension by W_init. If\n",
    "    W_init is not provided, it is initialized from a random normal(0, 1). Hence\n",
    "    data normalization is essential.\n",
    "    2. Prototype are computed by running a  k-means clustering on the projected\n",
    "    data.\n",
    "    3. The median distance is then estimated by calculating median distance\n",
    "    between prototypes and projected data points.\n",
    "\n",
    "    data needs to be [-1, numFeats]\n",
    "    If using this method to initialize gamma, please use the W and B as well.\n",
    "\n",
    "    TODO: Return estimate of Z (prototype labels) based on cluster centroids\n",
    "    andand labels\n",
    "\n",
    "    TODO: Clustering fails due to singularity error if projecting upwards\n",
    "\n",
    "    W [dxd_cap]\n",
    "    B [d_cap, m]\n",
    "    returns gamma, W, B\n",
    "    '''\n",
    "    assert data.ndim == 2\n",
    "    X = data\n",
    "    featDim = data.shape[1]\n",
    "    if projectionDimension > featDim:\n",
    "        print(\"Warning: Projection dimension > feature dimension. Gamma\")\n",
    "        print(\"\\t estimation due to median heuristic could fail.\")\n",
    "        print(\"\\tTo retain the projection dataDimension, provide\")\n",
    "        print(\"\\ta value for gamma.\")\n",
    "\n",
    "    if W_init is None:\n",
    "        W_init = np.random.normal(size=[featDim, projectionDimension])\n",
    "    W = W_init\n",
    "    XW = np.matmul(X, W)\n",
    "    assert XW.shape[1] == projectionDimension\n",
    "    assert XW.shape[0] == len(X)\n",
    "    # Requires [N x d_cap] data matrix of N observations of d_cap-dimension and\n",
    "    # the number of centroids m. Returns, [n x d_cap] centroids and\n",
    "    # elementwise center information.\n",
    "    B, centers = scipy.cluster.vq.kmeans2(XW, numPrototypes)\n",
    "    # Requires two matrices. Number of observations x dimension of observation\n",
    "    # space. Distances[i,j] is the distance between XW[i] and B[j]\n",
    "    distances = scipy.spatial.distance.cdist(XW, B, metric='euclidean')\n",
    "    distances = np.reshape(distances, [-1])\n",
    "    gamma = np.median(distances)\n",
    "    gamma = 1 / (2.5 * gamma)\n",
    "    return gamma.astype('float32'), W.astype('float32'), B.T.astype('float32')\n",
    "\n",
    "\n",
    "def multiClassHingeLoss(logits, label, batch_th):\n",
    "    '''\n",
    "    MultiClassHingeLoss to match C++ Version - No TF internal version\n",
    "    '''\n",
    "    flatLogits = tf.reshape(logits, [-1, ])\n",
    "    label_ = tf.argmax(label, 1)\n",
    "\n",
    "    correctId = tf.range(0, batch_th) * label.shape[1] + label_\n",
    "    correctLogit = tf.gather(flatLogits, correctId)\n",
    "\n",
    "    maxLabel = tf.argmax(logits, 1)\n",
    "    top2, _ = tf.nn.top_k(logits, k=2, sorted=True)\n",
    "\n",
    "    wrongMaxLogit = tf.where(\n",
    "        tf.equal(maxLabel, label_), top2[:, 1], top2[:, 0])\n",
    "\n",
    "    return tf.reduce_mean(tf.nn.relu(1. + wrongMaxLogit - correctLogit))\n",
    "\n",
    "\n",
    "def crossEntropyLoss(logits, label):\n",
    "    '''\n",
    "    Cross Entropy loss for MultiClass case in joint training for\n",
    "    faster convergence\n",
    "    '''\n",
    "    return tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                   labels=tf.stop_gradient(label)))\n",
    "\n",
    "\n",
    "def mean_absolute_error(logits, label):\n",
    "    '''\n",
    "    Function to compute the mean absolute error.\n",
    "    '''\n",
    "    return tf.reduce_mean(tf.abs(tf.subtract(logits, label)))\n",
    "\n",
    "\n",
    "def hardThreshold(A, s):\n",
    "    '''\n",
    "    Hard thresholding function on Tensor A with sparsity s\n",
    "    '''\n",
    "    A_ = np.copy(A)\n",
    "    A_ = A_.ravel()\n",
    "    if len(A_) > 0:\n",
    "        th = np.percentile(np.abs(A_), (1 - s) * 100.0, interpolation='higher')\n",
    "        A_[np.abs(A_) < th] = 0.0\n",
    "    A_ = A_.reshape(A.shape)\n",
    "    return A_\n",
    "\n",
    "\n",
    "def copySupport(src, dest):\n",
    "    '''\n",
    "    copy support of src tensor to dest tensor\n",
    "    '''\n",
    "    support = np.nonzero(src)\n",
    "    dest_ = dest\n",
    "    dest = np.zeros(dest_.shape)\n",
    "    dest[support] = dest_[support]\n",
    "    return dest\n",
    "\n",
    "\n",
    "def countnnZ(A, s, bytesPerVar=4):\n",
    "    '''\n",
    "    Returns # of non-zeros and representative size of the tensor\n",
    "    Uses dense for s >= 0.5 - 4 byte\n",
    "    Else uses sparse - 8 byte\n",
    "    '''\n",
    "    params = 1\n",
    "    hasSparse = False\n",
    "    for i in range(0, len(A.shape)):\n",
    "        params *= int(A.shape[i])\n",
    "    if s < 0.5:\n",
    "        nnZ = np.ceil(params * s)\n",
    "        hasSparse = True\n",
    "        return nnZ, nnZ * 2 * bytesPerVar, hasSparse\n",
    "    else:\n",
    "        nnZ = params\n",
    "        return nnZ, nnZ * bytesPerVar, hasSparse\n",
    "\n",
    "\n",
    "def getConfusionMatrix(predicted, target, numClasses):\n",
    "    '''\n",
    "    Returns a confusion matrix for a multiclass classification\n",
    "    problem. `predicted` is a 1-D array of integers representing\n",
    "    the predicted classes and `target` is the target classes.\n",
    "\n",
    "    confusion[i][j]: Number of elements of class j\n",
    "        predicted as class i\n",
    "    Labels are assumed to be in range(0, numClasses)\n",
    "    Use`printFormattedConfusionMatrix` to echo the confusion matrix\n",
    "    in a user friendly form.\n",
    "    '''\n",
    "    assert(predicted.ndim == 1)\n",
    "    assert(target.ndim == 1)\n",
    "    arr = np.zeros([numClasses, numClasses])\n",
    "\n",
    "    for i in range(len(predicted)):\n",
    "        arr[predicted[i]][target[i]] += 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def printFormattedConfusionMatrix(matrix):\n",
    "    '''\n",
    "    Given a 2D confusion matrix, prints it in a human readable way.\n",
    "    The confusion matrix is expected to be a 2D numpy array with\n",
    "    square dimensions\n",
    "    '''\n",
    "    assert(matrix.ndim == 2)\n",
    "    assert(matrix.shape[0] == matrix.shape[1])\n",
    "    RECALL = 'Recall'\n",
    "    PRECISION = 'PRECISION'\n",
    "    print(\"|%s|\" % ('True->'), end='')\n",
    "    for i in range(matrix.shape[0]):\n",
    "        print(\"%7d|\" % i, end='')\n",
    "    print(\"%s|\" % 'Precision')\n",
    "\n",
    "    print(\"|%s|\" % ('-' * len(RECALL)), end='')\n",
    "    for i in range(matrix.shape[0]):\n",
    "        print(\"%s|\" % ('-' * 7), end='')\n",
    "    print(\"%s|\" % ('-' * len(PRECISION)))\n",
    "\n",
    "    precisionlist = np.sum(matrix, axis=1)\n",
    "    recalllist = np.sum(matrix, axis=0)\n",
    "    precisionlist = [matrix[i][i] / x if x !=\n",
    "                     0 else -1 for i, x in enumerate(precisionlist)]\n",
    "    recalllist = [matrix[i][i] / x if x !=\n",
    "                  0 else -1 for i, x in enumerate(recalllist)]\n",
    "    for i in range(matrix.shape[0]):\n",
    "        # len recall = 6\n",
    "        print(\"|%6d|\" % (i), end='')\n",
    "        for j in range(matrix.shape[0]):\n",
    "            print(\"%7d|\" % (matrix[i][j]), end='')\n",
    "        print(\"%s\" % (\" \" * (len(PRECISION) - 7)), end='')\n",
    "        if precisionlist[i] != -1:\n",
    "            print(\"%1.5f|\" % precisionlist[i])\n",
    "        else:\n",
    "            print(\"%7s|\" % \"nan\")\n",
    "\n",
    "    print(\"|%s|\" % ('-' * len(RECALL)), end='')\n",
    "    for i in range(matrix.shape[0]):\n",
    "        print(\"%s|\" % ('-' * 7), end='')\n",
    "    print(\"%s|\" % ('-' * len(PRECISION)))\n",
    "    print(\"|%s|\" % ('Recall'), end='')\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        if recalllist[i] != -1:\n",
    "            print(\"%1.5f|\" % (recalllist[i]), end='')\n",
    "        else:\n",
    "            print(\"%7s|\" % \"nan\", end='')\n",
    "\n",
    "    print('%s|' % (' ' * len(PRECISION)))\n",
    "\n",
    "\n",
    "def getPrecisionRecall(cmatrix, label=1):\n",
    "    trueP = cmatrix[label][label]\n",
    "    denom = np.sum(cmatrix, axis=0)[label]\n",
    "    if denom == 0:\n",
    "        denom = 1\n",
    "    recall = trueP / denom\n",
    "    denom = np.sum(cmatrix, axis=1)[label]\n",
    "    if denom == 0:\n",
    "        denom = 1\n",
    "    precision = trueP / denom\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def getMacroPrecisionRecall(cmatrix):\n",
    "    # TP + FP\n",
    "    precisionlist = np.sum(cmatrix, axis=1)\n",
    "    # TP + FN\n",
    "    recalllist = np.sum(cmatrix, axis=0)\n",
    "    precisionlist__ = [cmatrix[i][i] / x if x !=\n",
    "                       0 else 0 for i, x in enumerate(precisionlist)]\n",
    "    recalllist__ = [cmatrix[i][i] / x if x !=\n",
    "                    0 else 0 for i, x in enumerate(recalllist)]\n",
    "    precision = np.sum(precisionlist__)\n",
    "    precision /= len(precisionlist__)\n",
    "    recall = np.sum(recalllist__)\n",
    "    recall /= len(recalllist__)\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def getMicroPrecisionRecall(cmatrix):\n",
    "    # TP + FP\n",
    "    precisionlist = np.sum(cmatrix, axis=1)\n",
    "    # TP + FN\n",
    "    recalllist = np.sum(cmatrix, axis=0)\n",
    "    num = 0.0\n",
    "    for i in range(len(cmatrix)):\n",
    "        num += cmatrix[i][i]\n",
    "\n",
    "    precision = num / np.sum(precisionlist)\n",
    "    recall = num / np.sum(recalllist)\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def getMacroMicroFScore(cmatrix):\n",
    "    '''\n",
    "    Returns macro and micro f-scores.\n",
    "    Refer: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.8244&rep=rep1&type=pdf\n",
    "    '''\n",
    "    precisionlist = np.sum(cmatrix, axis=1)\n",
    "    recalllist = np.sum(cmatrix, axis=0)\n",
    "    precisionlist__ = [cmatrix[i][i] / x if x !=\n",
    "                       0 else 0 for i, x in enumerate(precisionlist)]\n",
    "    recalllist__ = [cmatrix[i][i] / x if x !=\n",
    "                    0 else 0 for i, x in enumerate(recalllist)]\n",
    "    macro = 0.0\n",
    "    for i in range(len(precisionlist)):\n",
    "        denom = precisionlist__[i] + recalllist__[i]\n",
    "        numer = precisionlist__[i] * recalllist__[i] * 2\n",
    "        if denom == 0:\n",
    "            denom = 1\n",
    "        macro += numer / denom\n",
    "    macro /= len(precisionlist)\n",
    "\n",
    "    num = 0.0\n",
    "    for i in range(len(precisionlist)):\n",
    "        num += cmatrix[i][i]\n",
    "\n",
    "    denom1 = np.sum(precisionlist)\n",
    "    denom2 = np.sum(recalllist)\n",
    "    pi = num / denom1\n",
    "    rho = num / denom2\n",
    "    denom = pi + rho\n",
    "    if denom == 0:\n",
    "        denom = 1\n",
    "    micro = 2 * pi * rho / denom\n",
    "    return macro, micro\n",
    "\n",
    "\n",
    "class GraphManager:\n",
    "    '''\n",
    "    Manages saving and restoring graphs. Designed to be used with EMI-RNN\n",
    "    though is general enough to be useful otherwise as well.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def checkpointModel(self, saver, sess, modelPrefix,\n",
    "                        globalStep=1000, redirFile=None):\n",
    "        saver.save(sess, modelPrefix, global_step=globalStep)\n",
    "        print('Model saved to %s, global_step %d' % (modelPrefix, globalStep),\n",
    "              file=redirFile)\n",
    "\n",
    "    def loadCheckpoint(self, sess, modelPrefix, globalStep,\n",
    "                       redirFile=None):\n",
    "        metaname = modelPrefix + '-%d.meta' % globalStep\n",
    "        basename = os.path.basename(metaname)\n",
    "        fileList = os.listdir(os.path.dirname(modelPrefix))\n",
    "        fileList = [x for x in fileList if x.startswith(basename)]\n",
    "        assert len(fileList) > 0, 'Checkpoint file not found'\n",
    "        msg = 'Too many or too few checkpoint files for globalStep: %d' % globalStep\n",
    "        assert len(fileList) is 1, msg\n",
    "        chkpt = basename + '/' + fileList[0]\n",
    "        saver = tf.train.import_meta_graph(metaname)\n",
    "        metaname = metaname[:-5]\n",
    "        saver.restore(sess, metaname)\n",
    "        graph = tf.get_default_graph()\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAjSVSOFtFmm"
   },
   "source": [
    "# Model Trainer - ProtoNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp5dEFiZR_sy"
   },
   "outputs": [],
   "source": [
    "#Trainer\n",
    "class ProtoNNTrainer:\n",
    "    def __init__(self, protoNNObj, regW, regB, regZ,\n",
    "                 sparcityW, sparcityB, sparcityZ,\n",
    "                 learningRate, X, Y, lossType='l2'):\n",
    "        '''\n",
    "        A wrapper for the various techniques used for training ProtoNN. This\n",
    "        subsumes both the responsibility of loss graph construction and\n",
    "        performing training. The original training routine that is part of the\n",
    "        C++ implementation of EdgeML used iterative hard thresholding (IHT),\n",
    "        gamma estimation through median heuristic and other tricks for\n",
    "        training ProtoNN. This module implements the same in Tensorflow\n",
    "        and python.\n",
    "\n",
    "        protoNNObj: An instance of ProtoNN class defining the forward\n",
    "            computation graph. The loss functions and training routines will be\n",
    "            attached to this instance.\n",
    "        regW, regB, regZ: Regularization constants for W, B, and\n",
    "            Z matrices of protoNN.\n",
    "        sparcityW, sparcityB, sparcityZ: Sparsity constraints\n",
    "            for W, B and Z matrices. A value between 0 (exclusive) and 1\n",
    "            (inclusive) is expected. A value of 1 indicates dense training.\n",
    "        learningRate: Initial learning rate for ADAM optimizer.\n",
    "        X, Y : Placeholders for data and labels.\n",
    "            X [-1, featureDimension]\n",
    "            Y [-1, num Labels]\n",
    "        lossType: ['l2', 'xentropy']\n",
    "        '''\n",
    "        self.protoNNObj = protoNNObj\n",
    "        self.__regW = regW\n",
    "        self.__regB = regB\n",
    "        self.__regZ = regZ\n",
    "        self.__sW = sparcityW\n",
    "        self.__sB = sparcityB\n",
    "        self.__sZ = sparcityZ\n",
    "        self.__lR = learningRate\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.sparseTraining = True\n",
    "        if (sparcityW == 1.0) and (sparcityB == 1.0) and (sparcityZ == 1.0):\n",
    "            self.sparseTraining = False\n",
    "            print(\"Sparse training disabled.\", file=sys.stderr)\n",
    "        # Define placeholders for sparse training\n",
    "        self.W_th = None\n",
    "        self.B_th = None\n",
    "        self.Z_th = None\n",
    "        self.__lossType = lossType\n",
    "        self.__validInit = False\n",
    "        self.__validInit = self.__validateInit()\n",
    "        self.__protoNNOut = protoNNObj(X, Y)\n",
    "        self.loss = self.__lossGraph()\n",
    "        self.trainStep = self.__trainGraph()\n",
    "        self.__hthOp = self.__getHardThresholdOp()\n",
    "        self.accuracy = protoNNObj.getAccuracyOp()\n",
    "\n",
    "    def __validateInit(self):\n",
    "        self.__validInit = False\n",
    "        msg = \"Sparsity value should be between\"\n",
    "        msg += \" 0 and 1 (both inclusive).\"\n",
    "        assert self.__sW >= 0. and self.__sW <= 1., 'W:' + msg\n",
    "        assert self.__sB >= 0. and self.__sB <= 1., 'B:' + msg\n",
    "        assert self.__sZ >= 0. and self.__sZ <= 1., 'Z:' + msg\n",
    "        d, dcap, m, L, _ = self.protoNNObj.getHyperParams()\n",
    "        msg = 'Y should be of dimension [-1, num labels/classes]'\n",
    "        msg += ' specified as part of ProtoNN object.'\n",
    "        assert (len(self.Y.shape)) == 2, msg\n",
    "        assert (self.Y.shape[1] == L), msg\n",
    "        msg = 'X should be of dimension [-1, featureDimension]'\n",
    "        msg += ' specified as part of ProtoNN object.'\n",
    "        assert (len(self.X.shape) == 2), msg\n",
    "        assert (self.X.shape[1] == d), msg\n",
    "        self.__validInit = True\n",
    "        msg = 'Values can be \\'l2\\', or \\'xentropy\\''\n",
    "        if self.__lossType not in ['l2', 'xentropy']:\n",
    "            raise ValueError(msg)\n",
    "        return True\n",
    "\n",
    "    def __lossGraph(self):\n",
    "        pnnOut = self.__protoNNOut\n",
    "        l1, l2, l3 = self.__regW, self.__regB, self.__regZ\n",
    "        W, B, Z, _ = self.protoNNObj.getModelMatrices()\n",
    "        if self.__lossType == 'l2':\n",
    "            with tf.name_scope('protonn-l2-loss'):\n",
    "                loss_0 = tf.nn.l2_loss(self.Y - pnnOut)\n",
    "                reg = l1 * tf.nn.l2_loss(W) + l2 * tf.nn.l2_loss(B)\n",
    "                reg += l3 * tf.nn.l2_loss(Z)\n",
    "                loss = loss_0 + reg\n",
    "        elif self.__lossType == 'xentropy':\n",
    "            with tf.name_scope('protonn-xentropy-loss'):\n",
    "                loss_0 = tf.nn.softmax_cross_entropy_with_logits_v2(logits=pnnOut,\n",
    "                                                         labels=tf.stop_gradient(self.Y))\n",
    "                loss_0 = tf.reduce_mean(loss_0)\n",
    "                reg = l1 * tf.nn.l2_loss(W) + l2 * tf.nn.l2_loss(B)\n",
    "                reg += l3 * tf.nn.l2_loss(Z)\n",
    "                loss = loss_0 + reg\n",
    "        return loss\n",
    "\n",
    "    def __trainGraph(self):\n",
    "        with tf.name_scope('protonn-gradient-adam'):\n",
    "            trainStep = tf.train.AdamOptimizer(self.__lR)\n",
    "            trainStep = trainStep.minimize(self.loss)\n",
    "        return trainStep\n",
    "\n",
    "    def __getHardThresholdOp(self):\n",
    "        W, B, Z, _ = self.protoNNObj.getModelMatrices()\n",
    "        self.W_th = tf.placeholder(tf.float32, name='W_th')\n",
    "        self.B_th = tf.placeholder(tf.float32, name='B_th')\n",
    "        self.Z_th = tf.placeholder(tf.float32, name='Z_th')\n",
    "        with tf.name_scope('hard-threshold-assignments'):\n",
    "            hard_thrsd_W = W.assign(self.W_th)\n",
    "            hard_thrsd_B = B.assign(self.B_th)\n",
    "            hard_thrsd_Z = Z.assign(self.Z_th)\n",
    "            hard_thrsd_op = tf.group(hard_thrsd_W, hard_thrsd_B, hard_thrsd_Z)\n",
    "        return hard_thrsd_op\n",
    "\n",
    "    def train(self, batchSize, totalEpochs, sess,\n",
    "              x_train, x_val, y_train, y_val, noInit=False,\n",
    "              redirFile=None, printStep=10, valStep=3):\n",
    "        '''\n",
    "        Performs dense training of ProtoNN followed by iterative hard\n",
    "        thresholding to enforce sparsity constraints.\n",
    "\n",
    "        batchSize: Batch size per update\n",
    "        totalEpochs: The number of epochs to run training for. One epoch is\n",
    "            defined as one pass over the entire training data.\n",
    "        sess: The Tensorflow session to use for running various graph\n",
    "            operators.\n",
    "        x_train, x_val, y_train, y_val: The numpy array containing train and\n",
    "            validation data. x data is assumed to in of shape [-1,\n",
    "            featureDimension] while y should have shape [-1, numberLabels].\n",
    "        noInit: By default, all the tensors of the computation graph are\n",
    "        initialized at the start of the training session. Set noInit=False to\n",
    "        disable this behaviour.\n",
    "        printStep: Number of batches between echoing of loss and train accuracy.\n",
    "        valStep: Number of epochs between evolutions on validation set.\n",
    "        '''\n",
    "        d, d_cap, m, L, gamma = self.protoNNObj.getHyperParams()\n",
    "        assert batchSize >= 1, 'Batch size should be positive integer'\n",
    "        assert totalEpochs >= 1, 'Total epochs should be positive integer'\n",
    "        assert x_train.ndim == 2, 'Expected training data to be of rank 2'\n",
    "        assert x_train.shape[1] == d, 'Expected x_train to be [-1, %d]' % d\n",
    "        assert x_val.ndim == 2, 'Expected validation data to be of rank 2'\n",
    "        assert x_val.shape[1] == d, 'Expected x_val to be [-1, %d]' % d\n",
    "        assert y_train.ndim == 2, 'Expected training labels to be of rank 2'\n",
    "        assert y_train.shape[1] == L, 'Expected y_train to be [-1, %d]' % L\n",
    "        assert y_val.ndim == 2, 'Expected validation labels to be of rank 2'\n",
    "        assert y_val.shape[1] == L, 'Expected y_val to be [-1, %d]' % L\n",
    "\n",
    "        # Numpy will throw asserts for arrays\n",
    "        if sess is None:\n",
    "            raise ValueError('sess must be valid Tensorflow session.')\n",
    "\n",
    "        trainNumBatches = int(np.ceil(len(x_train) / batchSize))\n",
    "        valNumBatches = int(np.ceil(len(x_val) / batchSize))\n",
    "        x_train_batches = np.array_split(x_train, trainNumBatches)\n",
    "        y_train_batches = np.array_split(y_train, trainNumBatches)\n",
    "        x_val_batches = np.array_split(x_val, valNumBatches)\n",
    "        y_val_batches = np.array_split(y_val, valNumBatches)\n",
    "        if not noInit:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        X, Y = self.X, self.Y\n",
    "        W, B, Z, _ = self.protoNNObj.getModelMatrices()\n",
    "        for epoch in range(totalEpochs):\n",
    "            for i in range(len(x_train_batches)):\n",
    "                batch_x = x_train_batches[i]\n",
    "                batch_y = y_train_batches[i]\n",
    "                feed_dict = {\n",
    "                    X: batch_x,\n",
    "                    Y: batch_y\n",
    "                }\n",
    "                sess.run(self.trainStep, feed_dict=feed_dict)\n",
    "                if i % printStep == 0:\n",
    "                    loss, acc = sess.run([self.loss, self.accuracy],\n",
    "                                         feed_dict=feed_dict)\n",
    "                    msg = \"Epoch: %3d Batch: %3d\" % (epoch, i)\n",
    "                    msg += \" Loss: %3.5f Accuracy: %2.5f\" % (loss, acc)\n",
    "                    print(msg, file=redirFile)\n",
    "\n",
    "            # Perform Hard thresholding\n",
    "            if self.sparseTraining:\n",
    "                W_, B_, Z_ = sess.run([W, B, Z])\n",
    "                fd_thrsd = {\n",
    "                    self.W_th: hardThreshold(W_, self.__sW),\n",
    "                    self.B_th: hardThreshold(B_, self.__sB),\n",
    "                    self.Z_th: hardThreshold(Z_, self.__sZ)\n",
    "                }\n",
    "                sess.run(self.__hthOp, feed_dict=fd_thrsd)\n",
    "\n",
    "            if (epoch + 1) % valStep  == 0:\n",
    "                acc = 0.0\n",
    "                loss = 0.0\n",
    "                for j in range(len(x_val_batches)):\n",
    "                    batch_x = x_val_batches[j]\n",
    "                    batch_y = y_val_batches[j]\n",
    "                    feed_dict = {\n",
    "                        X: batch_x,\n",
    "                        Y: batch_y\n",
    "                    }\n",
    "                    acc_, loss_ = sess.run([self.accuracy, self.loss],\n",
    "                                           feed_dict=feed_dict)\n",
    "                    acc += acc_\n",
    "                    loss += loss_\n",
    "                acc /= len(y_val_batches)\n",
    "                loss /= len(y_val_batches)\n",
    "                print(\"Test Loss: %2.5f Accuracy: %2.5f\" % (loss, acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Z6ym4k_s9pS"
   },
   "source": [
    "# Model Graph - ProtoNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRPFglKHSbu-"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ProtoNN:\n",
    "    def __init__(self, inputDimension, projectionDimension, numPrototypes,\n",
    "                 numOutputLabels, gamma,\n",
    "                 W = None, B = None, Z = None):\n",
    "        '''\n",
    "        Forward computation graph for ProtoNN.\n",
    "\n",
    "        inputDimension: Input data dimension or feature dimension.\n",
    "        projectionDimension: hyperparameter\n",
    "        numPrototypes: hyperparameter\n",
    "        numOutputLabels: The number of output labels or classes\n",
    "        W, B, Z: Numpy matrices that can be used to initialize\n",
    "            projection matrix(W), prototype matrix (B) and prototype labels\n",
    "            matrix (B).\n",
    "            Expected Dimensions:\n",
    "                W   inputDimension (d) x projectionDimension (d_cap)\n",
    "                B   projectionDimension (d_cap) x numPrototypes (m)\n",
    "                Z   numOutputLabels (L) x numPrototypes (m)\n",
    "        '''\n",
    "        with tf.name_scope('protoNN') as ns:\n",
    "            self.__nscope = ns\n",
    "        self.__d = inputDimension\n",
    "        self.__d_cap = projectionDimension\n",
    "        self.__m = numPrototypes\n",
    "        self.__L = numOutputLabels\n",
    "\n",
    "        self.__inW = W\n",
    "        self.__inB = B\n",
    "        self.__inZ = Z\n",
    "        self.__inGamma = gamma\n",
    "        self.W, self.B, self.Z = None, None, None\n",
    "        self.gamma = None\n",
    "\n",
    "        self.__validInit = False\n",
    "        self.__initWBZ()\n",
    "        self.__initGamma()\n",
    "        self.__validateInit()\n",
    "        self.protoNNOut = None\n",
    "        self.predictions = None\n",
    "        self.accuracy = None\n",
    "\n",
    "    def __validateInit(self):\n",
    "        self.__validInit = False\n",
    "        errmsg = \"Dimensions mismatch! Should be W[d, d_cap]\"\n",
    "        errmsg += \", B[d_cap, m] and Z[L, m]\"\n",
    "        d, d_cap, m, L, _ = self.getHyperParams()\n",
    "        assert self.W.shape[0] == d, errmsg\n",
    "        assert self.W.shape[1] == d_cap, errmsg\n",
    "        assert self.B.shape[0] == d_cap, errmsg\n",
    "        assert self.B.shape[1] == m, errmsg\n",
    "        assert self.Z.shape[0] == L, errmsg\n",
    "        assert self.Z.shape[1] == m, errmsg\n",
    "        self.__validInit = True\n",
    "\n",
    "    def __initWBZ(self):\n",
    "        with tf.name_scope(self.__nscope):\n",
    "            W = self.__inW\n",
    "            if W is None:\n",
    "                W = tf.random_normal_initializer()\n",
    "                W = W([self.__d, self.__d_cap])\n",
    "            self.W = tf.Variable(W, name='W', dtype=tf.float32)\n",
    "\n",
    "            B = self.__inB\n",
    "            if B is None:\n",
    "                B = tf.random_uniform_initializer()\n",
    "                B = B([self.__d_cap, self.__m])\n",
    "            self.B = tf.Variable(B, name='B', dtype=tf.float32)\n",
    "\n",
    "            Z = self.__inZ\n",
    "            if Z is None:\n",
    "                Z = tf.random_normal_initializer()\n",
    "                Z = Z([self.__L, self.__m])\n",
    "            Z = tf.Variable(Z, name='Z', dtype=tf.float32)\n",
    "            self.Z = Z\n",
    "        return self.W, self.B, self.Z\n",
    "\n",
    "    def __initGamma(self):\n",
    "        with tf.name_scope(self.__nscope):\n",
    "            gamma = self.__inGamma\n",
    "            self.gamma = tf.constant(gamma, name='gamma')\n",
    "\n",
    "    def getHyperParams(self):\n",
    "        '''\n",
    "        Returns the model hyperparameters:\n",
    "            [inputDimension, projectionDimension,\n",
    "            numPrototypes, numOutputLabels, gamma]\n",
    "        '''\n",
    "        d = self.__d\n",
    "        dcap = self.__d_cap\n",
    "        m = self.__m\n",
    "        L = self.__L\n",
    "        return d, dcap, m, L, self.gamma\n",
    "\n",
    "    def getModelMatrices(self):\n",
    "        '''\n",
    "        Returns Tensorflow tensors of the model matrices, which\n",
    "        can then be evaluated to obtain corresponding numpy arrays.\n",
    "\n",
    "        These can then be exported as part of other implementations of\n",
    "        ProtonNN, for instance a C++ implementation or pure python\n",
    "        implementation.\n",
    "        Returns\n",
    "            [ProjectionMatrix (W), prototypeMatrix (B),\n",
    "             prototypeLabelsMatrix (Z), gamma]\n",
    "        '''\n",
    "        return self.W, self.B, self.Z, self.gamma\n",
    "\n",
    "    def __call__(self, X, Y=None):\n",
    "        '''\n",
    "        This method is responsible for construction of the forward computation\n",
    "        graph. The end point of the computation graph, or in other words the\n",
    "        output operator for the forward computation is returned. Additionally,\n",
    "        if the argument Y is provided, a classification accuracy operator with\n",
    "        Y as target will also be created. For this, Y is assumed to in one-hot\n",
    "        encoded format and the class with the maximum prediction score is\n",
    "        compared to the encoded class in Y.  This accuracy operator is returned\n",
    "        by getAccuracyOp() method. If a different accuracyOp is required, it\n",
    "        can be defined by overriding the createAccOp(protoNNScoresOut, Y)\n",
    "        method.\n",
    "\n",
    "        X: Input tensor or placeholder of shape [-1, inputDimension]\n",
    "        Y: Optional tensor or placeholder for targets (labels or classes).\n",
    "            Expected shape is [-1, numOutputLabels].\n",
    "        returns: The forward computation outputs, self.protoNNOut\n",
    "        '''\n",
    "        # This should never execute\n",
    "        assert self.__validInit is True, \"Initialization failed!\"\n",
    "        if self.protoNNOut is not None:\n",
    "            return self.protoNNOut\n",
    "\n",
    "        W, B, Z, gamma = self.W, self.B, self.Z, self.gamma\n",
    "        with tf.name_scope(self.__nscope):\n",
    "            WX = tf.matmul(X, W)\n",
    "            # Convert WX to tensor so that broadcasting can work\n",
    "            dim = [-1, WX.shape.as_list()[1], 1]\n",
    "            WX = tf.reshape(WX, dim)\n",
    "            dim = [1, B.shape.as_list()[0], -1]\n",
    "            B = tf.reshape(B, dim)\n",
    "            l2sim = B - WX\n",
    "            l2sim = tf.pow(l2sim, 2)\n",
    "            l2sim = tf.reduce_sum(l2sim, 1, keepdims=True)\n",
    "            self.l2sim = l2sim\n",
    "            gammal2sim = (-1 * gamma * gamma) * l2sim\n",
    "            M = tf.exp(gammal2sim)\n",
    "            dim = [1] + Z.shape.as_list()\n",
    "            Z = tf.reshape(Z, dim)\n",
    "            y = tf.multiply(Z, M)\n",
    "            y = tf.reduce_sum(y, 2, name='protoNNScoreOut')\n",
    "            self.protoNNOut = y\n",
    "            self.predictions = tf.argmax(y, 1, name='protoNNPredictions')\n",
    "            if Y is not None:\n",
    "                self.createAccOp(self.protoNNOut, Y)\n",
    "        return y\n",
    "\n",
    "    def createAccOp(self, outputs, target):\n",
    "        '''\n",
    "        Define an accuracy operation on ProtoNN's output scores and targets.\n",
    "        Here a simple classification accuracy operator is defined. More\n",
    "        complicated operators (for multiple label problems and so forth) can be\n",
    "        defined by overriding this method\n",
    "        '''\n",
    "        assert self.predictions is not None\n",
    "        target = tf.argmax(target, 1)\n",
    "        correctPrediction = tf.equal(self.predictions, target)\n",
    "        acc = tf.reduce_mean(tf.cast(correctPrediction, tf.float32),\n",
    "                             name='protoNNAccuracy')\n",
    "        self.accuracy = acc\n",
    "\n",
    "    def getPredictionsOp(self):\n",
    "        '''\n",
    "        The predictions operator is defined as argmax(protoNNScores) for each\n",
    "        prediction.\n",
    "        '''\n",
    "        return self.predictions\n",
    "\n",
    "    def getAccuracyOp(self):\n",
    "        '''\n",
    "        returns accuracyOp as defined by createAccOp. It defaults to\n",
    "        multi-class classification accuracy.\n",
    "        '''\n",
    "        msg = \"Accuracy operator not defined in graph. Did you provide Y as an\"\n",
    "        msg += \" argument to _call_?\"\n",
    "        assert self.accuracy is not None, msg\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEBMKewPQJ1c"
   },
   "source": [
    "# Obtain Data\n",
    "\n",
    "It is assumed that the Daphnet data has already been downloaded,preprocessed and set up in subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension:  423\n",
      "Num classes:  2\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"./experiments\"\n",
    "windowLen = 'data'\n",
    "out = preprocessData(DATA_DIR,windowLen)\n",
    "dataDimension = out[0]\n",
    "numClasses = out[1]\n",
    "x_train, y_train = out[2], out[3]\n",
    "x_test, y_test = out[4], out[5]\n",
    "print(\"Feature Dimension: \", dataDimension)\n",
    "print(\"Num classes: \", numClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"./experiments\"\n",
    "train, test = np.load(DATA_DIR + '/ttrain_data.npy'), np.load(DATA_DIR + '/ttest_data.npy')\n",
    "x_train, y_train = train[:, 1:], train[:, 0]\n",
    "x_test, y_test = test[:, 1:], test[:, 0]\n",
    "\n",
    "numClasses = max(y_train) - min(y_train) + 1\n",
    "numClasses = max(numClasses, max(y_test) - min(y_test) + 1)\n",
    "numClasses = int(numClasses)\n",
    "\n",
    "y_train = helper.to_onehot(y_train, numClasses)\n",
    "y_test = helper.to_onehot(y_test, numClasses)\n",
    "dataDimension = x_train.shape[1]\n",
    "numClasses = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1u6oX8eJQJ2N"
   },
   "source": [
    "# Model Parameters\n",
    "\n",
    "Note that ProtoNN is very sensitive to the value of the hyperparameter $\\gamma$, here stored in valiable `GAMMA`. If `GAMMA` is set to `None`, median heuristic will be used to estimate a good value of $\\gamma$ through the `helper.getGamma()` method. This method also returns the corresponding `W` and `B` matrices which should be used to initialize ProtoNN (as is done here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.279204Z",
     "start_time": "2018-08-15T13:06:10.272880Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UaduZ1vJQJ2P"
   },
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 5 #d^\n",
    "NUM_PROTOTYPES = 40 #m\n",
    "REG_W = 0.000005\n",
    "REG_B = 0.0\n",
    "REG_Z = 0.00005\n",
    "SPAR_W = 1.0\n",
    "SPAR_B = 0.8\n",
    "SPAR_Z = 0.8\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 600\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.007586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.307632Z",
     "start_time": "2018-08-15T13:06:10.280955Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1003,
     "status": "ok",
     "timestamp": 1567154485603,
     "user": {
      "displayName": "Gokul Hari",
      "photoUrl": "",
      "userId": "16159457985484250305"
     },
     "user_tz": -330
    },
    "id": "teqlUPhLQJ2W",
    "outputId": "e7e7f7f2-9ddb-448b-9539-65a1a2dc1c03"
   },
   "outputs": [],
   "source": [
    "W, B, gamma = getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from functools import partial\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "def objective(trial,x_train, x_test, y_train, y_test):\n",
    "    W, B, gamma = getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)\n",
    "    # Inside the optimization function, you use the 'trial' object to suggest hyperparameters\n",
    "    REG_W = trial.suggest_float('REG_W', 2e-6, 5e-6)\n",
    "    REG_B = trial.suggest_float('REG_B', 0.0, 0.01)\n",
    "    REG_Z = trial.suggest_float('REG_Z', 2e-5, 5e-5)\n",
    "    SPAR_W = trial.suggest_float('SPAR_W', 0.5, 1.0)\n",
    "    SPAR_B = trial.suggest_float('SPAR_B', 0.5, 1.0)\n",
    "    SPAR_Z = trial.suggest_float('SPAR_Z', 0.5, 1.0)\n",
    "    LEARNING_RATE = trial.suggest_float('LEARNING_RATE', 1e-4, 1e-3)\n",
    "    NUM_EPOCHS = trial.suggest_int('NUM_EPOCHS', 200, 600)\n",
    "\n",
    "    # Set the suggested hyperparameters in the trainer\n",
    "    protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                  NUM_PROTOTYPES, numClasses,\n",
    "                  gamma, W=W, B=B)\n",
    "    trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
    "                         SPAR_W, SPAR_B, SPAR_Z,\n",
    "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
    "    # Call your ProtoNN trainer function or use it as needed\n",
    "    sess = tf.Session()\n",
    "\n",
    "    trainer.train(BATCH_SIZE, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,printStep=600, valStep=10)\n",
    "    acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "    pred = sess.run(protoNN.predictions, feed_dict={X: x_test, Y: y_test})\n",
    "    # W, B, Z are tensorflow graph nodes\n",
    "    W, B, Z, _ = protoNN.getModelMatrices()\n",
    "    matrixList = sess.run([W, B, Z])\n",
    "    sparcityList = [SPAR_W, SPAR_B, SPAR_Z]                       \n",
    "    nnz, size, sparse = getModelSize(matrixList, sparcityList)\n",
    "    y_test = np.argmax(y_test,axis=1)\n",
    "    sensitivity = confusion_matrix(y_test,pred)[1][1]/(confusion_matrix(y_test,pred)[1][1] + confusion_matrix(y_test,pred)[1][0])\n",
    "    specificity = confusion_matrix(y_test,pred)[0][0]/(confusion_matrix(y_test,pred)[0][0] + confusion_matrix(y_test,pred)[0][1])\n",
    "    return (sensitivity+specificity)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 09:40:02,802] A new study created in memory with name: no-name-58267e5c-7498-40f8-9415-5f6bbf07060c\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='maximize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.18710 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.50604 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.22825 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.40010 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.44677 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.46837 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.47680 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.47562 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.46665 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.45089 Accuracy: 0.00000\n",
      "Test Loss: 1.26358 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.42958 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.40142 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.36982 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.33277 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.29247 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.24897 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.20095 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.15023 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.09481 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.03599 Accuracy: 0.00000\n",
      "Test Loss: 1.19961 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.97313 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.90875 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.84187 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.77376 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.70548 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.63732 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.56843 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.49835 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.43128 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.36670 Accuracy: 0.00000\n",
      "Test Loss: 1.09918 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.30479 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.24715 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.19295 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.14344 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.09763 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.05594 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.01807 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.98420 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.95398 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.92749 Accuracy: 0.00000\n",
      "Test Loss: 0.96762 Accuracy: 0.50050\n",
      "Epoch:  40 Batch:   0 Loss: 0.90427 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.88401 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.86658 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.85135 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.83822 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.82706 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.81772 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.81017 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.80414 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.79944 Accuracy: 0.00000\n",
      "Test Loss: 0.87533 Accuracy: 0.50060\n",
      "Epoch:  50 Batch:   0 Loss: 0.79603 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.79355 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.79205 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.79130 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.79104 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.79141 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.79214 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.79315 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.79424 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.79541 Accuracy: 0.00000\n",
      "Test Loss: 0.83221 Accuracy: 0.50060\n",
      "Epoch:  60 Batch:   0 Loss: 0.79659 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.79762 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.79865 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.79958 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.80046 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.80119 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.80192 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.80250 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.80304 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.80349 Accuracy: 0.00000\n",
      "Test Loss: 0.79976 Accuracy: 0.50060\n",
      "Epoch:  70 Batch:   0 Loss: 0.80389 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.80421 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.80453 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.80474 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.80500 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.80522 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.80553 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.80578 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.80601 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.80626 Accuracy: 0.00000\n",
      "Test Loss: 0.77750 Accuracy: 0.50070\n",
      "Epoch:  80 Batch:   0 Loss: 0.80645 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.80662 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.80681 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.80699 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.80710 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.80717 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.80723 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.80730 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.80739 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.80746 Accuracy: 0.00000\n",
      "Test Loss: 0.76135 Accuracy: 0.50060\n",
      "Epoch:  90 Batch:   0 Loss: 0.80753 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.80756 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.80758 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.80759 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.80760 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.80764 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.80762 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.80761 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.80759 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.80756 Accuracy: 0.00000\n",
      "Test Loss: 0.74871 Accuracy: 0.50060\n",
      "Epoch: 100 Batch:   0 Loss: 0.80751 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.80747 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.80742 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.80736 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.80728 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.80717 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.80706 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.80692 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.80682 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.80671 Accuracy: 0.00000\n",
      "Test Loss: 0.73825 Accuracy: 0.50060\n",
      "Epoch: 110 Batch:   0 Loss: 0.80657 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.80643 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.80626 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.80608 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.80589 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.80569 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.80549 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.80525 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.80500 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.80474 Accuracy: 0.00000\n",
      "Test Loss: 0.72949 Accuracy: 0.50060\n",
      "Epoch: 120 Batch:   0 Loss: 0.80449 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.80423 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.80397 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.80367 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.80338 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.80303 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.80268 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.80232 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.80195 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.80155 Accuracy: 0.00000\n",
      "Test Loss: 0.72198 Accuracy: 0.50060\n",
      "Epoch: 130 Batch:   0 Loss: 0.80116 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.80080 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.80042 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.80003 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.79967 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.79930 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.79894 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.79858 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.79827 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.79795 Accuracy: 0.00000\n",
      "Test Loss: 0.71574 Accuracy: 0.50060\n",
      "Epoch: 140 Batch:   0 Loss: 0.79761 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.79730 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.79700 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.79672 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.79645 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.79620 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.79594 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.79570 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.79545 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.79523 Accuracy: 0.00000\n",
      "Test Loss: 0.71058 Accuracy: 0.50060\n",
      "Epoch: 150 Batch:   0 Loss: 0.79504 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.79483 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.79464 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.79444 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.79425 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.79409 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.79392 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.79375 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.79356 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.79340 Accuracy: 0.00000\n",
      "Test Loss: 0.70650 Accuracy: 0.50060\n",
      "Epoch: 160 Batch:   0 Loss: 0.79325 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.79310 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.79293 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.79276 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.79261 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.79247 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.79233 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.79220 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.79207 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.79196 Accuracy: 0.00000\n",
      "Test Loss: 0.70339 Accuracy: 0.50060\n",
      "Epoch: 170 Batch:   0 Loss: 0.79186 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.79175 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.79164 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.79157 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.79146 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.79140 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.79132 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.79124 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.79116 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.79110 Accuracy: 0.00000\n",
      "Test Loss: 0.70091 Accuracy: 0.50060\n",
      "Epoch: 180 Batch:   0 Loss: 0.79106 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.79102 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.79100 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.79098 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.79097 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.79095 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.79095 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.79097 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.79100 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.79103 Accuracy: 0.00000\n",
      "Test Loss: 0.69910 Accuracy: 0.50060\n",
      "Epoch: 190 Batch:   0 Loss: 0.79106 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.79110 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.79114 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.79117 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.79122 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.79126 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.79131 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.79137 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.79142 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.79147 Accuracy: 0.00000\n",
      "Test Loss: 0.69789 Accuracy: 0.50060\n",
      "Epoch: 200 Batch:   0 Loss: 0.79153 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.79156 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.79163 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.79172 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.79182 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.79189 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.79201 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.79210 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.79220 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.79230 Accuracy: 0.00000\n",
      "Test Loss: 0.69700 Accuracy: 0.50060\n",
      "Epoch: 210 Batch:   0 Loss: 0.79239 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.79249 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.79257 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.79263 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.79265 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.79264 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.79257 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.79244 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.79224 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.79199 Accuracy: 0.00000\n",
      "Test Loss: 0.69566 Accuracy: 0.50060\n",
      "Epoch: 220 Batch:   0 Loss: 0.79165 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.79125 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.79081 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.79033 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.78985 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.78934 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.78883 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.78832 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.78781 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.78731 Accuracy: 0.00000\n",
      "Test Loss: 0.69385 Accuracy: 0.50060\n",
      "Epoch: 230 Batch:   0 Loss: 0.78682 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.78632 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.78584 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.78538 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.78494 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.78452 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.78414 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.78377 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.78342 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.78307 Accuracy: 0.00000\n",
      "Test Loss: 0.69278 Accuracy: 0.50070\n",
      "Epoch: 240 Batch:   0 Loss: 0.78277 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.78248 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.78222 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.78199 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.78180 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.78164 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.78147 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.78136 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.78126 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.78119 Accuracy: 0.00000\n",
      "Test Loss: 0.69230 Accuracy: 0.50060\n",
      "Epoch: 250 Batch:   0 Loss: 0.78110 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.78103 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.78096 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.78087 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.78079 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.78068 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.78056 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.78045 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.78036 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.78028 Accuracy: 0.00000\n",
      "Test Loss: 0.69224 Accuracy: 0.50050\n",
      "Epoch: 260 Batch:   0 Loss: 0.78023 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.78020 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.78020 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.78023 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.78028 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.78037 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.78043 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.78046 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.78046 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.78044 Accuracy: 0.00000\n",
      "Test Loss: 0.69272 Accuracy: 0.50050\n",
      "Epoch: 270 Batch:   0 Loss: 0.78037 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.78026 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.78013 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.77996 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.77973 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.77944 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.77906 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.77861 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.77809 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.77752 Accuracy: 0.00000\n",
      "Test Loss: 0.69265 Accuracy: 0.50050\n",
      "Epoch: 280 Batch:   0 Loss: 0.77691 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.77628 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.77564 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.77499 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.77435 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.77371 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.77308 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.77249 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.77193 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.77138 Accuracy: 0.00000\n",
      "Test Loss: 0.69292 Accuracy: 0.50050\n",
      "Epoch: 290 Batch:   0 Loss: 0.77088 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.77039 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.76993 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.76949 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.76907 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.76867 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.76827 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.76791 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.76756 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.76722 Accuracy: 0.00000\n",
      "Test Loss: 0.69396 Accuracy: 0.50050\n",
      "Epoch: 300 Batch:   0 Loss: 0.76690 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.76661 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.76632 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.76605 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.76579 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.76554 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.76531 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.76508 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.76487 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.76466 Accuracy: 0.00000\n",
      "Test Loss: 0.69542 Accuracy: 0.50050\n",
      "Epoch: 310 Batch:   0 Loss: 0.76446 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 09:43:02,041] Trial 0 finished with value: 0.5003015681544029 and parameters: {'REG_W': 4.4063589336745566e-06, 'REG_B': 0.00550086588574879, 'REG_Z': 2.738256523855445e-05, 'SPAR_W': 0.7924326708349763, 'SPAR_B': 0.9252195803215768, 'SPAR_Z': 0.9738285286612246, 'LEARNING_RATE': 0.0005235324510491807, 'NUM_EPOCHS': 311}. Best is trial 0 with value: 0.5003015681544029.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.23718 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 2.83710 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.79966 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.79775 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.79150 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.77877 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.76072 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.73840 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.71271 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.68440 Accuracy: 0.00000\n",
      "Test Loss: 1.38927 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.65402 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.62198 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.58844 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.55356 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.51738 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.48008 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.44126 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.39951 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.35685 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.31275 Accuracy: 0.00000\n",
      "Test Loss: 1.36271 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.26853 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.22209 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.17095 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.12137 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.06950 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 2.01778 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.96348 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.90907 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.85442 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.79896 Accuracy: 0.00000\n",
      "Test Loss: 1.30061 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.74282 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.68505 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.62969 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.57421 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.51907 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.46474 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.41080 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.35789 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.30629 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.25711 Accuracy: 0.00000\n",
      "Test Loss: 1.18633 Accuracy: 0.50030\n",
      "Epoch:  40 Batch:   0 Loss: 1.20994 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.16587 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.12410 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.08562 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.05011 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.01823 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.98934 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.96322 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.94054 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.92019 Accuracy: 0.00000\n",
      "Test Loss: 1.05645 Accuracy: 0.50070\n",
      "Epoch:  50 Batch:   0 Loss: 0.90222 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.88637 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.87199 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.85945 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.84834 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.83855 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.82970 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.82208 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.81542 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.80960 Accuracy: 0.00000\n",
      "Test Loss: 0.95175 Accuracy: 0.50070\n",
      "Epoch:  60 Batch:   0 Loss: 0.80477 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.80075 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.79765 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.79531 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.79370 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.79261 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.79224 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.79232 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.79272 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.79345 Accuracy: 0.00000\n",
      "Test Loss: 0.89597 Accuracy: 0.50070\n",
      "Epoch:  70 Batch:   0 Loss: 0.79438 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.79560 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.79671 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.79796 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.79917 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.80045 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.80173 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.80300 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.80429 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.80549 Accuracy: 0.00000\n",
      "Test Loss: 0.85781 Accuracy: 0.50070\n",
      "Epoch:  80 Batch:   0 Loss: 0.80667 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.80768 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.80848 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.80920 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.80981 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.81042 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.81087 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.81134 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.81176 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.81215 Accuracy: 0.00000\n",
      "Test Loss: 0.82761 Accuracy: 0.50070\n",
      "Epoch:  90 Batch:   0 Loss: 0.81249 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.81278 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.81305 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.81331 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.81359 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.81386 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.81410 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.81433 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.81451 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.81463 Accuracy: 0.00000\n",
      "Test Loss: 0.80654 Accuracy: 0.50070\n",
      "Epoch: 100 Batch:   0 Loss: 0.81475 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.81487 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.81499 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.81515 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.81526 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.81541 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.81557 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.81562 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.81575 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.81588 Accuracy: 0.00000\n",
      "Test Loss: 0.79134 Accuracy: 0.50070\n",
      "Epoch: 110 Batch:   0 Loss: 0.81597 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.81601 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.81605 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.81609 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.81610 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.81608 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.81602 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.81597 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.81593 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.81587 Accuracy: 0.00000\n",
      "Test Loss: 0.78005 Accuracy: 0.50070\n",
      "Epoch: 120 Batch:   0 Loss: 0.81581 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.81573 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.81566 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.81560 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.81552 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.81549 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.81545 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.81537 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.81537 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.81538 Accuracy: 0.00000\n",
      "Test Loss: 0.77144 Accuracy: 0.50070\n",
      "Epoch: 130 Batch:   0 Loss: 0.81539 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.81539 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.81532 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.81526 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.81523 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.81519 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.81518 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.81514 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.81497 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.81483 Accuracy: 0.00000\n",
      "Test Loss: 0.76522 Accuracy: 0.50070\n",
      "Epoch: 140 Batch:   0 Loss: 0.81459 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.81437 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.81419 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.81399 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.81382 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.81366 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.81348 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.81331 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.81320 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.81301 Accuracy: 0.00000\n",
      "Test Loss: 0.76047 Accuracy: 0.50070\n",
      "Epoch: 150 Batch:   0 Loss: 0.81281 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.81261 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.81242 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.81225 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.81209 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.81193 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.81178 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.81169 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.81153 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.81142 Accuracy: 0.00000\n",
      "Test Loss: 0.75660 Accuracy: 0.50070\n",
      "Epoch: 160 Batch:   0 Loss: 0.81127 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.81113 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.81101 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.81091 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.81084 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.81079 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.81078 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.81073 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.81068 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.81065 Accuracy: 0.00000\n",
      "Test Loss: 0.75323 Accuracy: 0.50070\n",
      "Epoch: 170 Batch:   0 Loss: 0.81065 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.81070 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.81078 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.81089 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.81101 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.81118 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.81140 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.81161 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.81184 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.81214 Accuracy: 0.00000\n",
      "Test Loss: 0.75109 Accuracy: 0.50070\n",
      "Epoch: 180 Batch:   0 Loss: 0.81247 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.81283 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.81323 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.81368 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.81410 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.81457 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.81505 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.81552 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.81599 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.81642 Accuracy: 0.00000\n",
      "Test Loss: 0.74914 Accuracy: 0.50060\n",
      "Epoch: 190 Batch:   0 Loss: 0.81680 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.81709 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.81729 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.81739 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.81738 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.81729 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.81716 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.81694 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.81668 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.81639 Accuracy: 0.00000\n",
      "Test Loss: 0.74547 Accuracy: 0.50060\n",
      "Epoch: 200 Batch:   0 Loss: 0.81608 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.81579 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.81557 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.81537 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.81513 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.81495 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.81484 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.81475 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.81470 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.81472 Accuracy: 0.00000\n",
      "Test Loss: 0.74275 Accuracy: 0.50050\n",
      "Epoch: 210 Batch:   0 Loss: 0.81474 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.81477 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.81481 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.81478 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.81473 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.81465 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.81453 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.81440 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.81433 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.81433 Accuracy: 0.00000\n",
      "Test Loss: 0.74050 Accuracy: 0.50050\n",
      "Epoch: 220 Batch:   0 Loss: 0.81436 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.81445 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.81460 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.81470 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.81473 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.81462 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.81432 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.81392 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.81335 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.81266 Accuracy: 0.00000\n",
      "Test Loss: 0.73926 Accuracy: 0.50050\n",
      "Epoch: 230 Batch:   0 Loss: 0.81187 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.81095 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.80999 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.80896 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.80788 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.80680 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.80573 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.80468 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.80365 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.80260 Accuracy: 0.00000\n",
      "Test Loss: 0.73845 Accuracy: 0.50050\n",
      "Epoch: 240 Batch:   0 Loss: 0.80158 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.80059 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.79963 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.79871 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.79782 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.79697 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.79615 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.79536 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.79462 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.79391 Accuracy: 0.00000\n",
      "Test Loss: 0.73863 Accuracy: 0.50050\n",
      "Epoch: 250 Batch:   0 Loss: 0.79324 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.79258 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.79196 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.79136 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.79077 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.79022 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.78968 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.78917 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.78868 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.78821 Accuracy: 0.00000\n",
      "Test Loss: 0.73927 Accuracy: 0.50050\n",
      "Epoch: 260 Batch:   0 Loss: 0.78776 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.78732 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.78689 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.78648 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.78608 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.78571 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.78534 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.78500 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.78467 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.78434 Accuracy: 0.00000\n",
      "Test Loss: 0.74008 Accuracy: 0.50040\n",
      "Epoch: 270 Batch:   0 Loss: 0.78402 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.78372 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.78342 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.78314 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.78286 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.78260 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.78234 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.78209 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.78185 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.78162 Accuracy: 0.00000\n",
      "Test Loss: 0.74087 Accuracy: 0.50040\n",
      "Epoch: 280 Batch:   0 Loss: 0.78139 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.78118 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.78097 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.78076 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.78057 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.78037 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.78019 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.78001 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.77984 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.77967 Accuracy: 0.00000\n",
      "Test Loss: 0.74181 Accuracy: 0.50040\n",
      "Epoch: 290 Batch:   0 Loss: 0.77950 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.77934 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.77918 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.77903 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.77888 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.77873 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.77859 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.77845 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.77832 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.77819 Accuracy: 0.00000\n",
      "Test Loss: 0.74275 Accuracy: 0.50040\n",
      "Epoch: 300 Batch:   0 Loss: 0.77807 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.77795 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.77784 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.77772 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.77761 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.77750 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.77738 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.77727 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.77716 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.77706 Accuracy: 0.00000\n",
      "Test Loss: 0.74360 Accuracy: 0.50040\n",
      "Epoch: 310 Batch:   0 Loss: 0.77695 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.77685 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.77676 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.77666 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.77657 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.77648 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.77638 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.77629 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.77621 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.77613 Accuracy: 0.00000\n",
      "Test Loss: 0.74448 Accuracy: 0.50040\n",
      "Epoch: 320 Batch:   0 Loss: 0.77605 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.77598 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.77591 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.77585 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.77577 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.77570 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.77563 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.77556 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.77550 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.77544 Accuracy: 0.00000\n",
      "Test Loss: 0.74533 Accuracy: 0.50040\n",
      "Epoch: 330 Batch:   0 Loss: 0.77538 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.77532 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.77527 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.77522 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.77517 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.77512 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.77507 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.77501 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.77495 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.77489 Accuracy: 0.00000\n",
      "Test Loss: 0.74620 Accuracy: 0.50060\n",
      "Epoch: 340 Batch:   0 Loss: 0.77484 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.77477 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.77471 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.77465 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.77459 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.77454 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.77448 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.77443 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.77438 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.77434 Accuracy: 0.00000\n",
      "Test Loss: 0.74695 Accuracy: 0.50060\n",
      "Epoch: 350 Batch:   0 Loss: 0.77429 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.77424 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.77418 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.77413 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.77408 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.77403 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.77399 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.77394 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.77389 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.77384 Accuracy: 0.00000\n",
      "Test Loss: 0.74784 Accuracy: 0.50060\n",
      "Epoch: 360 Batch:   0 Loss: 0.77379 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.77374 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.77369 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.77364 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.77359 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.77355 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.77350 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.77346 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.77342 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.77337 Accuracy: 0.00000\n",
      "Test Loss: 0.74880 Accuracy: 0.50060\n",
      "Epoch: 370 Batch:   0 Loss: 0.77333 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.77329 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.77325 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.77321 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.77318 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.77314 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.77310 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.77307 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.77303 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.77300 Accuracy: 0.00000\n",
      "Test Loss: 0.74981 Accuracy: 0.50060\n",
      "Epoch: 380 Batch:   0 Loss: 0.77296 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.77292 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.77289 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.77285 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.77281 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.77277 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.77273 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.77269 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.77266 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.77262 Accuracy: 0.00000\n",
      "Test Loss: 0.75076 Accuracy: 0.50060\n",
      "Epoch: 390 Batch:   0 Loss: 0.77259 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.77256 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.77252 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.77249 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.77246 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.77244 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.77242 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.77240 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.77238 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.77237 Accuracy: 0.00000\n",
      "Test Loss: 0.75149 Accuracy: 0.50060\n",
      "Epoch: 400 Batch:   0 Loss: 0.77235 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.77232 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.77230 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.77228 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.77226 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.77225 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.77224 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.77223 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.77221 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.77219 Accuracy: 0.00000\n",
      "Test Loss: 0.75209 Accuracy: 0.50060\n",
      "Epoch: 410 Batch:   0 Loss: 0.77218 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.77216 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.77215 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.77213 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.77211 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.77209 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.77207 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.77205 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.77203 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.77200 Accuracy: 0.00000\n",
      "Test Loss: 0.75256 Accuracy: 0.50060\n",
      "Epoch: 420 Batch:   0 Loss: 0.77198 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.77196 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.77193 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.77191 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.77189 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.77187 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.77185 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.77183 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.77181 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.77178 Accuracy: 0.00000\n",
      "Test Loss: 0.75307 Accuracy: 0.50060\n",
      "Epoch: 430 Batch:   0 Loss: 0.77175 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.77172 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.77170 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.77167 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.77165 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.77162 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.77160 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.77157 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.77155 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.77153 Accuracy: 0.00000\n",
      "Test Loss: 0.75357 Accuracy: 0.50060\n",
      "Epoch: 440 Batch:   0 Loss: 0.77151 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.77149 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.77147 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.77145 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.77143 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.77141 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.77139 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.77137 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.77135 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.77134 Accuracy: 0.00000\n",
      "Test Loss: 0.75391 Accuracy: 0.50060\n",
      "Epoch: 450 Batch:   0 Loss: 0.77132 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.77130 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.77128 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.77126 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.77123 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.77121 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.77118 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.77115 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.77113 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.77111 Accuracy: 0.00000\n",
      "Test Loss: 0.75441 Accuracy: 0.50060\n",
      "Epoch: 460 Batch:   0 Loss: 0.77108 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.77106 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.77104 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.77101 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.77099 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.77096 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.77094 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.77090 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.77086 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.77082 Accuracy: 0.00000\n",
      "Test Loss: 0.75496 Accuracy: 0.50060\n",
      "Epoch: 470 Batch:   0 Loss: 0.77079 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.77075 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.77072 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.77068 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.77063 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.77059 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.77055 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.77051 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.77047 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.77043 Accuracy: 0.00000\n",
      "Test Loss: 0.75562 Accuracy: 0.50060\n",
      "Epoch: 480 Batch:   0 Loss: 0.77040 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.77036 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.77033 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.77031 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.77028 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.77025 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.77023 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.77020 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.77018 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.77015 Accuracy: 0.00000\n",
      "Test Loss: 0.75628 Accuracy: 0.50060\n",
      "Epoch: 490 Batch:   0 Loss: 0.77013 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.77011 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.77008 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.77006 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.77004 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 09:48:31,299] Trial 1 finished with value: 0.5004020908725372 and parameters: {'REG_W': 4.989016392035679e-06, 'REG_B': 0.006285881469037077, 'REG_Z': 4.620919544050023e-05, 'SPAR_W': 0.5580069993122618, 'SPAR_B': 0.9961478147253725, 'SPAR_Z': 0.8006718659290757, 'LEARNING_RATE': 0.0006325314401711697, 'NUM_EPOCHS': 495}. Best is trial 1 with value: 0.5004020908725372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 3.20639 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 3.24029 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.98119 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.89997 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.86077 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.82731 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.78818 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.74154 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.68951 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.63373 Accuracy: 0.00000\n",
      "Test Loss: 1.46175 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.57327 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.50877 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.44131 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.37155 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.29998 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.22805 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.15471 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.08098 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.00607 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.93019 Accuracy: 0.00000\n",
      "Test Loss: 1.40005 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 1.85674 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.78157 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.70782 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.63468 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.56339 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.49498 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.42823 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.36526 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.30527 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.24837 Accuracy: 0.00000\n",
      "Test Loss: 1.30270 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.19552 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.14628 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.10020 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.05868 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.02100 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.98732 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.95716 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.93002 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.90625 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.88585 Accuracy: 0.00000\n",
      "Test Loss: 1.17500 Accuracy: 0.50050\n",
      "Epoch:  40 Batch:   0 Loss: 0.86772 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.85198 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.83808 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.82574 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.81487 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.80524 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.79664 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.78895 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.78205 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.77586 Accuracy: 0.00000\n",
      "Test Loss: 1.07582 Accuracy: 0.50050\n",
      "Epoch:  50 Batch:   0 Loss: 0.77021 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.76522 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.76061 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.75641 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.75270 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.74947 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.74670 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.74435 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.74250 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.74118 Accuracy: 0.00000\n",
      "Test Loss: 0.96213 Accuracy: 0.50070\n",
      "Epoch:  60 Batch:   0 Loss: 0.74024 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.73972 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.73956 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.73966 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.74011 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.74074 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.74152 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.74236 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.74332 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.74443 Accuracy: 0.00000\n",
      "Test Loss: 0.89464 Accuracy: 0.50080\n",
      "Epoch:  70 Batch:   0 Loss: 0.74563 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.74685 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.74810 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.74935 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.75058 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.75180 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.75300 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.75418 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.75536 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.75649 Accuracy: 0.00000\n",
      "Test Loss: 0.84424 Accuracy: 0.50080\n",
      "Epoch:  80 Batch:   0 Loss: 0.75767 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.75880 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.75988 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.76094 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.76201 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.76303 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.76400 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.76495 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.76585 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.76669 Accuracy: 0.00000\n",
      "Test Loss: 0.80935 Accuracy: 0.50080\n",
      "Epoch:  90 Batch:   0 Loss: 0.76751 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.76831 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.76905 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.76982 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.77049 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.77115 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.77176 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.77232 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.77285 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.77331 Accuracy: 0.00000\n",
      "Test Loss: 0.78743 Accuracy: 0.50080\n",
      "Epoch: 100 Batch:   0 Loss: 0.77368 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.77402 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.77431 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.77462 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.77489 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.77514 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.77535 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.77552 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.77563 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.77573 Accuracy: 0.00000\n",
      "Test Loss: 0.77258 Accuracy: 0.50080\n",
      "Epoch: 110 Batch:   0 Loss: 0.77578 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.77580 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.77577 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.77571 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.77565 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.77558 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.77548 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.77541 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.77532 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.77521 Accuracy: 0.00000\n",
      "Test Loss: 0.76181 Accuracy: 0.50090\n",
      "Epoch: 120 Batch:   0 Loss: 0.77512 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.77503 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.77491 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77478 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77466 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77455 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.77440 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.77427 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.77417 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.77407 Accuracy: 0.00000\n",
      "Test Loss: 0.75401 Accuracy: 0.50090\n",
      "Epoch: 130 Batch:   0 Loss: 0.77396 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.77385 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77372 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77357 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77344 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77331 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77319 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77306 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77294 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77282 Accuracy: 0.00000\n",
      "Test Loss: 0.74814 Accuracy: 0.50090\n",
      "Epoch: 140 Batch:   0 Loss: 0.77272 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77261 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77249 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77240 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77231 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.77220 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.77209 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.77198 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.77187 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.77177 Accuracy: 0.00000\n",
      "Test Loss: 0.74330 Accuracy: 0.50100\n",
      "Epoch: 150 Batch:   0 Loss: 0.77167 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.77160 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.77152 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.77142 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.77132 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.77123 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.77117 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.77109 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.77102 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.77096 Accuracy: 0.00000\n",
      "Test Loss: 0.73930 Accuracy: 0.50100\n",
      "Epoch: 160 Batch:   0 Loss: 0.77088 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.77081 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.77074 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.77067 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.77059 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.77050 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.77041 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.77032 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.77023 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.77012 Accuracy: 0.00000\n",
      "Test Loss: 0.73605 Accuracy: 0.50100\n",
      "Epoch: 170 Batch:   0 Loss: 0.77001 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.76991 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.76979 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.76966 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.76957 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.76946 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.76935 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.76926 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.76915 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.76907 Accuracy: 0.00000\n",
      "Test Loss: 0.73368 Accuracy: 0.50100\n",
      "Epoch: 180 Batch:   0 Loss: 0.76899 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.76893 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.76890 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.76887 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.76886 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.76889 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.76896 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.76907 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.76920 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.76940 Accuracy: 0.00000\n",
      "Test Loss: 0.73189 Accuracy: 0.50090\n",
      "Epoch: 190 Batch:   0 Loss: 0.76965 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.76990 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.77018 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.77043 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.77064 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.77074 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.77072 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.77056 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.77031 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.76998 Accuracy: 0.00000\n",
      "Test Loss: 0.72826 Accuracy: 0.50090\n",
      "Epoch: 200 Batch:   0 Loss: 0.76960 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.76916 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.76871 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.76824 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.76778 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.76733 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.76689 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.76644 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.76602 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.76560 Accuracy: 0.00000\n",
      "Test Loss: 0.72446 Accuracy: 0.50090\n",
      "Epoch: 210 Batch:   0 Loss: 0.76521 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.76483 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.76449 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.76418 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.76391 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.76370 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.76354 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.76341 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.76338 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.76340 Accuracy: 0.00000\n",
      "Test Loss: 0.72148 Accuracy: 0.50080\n",
      "Epoch: 220 Batch:   0 Loss: 0.76347 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.76359 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.76372 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.76384 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.76388 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.76385 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.76374 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.76357 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.76335 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.76310 Accuracy: 0.00000\n",
      "Test Loss: 0.71838 Accuracy: 0.50080\n",
      "Epoch: 230 Batch:   0 Loss: 0.76286 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.76263 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.76240 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.76222 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.76208 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.76202 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.76202 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.76211 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.76225 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.76242 Accuracy: 0.00000\n",
      "Test Loss: 0.71729 Accuracy: 0.50080\n",
      "Epoch: 240 Batch:   0 Loss: 0.76257 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.76266 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.76260 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.76236 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.76193 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.76136 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.76071 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.76003 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.75932 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.75863 Accuracy: 0.00000\n",
      "Test Loss: 0.71565 Accuracy: 0.50080\n",
      "Epoch: 250 Batch:   0 Loss: 0.75796 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.75732 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.75673 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.75617 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.75565 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.75516 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.75470 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.75427 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.75386 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.75347 Accuracy: 0.00000\n",
      "Test Loss: 0.71621 Accuracy: 0.50080\n",
      "Epoch: 260 Batch:   0 Loss: 0.75311 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.75278 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.75247 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.75219 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.75193 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.75168 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.75145 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.75123 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.75102 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.75084 Accuracy: 0.00000\n",
      "Test Loss: 0.71794 Accuracy: 0.50080\n",
      "Epoch: 270 Batch:   0 Loss: 0.75066 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.75049 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.75033 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.75018 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.75003 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.74989 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.74977 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.74964 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.74952 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.74940 Accuracy: 0.00000\n",
      "Test Loss: 0.72000 Accuracy: 0.50080\n",
      "Epoch: 280 Batch:   0 Loss: 0.74929 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.74918 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.74907 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.74897 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.74887 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.74877 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.74867 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.74858 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.74849 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.74839 Accuracy: 0.00000\n",
      "Test Loss: 0.72228 Accuracy: 0.50080\n",
      "Epoch: 290 Batch:   0 Loss: 0.74830 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.74821 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.74812 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.74803 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.74795 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.74786 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.74778 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.74770 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.74763 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.74755 Accuracy: 0.00000\n",
      "Test Loss: 0.72458 Accuracy: 0.50090\n",
      "Epoch: 300 Batch:   0 Loss: 0.74748 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.74741 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.74734 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.74727 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.74721 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.74714 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.74708 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.74701 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.74695 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.74689 Accuracy: 0.00000\n",
      "Test Loss: 0.72689 Accuracy: 0.50100\n",
      "Epoch: 310 Batch:   0 Loss: 0.74683 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.74677 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.74671 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.74665 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.74659 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.74653 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.74647 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.74642 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.74636 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.74631 Accuracy: 0.00000\n",
      "Test Loss: 0.72917 Accuracy: 0.50100\n",
      "Epoch: 320 Batch:   0 Loss: 0.74626 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.74620 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.74615 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.74609 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.74604 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.74599 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.74594 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.74589 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 09:51:26,586] Trial 2 finished with value: 0.5008041817450744 and parameters: {'REG_W': 2.6045101624763913e-06, 'REG_B': 0.0008140312513964287, 'REG_Z': 2.905458883387219e-05, 'SPAR_W': 0.7803300030330671, 'SPAR_B': 0.5086272015109017, 'SPAR_Z': 0.6420072077306945, 'LEARNING_RATE': 0.000710503022728103, 'NUM_EPOCHS': 328}. Best is trial 2 with value: 0.5008041817450744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.31497 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.18979 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.91891 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.00794 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.25683 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.32840 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.36272 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.38367 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.39622 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.40205 Accuracy: 0.00000\n",
      "Test Loss: 1.20858 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.40230 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.39724 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.38771 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.37483 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.35785 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.33712 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.31276 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.28374 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.25162 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.21541 Accuracy: 0.00000\n",
      "Test Loss: 1.19690 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.17572 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.13191 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.08395 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.03299 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.97867 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.92133 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.86245 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.80261 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.74142 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.67970 Accuracy: 0.00000\n",
      "Test Loss: 1.13550 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.61763 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.55630 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.49452 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.43450 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.37609 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.31878 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.26445 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.21302 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.16452 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.11977 Accuracy: 0.00000\n",
      "Test Loss: 1.03030 Accuracy: 0.50040\n",
      "Epoch:  40 Batch:   0 Loss: 1.07813 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.04019 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.00564 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.97457 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.94643 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.92159 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.89965 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.88031 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.86348 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.84868 Accuracy: 0.00000\n",
      "Test Loss: 0.90688 Accuracy: 0.50060\n",
      "Epoch:  50 Batch:   0 Loss: 0.83566 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.82442 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.81455 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.80604 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.79876 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.79266 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.78763 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.78356 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.78041 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.77818 Accuracy: 0.00000\n",
      "Test Loss: 0.83670 Accuracy: 0.50060\n",
      "Epoch:  60 Batch:   0 Loss: 0.77683 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.77617 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.77620 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.77680 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.77777 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.77908 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.78074 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.78272 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.78491 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.78707 Accuracy: 0.00000\n",
      "Test Loss: 0.81049 Accuracy: 0.50070\n",
      "Epoch:  70 Batch:   0 Loss: 0.78934 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.79150 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.79359 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.79558 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.79743 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.79922 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.80088 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.80239 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.80376 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.80510 Accuracy: 0.00000\n",
      "Test Loss: 0.78508 Accuracy: 0.50080\n",
      "Epoch:  80 Batch:   0 Loss: 0.80629 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.80742 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.80847 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.80942 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.81033 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.81120 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.81202 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.81275 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.81346 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.81407 Accuracy: 0.00000\n",
      "Test Loss: 0.76605 Accuracy: 0.50080\n",
      "Epoch:  90 Batch:   0 Loss: 0.81464 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.81514 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.81561 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.81599 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.81634 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.81667 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.81698 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.81720 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.81737 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.81750 Accuracy: 0.00000\n",
      "Test Loss: 0.75196 Accuracy: 0.50080\n",
      "Epoch: 100 Batch:   0 Loss: 0.81752 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.81748 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.81745 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.81740 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.81730 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.81714 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.81691 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.81664 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.81635 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.81601 Accuracy: 0.00000\n",
      "Test Loss: 0.74086 Accuracy: 0.50080\n",
      "Epoch: 110 Batch:   0 Loss: 0.81567 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.81529 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.81490 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.81448 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.81406 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.81358 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.81312 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.81265 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.81212 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.81158 Accuracy: 0.00000\n",
      "Test Loss: 0.73180 Accuracy: 0.50080\n",
      "Epoch: 120 Batch:   0 Loss: 0.81104 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.81051 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.80997 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.80943 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.80890 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.80836 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.80780 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.80725 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.80669 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.80617 Accuracy: 0.00000\n",
      "Test Loss: 0.72452 Accuracy: 0.50080\n",
      "Epoch: 130 Batch:   0 Loss: 0.80565 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.80513 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.80461 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.80408 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.80357 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.80307 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.80258 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.80209 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.80161 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.80112 Accuracy: 0.00000\n",
      "Test Loss: 0.71860 Accuracy: 0.50080\n",
      "Epoch: 140 Batch:   0 Loss: 0.80071 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.80029 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.79987 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.79946 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.79907 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.79869 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.79831 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.79793 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.79757 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.79721 Accuracy: 0.00000\n",
      "Test Loss: 0.71377 Accuracy: 0.50080\n",
      "Epoch: 150 Batch:   0 Loss: 0.79685 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.79650 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.79617 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.79583 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.79551 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.79516 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.79484 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.79453 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.79422 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.79391 Accuracy: 0.00000\n",
      "Test Loss: 0.70987 Accuracy: 0.50080\n",
      "Epoch: 160 Batch:   0 Loss: 0.79365 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.79342 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.79316 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.79291 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.79267 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.79245 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.79222 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.79200 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.79180 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.79159 Accuracy: 0.00000\n",
      "Test Loss: 0.70672 Accuracy: 0.50080\n",
      "Epoch: 170 Batch:   0 Loss: 0.79140 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.79121 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.79103 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.79085 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.79066 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.79049 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.79031 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.79015 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.79001 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.78987 Accuracy: 0.00000\n",
      "Test Loss: 0.70429 Accuracy: 0.50080\n",
      "Epoch: 180 Batch:   0 Loss: 0.78972 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.78958 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.78945 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.78931 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.78917 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.78904 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.78891 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.78879 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.78866 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.78853 Accuracy: 0.00000\n",
      "Test Loss: 0.70247 Accuracy: 0.50080\n",
      "Epoch: 190 Batch:   0 Loss: 0.78841 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.78828 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.78816 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.78803 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.78790 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.78777 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.78766 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.78755 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.78744 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.78733 Accuracy: 0.00000\n",
      "Test Loss: 0.70115 Accuracy: 0.50080\n",
      "Epoch: 200 Batch:   0 Loss: 0.78722 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.78711 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.78700 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.78689 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.78679 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.78671 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.78660 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.78650 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.78640 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.78630 Accuracy: 0.00000\n",
      "Test Loss: 0.70038 Accuracy: 0.50080\n",
      "Epoch: 210 Batch:   0 Loss: 0.78621 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.78611 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.78602 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.78593 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.78585 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.78576 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.78568 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.78559 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.78551 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.78543 Accuracy: 0.00000\n",
      "Test Loss: 0.70002 Accuracy: 0.50080\n",
      "Epoch: 220 Batch:   0 Loss: 0.78536 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.78528 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.78521 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.78513 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.78506 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.78498 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.78491 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.78483 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.78475 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.78467 Accuracy: 0.00000\n",
      "Test Loss: 0.69999 Accuracy: 0.50080\n",
      "Epoch: 230 Batch:   0 Loss: 0.78459 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.78451 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.78443 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.78435 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.78427 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.78419 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.78411 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.78403 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.78395 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.78387 Accuracy: 0.00000\n",
      "Test Loss: 0.70018 Accuracy: 0.50080\n",
      "Epoch: 240 Batch:   0 Loss: 0.78378 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.78370 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.78361 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.78352 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.78343 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.78334 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.78325 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.78316 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.78308 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.78299 Accuracy: 0.00000\n",
      "Test Loss: 0.70046 Accuracy: 0.50080\n",
      "Epoch: 250 Batch:   0 Loss: 0.78290 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.78283 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.78275 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.78267 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.78260 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.78255 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.78248 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.78243 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.78239 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.78235 Accuracy: 0.00000\n",
      "Test Loss: 0.70076 Accuracy: 0.50080\n",
      "Epoch: 260 Batch:   0 Loss: 0.78234 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.78233 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.78233 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.78233 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.78235 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.78237 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.78241 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.78245 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.78250 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.78252 Accuracy: 0.00000\n",
      "Test Loss: 0.70077 Accuracy: 0.50080\n",
      "Epoch: 270 Batch:   0 Loss: 0.78253 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.78252 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.78247 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.78239 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.78227 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.78212 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.78193 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.78170 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.78145 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.78118 Accuracy: 0.00000\n",
      "Test Loss: 0.69988 Accuracy: 0.50080\n",
      "Epoch: 280 Batch:   0 Loss: 0.78089 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.78058 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.78027 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.77995 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.77963 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.77931 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.77899 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.77868 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.77837 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.77807 Accuracy: 0.00000\n",
      "Test Loss: 0.69874 Accuracy: 0.50080\n",
      "Epoch: 290 Batch:   0 Loss: 0.77779 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.77752 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.77726 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.77702 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.77680 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.77660 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.77642 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.77626 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.77614 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.77603 Accuracy: 0.00000\n",
      "Test Loss: 0.69762 Accuracy: 0.50080\n",
      "Epoch: 300 Batch:   0 Loss: 0.77594 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.77588 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.77583 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.77579 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.77579 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.77580 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.77582 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.77583 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.77583 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.77582 Accuracy: 0.00000\n",
      "Test Loss: 0.69666 Accuracy: 0.50090\n",
      "Epoch: 310 Batch:   0 Loss: 0.77579 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.77572 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.77561 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.77545 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.77527 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.77505 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.77481 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.77458 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.77434 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.77411 Accuracy: 0.00000\n",
      "Test Loss: 0.69627 Accuracy: 0.50080\n",
      "Epoch: 320 Batch:   0 Loss: 0.77390 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.77374 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.77362 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.77356 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.77355 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.77360 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.77375 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.77397 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.77427 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.77463 Accuracy: 0.00000\n",
      "Test Loss: 0.69709 Accuracy: 0.50080\n",
      "Epoch: 330 Batch:   0 Loss: 0.77501 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.77536 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.77564 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.77580 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.77579 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.77565 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.77537 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.77497 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.77447 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.77391 Accuracy: 0.00000\n",
      "Test Loss: 0.69671 Accuracy: 0.50090\n",
      "Epoch: 340 Batch:   0 Loss: 0.77330 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.77267 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.77202 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.77136 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.77071 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.77008 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.76944 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.76882 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.76822 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.76764 Accuracy: 0.00000\n",
      "Test Loss: 0.69740 Accuracy: 0.50080\n",
      "Epoch: 350 Batch:   0 Loss: 0.76706 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.76653 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.76601 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.76552 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.76505 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.76459 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.76417 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.76375 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.76334 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.76295 Accuracy: 0.00000\n",
      "Test Loss: 0.69915 Accuracy: 0.50080\n",
      "Epoch: 360 Batch:   0 Loss: 0.76258 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.76222 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.76187 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.76153 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.76121 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.76090 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.76060 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.76031 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.76003 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.75976 Accuracy: 0.00000\n",
      "Test Loss: 0.70125 Accuracy: 0.50080\n",
      "Epoch: 370 Batch:   0 Loss: 0.75950 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.75925 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.75900 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.75877 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.75854 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.75831 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.75808 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.75787 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.75766 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.75746 Accuracy: 0.00000\n",
      "Test Loss: 0.70339 Accuracy: 0.50080\n",
      "Epoch: 380 Batch:   0 Loss: 0.75726 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.75706 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.75687 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.75668 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.75650 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.75633 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.75616 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.75600 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.75584 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.75569 Accuracy: 0.00000\n",
      "Test Loss: 0.70557 Accuracy: 0.50080\n",
      "Epoch: 390 Batch:   0 Loss: 0.75555 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.75542 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.75528 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.75515 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.75502 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.75490 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.75478 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.75466 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.75454 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.75443 Accuracy: 0.00000\n",
      "Test Loss: 0.70775 Accuracy: 0.50080\n",
      "Epoch: 400 Batch:   0 Loss: 0.75432 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.75421 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.75411 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.75401 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.75391 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.75382 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.75372 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.75363 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.75354 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.75346 Accuracy: 0.00000\n",
      "Test Loss: 0.70987 Accuracy: 0.50080\n",
      "Epoch: 410 Batch:   0 Loss: 0.75337 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.75329 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.75320 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.75312 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.75304 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.75297 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.75289 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.75281 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.75273 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.75266 Accuracy: 0.00000\n",
      "Test Loss: 0.71193 Accuracy: 0.50080\n",
      "Epoch: 420 Batch:   0 Loss: 0.75258 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.75251 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.75244 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.75237 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.75230 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.75224 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.75217 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.75211 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.75205 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.75198 Accuracy: 0.00000\n",
      "Test Loss: 0.71400 Accuracy: 0.50090\n",
      "Epoch: 430 Batch:   0 Loss: 0.75192 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.75186 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.75180 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.75174 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.75169 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.75163 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.75158 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.75152 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.75147 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Test Loss: 0.71602 Accuracy: 0.50090\n",
      "Epoch: 440 Batch:   0 Loss: 0.75136 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.75131 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.75121 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.75116 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.75112 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.75107 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.75102 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.75097 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.75093 Accuracy: 0.00000\n",
      "Test Loss: 0.71806 Accuracy: 0.50090\n",
      "Epoch: 450 Batch:   0 Loss: 0.75088 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.75084 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.75080 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.75076 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.75071 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.75067 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.75063 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.75059 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.75055 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.75052 Accuracy: 0.00000\n",
      "Test Loss: 0.72012 Accuracy: 0.50090\n",
      "Epoch: 460 Batch:   0 Loss: 0.75047 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.75043 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.75039 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.75035 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.75031 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.75027 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.75023 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.75020 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.75016 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.75012 Accuracy: 0.00000\n",
      "Test Loss: 0.72218 Accuracy: 0.50090\n",
      "Epoch: 470 Batch:   0 Loss: 0.75008 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.75006 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.75002 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.74999 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.74995 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.74992 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.74988 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.74985 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.74981 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.74978 Accuracy: 0.00000\n",
      "Test Loss: 0.72428 Accuracy: 0.50090\n",
      "Epoch: 480 Batch:   0 Loss: 0.74975 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.74972 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.74969 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.74967 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.74964 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.74961 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.74958 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.74955 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.74952 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.74950 Accuracy: 0.00000\n",
      "Test Loss: 0.72641 Accuracy: 0.50090\n",
      "Epoch: 490 Batch:   0 Loss: 0.74947 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.74944 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.74941 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.74939 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.74937 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.74934 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.74931 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.74929 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.74926 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.74924 Accuracy: 0.00000\n",
      "Test Loss: 0.72851 Accuracy: 0.50090\n",
      "Epoch: 500 Batch:   0 Loss: 0.74922 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.74919 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.74917 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.74914 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.74912 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 09:59:07,840] Trial 3 finished with value: 0.5007036590269401 and parameters: {'REG_W': 2.6161397357985874e-06, 'REG_B': 0.009477218367191434, 'REG_Z': 2.6137996213348635e-05, 'SPAR_W': 0.7924278818592528, 'SPAR_B': 0.9869714957831939, 'SPAR_Z': 0.8812742144423291, 'LEARNING_RATE': 0.00047823494417497005, 'NUM_EPOCHS': 505}. Best is trial 2 with value: 0.5008041817450744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 3.32370 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 4.83086 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 3.15451 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.50528 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.26500 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.18157 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.15504 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.14638 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.14021 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.13123 Accuracy: 0.00000\n",
      "Test Loss: 1.05755 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.11931 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.10343 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.08405 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.06258 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.03798 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.01102 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.98309 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.95288 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.92107 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.88712 Accuracy: 0.00000\n",
      "Test Loss: 0.99346 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.85148 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.81411 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.77520 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.73552 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.69452 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.65347 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.61167 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.56917 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.52750 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.48611 Accuracy: 0.00000\n",
      "Test Loss: 0.92665 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.44523 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.40556 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.36679 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.32938 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.29342 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.25870 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.22644 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.19605 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.16740 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.14070 Accuracy: 0.00000\n",
      "Test Loss: 0.86111 Accuracy: 0.50030\n",
      "Epoch:  40 Batch:   0 Loss: 1.11574 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.09275 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.07119 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.05125 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.03270 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.01560 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.99990 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.98589 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.97306 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.96147 Accuracy: 0.00000\n",
      "Test Loss: 0.79840 Accuracy: 0.50040\n",
      "Epoch:  50 Batch:   0 Loss: 0.95128 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.94243 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.93448 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.92753 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.92142 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.91601 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.91122 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.90687 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.90287 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.89931 Accuracy: 0.00000\n",
      "Test Loss: 0.76392 Accuracy: 0.50050\n",
      "Epoch:  60 Batch:   0 Loss: 0.89597 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.89297 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.89007 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.88738 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.88475 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.88233 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.87995 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.87770 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.87561 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.87361 Accuracy: 0.00000\n",
      "Test Loss: 0.74467 Accuracy: 0.50050\n",
      "Epoch:  70 Batch:   0 Loss: 0.87173 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.86993 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.86824 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.86666 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.86514 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.86370 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.86239 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.86117 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.86003 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.85897 Accuracy: 0.00000\n",
      "Test Loss: 0.73202 Accuracy: 0.50050\n",
      "Epoch:  80 Batch:   0 Loss: 0.85795 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.85699 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.85607 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.85519 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.85436 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.85355 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.85274 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.85198 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.85123 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.85052 Accuracy: 0.00000\n",
      "Test Loss: 0.72263 Accuracy: 0.50050\n",
      "Epoch:  90 Batch:   0 Loss: 0.84992 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.84929 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.84875 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.84826 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.84778 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.84733 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.84692 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.84651 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.84615 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.84577 Accuracy: 0.00000\n",
      "Test Loss: 0.71527 Accuracy: 0.50060\n",
      "Epoch: 100 Batch:   0 Loss: 0.84537 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.84494 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.84451 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.84407 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.84362 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.84319 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.84276 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.84228 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.84177 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.84124 Accuracy: 0.00000\n",
      "Test Loss: 0.70900 Accuracy: 0.50060\n",
      "Epoch: 110 Batch:   0 Loss: 0.84066 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.84011 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.83953 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.83897 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.83838 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.83777 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.83718 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.83661 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.83602 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.83540 Accuracy: 0.00000\n",
      "Test Loss: 0.70366 Accuracy: 0.50060\n",
      "Epoch: 120 Batch:   0 Loss: 0.83479 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.83418 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.83356 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.83290 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.83224 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.83156 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.83085 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.83015 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.82942 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.82867 Accuracy: 0.00000\n",
      "Test Loss: 0.69877 Accuracy: 0.50060\n",
      "Epoch: 130 Batch:   0 Loss: 0.82790 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.82708 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.82625 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.82540 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.82451 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.82361 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.82270 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.82177 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.82081 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.81985 Accuracy: 0.00000\n",
      "Test Loss: 0.69395 Accuracy: 0.50060\n",
      "Epoch: 140 Batch:   0 Loss: 0.81888 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.81789 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.81694 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.81594 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.81496 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.81399 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.81301 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.81206 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.81112 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.81021 Accuracy: 0.00000\n",
      "Test Loss: 0.68947 Accuracy: 0.50070\n",
      "Epoch: 150 Batch:   0 Loss: 0.80931 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.80843 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.80756 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.80670 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.80586 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.80505 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.80424 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.80347 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.80271 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.80198 Accuracy: 0.00000\n",
      "Test Loss: 0.68555 Accuracy: 0.50070\n",
      "Epoch: 160 Batch:   0 Loss: 0.80126 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.80056 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.79988 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.79921 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.79856 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.79792 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.79730 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.79669 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.79610 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.79551 Accuracy: 0.00000\n",
      "Test Loss: 0.68208 Accuracy: 0.50070\n",
      "Epoch: 170 Batch:   0 Loss: 0.79494 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.79439 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.79384 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.79331 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.79280 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.79228 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.79180 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.79131 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.79085 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.79040 Accuracy: 0.00000\n",
      "Test Loss: 0.67908 Accuracy: 0.50070\n",
      "Epoch: 180 Batch:   0 Loss: 0.78996 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.78953 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.78911 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.78870 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.78828 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.78787 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.78746 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.78707 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.78666 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.78626 Accuracy: 0.00000\n",
      "Test Loss: 0.67651 Accuracy: 0.50070\n",
      "Epoch: 190 Batch:   0 Loss: 0.78587 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.78550 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.78514 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.78478 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.78443 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.78409 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.78374 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.78341 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.78309 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.78277 Accuracy: 0.00000\n",
      "Test Loss: 0.67427 Accuracy: 0.50070\n",
      "Epoch: 200 Batch:   0 Loss: 0.78245 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.78215 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.78183 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.78153 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.78124 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.78095 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.78066 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.78039 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.78012 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.77985 Accuracy: 0.00000\n",
      "Test Loss: 0.67233 Accuracy: 0.50070\n",
      "Epoch: 210 Batch:   0 Loss: 0.77959 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.77934 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.77908 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.77884 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.77859 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.77834 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.77810 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.77787 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.77764 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.77741 Accuracy: 0.00000\n",
      "Test Loss: 0.67072 Accuracy: 0.50070\n",
      "Epoch: 220 Batch:   0 Loss: 0.77719 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.77697 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.77675 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.77654 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.77632 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.77610 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.77589 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.77568 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.77547 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.77527 Accuracy: 0.00000\n",
      "Test Loss: 0.66937 Accuracy: 0.50070\n",
      "Epoch: 230 Batch:   0 Loss: 0.77507 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.77487 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.77468 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.77449 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.77430 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.77412 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.77393 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.77375 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.77358 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.77340 Accuracy: 0.00000\n",
      "Test Loss: 0.66833 Accuracy: 0.50070\n",
      "Epoch: 240 Batch:   0 Loss: 0.77322 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.77305 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.77288 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.77271 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.77255 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.77239 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.77223 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.77207 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.77192 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.77176 Accuracy: 0.00000\n",
      "Test Loss: 0.66755 Accuracy: 0.50070\n",
      "Epoch: 250 Batch:   0 Loss: 0.77161 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.77146 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.77132 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.77118 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.77103 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.77089 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.77076 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.77062 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.77048 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.77035 Accuracy: 0.00000\n",
      "Test Loss: 0.66699 Accuracy: 0.50070\n",
      "Epoch: 260 Batch:   0 Loss: 0.77022 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.77009 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.76996 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.76983 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.76971 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.76958 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.76946 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.76935 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.76923 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.76911 Accuracy: 0.00000\n",
      "Test Loss: 0.66663 Accuracy: 0.50060\n",
      "Epoch: 270 Batch:   0 Loss: 0.76900 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.76888 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.76877 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.76866 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.76855 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.76844 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.76833 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.76823 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.76812 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.76802 Accuracy: 0.00000\n",
      "Test Loss: 0.66644 Accuracy: 0.50060\n",
      "Epoch: 280 Batch:   0 Loss: 0.76791 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.76780 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.76770 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.76760 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.76750 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.76740 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.76730 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.76720 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.76710 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.76700 Accuracy: 0.00000\n",
      "Test Loss: 0.66639 Accuracy: 0.50060\n",
      "Epoch: 290 Batch:   0 Loss: 0.76691 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.76682 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.76673 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.76663 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.76654 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.76645 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.76636 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.76626 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.76617 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.76607 Accuracy: 0.00000\n",
      "Test Loss: 0.66647 Accuracy: 0.50070\n",
      "Epoch: 300 Batch:   0 Loss: 0.76598 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.76589 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.76580 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.76571 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.76562 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.76554 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.76545 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.76537 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.76528 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.76520 Accuracy: 0.00000\n",
      "Test Loss: 0.66665 Accuracy: 0.50070\n",
      "Epoch: 310 Batch:   0 Loss: 0.76511 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.76503 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.76494 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.76486 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.76478 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.76470 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.76463 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.76455 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.76448 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.76440 Accuracy: 0.00000\n",
      "Test Loss: 0.66693 Accuracy: 0.50070\n",
      "Epoch: 320 Batch:   0 Loss: 0.76432 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.76425 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.76418 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.76410 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.76403 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.76396 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.76389 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.76381 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.76373 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.76366 Accuracy: 0.00000\n",
      "Test Loss: 0.66732 Accuracy: 0.50070\n",
      "Epoch: 330 Batch:   0 Loss: 0.76358 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.76351 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.76344 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.76337 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.76330 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.76323 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.76316 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.76309 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.76301 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.76294 Accuracy: 0.00000\n",
      "Test Loss: 0.66782 Accuracy: 0.50060\n",
      "Epoch: 340 Batch:   0 Loss: 0.76287 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.76280 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.76274 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.76267 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.76261 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.76255 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.76248 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.76242 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.76235 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.76229 Accuracy: 0.00000\n",
      "Test Loss: 0.66840 Accuracy: 0.50060\n",
      "Epoch: 350 Batch:   0 Loss: 0.76223 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.76216 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.76210 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.76204 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.76198 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.76192 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.76187 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.76181 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.76176 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.76170 Accuracy: 0.00000\n",
      "Test Loss: 0.66909 Accuracy: 0.50060\n",
      "Epoch: 360 Batch:   0 Loss: 0.76165 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.76159 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.76154 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.76149 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.76143 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.76138 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.76133 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.76127 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.76121 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.76116 Accuracy: 0.00000\n",
      "Test Loss: 0.66985 Accuracy: 0.50060\n",
      "Epoch: 370 Batch:   0 Loss: 0.76110 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.76105 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.76100 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.76094 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:02:31,014] Trial 4 finished with value: 0.5004020908725372 and parameters: {'REG_W': 3.7655374124460386e-06, 'REG_B': 0.005034276869007759, 'REG_Z': 3.003075871217921e-05, 'SPAR_W': 0.8573520329247419, 'SPAR_B': 0.6245691349325497, 'SPAR_Z': 0.5970282447732955, 'LEARNING_RATE': 0.00038398908555143177, 'NUM_EPOCHS': 374}. Best is trial 2 with value: 0.5008041817450744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 3.35493 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.62445 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.43811 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.32024 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.24843 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.20529 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.17949 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.16401 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.15458 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.14864 Accuracy: 0.00000\n",
      "Test Loss: 0.75496 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.14467 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.14178 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.13945 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.13741 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.13548 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.13360 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.13155 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.12951 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.12733 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.12504 Accuracy: 0.00000\n",
      "Test Loss: 0.74422 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.12264 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.12009 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.11745 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.11483 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.11208 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.10937 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.10673 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.10408 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.10141 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.09874 Accuracy: 0.00000\n",
      "Test Loss: 0.73613 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.09575 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.09286 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.08970 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.08662 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.08364 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.08068 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.07773 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.07479 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.07184 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.06890 Accuracy: 0.00000\n",
      "Test Loss: 0.73177 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.06597 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.06306 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.06003 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.05705 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.05405 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.05091 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.04781 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.04470 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.04166 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.03862 Accuracy: 0.00000\n",
      "Test Loss: 0.73028 Accuracy: 0.50030\n",
      "Epoch:  50 Batch:   0 Loss: 1.03566 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.03269 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.02970 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.02674 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.02384 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.02095 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.01809 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.01532 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.01258 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.00993 Accuracy: 0.00000\n",
      "Test Loss: 0.72980 Accuracy: 0.50040\n",
      "Epoch:  60 Batch:   0 Loss: 1.00733 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.00475 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.00218 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.99964 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.99712 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.99461 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.99209 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.98959 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.98713 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.98467 Accuracy: 0.00000\n",
      "Test Loss: 0.72913 Accuracy: 0.52241\n",
      "Epoch:  70 Batch:   0 Loss: 0.98220 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.97969 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.97718 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.97467 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.97217 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.96966 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.96714 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.96463 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.96214 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.95966 Accuracy: 0.00000\n",
      "Test Loss: 0.72796 Accuracy: 0.52482\n",
      "Epoch:  80 Batch:   0 Loss: 0.95717 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.95469 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.95220 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.94968 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.94714 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.94463 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.94213 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.93962 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.93710 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.93460 Accuracy: 0.00000\n",
      "Test Loss: 0.72637 Accuracy: 0.52623\n",
      "Epoch:  90 Batch:   0 Loss: 0.93211 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.92959 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.92713 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.92467 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.92224 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.91979 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.91736 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.91498 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.91257 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.91019 Accuracy: 0.00000\n",
      "Test Loss: 0.72449 Accuracy: 0.52793\n",
      "Epoch: 100 Batch:   0 Loss: 0.90780 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.90543 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.90305 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.90072 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.89842 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.89614 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.89388 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.89166 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.88943 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.88725 Accuracy: 0.00000\n",
      "Test Loss: 0.72257 Accuracy: 0.53266\n",
      "Epoch: 110 Batch:   0 Loss: 0.88511 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.88298 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.88088 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.87881 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.87677 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.87475 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.87273 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.87076 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.86880 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.86687 Accuracy: 0.00000\n",
      "Test Loss: 0.72081 Accuracy: 0.53828\n",
      "Epoch: 120 Batch:   0 Loss: 0.86496 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.86307 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.86120 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.85935 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.85751 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.85570 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.85393 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.85216 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.85043 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.84871 Accuracy: 0.00000\n",
      "Test Loss: 0.71931 Accuracy: 0.54602\n",
      "Epoch: 130 Batch:   0 Loss: 0.84700 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.84530 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.84367 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.84205 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.84046 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.83888 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.83733 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.83578 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.83425 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.83275 Accuracy: 0.00000\n",
      "Test Loss: 0.71812 Accuracy: 0.55386\n",
      "Epoch: 140 Batch:   0 Loss: 0.83127 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.82981 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.82836 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.82695 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.82556 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.82419 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.82281 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.82149 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.82016 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.81887 Accuracy: 0.03125\n",
      "Test Loss: 0.71722 Accuracy: 0.56209\n",
      "Epoch: 150 Batch:   0 Loss: 0.81761 Accuracy: 0.03125\n",
      "Epoch: 151 Batch:   0 Loss: 0.81637 Accuracy: 0.03125\n",
      "Epoch: 152 Batch:   0 Loss: 0.81509 Accuracy: 0.03125\n",
      "Epoch: 153 Batch:   0 Loss: 0.81385 Accuracy: 0.03125\n",
      "Epoch: 154 Batch:   0 Loss: 0.81263 Accuracy: 0.03125\n",
      "Epoch: 155 Batch:   0 Loss: 0.81143 Accuracy: 0.03125\n",
      "Epoch: 156 Batch:   0 Loss: 0.81023 Accuracy: 0.03125\n",
      "Epoch: 157 Batch:   0 Loss: 0.80905 Accuracy: 0.03125\n",
      "Epoch: 158 Batch:   0 Loss: 0.80787 Accuracy: 0.06250\n",
      "Epoch: 159 Batch:   0 Loss: 0.80669 Accuracy: 0.06250\n",
      "Test Loss: 0.71652 Accuracy: 0.56983\n",
      "Epoch: 160 Batch:   0 Loss: 0.80555 Accuracy: 0.06250\n",
      "Epoch: 161 Batch:   0 Loss: 0.80441 Accuracy: 0.06250\n",
      "Epoch: 162 Batch:   0 Loss: 0.80326 Accuracy: 0.06250\n",
      "Epoch: 163 Batch:   0 Loss: 0.80213 Accuracy: 0.06250\n",
      "Epoch: 164 Batch:   0 Loss: 0.80102 Accuracy: 0.06250\n",
      "Epoch: 165 Batch:   0 Loss: 0.79993 Accuracy: 0.09375\n",
      "Epoch: 166 Batch:   0 Loss: 0.79886 Accuracy: 0.09375\n",
      "Epoch: 167 Batch:   0 Loss: 0.79780 Accuracy: 0.09375\n",
      "Epoch: 168 Batch:   0 Loss: 0.79678 Accuracy: 0.09375\n",
      "Epoch: 169 Batch:   0 Loss: 0.79577 Accuracy: 0.12500\n",
      "Test Loss: 0.71596 Accuracy: 0.57817\n",
      "Epoch: 170 Batch:   0 Loss: 0.79476 Accuracy: 0.12500\n",
      "Epoch: 171 Batch:   0 Loss: 0.79375 Accuracy: 0.12500\n",
      "Epoch: 172 Batch:   0 Loss: 0.79277 Accuracy: 0.12500\n",
      "Epoch: 173 Batch:   0 Loss: 0.79179 Accuracy: 0.15625\n",
      "Epoch: 174 Batch:   0 Loss: 0.79083 Accuracy: 0.15625\n",
      "Epoch: 175 Batch:   0 Loss: 0.78988 Accuracy: 0.15625\n",
      "Epoch: 176 Batch:   0 Loss: 0.78894 Accuracy: 0.15625\n",
      "Epoch: 177 Batch:   0 Loss: 0.78801 Accuracy: 0.18750\n",
      "Epoch: 178 Batch:   0 Loss: 0.78709 Accuracy: 0.21875\n",
      "Epoch: 179 Batch:   0 Loss: 0.78615 Accuracy: 0.21875\n",
      "Test Loss: 0.71551 Accuracy: 0.58500\n",
      "Epoch: 180 Batch:   0 Loss: 0.78521 Accuracy: 0.28125\n",
      "Epoch: 181 Batch:   0 Loss: 0.78428 Accuracy: 0.28125\n",
      "Epoch: 182 Batch:   0 Loss: 0.78338 Accuracy: 0.28125\n",
      "Epoch: 183 Batch:   0 Loss: 0.78249 Accuracy: 0.28125\n",
      "Epoch: 184 Batch:   0 Loss: 0.78161 Accuracy: 0.28125\n",
      "Epoch: 185 Batch:   0 Loss: 0.78073 Accuracy: 0.31250\n",
      "Epoch: 186 Batch:   0 Loss: 0.77989 Accuracy: 0.31250\n",
      "Epoch: 187 Batch:   0 Loss: 0.77906 Accuracy: 0.34375\n",
      "Epoch: 188 Batch:   0 Loss: 0.77824 Accuracy: 0.37500\n",
      "Epoch: 189 Batch:   0 Loss: 0.77742 Accuracy: 0.37500\n",
      "Test Loss: 0.71515 Accuracy: 0.58952\n",
      "Epoch: 190 Batch:   0 Loss: 0.77662 Accuracy: 0.37500\n",
      "Epoch: 191 Batch:   0 Loss: 0.77582 Accuracy: 0.37500\n",
      "Epoch: 192 Batch:   0 Loss: 0.77503 Accuracy: 0.37500\n",
      "Epoch: 193 Batch:   0 Loss: 0.77424 Accuracy: 0.40625\n",
      "Epoch: 194 Batch:   0 Loss: 0.77347 Accuracy: 0.43750\n",
      "Epoch: 195 Batch:   0 Loss: 0.77270 Accuracy: 0.43750\n",
      "Epoch: 196 Batch:   0 Loss: 0.77193 Accuracy: 0.43750\n",
      "Epoch: 197 Batch:   0 Loss: 0.77119 Accuracy: 0.43750\n",
      "Epoch: 198 Batch:   0 Loss: 0.77045 Accuracy: 0.43750\n",
      "Epoch: 199 Batch:   0 Loss: 0.76972 Accuracy: 0.43750\n",
      "Test Loss: 0.71482 Accuracy: 0.59515\n",
      "Epoch: 200 Batch:   0 Loss: 0.76899 Accuracy: 0.46875\n",
      "Epoch: 201 Batch:   0 Loss: 0.76829 Accuracy: 0.50000\n",
      "Epoch: 202 Batch:   0 Loss: 0.76759 Accuracy: 0.50000\n",
      "Epoch: 203 Batch:   0 Loss: 0.76691 Accuracy: 0.50000\n",
      "Epoch: 204 Batch:   0 Loss: 0.76623 Accuracy: 0.50000\n",
      "Epoch: 205 Batch:   0 Loss: 0.76555 Accuracy: 0.50000\n",
      "Epoch: 206 Batch:   0 Loss: 0.76486 Accuracy: 0.50000\n",
      "Epoch: 207 Batch:   0 Loss: 0.76416 Accuracy: 0.53125\n",
      "Epoch: 208 Batch:   0 Loss: 0.76348 Accuracy: 0.53125\n",
      "Epoch: 209 Batch:   0 Loss: 0.76280 Accuracy: 0.56250\n",
      "Test Loss: 0.71451 Accuracy: 0.60078\n",
      "Epoch: 210 Batch:   0 Loss: 0.76213 Accuracy: 0.59375\n",
      "Epoch: 211 Batch:   0 Loss: 0.76145 Accuracy: 0.59375\n",
      "Epoch: 212 Batch:   0 Loss: 0.76079 Accuracy: 0.59375\n",
      "Epoch: 213 Batch:   0 Loss: 0.76013 Accuracy: 0.59375\n",
      "Epoch: 214 Batch:   0 Loss: 0.75947 Accuracy: 0.59375\n",
      "Epoch: 215 Batch:   0 Loss: 0.75882 Accuracy: 0.59375\n",
      "Epoch: 216 Batch:   0 Loss: 0.75818 Accuracy: 0.59375\n",
      "Epoch: 217 Batch:   0 Loss: 0.75756 Accuracy: 0.59375\n",
      "Epoch: 218 Batch:   0 Loss: 0.75693 Accuracy: 0.59375\n",
      "Epoch: 219 Batch:   0 Loss: 0.75632 Accuracy: 0.62500\n",
      "Test Loss: 0.71421 Accuracy: 0.60580\n",
      "Epoch: 220 Batch:   0 Loss: 0.75570 Accuracy: 0.65625\n",
      "Epoch: 221 Batch:   0 Loss: 0.75510 Accuracy: 0.65625\n",
      "Epoch: 222 Batch:   0 Loss: 0.75450 Accuracy: 0.65625\n",
      "Epoch: 223 Batch:   0 Loss: 0.75391 Accuracy: 0.65625\n",
      "Epoch: 224 Batch:   0 Loss: 0.75331 Accuracy: 0.65625\n",
      "Epoch: 225 Batch:   0 Loss: 0.75273 Accuracy: 0.65625\n",
      "Epoch: 226 Batch:   0 Loss: 0.75214 Accuracy: 0.65625\n",
      "Epoch: 227 Batch:   0 Loss: 0.75154 Accuracy: 0.65625\n",
      "Epoch: 228 Batch:   0 Loss: 0.75095 Accuracy: 0.65625\n",
      "Epoch: 229 Batch:   0 Loss: 0.75037 Accuracy: 0.65625\n",
      "Test Loss: 0.71393 Accuracy: 0.61364\n",
      "Epoch: 230 Batch:   0 Loss: 0.74980 Accuracy: 0.65625\n",
      "Epoch: 231 Batch:   0 Loss: 0.74924 Accuracy: 0.65625\n",
      "Epoch: 232 Batch:   0 Loss: 0.74868 Accuracy: 0.65625\n",
      "Epoch: 233 Batch:   0 Loss: 0.74814 Accuracy: 0.65625\n",
      "Epoch: 234 Batch:   0 Loss: 0.74760 Accuracy: 0.65625\n",
      "Epoch: 235 Batch:   0 Loss: 0.74708 Accuracy: 0.65625\n",
      "Epoch: 236 Batch:   0 Loss: 0.74655 Accuracy: 0.65625\n",
      "Epoch: 237 Batch:   0 Loss: 0.74603 Accuracy: 0.65625\n",
      "Epoch: 238 Batch:   0 Loss: 0.74552 Accuracy: 0.68750\n",
      "Epoch: 239 Batch:   0 Loss: 0.74501 Accuracy: 0.68750\n",
      "Test Loss: 0.71365 Accuracy: 0.61896\n",
      "Epoch: 240 Batch:   0 Loss: 0.74451 Accuracy: 0.68750\n",
      "Epoch: 241 Batch:   0 Loss: 0.74401 Accuracy: 0.68750\n",
      "Epoch: 242 Batch:   0 Loss: 0.74352 Accuracy: 0.71875\n",
      "Epoch: 243 Batch:   0 Loss: 0.74303 Accuracy: 0.71875\n",
      "Epoch: 244 Batch:   0 Loss: 0.74253 Accuracy: 0.71875\n",
      "Epoch: 245 Batch:   0 Loss: 0.74202 Accuracy: 0.71875\n",
      "Epoch: 246 Batch:   0 Loss: 0.74150 Accuracy: 0.75000\n",
      "Epoch: 247 Batch:   0 Loss: 0.74098 Accuracy: 0.75000\n",
      "Epoch: 248 Batch:   0 Loss: 0.74047 Accuracy: 0.75000\n",
      "Epoch: 249 Batch:   0 Loss: 0.73997 Accuracy: 0.78125\n",
      "Test Loss: 0.71337 Accuracy: 0.62499\n",
      "Epoch: 250 Batch:   0 Loss: 0.73948 Accuracy: 0.81250\n",
      "Epoch: 251 Batch:   0 Loss: 0.73899 Accuracy: 0.81250\n",
      "Epoch: 252 Batch:   0 Loss: 0.73851 Accuracy: 0.81250\n",
      "Epoch: 253 Batch:   0 Loss: 0.73803 Accuracy: 0.81250\n",
      "Epoch: 254 Batch:   0 Loss: 0.73756 Accuracy: 0.84375\n",
      "Epoch: 255 Batch:   0 Loss: 0.73709 Accuracy: 0.84375\n",
      "Epoch: 256 Batch:   0 Loss: 0.73662 Accuracy: 0.84375\n",
      "Epoch: 257 Batch:   0 Loss: 0.73616 Accuracy: 0.84375\n",
      "Epoch: 258 Batch:   0 Loss: 0.73570 Accuracy: 0.84375\n",
      "Epoch: 259 Batch:   0 Loss: 0.73525 Accuracy: 0.84375\n",
      "Test Loss: 0.71307 Accuracy: 0.62952\n",
      "Epoch: 260 Batch:   0 Loss: 0.73480 Accuracy: 0.84375\n",
      "Epoch: 261 Batch:   0 Loss: 0.73437 Accuracy: 0.84375\n",
      "Epoch: 262 Batch:   0 Loss: 0.73393 Accuracy: 0.84375\n",
      "Epoch: 263 Batch:   0 Loss: 0.73350 Accuracy: 0.84375\n",
      "Epoch: 264 Batch:   0 Loss: 0.73307 Accuracy: 0.87500\n",
      "Epoch: 265 Batch:   0 Loss: 0.73265 Accuracy: 0.87500\n",
      "Epoch: 266 Batch:   0 Loss: 0.73222 Accuracy: 0.90625\n",
      "Epoch: 267 Batch:   0 Loss: 0.73180 Accuracy: 0.90625\n",
      "Epoch: 268 Batch:   0 Loss: 0.73138 Accuracy: 0.90625\n",
      "Epoch: 269 Batch:   0 Loss: 0.73096 Accuracy: 0.90625\n",
      "Test Loss: 0.71275 Accuracy: 0.63514\n",
      "Epoch: 270 Batch:   0 Loss: 0.73055 Accuracy: 0.90625\n",
      "Epoch: 271 Batch:   0 Loss: 0.73013 Accuracy: 0.90625\n",
      "Epoch: 272 Batch:   0 Loss: 0.72973 Accuracy: 0.90625\n",
      "Epoch: 273 Batch:   0 Loss: 0.72932 Accuracy: 0.90625\n",
      "Epoch: 274 Batch:   0 Loss: 0.72892 Accuracy: 0.90625\n",
      "Epoch: 275 Batch:   0 Loss: 0.72852 Accuracy: 0.90625\n",
      "Epoch: 276 Batch:   0 Loss: 0.72812 Accuracy: 0.90625\n",
      "Epoch: 277 Batch:   0 Loss: 0.72773 Accuracy: 0.90625\n",
      "Epoch: 278 Batch:   0 Loss: 0.72734 Accuracy: 0.90625\n",
      "Epoch: 279 Batch:   0 Loss: 0.72695 Accuracy: 0.90625\n",
      "Test Loss: 0.71240 Accuracy: 0.63946\n",
      "Epoch: 280 Batch:   0 Loss: 0.72656 Accuracy: 0.90625\n",
      "Epoch: 281 Batch:   0 Loss: 0.72617 Accuracy: 0.90625\n",
      "Epoch: 282 Batch:   0 Loss: 0.72579 Accuracy: 0.90625\n",
      "Epoch: 283 Batch:   0 Loss: 0.72541 Accuracy: 0.90625\n",
      "Epoch: 284 Batch:   0 Loss: 0.72504 Accuracy: 0.90625\n",
      "Epoch: 285 Batch:   0 Loss: 0.72466 Accuracy: 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.72429 Accuracy: 0.90625\n",
      "Epoch: 287 Batch:   0 Loss: 0.72391 Accuracy: 0.90625\n",
      "Epoch: 288 Batch:   0 Loss: 0.72354 Accuracy: 0.90625\n",
      "Epoch: 289 Batch:   0 Loss: 0.72317 Accuracy: 0.90625\n",
      "Test Loss: 0.71203 Accuracy: 0.64338\n",
      "Epoch: 290 Batch:   0 Loss: 0.72280 Accuracy: 0.90625\n",
      "Epoch: 291 Batch:   0 Loss: 0.72244 Accuracy: 0.90625\n",
      "Epoch: 292 Batch:   0 Loss: 0.72208 Accuracy: 0.90625\n",
      "Epoch: 293 Batch:   0 Loss: 0.72172 Accuracy: 0.90625\n",
      "Epoch: 294 Batch:   0 Loss: 0.72136 Accuracy: 0.93750\n",
      "Epoch: 295 Batch:   0 Loss: 0.72100 Accuracy: 0.93750\n",
      "Epoch: 296 Batch:   0 Loss: 0.72064 Accuracy: 0.93750\n",
      "Epoch: 297 Batch:   0 Loss: 0.72029 Accuracy: 0.96875\n",
      "Epoch: 298 Batch:   0 Loss: 0.71994 Accuracy: 0.96875\n",
      "Epoch: 299 Batch:   0 Loss: 0.71959 Accuracy: 1.00000\n",
      "Test Loss: 0.71164 Accuracy: 0.64630\n",
      "Epoch: 300 Batch:   0 Loss: 0.71924 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.71890 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.71856 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.71822 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.71788 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.71754 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.71720 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.71687 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.71654 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.71621 Accuracy: 1.00000\n",
      "Test Loss: 0.71124 Accuracy: 0.65032\n",
      "Epoch: 310 Batch:   0 Loss: 0.71588 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.71555 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.71523 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.71491 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.71459 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.71426 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.71395 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.71363 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.71332 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.71301 Accuracy: 1.00000\n",
      "Test Loss: 0.71083 Accuracy: 0.65283\n",
      "Epoch: 320 Batch:   0 Loss: 0.71271 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.71240 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.71210 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.71180 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.71150 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.71120 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.71090 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.71060 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.71031 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.71002 Accuracy: 1.00000\n",
      "Test Loss: 0.71042 Accuracy: 0.65544\n",
      "Epoch: 330 Batch:   0 Loss: 0.70972 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.70943 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.70915 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.70886 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.70858 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.70829 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.70801 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.70773 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.70744 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.70716 Accuracy: 1.00000\n",
      "Test Loss: 0.70999 Accuracy: 0.65855\n",
      "Epoch: 340 Batch:   0 Loss: 0.70688 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.70660 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.70633 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.70606 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.70578 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.70551 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.70524 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.70497 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.70470 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.70443 Accuracy: 1.00000\n",
      "Test Loss: 0.70957 Accuracy: 0.66177\n",
      "Epoch: 350 Batch:   0 Loss: 0.70416 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.70389 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.70362 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.70335 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.70309 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.70282 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.70256 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.70230 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.70204 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.70178 Accuracy: 1.00000\n",
      "Test Loss: 0.70914 Accuracy: 0.66418\n",
      "Epoch: 360 Batch:   0 Loss: 0.70152 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.70127 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.70101 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.70076 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.70051 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.70026 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.70001 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.69977 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.69952 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.69928 Accuracy: 1.00000\n",
      "Test Loss: 0.70869 Accuracy: 0.66679\n",
      "Epoch: 370 Batch:   0 Loss: 0.69904 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.69880 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.69856 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.69832 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.69808 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.69784 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.69760 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.69736 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.69713 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.69689 Accuracy: 1.00000\n",
      "Test Loss: 0.70823 Accuracy: 0.66880\n",
      "Epoch: 380 Batch:   0 Loss: 0.69666 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.69642 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.69619 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.69596 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.69572 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.69549 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.69526 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.69503 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.69480 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.69458 Accuracy: 1.00000\n",
      "Test Loss: 0.70777 Accuracy: 0.67131\n",
      "Epoch: 390 Batch:   0 Loss: 0.69435 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.69412 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.69389 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.69367 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.69344 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.69322 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.69300 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.69278 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.69256 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.69234 Accuracy: 1.00000\n",
      "Test Loss: 0.70731 Accuracy: 0.67362\n",
      "Epoch: 400 Batch:   0 Loss: 0.69212 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.69190 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.69168 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.69146 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.69124 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.69103 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.69081 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.69060 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.69039 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.69018 Accuracy: 1.00000\n",
      "Test Loss: 0.70685 Accuracy: 0.67493\n",
      "Epoch: 410 Batch:   0 Loss: 0.68997 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.68975 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.68955 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.68934 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.68913 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.68892 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.68871 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.68850 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.68829 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.68808 Accuracy: 1.00000\n",
      "Test Loss: 0.70639 Accuracy: 0.67593\n",
      "Epoch: 420 Batch:   0 Loss: 0.68787 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.68766 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.68745 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.68724 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.68704 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:06:12,118] Trial 5 finished with value: 0.6766184157619622 and parameters: {'REG_W': 3.979090600968805e-06, 'REG_B': 0.0007549210782041626, 'REG_Z': 2.1754592187918303e-05, 'SPAR_W': 0.70713793643758, 'SPAR_B': 0.6708918841540703, 'SPAR_Z': 0.5049920499452771, 'LEARNING_RATE': 0.00011383022856341377, 'NUM_EPOCHS': 425}. Best is trial 5 with value: 0.6766184157619622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.26583 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 5.43781 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 4.34331 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 3.87133 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 3.67692 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 3.60126 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 3.57393 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 3.56401 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 3.55835 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 3.55158 Accuracy: 0.00000\n",
      "Test Loss: 1.68333 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 3.54145 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 3.52679 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 3.50764 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 3.48229 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 3.45207 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 3.41548 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 3.37315 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 3.32212 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 3.26485 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 3.20107 Accuracy: 0.00000\n",
      "Test Loss: 1.65214 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 3.13018 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 3.05163 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.96148 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.86367 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.76526 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 2.66109 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 2.55408 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 2.44477 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 2.33342 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 2.22018 Accuracy: 0.00000\n",
      "Test Loss: 1.54923 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 2.10510 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.99450 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.88579 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.78196 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.68387 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.58843 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.49835 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.41265 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.33248 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.25946 Accuracy: 0.00000\n",
      "Test Loss: 1.37212 Accuracy: 0.50050\n",
      "Epoch:  40 Batch:   0 Loss: 1.19039 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.12848 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.07153 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.02117 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.97705 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.93865 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.90494 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.87733 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.85548 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.83793 Accuracy: 0.00000\n",
      "Test Loss: 1.14489 Accuracy: 0.50070\n",
      "Epoch:  50 Batch:   0 Loss: 0.82333 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.81083 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.80036 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.79096 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.78249 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.77490 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.76811 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.76231 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.75731 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.75321 Accuracy: 0.00000\n",
      "Test Loss: 1.00373 Accuracy: 0.50070\n",
      "Epoch:  60 Batch:   0 Loss: 0.74990 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.74735 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.74539 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.74394 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.74292 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.74233 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.74209 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.74214 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.74247 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.74303 Accuracy: 0.00000\n",
      "Test Loss: 0.93788 Accuracy: 0.50070\n",
      "Epoch:  70 Batch:   0 Loss: 0.74375 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.74458 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.74561 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.74666 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.74779 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.74899 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.75023 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.75151 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.75278 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.75413 Accuracy: 0.00000\n",
      "Test Loss: 0.90145 Accuracy: 0.50080\n",
      "Epoch:  80 Batch:   0 Loss: 0.75546 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.75674 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.75791 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.75914 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.76032 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.76148 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.76252 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.76347 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.76431 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.76508 Accuracy: 0.00000\n",
      "Test Loss: 0.87336 Accuracy: 0.50070\n",
      "Epoch:  90 Batch:   0 Loss: 0.76584 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.76651 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.76714 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.76767 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.76809 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.76845 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.76852 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.76862 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.76870 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.76877 Accuracy: 0.00000\n",
      "Test Loss: 0.85137 Accuracy: 0.50070\n",
      "Epoch: 100 Batch:   0 Loss: 0.76889 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.76897 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.76904 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.76908 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.76911 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.76911 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.76914 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.76913 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.76912 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.76908 Accuracy: 0.00000\n",
      "Test Loss: 0.83437 Accuracy: 0.50090\n",
      "Epoch: 110 Batch:   0 Loss: 0.76904 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.76898 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.76890 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.76880 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.76871 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.76864 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.76852 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.76839 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.76826 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.76813 Accuracy: 0.00000\n",
      "Test Loss: 0.81950 Accuracy: 0.50090\n",
      "Epoch: 120 Batch:   0 Loss: 0.76796 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.76780 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.76761 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.76739 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.76720 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.76697 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.76675 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.76653 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.76631 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.76613 Accuracy: 0.00000\n",
      "Test Loss: 0.80630 Accuracy: 0.50100\n",
      "Epoch: 130 Batch:   0 Loss: 0.76595 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.76577 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.76560 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.76549 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.76533 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.76518 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.76503 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.76488 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.76477 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.76467 Accuracy: 0.00000\n",
      "Test Loss: 0.79505 Accuracy: 0.50100\n",
      "Epoch: 140 Batch:   0 Loss: 0.76455 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.76444 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.76439 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.76429 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.76419 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.76414 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.76406 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.76398 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.76391 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.76382 Accuracy: 0.00000\n",
      "Test Loss: 0.78558 Accuracy: 0.50111\n",
      "Epoch: 150 Batch:   0 Loss: 0.76375 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.76367 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.76362 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.76356 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.76353 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.76354 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.76352 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.76351 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.76352 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.76350 Accuracy: 0.00000\n",
      "Test Loss: 0.77752 Accuracy: 0.50111\n",
      "Epoch: 160 Batch:   0 Loss: 0.76348 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.76346 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.76344 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.76343 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.76340 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.76336 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.76332 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.76329 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.76329 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.76327 Accuracy: 0.00000\n",
      "Test Loss: 0.77111 Accuracy: 0.50111\n",
      "Epoch: 170 Batch:   0 Loss: 0.76324 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.76322 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.76321 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.76323 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.76324 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.76325 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.76327 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.76328 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.76331 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.76334 Accuracy: 0.00000\n",
      "Test Loss: 0.76545 Accuracy: 0.50111\n",
      "Epoch: 180 Batch:   0 Loss: 0.76337 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.76343 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.76347 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.76352 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.76359 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.76368 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.76378 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.76392 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.76402 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.76416 Accuracy: 0.00000\n",
      "Test Loss: 0.76026 Accuracy: 0.50111\n",
      "Epoch: 190 Batch:   0 Loss: 0.76430 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.76448 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.76467 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.76489 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.76515 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.76541 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.76569 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.76603 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.76638 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.76674 Accuracy: 0.00000\n",
      "Test Loss: 0.75493 Accuracy: 0.50100\n",
      "Epoch: 200 Batch:   0 Loss: 0.76710 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.76742 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.76768 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.76785 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.76793 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.76795 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.76787 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.76773 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.76754 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.76733 Accuracy: 0.00000\n",
      "Test Loss: 0.74754 Accuracy: 0.50100\n",
      "Epoch: 210 Batch:   0 Loss: 0.76711 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.76686 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.76661 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.76639 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.76618 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.76600 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.76586 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.76573 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.76564 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.76561 Accuracy: 0.00000\n",
      "Test Loss: 0.74174 Accuracy: 0.50100\n",
      "Epoch: 220 Batch:   0 Loss: 0.76562 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.76565 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.76573 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.76583 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.76595 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.76602 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.76607 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.76607 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.76604 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.76598 Accuracy: 0.00000\n",
      "Test Loss: 0.73640 Accuracy: 0.50090\n",
      "Epoch: 230 Batch:   0 Loss: 0.76591 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.76586 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.76587 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.76592 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.76606 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.76630 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.76663 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.76701 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.76741 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.76775 Accuracy: 0.00000\n",
      "Test Loss: 0.73366 Accuracy: 0.50080\n",
      "Epoch: 240 Batch:   0 Loss: 0.76800 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.76807 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.76793 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.76762 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.76718 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.76666 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.76609 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.76546 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.76482 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.76419 Accuracy: 0.00000\n",
      "Test Loss: 0.73058 Accuracy: 0.50080\n",
      "Epoch: 250 Batch:   0 Loss: 0.76357 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.76298 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.76241 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.76186 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.76133 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.76082 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.76032 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:08:27,692] Trial 6 finished with value: 0.5006031363088058 and parameters: {'REG_W': 2.0528350097010382e-06, 'REG_B': 0.006829258612051157, 'REG_Z': 4.787300524527533e-05, 'SPAR_W': 0.5443711183252911, 'SPAR_B': 0.6858431200088022, 'SPAR_Z': 0.5348947280603884, 'LEARNING_RATE': 0.0008885332323979621, 'NUM_EPOCHS': 257}. Best is trial 5 with value: 0.6766184157619622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.10138 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 2.15106 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.79645 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 3.11885 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 3.25503 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 3.29441 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 3.28624 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 3.25507 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 3.21394 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 3.16907 Accuracy: 0.00000\n",
      "Test Loss: 1.61415 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 3.12352 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 3.07332 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 3.02088 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.96194 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.89383 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.81728 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.72952 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.62992 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.51823 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.39867 Accuracy: 0.00000\n",
      "Test Loss: 1.54181 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.27340 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.14323 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.01032 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.87884 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.75114 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.62797 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.51243 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.40429 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.30472 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.21655 Accuracy: 0.00000\n",
      "Test Loss: 1.34944 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.13640 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.06721 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.00668 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.95408 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.90988 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.87338 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.84415 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.82046 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.80211 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.78734 Accuracy: 0.00000\n",
      "Test Loss: 1.07028 Accuracy: 0.50070\n",
      "Epoch:  40 Batch:   0 Loss: 0.77561 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.76629 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.75892 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.75305 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.74850 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.74497 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.74246 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.74076 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.73999 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.74002 Accuracy: 0.00000\n",
      "Test Loss: 0.91391 Accuracy: 0.50090\n",
      "Epoch:  50 Batch:   0 Loss: 0.74084 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.74228 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.74430 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.74674 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.74958 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.75254 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.75565 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.75873 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.76173 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.76458 Accuracy: 0.00000\n",
      "Test Loss: 0.85073 Accuracy: 0.50090\n",
      "Epoch:  60 Batch:   0 Loss: 0.76731 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.76997 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.77243 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.77467 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.77672 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.77863 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.78036 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.78184 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.78308 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.78421 Accuracy: 0.00000\n",
      "Test Loss: 0.80983 Accuracy: 0.50100\n",
      "Epoch:  70 Batch:   0 Loss: 0.78525 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.78609 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.78681 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.78734 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.78776 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.78820 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.78859 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.78881 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.78900 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.78915 Accuracy: 0.00000\n",
      "Test Loss: 0.78438 Accuracy: 0.50100\n",
      "Epoch:  80 Batch:   0 Loss: 0.78928 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.78931 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.78933 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.78930 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.78922 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.78910 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.78895 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.78877 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.78846 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.78809 Accuracy: 0.00000\n",
      "Test Loss: 0.76675 Accuracy: 0.50100\n",
      "Epoch:  90 Batch:   0 Loss: 0.78772 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.78730 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.78688 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.78647 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.78612 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.78572 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.78539 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.78504 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.78464 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.78421 Accuracy: 0.00000\n",
      "Test Loss: 0.75358 Accuracy: 0.50100\n",
      "Epoch: 100 Batch:   0 Loss: 0.78383 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.78344 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.78306 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.78269 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.78235 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.78189 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.78145 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.78103 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.78062 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.78023 Accuracy: 0.00000\n",
      "Test Loss: 0.74434 Accuracy: 0.50121\n",
      "Epoch: 110 Batch:   0 Loss: 0.77980 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.77937 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.77897 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.77861 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.77824 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.77786 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.77746 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.77706 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.77668 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.77632 Accuracy: 0.00000\n",
      "Test Loss: 0.73833 Accuracy: 0.50121\n",
      "Epoch: 120 Batch:   0 Loss: 0.77597 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.77562 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.77528 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.77492 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.77459 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.77429 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.77397 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.77369 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.77341 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.77316 Accuracy: 0.00000\n",
      "Test Loss: 0.73457 Accuracy: 0.50121\n",
      "Epoch: 130 Batch:   0 Loss: 0.77294 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.77276 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77260 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77246 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77234 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77223 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77215 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77211 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77207 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77205 Accuracy: 0.00000\n",
      "Test Loss: 0.73243 Accuracy: 0.50121\n",
      "Epoch: 140 Batch:   0 Loss: 0.77206 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77213 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77222 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77236 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.77255 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.77280 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.77312 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.77351 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.77397 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.77447 Accuracy: 0.00000\n",
      "Test Loss: 0.73116 Accuracy: 0.50121\n",
      "Epoch: 150 Batch:   0 Loss: 0.77496 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.77538 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.77561 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.77562 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.77540 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.77499 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.77444 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.77378 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.77308 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.77237 Accuracy: 0.00000\n",
      "Test Loss: 0.72754 Accuracy: 0.50121\n",
      "Epoch: 160 Batch:   0 Loss: 0.77164 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.77093 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.77021 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.76951 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.76884 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.76821 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.76759 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.76703 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.76652 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.76609 Accuracy: 0.00000\n",
      "Test Loss: 0.72493 Accuracy: 0.50121\n",
      "Epoch: 170 Batch:   0 Loss: 0.76570 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.76539 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.76515 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.76500 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.76491 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.76487 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.76484 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.76478 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.76464 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.76439 Accuracy: 0.00000\n",
      "Test Loss: 0.72266 Accuracy: 0.50121\n",
      "Epoch: 180 Batch:   0 Loss: 0.76408 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.76367 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.76327 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.76287 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.76247 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.76210 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.76174 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.76105 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.76067 Accuracy: 0.00000\n",
      "Test Loss: 0.72069 Accuracy: 0.50121\n",
      "Epoch: 190 Batch:   0 Loss: 0.76025 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.75981 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.75940 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.75899 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.75857 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.75817 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.75781 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.75738 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.75694 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.75642 Accuracy: 0.00000\n",
      "Test Loss: 0.71897 Accuracy: 0.50111\n",
      "Epoch: 200 Batch:   0 Loss: 0.75587 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.75529 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.75469 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.75410 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.75351 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.75296 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.75242 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.75189 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.75137 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.75089 Accuracy: 0.00000\n",
      "Test Loss: 0.71809 Accuracy: 0.50111\n",
      "Epoch: 210 Batch:   0 Loss: 0.75041 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.74994 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.74949 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.74906 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.74867 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.74829 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.74793 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.74758 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.74725 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.74694 Accuracy: 0.00000\n",
      "Test Loss: 0.71890 Accuracy: 0.50111\n",
      "Epoch: 220 Batch:   0 Loss: 0.74665 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.74636 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.74609 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.74585 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.74561 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.74538 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.74517 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.74496 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.74477 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.74458 Accuracy: 0.00000\n",
      "Test Loss: 0.72038 Accuracy: 0.50111\n",
      "Epoch: 230 Batch:   0 Loss: 0.74440 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.74423 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.74406 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.74391 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.74377 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.74364 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.74351 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.74341 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.74328 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.74316 Accuracy: 0.00000\n",
      "Test Loss: 0.72227 Accuracy: 0.50111\n",
      "Epoch: 240 Batch:   0 Loss: 0.74304 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.74294 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.74284 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.74274 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.74265 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.74256 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.74247 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.74239 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.74231 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.74222 Accuracy: 0.00000\n",
      "Test Loss: 0.72462 Accuracy: 0.50121\n",
      "Epoch: 250 Batch:   0 Loss: 0.74214 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.74206 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.74198 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.74191 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.74186 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.74178 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.74170 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.74163 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.74157 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.74150 Accuracy: 0.00000\n",
      "Test Loss: 0.72693 Accuracy: 0.50121\n",
      "Epoch: 260 Batch:   0 Loss: 0.74144 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.74138 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.74133 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.74128 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.74123 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.74118 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.74113 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.74108 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.74103 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.74098 Accuracy: 0.00000\n",
      "Test Loss: 0.72936 Accuracy: 0.50121\n",
      "Epoch: 270 Batch:   0 Loss: 0.74094 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.74089 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.74085 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.74081 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.74078 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.74074 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.74069 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.74065 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.74061 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.74057 Accuracy: 0.00000\n",
      "Test Loss: 0.73185 Accuracy: 0.50121\n",
      "Epoch: 280 Batch:   0 Loss: 0.74054 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.74050 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.74045 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.74041 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.74037 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.74034 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.74030 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.74027 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.74024 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.74020 Accuracy: 0.00000\n",
      "Test Loss: 0.73449 Accuracy: 0.50121\n",
      "Epoch: 290 Batch:   0 Loss: 0.74016 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.74013 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.74009 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.74005 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.74001 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.73997 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.73992 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.73989 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.73986 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.73981 Accuracy: 0.00000\n",
      "Test Loss: 0.73737 Accuracy: 0.50121\n",
      "Epoch: 300 Batch:   0 Loss: 0.73976 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.73972 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.73968 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.73964 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.73959 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.73956 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.73951 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.73947 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.73944 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.73940 Accuracy: 0.00000\n",
      "Test Loss: 0.74041 Accuracy: 0.50121\n",
      "Epoch: 310 Batch:   0 Loss: 0.73936 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.73933 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.73929 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.73926 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.73922 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.73920 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.73916 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.73913 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.73909 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.73906 Accuracy: 0.00000\n",
      "Test Loss: 0.74350 Accuracy: 0.50121\n",
      "Epoch: 320 Batch:   0 Loss: 0.73902 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.73899 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.73896 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.73893 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.73890 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.73887 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.73884 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.73882 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.73878 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.73875 Accuracy: 0.00000\n",
      "Test Loss: 0.74655 Accuracy: 0.50121\n",
      "Epoch: 330 Batch:   0 Loss: 0.73872 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.73870 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.73867 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.73864 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.73861 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.73859 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.73855 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.73853 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.73850 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.73846 Accuracy: 0.00000\n",
      "Test Loss: 0.74936 Accuracy: 0.50111\n",
      "Epoch: 340 Batch:   0 Loss: 0.73843 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.73841 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.73838 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.73836 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.73833 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.73831 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.73829 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.73827 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.73824 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.73822 Accuracy: 0.00000\n",
      "Test Loss: 0.75232 Accuracy: 0.50111\n",
      "Epoch: 350 Batch:   0 Loss: 0.73820 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.73818 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.73816 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.73814 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.73812 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.73810 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.73808 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.73806 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.73805 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.73803 Accuracy: 0.00000\n",
      "Test Loss: 0.75545 Accuracy: 0.50111\n",
      "Epoch: 360 Batch:   0 Loss: 0.73801 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.73799 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.73798 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.73796 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.73795 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.73794 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.73792 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.73791 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.73790 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.73789 Accuracy: 0.00000\n",
      "Test Loss: 0.75856 Accuracy: 0.50111\n",
      "Epoch: 370 Batch:   0 Loss: 0.73788 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.73787 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.73786 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.73784 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.73783 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.73782 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.73781 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.73780 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.73778 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.73777 Accuracy: 0.00000\n",
      "Test Loss: 0.76162 Accuracy: 0.50111\n",
      "Epoch: 380 Batch:   0 Loss: 0.73775 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.73774 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.73773 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.73772 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.73771 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.73770 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.73768 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.73767 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.73766 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.73764 Accuracy: 0.00000\n",
      "Test Loss: 0.76439 Accuracy: 0.50121\n",
      "Epoch: 390 Batch:   0 Loss: 0.73763 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.73761 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.73761 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.73759 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.73758 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.73757 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.73756 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.73754 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.73753 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.73752 Accuracy: 0.00000\n",
      "Test Loss: 0.76722 Accuracy: 0.50121\n",
      "Epoch: 400 Batch:   0 Loss: 0.73751 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.73749 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.73748 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.73747 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.73746 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.73745 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.73744 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.73742 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.73741 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.73740 Accuracy: 0.00000\n",
      "Test Loss: 0.77006 Accuracy: 0.50121\n",
      "Epoch: 410 Batch:   0 Loss: 0.73739 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.73737 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.73737 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.73735 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.73733 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.73732 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.73731 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.73730 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.73729 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.73727 Accuracy: 0.00000\n",
      "Test Loss: 0.77285 Accuracy: 0.50121\n",
      "Epoch: 420 Batch:   0 Loss: 0.73726 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.73725 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.73724 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.73723 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.73721 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.73720 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.73719 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.73718 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.73716 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.73716 Accuracy: 0.00000\n",
      "Test Loss: 0.77556 Accuracy: 0.50121\n",
      "Epoch: 430 Batch:   0 Loss: 0.73714 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.73713 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.73712 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.73711 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.73710 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.73709 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.73708 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.73707 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.73706 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.73706 Accuracy: 0.00000\n",
      "Test Loss: 0.77826 Accuracy: 0.50121\n",
      "Epoch: 440 Batch:   0 Loss: 0.73705 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.73705 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.73705 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.73704 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.73703 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.73703 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.73702 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.73701 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.73701 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.73700 Accuracy: 0.00000\n",
      "Test Loss: 0.78096 Accuracy: 0.50121\n",
      "Epoch: 450 Batch:   0 Loss: 0.73699 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.73698 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.73697 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.73696 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.73696 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.73695 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.73694 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.73694 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.73693 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.73693 Accuracy: 0.00000\n",
      "Test Loss: 0.78347 Accuracy: 0.50121\n",
      "Epoch: 460 Batch:   0 Loss: 0.73693 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.73692 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.73691 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.73691 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.73690 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.73693 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.73693 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.73693 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:12:33,292] Trial 7 finished with value: 0.501005227181343 and parameters: {'REG_W': 2.065814770435679e-06, 'REG_B': 0.0027971383710636054, 'REG_Z': 2.2493241430179776e-05, 'SPAR_W': 0.7398953282035616, 'SPAR_B': 0.9512823691406264, 'SPAR_Z': 0.5377375024841398, 'LEARNING_RATE': 0.0009050175708167293, 'NUM_EPOCHS': 468}. Best is trial 5 with value: 0.6766184157619622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.06252 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 2.26880 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.57547 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.72824 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.79466 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.81565 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 2.81334 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 2.79865 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 2.77735 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.75240 Accuracy: 0.00000\n",
      "Test Loss: 1.38972 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.72536 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.69725 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.66853 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.63918 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.60954 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.58056 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.55132 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.52101 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.48876 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.45567 Accuracy: 0.00000\n",
      "Test Loss: 1.33262 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.42065 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.38463 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.34541 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.30517 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.26316 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 2.22114 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 2.17700 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 2.13268 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 2.08713 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 2.04167 Accuracy: 0.00000\n",
      "Test Loss: 1.30619 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.99420 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.94804 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.90178 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.85670 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.81033 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.76510 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.72031 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.67604 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.63225 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.58892 Accuracy: 0.00000\n",
      "Test Loss: 1.27422 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.54589 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.50418 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.46344 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.42301 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.38405 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.34615 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.30832 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.27131 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.23629 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.20251 Accuracy: 0.00000\n",
      "Test Loss: 1.20917 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.16924 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.13780 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.10795 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.07964 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.05299 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.02845 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.00545 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.98368 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.96345 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.94477 Accuracy: 0.00000\n",
      "Test Loss: 1.12784 Accuracy: 0.50040\n",
      "Epoch:  60 Batch:   0 Loss: 0.92730 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.91108 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.89613 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.88231 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.86958 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.85786 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.84703 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.83733 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.82832 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.82015 Accuracy: 0.00000\n",
      "Test Loss: 1.06043 Accuracy: 0.50050\n",
      "Epoch:  70 Batch:   0 Loss: 0.81256 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.80558 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.79916 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.79322 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.78780 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.78284 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.77828 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.77407 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.77014 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.76657 Accuracy: 0.00000\n",
      "Test Loss: 1.00015 Accuracy: 0.50060\n",
      "Epoch:  80 Batch:   0 Loss: 0.76332 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.76033 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.75767 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.75527 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.75312 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.74963 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.74820 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.74691 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.74586 Accuracy: 0.00000\n",
      "Test Loss: 0.95119 Accuracy: 0.50070\n",
      "Epoch:  90 Batch:   0 Loss: 0.74493 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.74414 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.74352 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.74306 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.74276 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.74265 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.74267 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.74283 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.74320 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.74361 Accuracy: 0.00000\n",
      "Test Loss: 0.90786 Accuracy: 0.50070\n",
      "Epoch: 100 Batch:   0 Loss: 0.74414 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.74481 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.74556 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.74641 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.74729 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.74820 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.74914 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.75012 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.75109 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.75202 Accuracy: 0.00000\n",
      "Test Loss: 0.86341 Accuracy: 0.50070\n",
      "Epoch: 110 Batch:   0 Loss: 0.75296 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.75388 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.75482 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.75573 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.75662 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.75750 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.75835 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.75916 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.75999 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.76079 Accuracy: 0.00000\n",
      "Test Loss: 0.82525 Accuracy: 0.50080\n",
      "Epoch: 120 Batch:   0 Loss: 0.76162 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.76240 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.76315 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.76388 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.76462 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.76531 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.76606 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.76683 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.76761 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.76840 Accuracy: 0.00000\n",
      "Test Loss: 0.79808 Accuracy: 0.50080\n",
      "Epoch: 130 Batch:   0 Loss: 0.76917 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.76998 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.77084 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.77169 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.77249 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.77331 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.77413 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.77495 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.77577 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.77658 Accuracy: 0.00000\n",
      "Test Loss: 0.77952 Accuracy: 0.50070\n",
      "Epoch: 140 Batch:   0 Loss: 0.77738 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.77819 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.77899 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.77979 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.78062 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.78141 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.78216 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.78290 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.78364 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.78436 Accuracy: 0.00000\n",
      "Test Loss: 0.76561 Accuracy: 0.50070\n",
      "Epoch: 150 Batch:   0 Loss: 0.78508 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.78579 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.78648 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.78713 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.78787 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.78856 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.78925 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.78992 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.79060 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.79125 Accuracy: 0.00000\n",
      "Test Loss: 0.75479 Accuracy: 0.50070\n",
      "Epoch: 160 Batch:   0 Loss: 0.79188 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.79252 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.79315 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.79378 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.79433 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.79486 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.79538 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.79588 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.79638 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.79682 Accuracy: 0.00000\n",
      "Test Loss: 0.74613 Accuracy: 0.50070\n",
      "Epoch: 170 Batch:   0 Loss: 0.79723 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.79758 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.79793 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.79826 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.79858 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.79888 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.79916 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.79941 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.79960 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.79978 Accuracy: 0.00000\n",
      "Test Loss: 0.73913 Accuracy: 0.50070\n",
      "Epoch: 180 Batch:   0 Loss: 0.79994 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.80006 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.80018 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.80022 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.80026 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.80027 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.80028 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.80027 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.80023 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.80021 Accuracy: 0.00000\n",
      "Test Loss: 0.73402 Accuracy: 0.50070\n",
      "Epoch: 190 Batch:   0 Loss: 0.80017 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.80013 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.80006 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.79999 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.79991 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.79984 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.79974 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.79964 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.79953 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.79943 Accuracy: 0.00000\n",
      "Test Loss: 0.73029 Accuracy: 0.50060\n",
      "Epoch: 200 Batch:   0 Loss: 0.79932 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.79923 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.79909 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.79902 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.79893 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.79882 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.79869 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.79856 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.79842 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.79826 Accuracy: 0.00000\n",
      "Test Loss: 0.72751 Accuracy: 0.50060\n",
      "Epoch: 210 Batch:   0 Loss: 0.79810 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.79793 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.79775 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.79760 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.79742 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.79723 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.79704 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.79683 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.79665 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.79640 Accuracy: 0.00000\n",
      "Test Loss: 0.72580 Accuracy: 0.50060\n",
      "Epoch: 220 Batch:   0 Loss: 0.79613 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.79586 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.79557 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.79527 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.79497 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.79469 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.79441 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.79411 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.79385 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.79359 Accuracy: 0.00000\n",
      "Test Loss: 0.72492 Accuracy: 0.50060\n",
      "Epoch: 230 Batch:   0 Loss: 0.79333 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.79306 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.79281 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.79256 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.79231 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.79206 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.79181 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.79158 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.79133 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.79109 Accuracy: 0.00000\n",
      "Test Loss: 0.72477 Accuracy: 0.50060\n",
      "Epoch: 240 Batch:   0 Loss: 0.79086 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.79063 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.79038 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.79013 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.78988 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.78964 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.78940 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.78917 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.78894 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.78868 Accuracy: 0.00000\n",
      "Test Loss: 0.72495 Accuracy: 0.50060\n",
      "Epoch: 250 Batch:   0 Loss: 0.78842 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.78815 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.78789 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.78764 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.78739 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.78714 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.78692 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.78670 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.78647 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.78625 Accuracy: 0.00000\n",
      "Test Loss: 0.72535 Accuracy: 0.50060\n",
      "Epoch: 260 Batch:   0 Loss: 0.78604 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.78582 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.78561 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.78540 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.78523 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.78503 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.78484 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.78464 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.78442 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.78421 Accuracy: 0.00000\n",
      "Test Loss: 0.72595 Accuracy: 0.50060\n",
      "Epoch: 270 Batch:   0 Loss: 0.78399 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.78379 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.78358 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.78336 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.78314 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.78293 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.78271 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.78249 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.78228 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.78207 Accuracy: 0.00000\n",
      "Test Loss: 0.72674 Accuracy: 0.50060\n",
      "Epoch: 280 Batch:   0 Loss: 0.78185 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.78164 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.78143 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.78122 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.78102 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.78082 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.78064 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.78047 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.78030 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.78012 Accuracy: 0.00000\n",
      "Test Loss: 0.72768 Accuracy: 0.50060\n",
      "Epoch: 290 Batch:   0 Loss: 0.77995 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.77977 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.77961 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.77945 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.77928 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.77912 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.77897 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.77883 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.77869 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.77855 Accuracy: 0.00000\n",
      "Test Loss: 0.72884 Accuracy: 0.50060\n",
      "Epoch: 300 Batch:   0 Loss: 0.77842 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.77829 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.77817 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.77806 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.77794 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.77783 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.77773 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.77763 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.77754 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.77746 Accuracy: 0.00000\n",
      "Test Loss: 0.73014 Accuracy: 0.50060\n",
      "Epoch: 310 Batch:   0 Loss: 0.77739 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.77733 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.77727 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.77722 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.77717 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.77711 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.77707 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.77702 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.77698 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.77696 Accuracy: 0.00000\n",
      "Test Loss: 0.73147 Accuracy: 0.50060\n",
      "Epoch: 320 Batch:   0 Loss: 0.77693 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.77692 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.77691 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.77689 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.77688 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.77690 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.77692 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.77693 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.77696 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.77699 Accuracy: 0.00000\n",
      "Test Loss: 0.73283 Accuracy: 0.50060\n",
      "Epoch: 330 Batch:   0 Loss: 0.77703 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.77709 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.77714 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.77720 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.77727 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.77734 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.77742 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.77751 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.77761 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.77771 Accuracy: 0.00000\n",
      "Test Loss: 0.73373 Accuracy: 0.50060\n",
      "Epoch: 340 Batch:   0 Loss: 0.77779 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.77786 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.77792 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.77799 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.77802 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.77802 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.77801 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.77797 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.77793 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.77786 Accuracy: 0.00000\n",
      "Test Loss: 0.73317 Accuracy: 0.50060\n",
      "Epoch: 350 Batch:   0 Loss: 0.77777 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.77767 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.77755 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.77742 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.77729 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.77713 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.77698 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.77682 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.77664 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.77646 Accuracy: 0.00000\n",
      "Test Loss: 0.73153 Accuracy: 0.50060\n",
      "Epoch: 360 Batch:   0 Loss: 0.77626 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.77606 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.77586 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.77564 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.77542 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.77520 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.77501 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.77482 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.77463 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.77446 Accuracy: 0.00000\n",
      "Test Loss: 0.72999 Accuracy: 0.50060\n",
      "Epoch: 370 Batch:   0 Loss: 0.77431 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.77419 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.77410 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.77403 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.77399 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.77398 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.77401 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.77407 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.77416 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.77428 Accuracy: 0.00000\n",
      "Test Loss: 0.72912 Accuracy: 0.50060\n",
      "Epoch: 380 Batch:   0 Loss: 0.77438 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.77447 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.77452 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.77451 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.77443 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.77430 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.77414 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.77394 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.77373 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.77351 Accuracy: 0.00000\n",
      "Test Loss: 0.72790 Accuracy: 0.50050\n",
      "Epoch: 390 Batch:   0 Loss: 0.77331 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.77314 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.77299 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.77289 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.77286 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.77289 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.77299 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.77320 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.77343 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.77362 Accuracy: 0.00000\n",
      "Test Loss: 0.72877 Accuracy: 0.50040\n",
      "Epoch: 400 Batch:   0 Loss: 0.77374 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.77373 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.77358 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.77329 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.77289 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.77238 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.77181 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.77121 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.77060 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.76999 Accuracy: 0.00000\n",
      "Test Loss: 0.72805 Accuracy: 0.50040\n",
      "Epoch: 410 Batch:   0 Loss: 0.76940 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.76882 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.76827 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.76774 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.76723 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.76674 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.76628 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.76585 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.76542 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.76501 Accuracy: 0.00000\n",
      "Test Loss: 0.72882 Accuracy: 0.50040\n",
      "Epoch: 420 Batch:   0 Loss: 0.76463 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.76426 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.76393 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.76359 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.76328 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.76298 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.76269 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.76243 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.76218 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.76194 Accuracy: 0.00000\n",
      "Test Loss: 0.73069 Accuracy: 0.50040\n",
      "Epoch: 430 Batch:   0 Loss: 0.76173 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.76151 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.76130 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.76110 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.76091 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.76073 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.76056 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.76039 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.76022 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.76007 Accuracy: 0.00000\n",
      "Test Loss: 0.73294 Accuracy: 0.50040\n",
      "Epoch: 440 Batch:   0 Loss: 0.75992 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.75978 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.75964 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.75951 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.75939 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.75927 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.75915 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.75904 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.75892 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.75882 Accuracy: 0.00000\n",
      "Test Loss: 0.73536 Accuracy: 0.50040\n",
      "Epoch: 450 Batch:   0 Loss: 0.75871 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.75861 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.75851 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.75842 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.75832 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.75824 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.75815 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.75807 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.75798 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.75790 Accuracy: 0.00000\n",
      "Test Loss: 0.73775 Accuracy: 0.50040\n",
      "Epoch: 460 Batch:   0 Loss: 0.75781 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.75773 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.75766 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.75758 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.75751 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.75744 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.75737 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.75731 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.75724 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.75718 Accuracy: 0.00000\n",
      "Test Loss: 0.74020 Accuracy: 0.50040\n",
      "Epoch: 470 Batch:   0 Loss: 0.75711 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.75705 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.75699 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.75693 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.75687 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.75681 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.75676 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.75671 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:16:44,997] Trial 8 finished with value: 0.5002010454362686 and parameters: {'REG_W': 3.817346363815336e-06, 'REG_B': 0.0010276432618562658, 'REG_Z': 3.062080140298306e-05, 'SPAR_W': 0.5598304338719655, 'SPAR_B': 0.7150516014943187, 'SPAR_Z': 0.5354972341993837, 'LEARNING_RATE': 0.0006150948015361265, 'NUM_EPOCHS': 478}. Best is trial 5 with value: 0.6766184157619622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 1.57460 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 3.76517 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 3.55688 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 3.44636 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 3.35841 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 3.27620 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 3.19699 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 3.11884 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 3.03908 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 2.95463 Accuracy: 0.00000\n",
      "Test Loss: 1.69742 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 2.86491 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 2.76644 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.66131 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.54549 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.42377 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.29167 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.15594 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.01169 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.86998 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.73291 Accuracy: 0.00000\n",
      "Test Loss: 1.51524 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.60377 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.48228 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.37271 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.27697 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.19298 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.12041 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.05721 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.00374 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 0.95779 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 0.91906 Accuracy: 0.00000\n",
      "Test Loss: 1.23043 Accuracy: 0.50060\n",
      "Epoch:  30 Batch:   0 Loss: 0.88613 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 0.85888 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 0.83635 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.81850 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.80373 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.79200 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.78231 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.77441 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.76807 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.76309 Accuracy: 0.00000\n",
      "Test Loss: 0.99178 Accuracy: 0.50070\n",
      "Epoch:  40 Batch:   0 Loss: 0.75963 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.75741 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.75640 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.75668 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.75785 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.75994 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.76243 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.76496 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.76743 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.76997 Accuracy: 0.00000\n",
      "Test Loss: 0.88713 Accuracy: 0.50070\n",
      "Epoch:  50 Batch:   0 Loss: 0.77253 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.77475 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.77689 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.77881 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.78064 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.78231 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.78392 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.78540 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.78688 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.78838 Accuracy: 0.00000\n",
      "Test Loss: 0.83064 Accuracy: 0.50070\n",
      "Epoch:  60 Batch:   0 Loss: 0.78984 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.79124 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.79273 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.79422 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.79564 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.79697 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.79826 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.79948 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.80049 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.80144 Accuracy: 0.00000\n",
      "Test Loss: 0.80249 Accuracy: 0.50060\n",
      "Epoch:  70 Batch:   0 Loss: 0.80219 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.80285 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.80337 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.80375 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.80404 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.80426 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.80452 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.80472 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.80485 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.80498 Accuracy: 0.00000\n",
      "Test Loss: 0.78469 Accuracy: 0.50060\n",
      "Epoch:  80 Batch:   0 Loss: 0.80512 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.80522 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.80527 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.80539 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.80548 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.80560 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.80571 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.80574 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.80582 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.80589 Accuracy: 0.00000\n",
      "Test Loss: 0.77570 Accuracy: 0.50070\n",
      "Epoch:  90 Batch:   0 Loss: 0.80592 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.80597 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.80605 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.80617 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.80628 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.80640 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.80649 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.80661 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.80673 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.80692 Accuracy: 0.00000\n",
      "Test Loss: 0.77093 Accuracy: 0.50070\n",
      "Epoch: 100 Batch:   0 Loss: 0.80709 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.80729 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.80749 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.80773 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.80799 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.80824 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.80857 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.80894 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.80952 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.81021 Accuracy: 0.00000\n",
      "Test Loss: 0.76765 Accuracy: 0.50070\n",
      "Epoch: 110 Batch:   0 Loss: 0.81095 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.81176 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.81253 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.81310 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.81335 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.81322 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.81281 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.81231 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.81172 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.81111 Accuracy: 0.00000\n",
      "Test Loss: 0.76198 Accuracy: 0.50070\n",
      "Epoch: 120 Batch:   0 Loss: 0.81059 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.81011 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.80969 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.80938 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.80906 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.80873 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.80840 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.80800 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.80758 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.80721 Accuracy: 0.00000\n",
      "Test Loss: 0.75800 Accuracy: 0.50090\n",
      "Epoch: 130 Batch:   0 Loss: 0.80685 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.80664 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.80656 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.80664 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.80670 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.80671 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.80652 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.80590 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.80485 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.80330 Accuracy: 0.00000\n",
      "Test Loss: 0.75500 Accuracy: 0.50080\n",
      "Epoch: 140 Batch:   0 Loss: 0.80149 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.79965 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.79779 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.79596 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.79424 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.79264 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.79118 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.78981 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.78857 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.78739 Accuracy: 0.00000\n",
      "Test Loss: 0.75415 Accuracy: 0.50080\n",
      "Epoch: 150 Batch:   0 Loss: 0.78631 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.78528 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.78434 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.78350 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.78268 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.78193 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.78123 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.78058 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.77998 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.77941 Accuracy: 0.00000\n",
      "Test Loss: 0.75594 Accuracy: 0.50080\n",
      "Epoch: 160 Batch:   0 Loss: 0.77887 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.77837 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.77791 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.77746 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.77705 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.77663 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.77626 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.77587 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.77551 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.77520 Accuracy: 0.00000\n",
      "Test Loss: 0.75817 Accuracy: 0.50080\n",
      "Epoch: 170 Batch:   0 Loss: 0.77485 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.77454 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.77424 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.77396 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.77368 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.77342 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.77317 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.77292 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.77269 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.77245 Accuracy: 0.00000\n",
      "Test Loss: 0.76045 Accuracy: 0.50080\n",
      "Epoch: 180 Batch:   0 Loss: 0.77222 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.77201 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.77180 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.77160 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.77142 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.77123 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.77106 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.77088 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.77068 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.77049 Accuracy: 0.00000\n",
      "Test Loss: 0.76276 Accuracy: 0.50080\n",
      "Epoch: 190 Batch:   0 Loss: 0.77032 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.77014 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.76998 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.76982 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.76966 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.76950 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.76935 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.76920 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.76905 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.76891 Accuracy: 0.00000\n",
      "Test Loss: 0.76516 Accuracy: 0.50070\n",
      "Epoch: 200 Batch:   0 Loss: 0.76877 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.76863 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.76848 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.76834 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.76820 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.76808 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.76794 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.76780 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.76766 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.76752 Accuracy: 0.00000\n",
      "Test Loss: 0.76752 Accuracy: 0.50070\n",
      "Epoch: 210 Batch:   0 Loss: 0.76739 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.76726 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.76713 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.76701 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.76690 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.76680 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.76668 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.76657 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.76646 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.76636 Accuracy: 0.00000\n",
      "Test Loss: 0.76983 Accuracy: 0.50070\n",
      "Epoch: 220 Batch:   0 Loss: 0.76626 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.76616 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.76606 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.76596 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.76587 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.76578 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.76570 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.76561 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.76552 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.76544 Accuracy: 0.00000\n",
      "Test Loss: 0.77213 Accuracy: 0.50070\n",
      "Epoch: 230 Batch:   0 Loss: 0.76536 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.76529 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.76521 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.76514 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.76506 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.76500 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.76493 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.76486 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.76480 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.76473 Accuracy: 0.00000\n",
      "Test Loss: 0.77444 Accuracy: 0.50070\n",
      "Epoch: 240 Batch:   0 Loss: 0.76467 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.76461 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.76455 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.76450 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.76444 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.76439 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.76433 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.76428 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.76423 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.76418 Accuracy: 0.00000\n",
      "Test Loss: 0.77664 Accuracy: 0.50060\n",
      "Epoch: 250 Batch:   0 Loss: 0.76413 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.76410 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.76404 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.76399 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.76393 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.76388 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.76383 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.76378 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.76373 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.76368 Accuracy: 0.00000\n",
      "Test Loss: 0.77880 Accuracy: 0.50060\n",
      "Epoch: 260 Batch:   0 Loss: 0.76364 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.76358 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.76355 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.76352 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.76349 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.76346 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.76343 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.76342 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.76339 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.76337 Accuracy: 0.00000\n",
      "Test Loss: 0.78107 Accuracy: 0.50060\n",
      "Epoch: 270 Batch:   0 Loss: 0.76336 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.76333 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.76330 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.76328 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.76325 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.76323 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.76321 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.76319 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.76317 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.76314 Accuracy: 0.00000\n",
      "Test Loss: 0.78317 Accuracy: 0.50060\n",
      "Epoch: 280 Batch:   0 Loss: 0.76312 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.76310 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.76308 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.76306 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.76304 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.76302 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.76300 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.76298 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.76295 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.76292 Accuracy: 0.00000\n",
      "Test Loss: 0.78517 Accuracy: 0.50060\n",
      "Epoch: 290 Batch:   0 Loss: 0.76291 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.76289 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.76288 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.76286 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.76285 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.76284 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.76282 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.76281 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.76279 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.76278 Accuracy: 0.00000\n",
      "Test Loss: 0.78717 Accuracy: 0.50060\n",
      "Epoch: 300 Batch:   0 Loss: 0.76276 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.76276 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.76275 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.76273 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.76272 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.76271 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.76269 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.76268 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.76266 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.76266 Accuracy: 0.00000\n",
      "Test Loss: 0.78947 Accuracy: 0.50060\n",
      "Epoch: 310 Batch:   0 Loss: 0.76267 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.76265 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.76264 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.76266 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.76263 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.76262 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.76261 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.76260 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.76260 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.76260 Accuracy: 0.00000\n",
      "Test Loss: 0.79126 Accuracy: 0.50060\n",
      "Epoch: 320 Batch:   0 Loss: 0.76260 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.76259 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.76259 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.76258 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.76257 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.76256 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.76256 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.76255 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.76253 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.76252 Accuracy: 0.00000\n",
      "Test Loss: 0.79314 Accuracy: 0.50060\n",
      "Epoch: 330 Batch:   0 Loss: 0.76251 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.76249 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.76249 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.76247 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.76246 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.76244 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.76243 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.76242 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.76241 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.76241 Accuracy: 0.00000\n",
      "Test Loss: 0.79521 Accuracy: 0.50060\n",
      "Epoch: 340 Batch:   0 Loss: 0.76241 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.76240 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.76238 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.76237 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.76237 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.76236 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.76235 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.76233 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.76232 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.76230 Accuracy: 0.00000\n",
      "Test Loss: 0.79692 Accuracy: 0.50060\n",
      "Epoch: 350 Batch:   0 Loss: 0.76229 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.76228 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.76227 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.76226 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.76225 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.76224 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.76223 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.76222 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.76222 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.76221 Accuracy: 0.00000\n",
      "Test Loss: 0.79872 Accuracy: 0.50060\n",
      "Epoch: 360 Batch:   0 Loss: 0.76221 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.76220 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.76219 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.76219 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.76218 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.76217 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.76216 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.76216 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.76215 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.76215 Accuracy: 0.00000\n",
      "Test Loss: 0.80039 Accuracy: 0.50060\n",
      "Epoch: 370 Batch:   0 Loss: 0.76214 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.76214 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.76213 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.76213 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.76212 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.76212 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.76211 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.76210 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.76209 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.76208 Accuracy: 0.00000\n",
      "Test Loss: 0.80200 Accuracy: 0.50050\n",
      "Epoch: 380 Batch:   0 Loss: 0.76207 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.76206 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.76205 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.76205 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.76204 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.76203 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.76203 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.76202 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.76202 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.76201 Accuracy: 0.00000\n",
      "Test Loss: 0.80359 Accuracy: 0.50060\n",
      "Epoch: 390 Batch:   0 Loss: 0.76200 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.76200 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.76199 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.76199 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.76198 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.76198 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.76198 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.76197 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.76197 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.76197 Accuracy: 0.00000\n",
      "Test Loss: 0.80513 Accuracy: 0.50060\n",
      "Epoch: 400 Batch:   0 Loss: 0.76196 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.76196 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.76195 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.76195 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.76195 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.76195 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.76194 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.76194 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.76194 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.76194 Accuracy: 0.00000\n",
      "Test Loss: 0.80654 Accuracy: 0.50060\n",
      "Epoch: 410 Batch:   0 Loss: 0.76194 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.76193 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.76193 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.76193 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.76192 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.76192 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.76191 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.76191 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Test Loss: 0.80796 Accuracy: 0.50060\n",
      "Epoch: 420 Batch:   0 Loss: 0.76191 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.76189 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.76189 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.76188 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.76188 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.76187 Accuracy: 0.00000\n",
      "Test Loss: 0.80943 Accuracy: 0.50060\n",
      "Epoch: 430 Batch:   0 Loss: 0.76186 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.76185 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.76184 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.76183 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.76182 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.76182 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.76181 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.76180 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.76180 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.76179 Accuracy: 0.00000\n",
      "Test Loss: 0.81085 Accuracy: 0.50060\n",
      "Epoch: 440 Batch:   0 Loss: 0.76178 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.76177 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.76177 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.76176 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.76175 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.76175 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.76174 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.76173 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.76172 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.76172 Accuracy: 0.00000\n",
      "Test Loss: 0.81218 Accuracy: 0.50060\n",
      "Epoch: 450 Batch:   0 Loss: 0.76171 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.76170 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.76170 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.76169 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.76169 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.76168 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.76167 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.76167 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.76166 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.76166 Accuracy: 0.00000\n",
      "Test Loss: 0.81341 Accuracy: 0.50060\n",
      "Epoch: 460 Batch:   0 Loss: 0.76165 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.76165 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.76164 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.76164 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.76163 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.76163 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.76162 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.76162 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.76162 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.76161 Accuracy: 0.00000\n",
      "Test Loss: 0.81458 Accuracy: 0.50060\n",
      "Epoch: 470 Batch:   0 Loss: 0.76160 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.76159 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.76159 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.76158 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.76157 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.76157 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.76156 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.76156 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.76156 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.76155 Accuracy: 0.00000\n",
      "Test Loss: 0.81571 Accuracy: 0.50060\n",
      "Epoch: 480 Batch:   0 Loss: 0.76154 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.76154 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.76153 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.76153 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.76153 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.76152 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.76152 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.76152 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.76152 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.76151 Accuracy: 0.00000\n",
      "Test Loss: 0.81678 Accuracy: 0.50060\n",
      "Epoch: 490 Batch:   0 Loss: 0.76151 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.76150 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.76150 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.76150 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.76149 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.76149 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.76149 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.76148 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.76148 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.76148 Accuracy: 0.00000\n",
      "Test Loss: 0.81776 Accuracy: 0.50060\n",
      "Epoch: 500 Batch:   0 Loss: 0.76148 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.76147 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.76147 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.76147 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.76147 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.76147 Accuracy: 0.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.76146 Accuracy: 0.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.76146 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.76146 Accuracy: 0.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.76146 Accuracy: 0.00000\n",
      "Test Loss: 0.81865 Accuracy: 0.50060\n",
      "Epoch: 510 Batch:   0 Loss: 0.76145 Accuracy: 0.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.76144 Accuracy: 0.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.76144 Accuracy: 0.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.76144 Accuracy: 0.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.76143 Accuracy: 0.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.76143 Accuracy: 0.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.76143 Accuracy: 0.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.76143 Accuracy: 0.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Test Loss: 0.81949 Accuracy: 0.50060\n",
      "Epoch: 520 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.76142 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.76141 Accuracy: 0.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.76141 Accuracy: 0.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Test Loss: 0.82015 Accuracy: 0.50060\n",
      "Epoch: 530 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.76140 Accuracy: 0.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.76139 Accuracy: 0.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.76139 Accuracy: 0.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.76139 Accuracy: 0.00000\n",
      "Test Loss: 0.82083 Accuracy: 0.50060\n",
      "Epoch: 540 Batch:   0 Loss: 0.76139 Accuracy: 0.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.76139 Accuracy: 0.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.76139 Accuracy: 0.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.76138 Accuracy: 0.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.76138 Accuracy: 0.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.76138 Accuracy: 0.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.76137 Accuracy: 0.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.76137 Accuracy: 0.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.76137 Accuracy: 0.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.76136 Accuracy: 0.00000\n",
      "Test Loss: 0.82136 Accuracy: 0.50060\n",
      "Epoch: 550 Batch:   0 Loss: 0.76136 Accuracy: 0.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.76135 Accuracy: 0.00000\n",
      "Epoch: 552 Batch:   0 Loss: 0.76135 Accuracy: 0.00000\n",
      "Epoch: 553 Batch:   0 Loss: 0.76134 Accuracy: 0.00000\n",
      "Epoch: 554 Batch:   0 Loss: 0.76134 Accuracy: 0.00000\n",
      "Epoch: 555 Batch:   0 Loss: 0.76134 Accuracy: 0.00000\n",
      "Epoch: 556 Batch:   0 Loss: 0.76133 Accuracy: 0.00000\n",
      "Epoch: 557 Batch:   0 Loss: 0.76133 Accuracy: 0.00000\n",
      "Epoch: 558 Batch:   0 Loss: 0.76133 Accuracy: 0.00000\n",
      "Epoch: 559 Batch:   0 Loss: 0.76133 Accuracy: 0.00000\n",
      "Test Loss: 0.82182 Accuracy: 0.50060\n",
      "Epoch: 560 Batch:   0 Loss: 0.76132 Accuracy: 0.00000\n",
      "Epoch: 561 Batch:   0 Loss: 0.76132 Accuracy: 0.00000\n",
      "Epoch: 562 Batch:   0 Loss: 0.76132 Accuracy: 0.00000\n",
      "Epoch: 563 Batch:   0 Loss: 0.76132 Accuracy: 0.00000\n",
      "Epoch: 564 Batch:   0 Loss: 0.76132 Accuracy: 0.00000\n",
      "Epoch: 565 Batch:   0 Loss: 0.76131 Accuracy: 0.00000\n",
      "Epoch: 566 Batch:   0 Loss: 0.76131 Accuracy: 0.00000\n",
      "Epoch: 567 Batch:   0 Loss: 0.76130 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:22:49,477] Trial 9 finished with value: 0.5004020908725372 and parameters: {'REG_W': 4.868350288107119e-06, 'REG_B': 0.007451850465311245, 'REG_Z': 4.6738002974418115e-05, 'SPAR_W': 0.8302334538032026, 'SPAR_B': 0.9143803036852067, 'SPAR_Z': 0.8810790109315592, 'LEARNING_RATE': 0.0009517824797391942, 'NUM_EPOCHS': 568}. Best is trial 5 with value: 0.6766184157619622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 2.89099 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.90194 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.53739 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.35860 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.27392 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.23346 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.21331 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.20234 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.19542 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.19026 Accuracy: 0.00000\n",
      "Test Loss: 0.77289 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.18588 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.18190 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.17812 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.17456 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.17114 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.16797 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.16497 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.16215 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.15954 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.15714 Accuracy: 0.00000\n",
      "Test Loss: 0.74152 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.15496 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.15302 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.15127 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.14977 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.14849 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.14742 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.14660 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.14600 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.14567 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.14559 Accuracy: 0.00000\n",
      "Test Loss: 0.73141 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.14576 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.14620 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.14691 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.14791 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.14913 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.15060 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.15233 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.15430 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.15652 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.15897 Accuracy: 0.00000\n",
      "Test Loss: 0.72859 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.16164 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.16452 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.16759 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.17084 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.17426 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.17784 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.18154 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.18536 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.18928 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.19325 Accuracy: 0.00000\n",
      "Test Loss: 0.72656 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.19729 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.20132 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.20536 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.20936 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.21330 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.21716 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.22095 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.22463 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.22818 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.23158 Accuracy: 0.00000\n",
      "Test Loss: 0.72257 Accuracy: 0.50020\n",
      "Epoch:  60 Batch:   0 Loss: 1.23483 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.23790 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.24078 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.24347 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 1.24596 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 1.24823 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 1.25029 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 1.25212 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 1.25372 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 1.25509 Accuracy: 0.00000\n",
      "Test Loss: 0.71638 Accuracy: 0.50020\n",
      "Epoch:  70 Batch:   0 Loss: 1.25624 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 1.25717 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 1.25788 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 1.25837 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 1.25866 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 1.25874 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 1.25860 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 1.25825 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 1.25770 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 1.25696 Accuracy: 0.00000\n",
      "Test Loss: 0.70940 Accuracy: 0.50020\n",
      "Epoch:  80 Batch:   0 Loss: 1.25604 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 1.25493 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 1.25365 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 1.25219 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 1.25060 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 1.24884 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 1.24693 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 1.24489 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 1.24270 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 1.24037 Accuracy: 0.00000\n",
      "Test Loss: 0.70289 Accuracy: 0.50030\n",
      "Epoch:  90 Batch:   0 Loss: 1.23793 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 1.23536 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 1.23270 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 1.22994 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 1.22708 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 1.22414 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 1.22112 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 1.21800 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 1.21481 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 1.21156 Accuracy: 0.00000\n",
      "Test Loss: 0.69735 Accuracy: 0.50030\n",
      "Epoch: 100 Batch:   0 Loss: 1.20824 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 1.20485 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 1.20142 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 1.19792 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 1.19438 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 1.19081 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 1.18720 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 1.18355 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 1.17989 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 1.17618 Accuracy: 0.00000\n",
      "Test Loss: 0.69280 Accuracy: 0.50030\n",
      "Epoch: 110 Batch:   0 Loss: 1.17246 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 1.16872 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 1.16495 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 1.16118 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 1.15739 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 1.15360 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 1.14979 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 1.14598 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 1.14217 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 1.13836 Accuracy: 0.00000\n",
      "Test Loss: 0.68904 Accuracy: 0.50030\n",
      "Epoch: 120 Batch:   0 Loss: 1.13455 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 1.13073 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 1.12694 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 1.12315 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 1.11936 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 1.11558 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 1.11180 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 1.10804 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 1.10430 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 1.10056 Accuracy: 0.00000\n",
      "Test Loss: 0.68589 Accuracy: 0.50030\n",
      "Epoch: 130 Batch:   0 Loss: 1.09685 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 1.09315 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 1.08947 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 1.08580 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 1.08215 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 1.07853 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 1.07491 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 1.07132 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 1.06775 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 1.06420 Accuracy: 0.00000\n",
      "Test Loss: 0.68318 Accuracy: 0.50030\n",
      "Epoch: 140 Batch:   0 Loss: 1.06067 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 1.05719 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 1.05370 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 1.05025 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 1.04682 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 1.04341 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 1.04004 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 1.03668 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 1.03335 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 1.03005 Accuracy: 0.00000\n",
      "Test Loss: 0.68085 Accuracy: 0.50030\n",
      "Epoch: 150 Batch:   0 Loss: 1.02677 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 1.02352 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 1.02028 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 1.01708 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 1.01390 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 1.01075 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 1.00763 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 1.00455 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 1.00150 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.99847 Accuracy: 0.00000\n",
      "Test Loss: 0.67880 Accuracy: 0.50030\n",
      "Epoch: 160 Batch:   0 Loss: 0.99547 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.99251 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.98957 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.98666 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.98378 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.98093 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.97811 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.97532 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.97256 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.96982 Accuracy: 0.00000\n",
      "Test Loss: 0.67693 Accuracy: 0.50030\n",
      "Epoch: 170 Batch:   0 Loss: 0.96713 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.96445 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.96181 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.95919 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.95660 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.95405 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.95152 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.94903 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.94656 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.94412 Accuracy: 0.00000\n",
      "Test Loss: 0.67518 Accuracy: 0.50040\n",
      "Epoch: 180 Batch:   0 Loss: 0.94172 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.93934 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.93699 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.93467 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.93238 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.93012 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.92788 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.92568 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.92350 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.92136 Accuracy: 0.00000\n",
      "Test Loss: 0.67350 Accuracy: 0.50040\n",
      "Epoch: 190 Batch:   0 Loss: 0.91924 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.91714 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.91508 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.91304 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.91102 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.90903 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.90707 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.90514 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.90323 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.90135 Accuracy: 0.00000\n",
      "Test Loss: 0.67186 Accuracy: 0.50040\n",
      "Epoch: 200 Batch:   0 Loss: 0.89949 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.89766 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.89585 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.89406 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.89230 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.89057 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.88886 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.88717 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.88551 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.88387 Accuracy: 0.00000\n",
      "Test Loss: 0.67025 Accuracy: 0.50040\n",
      "Epoch: 210 Batch:   0 Loss: 0.88225 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.88066 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.87908 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.87753 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.87600 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.87448 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.87300 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.87153 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.87008 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.86865 Accuracy: 0.00000\n",
      "Test Loss: 0.66865 Accuracy: 0.50050\n",
      "Epoch: 220 Batch:   0 Loss: 0.86724 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.86585 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.86448 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.86313 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:24:49,189] Trial 10 finished with value: 0.5003015681544029 and parameters: {'REG_W': 3.2622571574382e-06, 'REG_B': 0.003250951059039567, 'REG_Z': 2.1267256299300327e-05, 'SPAR_W': 0.9975001651887614, 'SPAR_B': 0.7955717878438994, 'SPAR_Z': 0.6933435937087871, 'LEARNING_RATE': 0.00011841834233424083, 'NUM_EPOCHS': 224}. Best is trial 5 with value: 0.6766184157619622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.09468 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.57375 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.47806 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.43629 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.42412 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.42447 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.42894 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.43386 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.43780 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.44045 Accuracy: 0.00000\n",
      "Test Loss: 0.84859 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.44187 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.44230 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.44205 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.44128 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.44024 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.43898 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.43757 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.43608 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.43450 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.43285 Accuracy: 0.00000\n",
      "Test Loss: 0.83673 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.43110 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.42930 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.42742 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.42544 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.42336 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.42119 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.41892 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.41654 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.41407 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.41150 Accuracy: 0.00000\n",
      "Test Loss: 0.82748 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.40884 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.40608 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.40322 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.40026 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.39719 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.39397 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.39074 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.38741 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.38409 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.38063 Accuracy: 0.00000\n",
      "Test Loss: 0.81926 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.37710 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.37361 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.36995 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.36639 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.36276 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.35910 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.35530 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.35148 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.34767 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.34379 Accuracy: 0.00000\n",
      "Test Loss: 0.81315 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.33989 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.33599 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.33205 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.32808 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.32417 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.32019 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.31599 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.31188 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.30785 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.30373 Accuracy: 0.00000\n",
      "Test Loss: 0.80850 Accuracy: 0.50020\n",
      "Epoch:  60 Batch:   0 Loss: 1.29959 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.29540 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.29119 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.28701 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 1.28298 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 1.27892 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 1.27485 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 1.27072 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 1.26656 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 1.26242 Accuracy: 0.00000\n",
      "Test Loss: 0.80355 Accuracy: 0.50020\n",
      "Epoch:  70 Batch:   0 Loss: 1.25824 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 1.25409 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 1.25001 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 1.24589 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 1.24188 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 1.23791 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 1.23404 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 1.23016 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 1.22641 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 1.22267 Accuracy: 0.00000\n",
      "Test Loss: 0.79740 Accuracy: 0.50020\n",
      "Epoch:  80 Batch:   0 Loss: 1.21893 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 1.21522 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 1.21165 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 1.20813 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 1.20475 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 1.20153 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 1.19823 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 1.19519 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 1.19232 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 1.18965 Accuracy: 0.00000\n",
      "Test Loss: 0.78729 Accuracy: 0.50020\n",
      "Epoch:  90 Batch:   0 Loss: 1.18708 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 1.18462 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 1.18233 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 1.17999 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 1.17786 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 1.17583 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 1.17385 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 1.17202 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 1.17042 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 1.16905 Accuracy: 0.00000\n",
      "Test Loss: 0.77180 Accuracy: 0.50020\n",
      "Epoch: 100 Batch:   0 Loss: 1.16771 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 1.16644 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 1.16532 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 1.16421 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 1.16328 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 1.16240 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 1.16151 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 1.16061 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 1.15957 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 1.15859 Accuracy: 0.00000\n",
      "Test Loss: 0.75394 Accuracy: 0.50020\n",
      "Epoch: 110 Batch:   0 Loss: 1.15751 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 1.15647 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 1.15534 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 1.15402 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 1.15267 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 1.15131 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 1.14995 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 1.14840 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 1.14667 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 1.14477 Accuracy: 0.00000\n",
      "Test Loss: 0.73864 Accuracy: 0.50030\n",
      "Epoch: 120 Batch:   0 Loss: 1.14260 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 1.14038 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 1.13814 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 1.13567 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 1.13304 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 1.13022 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 1.12721 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 1.12405 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 1.12074 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 1.11730 Accuracy: 0.00000\n",
      "Test Loss: 0.72679 Accuracy: 0.50030\n",
      "Epoch: 130 Batch:   0 Loss: 1.11372 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 1.11005 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 1.10621 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 1.10220 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 1.09808 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 1.09383 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 1.08964 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 1.08536 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 1.08099 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 1.07672 Accuracy: 0.00000\n",
      "Test Loss: 0.71757 Accuracy: 0.50030\n",
      "Epoch: 140 Batch:   0 Loss: 1.07214 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 1.06757 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 1.06298 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 1.05844 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 1.05388 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 1.04932 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 1.04479 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 1.04025 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 1.03579 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 1.03136 Accuracy: 0.00000\n",
      "Test Loss: 0.71039 Accuracy: 0.50030\n",
      "Epoch: 150 Batch:   0 Loss: 1.02696 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 1.02260 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 1.01820 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 1.01380 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 1.00951 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 1.00526 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 1.00102 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.99697 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.99290 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.98889 Accuracy: 0.00000\n",
      "Test Loss: 0.70462 Accuracy: 0.50030\n",
      "Epoch: 160 Batch:   0 Loss: 0.98492 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.98100 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.97715 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.97338 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.96968 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.96604 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.96247 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.95894 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.95551 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.95213 Accuracy: 0.00000\n",
      "Test Loss: 0.69975 Accuracy: 0.50040\n",
      "Epoch: 170 Batch:   0 Loss: 0.94889 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.94565 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.94248 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.93921 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.93607 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.93298 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.92996 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.92703 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.92412 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.92127 Accuracy: 0.00000\n",
      "Test Loss: 0.69559 Accuracy: 0.50040\n",
      "Epoch: 180 Batch:   0 Loss: 0.91849 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.91576 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.91311 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.91051 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.90795 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.90539 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.90293 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.90054 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.89818 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.89585 Accuracy: 0.00000\n",
      "Test Loss: 0.69179 Accuracy: 0.50040\n",
      "Epoch: 190 Batch:   0 Loss: 0.89356 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.89129 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.88908 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.88691 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.88478 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.88268 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.88063 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.87862 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.87668 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.87477 Accuracy: 0.00000\n",
      "Test Loss: 0.68827 Accuracy: 0.50040\n",
      "Epoch: 200 Batch:   0 Loss: 0.87290 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.87107 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.86927 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.86746 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.86568 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.86395 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.86226 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.86059 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.85894 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.85733 Accuracy: 0.00000\n",
      "Test Loss: 0.68503 Accuracy: 0.50040\n",
      "Epoch: 210 Batch:   0 Loss: 0.85575 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.85420 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.85267 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.85117 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.84970 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.84825 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.84682 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.84542 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.84405 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.84269 Accuracy: 0.00000\n",
      "Test Loss: 0.68203 Accuracy: 0.50040\n",
      "Epoch: 220 Batch:   0 Loss: 0.84136 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.84004 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.83873 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.83743 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.83616 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.83487 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.83363 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.83242 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.83122 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.83004 Accuracy: 0.00000\n",
      "Test Loss: 0.67930 Accuracy: 0.50040\n",
      "Epoch: 230 Batch:   0 Loss: 0.82887 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.82771 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.82658 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.82544 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.82433 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.82323 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.82216 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.82110 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.82006 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.81903 Accuracy: 0.00000\n",
      "Test Loss: 0.67675 Accuracy: 0.50040\n",
      "Epoch: 240 Batch:   0 Loss: 0.81800 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.81699 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.81599 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.81503 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.81406 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.81311 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.81218 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.81126 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.81036 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.80947 Accuracy: 0.00000\n",
      "Test Loss: 0.67432 Accuracy: 0.50040\n",
      "Epoch: 250 Batch:   0 Loss: 0.80860 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.80774 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.80688 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.80604 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.80522 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.80440 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.80361 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.80282 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.80205 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.80129 Accuracy: 0.00000\n",
      "Test Loss: 0.67201 Accuracy: 0.50040\n",
      "Epoch: 260 Batch:   0 Loss: 0.80053 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.79980 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.79908 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.79837 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.79767 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.79698 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.79632 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.79566 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.79500 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.79435 Accuracy: 0.00000\n",
      "Test Loss: 0.66985 Accuracy: 0.50040\n",
      "Epoch: 270 Batch:   0 Loss: 0.79371 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.79309 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.79246 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.79185 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.79125 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.79066 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.79008 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.78951 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.78895 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.78839 Accuracy: 0.00000\n",
      "Test Loss: 0.66779 Accuracy: 0.50040\n",
      "Epoch: 280 Batch:   0 Loss: 0.78785 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.78732 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.78679 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.78627 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.78575 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.78525 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.78475 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.78426 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.78377 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.78330 Accuracy: 0.00000\n",
      "Test Loss: 0.66586 Accuracy: 0.50040\n",
      "Epoch: 290 Batch:   0 Loss: 0.78282 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.78235 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.78189 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.78143 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.78099 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.78055 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.78012 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.77969 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.77927 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.77886 Accuracy: 0.00000\n",
      "Test Loss: 0.66402 Accuracy: 0.50040\n",
      "Epoch: 300 Batch:   0 Loss: 0.77845 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.77804 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.77765 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.77726 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.77688 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.77650 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.77613 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.77576 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.77540 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.77504 Accuracy: 0.00000\n",
      "Test Loss: 0.66231 Accuracy: 0.50040\n",
      "Epoch: 310 Batch:   0 Loss: 0.77469 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.77435 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.77401 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.77367 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.77334 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.77301 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.77268 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.77237 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.77206 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.77175 Accuracy: 0.00000\n",
      "Test Loss: 0.66072 Accuracy: 0.50040\n",
      "Epoch: 320 Batch:   0 Loss: 0.77144 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.77114 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.77086 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.77058 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.77030 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.77003 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.76976 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.76950 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.76923 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.76898 Accuracy: 0.00000\n",
      "Test Loss: 0.65924 Accuracy: 0.50040\n",
      "Epoch: 330 Batch:   0 Loss: 0.76872 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.76847 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.76823 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.76799 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.76775 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.76752 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.76729 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.76706 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.76683 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.76661 Accuracy: 0.00000\n",
      "Test Loss: 0.65789 Accuracy: 0.50040\n",
      "Epoch: 340 Batch:   0 Loss: 0.76639 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.76618 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.76597 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.76576 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.76555 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.76534 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.76514 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.76494 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.76475 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.76456 Accuracy: 0.00000\n",
      "Test Loss: 0.65663 Accuracy: 0.50040\n",
      "Epoch: 350 Batch:   0 Loss: 0.76437 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.76418 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.76399 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.76381 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.76363 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.76346 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.76328 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.76311 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.76293 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.76277 Accuracy: 0.00000\n",
      "Test Loss: 0.65546 Accuracy: 0.50040\n",
      "Epoch: 360 Batch:   0 Loss: 0.76260 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.76244 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.76228 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.76212 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.76196 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.76181 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.76165 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.76150 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.76135 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.76121 Accuracy: 0.00000\n",
      "Test Loss: 0.65440 Accuracy: 0.50040\n",
      "Epoch: 370 Batch:   0 Loss: 0.76107 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.76093 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.76079 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.76065 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.76051 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.76038 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.76024 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.76011 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.75999 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.75986 Accuracy: 0.00000\n",
      "Test Loss: 0.65344 Accuracy: 0.50040\n",
      "Epoch: 380 Batch:   0 Loss: 0.75974 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.75962 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.75950 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.75938 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.75927 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.75916 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.75905 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.75894 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.75884 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.75873 Accuracy: 0.00000\n",
      "Test Loss: 0.65255 Accuracy: 0.50040\n",
      "Epoch: 390 Batch:   0 Loss: 0.75863 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.75852 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.75842 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.75832 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.75823 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.75813 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.75804 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.75795 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.75786 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.75777 Accuracy: 0.00000\n",
      "Test Loss: 0.65173 Accuracy: 0.50040\n",
      "Epoch: 400 Batch:   0 Loss: 0.75768 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.75759 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.75751 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.75742 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.75734 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.75726 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.75718 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.75710 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.75702 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.75694 Accuracy: 0.00000\n",
      "Test Loss: 0.65101 Accuracy: 0.50040\n",
      "Epoch: 410 Batch:   0 Loss: 0.75686 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.75678 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.75671 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.75663 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.75656 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.75648 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.75641 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.75634 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.75627 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.75621 Accuracy: 0.00000\n",
      "Test Loss: 0.65039 Accuracy: 0.50040\n",
      "Epoch: 420 Batch:   0 Loss: 0.75614 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.75607 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.75602 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.75595 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.75589 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.75582 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:28:38,692] Trial 11 finished with value: 0.5002010454362686 and parameters: {'REG_W': 3.4072378154173003e-06, 'REG_B': 0.002602785572417885, 'REG_Z': 2.0170246749393997e-05, 'SPAR_W': 0.6724704939309168, 'SPAR_B': 0.8145582260082351, 'SPAR_Z': 0.517161356568251, 'LEARNING_RATE': 0.0001906247918707398, 'NUM_EPOCHS': 426}. Best is trial 5 with value: 0.6766184157619622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 11.54125 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 7.95788 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 5.49431 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 3.69179 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 2.68513 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 2.17771 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.93412 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.82319 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.77736 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.76217 Accuracy: 0.00000\n",
      "Test Loss: 0.92040 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.76013 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.76242 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.76482 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.76549 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.76386 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.75996 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.75410 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.74664 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.73798 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.72839 Accuracy: 0.00000\n",
      "Test Loss: 0.92386 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.71812 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.70731 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.69611 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.68456 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.67273 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.66065 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.64804 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.63527 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.62224 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.60904 Accuracy: 0.00000\n",
      "Test Loss: 0.90979 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.59557 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.58193 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.56798 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.55414 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.54003 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.52590 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.51148 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.49668 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.48217 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.46732 Accuracy: 0.00000\n",
      "Test Loss: 0.89402 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.45234 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.43761 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.42241 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.40724 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.39192 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.37645 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.36073 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.34460 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.32865 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.31259 Accuracy: 0.00000\n",
      "Test Loss: 0.87590 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.29651 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.28058 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.26503 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.24955 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.23410 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.21898 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.20368 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.18893 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.17432 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.16018 Accuracy: 0.00000\n",
      "Test Loss: 0.85520 Accuracy: 0.50020\n",
      "Epoch:  60 Batch:   0 Loss: 1.14638 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.13284 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.11916 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.10573 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 1.09295 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 1.08053 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 1.06839 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 1.05685 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 1.04565 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 1.03487 Accuracy: 0.00000\n",
      "Test Loss: 0.83326 Accuracy: 0.50020\n",
      "Epoch:  70 Batch:   0 Loss: 1.02464 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 1.01498 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 1.00580 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.99708 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.98884 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.98099 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.97355 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.96655 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.95987 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.95354 Accuracy: 0.00000\n",
      "Test Loss: 0.81110 Accuracy: 0.50020\n",
      "Epoch:  80 Batch:   0 Loss: 0.94758 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.94179 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.93654 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.93141 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.92656 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.92216 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.91807 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.91435 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.91091 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.90770 Accuracy: 0.00000\n",
      "Test Loss: 0.78717 Accuracy: 0.50030\n",
      "Epoch:  90 Batch:   0 Loss: 0.90455 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.90173 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.89928 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.89703 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.89485 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.89289 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.89105 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.88913 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.88741 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.88588 Accuracy: 0.00000\n",
      "Test Loss: 0.76596 Accuracy: 0.50040\n",
      "Epoch: 100 Batch:   0 Loss: 0.88438 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.88284 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.88138 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.87988 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.87853 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.87707 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.87563 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.87432 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.87302 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.87172 Accuracy: 0.00000\n",
      "Test Loss: 0.74909 Accuracy: 0.50040\n",
      "Epoch: 110 Batch:   0 Loss: 0.87043 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.86915 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.86785 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.86656 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.86533 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.86414 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.86300 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.86190 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.86078 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.85968 Accuracy: 0.00000\n",
      "Test Loss: 0.73572 Accuracy: 0.50050\n",
      "Epoch: 120 Batch:   0 Loss: 0.85863 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.85760 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.85659 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.85566 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.85472 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.85383 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.85298 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.85217 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.85137 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.85061 Accuracy: 0.00000\n",
      "Test Loss: 0.72530 Accuracy: 0.50050\n",
      "Epoch: 130 Batch:   0 Loss: 0.84989 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.84923 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.84852 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.84789 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.84729 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.84675 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.84626 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.84577 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.84535 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.84496 Accuracy: 0.00000\n",
      "Test Loss: 0.71697 Accuracy: 0.50050\n",
      "Epoch: 140 Batch:   0 Loss: 0.84459 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.84417 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.84386 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.84355 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.84329 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.84306 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.84285 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.84266 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.84250 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.84234 Accuracy: 0.00000\n",
      "Test Loss: 0.71003 Accuracy: 0.50050\n",
      "Epoch: 150 Batch:   0 Loss: 0.84221 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.84209 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.84198 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.84187 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.84176 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.84164 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.84150 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.84141 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.84132 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.84122 Accuracy: 0.00000\n",
      "Test Loss: 0.70391 Accuracy: 0.50050\n",
      "Epoch: 160 Batch:   0 Loss: 0.84112 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.84098 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.84085 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.84069 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.84055 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.84040 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.84021 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.84005 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.83988 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.83969 Accuracy: 0.00000\n",
      "Test Loss: 0.69839 Accuracy: 0.50050\n",
      "Epoch: 170 Batch:   0 Loss: 0.83950 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.83932 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.83913 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.83896 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.83877 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.83861 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.83846 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.83832 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.83819 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.83808 Accuracy: 0.00000\n",
      "Test Loss: 0.69360 Accuracy: 0.50050\n",
      "Epoch: 180 Batch:   0 Loss: 0.83797 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.83787 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.83779 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.83774 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.83771 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.83770 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.83765 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.83762 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.83764 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.83766 Accuracy: 0.00000\n",
      "Test Loss: 0.68945 Accuracy: 0.50050\n",
      "Epoch: 190 Batch:   0 Loss: 0.83769 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.83768 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.83766 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.83758 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.83744 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.83722 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.83692 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.83656 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.83613 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.83563 Accuracy: 0.00000\n",
      "Test Loss: 0.68556 Accuracy: 0.50050\n",
      "Epoch: 200 Batch:   0 Loss: 0.83507 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.83444 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.83379 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.83307 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.83235 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.83158 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.83078 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.82996 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.82912 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.82827 Accuracy: 0.00000\n",
      "Test Loss: 0.68185 Accuracy: 0.50050\n",
      "Epoch: 210 Batch:   0 Loss: 0.82744 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.82660 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.82577 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.82494 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.82413 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.82332 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.82253 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.82174 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.82093 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.82013 Accuracy: 0.00000\n",
      "Test Loss: 0.67879 Accuracy: 0.50050\n",
      "Epoch: 220 Batch:   0 Loss: 0.81931 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.81850 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.81775 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.81701 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.81631 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.81562 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.81494 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.81424 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.81356 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.81289 Accuracy: 0.00000\n",
      "Test Loss: 0.67627 Accuracy: 0.50050\n",
      "Epoch: 230 Batch:   0 Loss: 0.81221 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.81158 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.81095 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.81032 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.80971 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.80911 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.80852 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.80796 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.80740 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.80685 Accuracy: 0.00000\n",
      "Test Loss: 0.67409 Accuracy: 0.50050\n",
      "Epoch: 240 Batch:   0 Loss: 0.80631 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.80578 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.80526 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.80475 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.80424 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.80374 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.80326 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.80278 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.80232 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.80184 Accuracy: 0.00000\n",
      "Test Loss: 0.67220 Accuracy: 0.50050\n",
      "Epoch: 250 Batch:   0 Loss: 0.80138 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.80092 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.80045 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.80001 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.79957 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.79913 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.79871 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.79827 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.79785 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.79742 Accuracy: 0.00000\n",
      "Test Loss: 0.67054 Accuracy: 0.50050\n",
      "Epoch: 260 Batch:   0 Loss: 0.79701 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.79660 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.79620 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.79580 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.79542 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.79503 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.79466 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.79429 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.79391 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.79354 Accuracy: 0.00000\n",
      "Test Loss: 0.66911 Accuracy: 0.50050\n",
      "Epoch: 270 Batch:   0 Loss: 0.79318 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.79282 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.79247 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.79213 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.79178 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.79145 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.79113 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.79078 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.79045 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.79013 Accuracy: 0.00000\n",
      "Test Loss: 0.66789 Accuracy: 0.50050\n",
      "Epoch: 280 Batch:   0 Loss: 0.78981 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.78951 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.78921 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.78892 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.78863 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.78834 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.78806 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.78779 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.78751 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.78725 Accuracy: 0.00000\n",
      "Test Loss: 0.66690 Accuracy: 0.50050\n",
      "Epoch: 290 Batch:   0 Loss: 0.78698 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.78673 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.78647 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.78621 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.78596 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.78571 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.78547 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.78523 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.78499 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.78476 Accuracy: 0.00000\n",
      "Test Loss: 0.66610 Accuracy: 0.50050\n",
      "Epoch: 300 Batch:   0 Loss: 0.78454 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.78431 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.78409 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.78388 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.78368 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.78347 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.78328 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.78308 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.78289 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.78268 Accuracy: 0.00000\n",
      "Test Loss: 0.66546 Accuracy: 0.50050\n",
      "Epoch: 310 Batch:   0 Loss: 0.78247 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.78228 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.78209 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.78191 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.78172 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.78153 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.78135 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.78117 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.78099 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.78082 Accuracy: 0.00000\n",
      "Test Loss: 0.66498 Accuracy: 0.50050\n",
      "Epoch: 320 Batch:   0 Loss: 0.78065 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.78048 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.78032 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.78016 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.77999 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.77983 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.77967 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.77952 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.77936 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.77921 Accuracy: 0.00000\n",
      "Test Loss: 0.66463 Accuracy: 0.50050\n",
      "Epoch: 330 Batch:   0 Loss: 0.77906 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.77891 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.77877 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.77862 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.77847 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.77833 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.77818 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.77804 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.77790 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.77776 Accuracy: 0.00000\n",
      "Test Loss: 0.66442 Accuracy: 0.50050\n",
      "Epoch: 340 Batch:   0 Loss: 0.77762 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.77748 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.77734 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.77720 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.77707 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.77693 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.77679 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.77665 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.77652 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.77639 Accuracy: 0.00000\n",
      "Test Loss: 0.66429 Accuracy: 0.50050\n",
      "Epoch: 350 Batch:   0 Loss: 0.77626 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.77613 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.77600 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.77588 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.77576 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.77564 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.77552 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.77539 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.77527 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.77516 Accuracy: 0.00000\n",
      "Test Loss: 0.66424 Accuracy: 0.50050\n",
      "Epoch: 360 Batch:   0 Loss: 0.77503 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.77492 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.77481 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.77470 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.77460 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.77450 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.77439 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.77429 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.77419 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.77409 Accuracy: 0.00000\n",
      "Test Loss: 0.66422 Accuracy: 0.50050\n",
      "Epoch: 370 Batch:   0 Loss: 0.77399 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.77389 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.77379 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.77370 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.77360 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.77350 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.77341 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.77331 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.77322 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.77312 Accuracy: 0.00000\n",
      "Test Loss: 0.66428 Accuracy: 0.50050\n",
      "Epoch: 380 Batch:   0 Loss: 0.77303 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.77294 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.77285 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.77276 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.77267 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.77258 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.77250 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.77241 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.77232 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.77223 Accuracy: 0.00000\n",
      "Test Loss: 0.66444 Accuracy: 0.50050\n",
      "Epoch: 390 Batch:   0 Loss: 0.77214 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.77204 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.77194 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.77186 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.77177 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.77169 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.77161 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.77153 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.77145 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.77136 Accuracy: 0.00000\n",
      "Test Loss: 0.66465 Accuracy: 0.50050\n",
      "Epoch: 400 Batch:   0 Loss: 0.77128 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.77120 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.77112 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.77104 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.77096 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.77088 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.77080 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.77073 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.77065 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.77057 Accuracy: 0.00000\n",
      "Test Loss: 0.66491 Accuracy: 0.50050\n",
      "Epoch: 410 Batch:   0 Loss: 0.77050 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.77043 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.77035 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.77027 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.77020 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.77013 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.77006 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.76998 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.76991 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.76984 Accuracy: 0.00000\n",
      "Test Loss: 0.66521 Accuracy: 0.50050\n",
      "Epoch: 420 Batch:   0 Loss: 0.76976 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.76969 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:32:24,736] Trial 12 finished with value: 0.5003015681544029 and parameters: {'REG_W': 4.11158743995577e-06, 'REG_B': 0.002997184575350683, 'REG_Z': 2.3415161857228485e-05, 'SPAR_W': 0.6842777308500527, 'SPAR_B': 0.8517741688183632, 'SPAR_Z': 0.5059483083458255, 'LEARNING_RATE': 0.00029404840238769303, 'NUM_EPOCHS': 422}. Best is trial 5 with value: 0.6766184157619622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.03627 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.91066 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.83649 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 3.20125 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 3.32216 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 3.34748 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 3.33565 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 3.30698 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 3.26917 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 3.22545 Accuracy: 0.00000\n",
      "Test Loss: 1.49759 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 3.17393 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 3.11581 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 3.05002 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.97829 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.89900 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.81792 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.73287 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.64386 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.55304 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.46160 Accuracy: 0.00000\n",
      "Test Loss: 1.47827 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.37307 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.28496 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.19905 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.11512 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.03438 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.95786 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.88568 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.81673 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.75094 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.69078 Accuracy: 0.00000\n",
      "Test Loss: 1.46997 Accuracy: 0.50030\n",
      "Epoch:  30 Batch:   0 Loss: 1.63293 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.57898 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.52875 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.48175 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.43859 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.39854 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.36156 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.32663 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.29437 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.26507 Accuracy: 0.00000\n",
      "Test Loss: 1.42793 Accuracy: 0.50161\n",
      "Epoch:  40 Batch:   0 Loss: 1.23802 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.21254 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.18940 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.16753 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.14776 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.12940 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.11263 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.09703 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.08251 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.06914 Accuracy: 0.00000\n",
      "Test Loss: 1.38723 Accuracy: 0.51145\n",
      "Epoch:  50 Batch:   0 Loss: 1.05672 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.04505 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.03430 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.02423 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.01456 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.00586 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.99783 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.99027 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.98311 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.97627 Accuracy: 0.00000\n",
      "Test Loss: 1.35680 Accuracy: 0.51929\n",
      "Epoch:  60 Batch:   0 Loss: 0.96978 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.96366 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.95811 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.95273 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.94755 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.94256 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.93777 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.93323 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.92874 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.92442 Accuracy: 0.00000\n",
      "Test Loss: 1.33132 Accuracy: 0.52562\n",
      "Epoch:  70 Batch:   0 Loss: 0.92031 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.91630 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.91239 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.90860 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.90475 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.90113 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.89767 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.89421 Accuracy: 0.03125\n",
      "Epoch:  78 Batch:   0 Loss: 0.89080 Accuracy: 0.03125\n",
      "Epoch:  79 Batch:   0 Loss: 0.88731 Accuracy: 0.06250\n",
      "Test Loss: 1.30759 Accuracy: 0.53306\n",
      "Epoch:  80 Batch:   0 Loss: 0.88386 Accuracy: 0.06250\n",
      "Epoch:  81 Batch:   0 Loss: 0.88045 Accuracy: 0.06250\n",
      "Epoch:  82 Batch:   0 Loss: 0.87713 Accuracy: 0.06250\n",
      "Epoch:  83 Batch:   0 Loss: 0.87384 Accuracy: 0.06250\n",
      "Epoch:  84 Batch:   0 Loss: 0.87066 Accuracy: 0.06250\n",
      "Epoch:  85 Batch:   0 Loss: 0.86755 Accuracy: 0.09375\n",
      "Epoch:  86 Batch:   0 Loss: 0.86454 Accuracy: 0.09375\n",
      "Epoch:  87 Batch:   0 Loss: 0.86156 Accuracy: 0.12500\n",
      "Epoch:  88 Batch:   0 Loss: 0.85863 Accuracy: 0.12500\n",
      "Epoch:  89 Batch:   0 Loss: 0.85572 Accuracy: 0.12500\n",
      "Test Loss: 1.28397 Accuracy: 0.53879\n",
      "Epoch:  90 Batch:   0 Loss: 0.85292 Accuracy: 0.18750\n",
      "Epoch:  91 Batch:   0 Loss: 0.85020 Accuracy: 0.18750\n",
      "Epoch:  92 Batch:   0 Loss: 0.84751 Accuracy: 0.18750\n",
      "Epoch:  93 Batch:   0 Loss: 0.84487 Accuracy: 0.21875\n",
      "Epoch:  94 Batch:   0 Loss: 0.84223 Accuracy: 0.21875\n",
      "Epoch:  95 Batch:   0 Loss: 0.83959 Accuracy: 0.21875\n",
      "Epoch:  96 Batch:   0 Loss: 0.83586 Accuracy: 0.25000\n",
      "Epoch:  97 Batch:   0 Loss: 0.83115 Accuracy: 0.25000\n",
      "Epoch:  98 Batch:   0 Loss: 0.82807 Accuracy: 0.25000\n",
      "Epoch:  99 Batch:   0 Loss: 0.82555 Accuracy: 0.25000\n",
      "Test Loss: 1.25412 Accuracy: 0.54361\n",
      "Epoch: 100 Batch:   0 Loss: 0.82324 Accuracy: 0.25000\n",
      "Epoch: 101 Batch:   0 Loss: 0.82106 Accuracy: 0.31250\n",
      "Epoch: 102 Batch:   0 Loss: 0.81890 Accuracy: 0.31250\n",
      "Epoch: 103 Batch:   0 Loss: 0.81675 Accuracy: 0.31250\n",
      "Epoch: 104 Batch:   0 Loss: 0.81457 Accuracy: 0.31250\n",
      "Epoch: 105 Batch:   0 Loss: 0.81244 Accuracy: 0.34375\n",
      "Epoch: 106 Batch:   0 Loss: 0.81025 Accuracy: 0.34375\n",
      "Epoch: 107 Batch:   0 Loss: 0.80809 Accuracy: 0.34375\n",
      "Epoch: 108 Batch:   0 Loss: 0.80593 Accuracy: 0.34375\n",
      "Epoch: 109 Batch:   0 Loss: 0.80381 Accuracy: 0.34375\n",
      "Test Loss: 1.23069 Accuracy: 0.54843\n",
      "Epoch: 110 Batch:   0 Loss: 0.80170 Accuracy: 0.34375\n",
      "Epoch: 111 Batch:   0 Loss: 0.79963 Accuracy: 0.40625\n",
      "Epoch: 112 Batch:   0 Loss: 0.79759 Accuracy: 0.40625\n",
      "Epoch: 113 Batch:   0 Loss: 0.79554 Accuracy: 0.43750\n",
      "Epoch: 114 Batch:   0 Loss: 0.79353 Accuracy: 0.46875\n",
      "Epoch: 115 Batch:   0 Loss: 0.79153 Accuracy: 0.46875\n",
      "Epoch: 116 Batch:   0 Loss: 0.78955 Accuracy: 0.46875\n",
      "Epoch: 117 Batch:   0 Loss: 0.78754 Accuracy: 0.46875\n",
      "Epoch: 118 Batch:   0 Loss: 0.78556 Accuracy: 0.50000\n",
      "Epoch: 119 Batch:   0 Loss: 0.78356 Accuracy: 0.53125\n",
      "Test Loss: 1.20702 Accuracy: 0.55567\n",
      "Epoch: 120 Batch:   0 Loss: 0.78156 Accuracy: 0.53125\n",
      "Epoch: 121 Batch:   0 Loss: 0.77962 Accuracy: 0.59375\n",
      "Epoch: 122 Batch:   0 Loss: 0.77769 Accuracy: 0.59375\n",
      "Epoch: 123 Batch:   0 Loss: 0.77578 Accuracy: 0.59375\n",
      "Epoch: 124 Batch:   0 Loss: 0.77383 Accuracy: 0.59375\n",
      "Epoch: 125 Batch:   0 Loss: 0.77193 Accuracy: 0.59375\n",
      "Epoch: 126 Batch:   0 Loss: 0.77004 Accuracy: 0.59375\n",
      "Epoch: 127 Batch:   0 Loss: 0.76819 Accuracy: 0.59375\n",
      "Epoch: 128 Batch:   0 Loss: 0.76632 Accuracy: 0.59375\n",
      "Epoch: 129 Batch:   0 Loss: 0.76446 Accuracy: 0.59375\n",
      "Test Loss: 1.18400 Accuracy: 0.56109\n",
      "Epoch: 130 Batch:   0 Loss: 0.76260 Accuracy: 0.59375\n",
      "Epoch: 131 Batch:   0 Loss: 0.76071 Accuracy: 0.62500\n",
      "Epoch: 132 Batch:   0 Loss: 0.75885 Accuracy: 0.62500\n",
      "Epoch: 133 Batch:   0 Loss: 0.75702 Accuracy: 0.62500\n",
      "Epoch: 134 Batch:   0 Loss: 0.75522 Accuracy: 0.65625\n",
      "Epoch: 135 Batch:   0 Loss: 0.75552 Accuracy: 0.65625\n",
      "Epoch: 136 Batch:   0 Loss: 0.75266 Accuracy: 0.65625\n",
      "Epoch: 137 Batch:   0 Loss: 0.75043 Accuracy: 0.65625\n",
      "Epoch: 138 Batch:   0 Loss: 0.74840 Accuracy: 0.65625\n",
      "Epoch: 139 Batch:   0 Loss: 0.74650 Accuracy: 0.65625\n",
      "Test Loss: 1.16266 Accuracy: 0.57215\n",
      "Epoch: 140 Batch:   0 Loss: 0.74470 Accuracy: 0.68750\n",
      "Epoch: 141 Batch:   0 Loss: 0.74292 Accuracy: 0.75000\n",
      "Epoch: 142 Batch:   0 Loss: 0.74114 Accuracy: 0.75000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.73935 Accuracy: 0.75000\n",
      "Epoch: 144 Batch:   0 Loss: 0.73759 Accuracy: 0.75000\n",
      "Epoch: 145 Batch:   0 Loss: 0.73582 Accuracy: 0.75000\n",
      "Epoch: 146 Batch:   0 Loss: 0.73409 Accuracy: 0.75000\n",
      "Epoch: 147 Batch:   0 Loss: 0.73235 Accuracy: 0.75000\n",
      "Epoch: 148 Batch:   0 Loss: 0.73062 Accuracy: 0.75000\n",
      "Epoch: 149 Batch:   0 Loss: 0.72891 Accuracy: 0.75000\n",
      "Test Loss: 1.14164 Accuracy: 0.58239\n",
      "Epoch: 150 Batch:   0 Loss: 0.72727 Accuracy: 0.75000\n",
      "Epoch: 151 Batch:   0 Loss: 0.72560 Accuracy: 0.75000\n",
      "Epoch: 152 Batch:   0 Loss: 0.72397 Accuracy: 0.75000\n",
      "Epoch: 153 Batch:   0 Loss: 0.72239 Accuracy: 0.75000\n",
      "Epoch: 154 Batch:   0 Loss: 0.72076 Accuracy: 0.75000\n",
      "Epoch: 155 Batch:   0 Loss: 0.71915 Accuracy: 0.75000\n",
      "Epoch: 156 Batch:   0 Loss: 0.71756 Accuracy: 0.75000\n",
      "Epoch: 157 Batch:   0 Loss: 0.71598 Accuracy: 0.75000\n",
      "Epoch: 158 Batch:   0 Loss: 0.71450 Accuracy: 0.75000\n",
      "Epoch: 159 Batch:   0 Loss: 0.71302 Accuracy: 0.75000\n",
      "Test Loss: 1.12222 Accuracy: 0.59143\n",
      "Epoch: 160 Batch:   0 Loss: 0.71154 Accuracy: 0.75000\n",
      "Epoch: 161 Batch:   0 Loss: 0.71008 Accuracy: 0.75000\n",
      "Epoch: 162 Batch:   0 Loss: 0.70858 Accuracy: 0.75000\n",
      "Epoch: 163 Batch:   0 Loss: 0.70710 Accuracy: 0.75000\n",
      "Epoch: 164 Batch:   0 Loss: 0.70563 Accuracy: 0.75000\n",
      "Epoch: 165 Batch:   0 Loss: 0.70416 Accuracy: 0.75000\n",
      "Epoch: 166 Batch:   0 Loss: 0.70266 Accuracy: 0.75000\n",
      "Epoch: 167 Batch:   0 Loss: 0.70120 Accuracy: 0.75000\n",
      "Epoch: 168 Batch:   0 Loss: 0.69977 Accuracy: 0.75000\n",
      "Epoch: 169 Batch:   0 Loss: 0.69829 Accuracy: 0.78125\n",
      "Test Loss: 1.10457 Accuracy: 0.60108\n",
      "Epoch: 170 Batch:   0 Loss: 0.69684 Accuracy: 0.78125\n",
      "Epoch: 171 Batch:   0 Loss: 0.69538 Accuracy: 0.78125\n",
      "Epoch: 172 Batch:   0 Loss: 0.69393 Accuracy: 0.81250\n",
      "Epoch: 173 Batch:   0 Loss: 0.69251 Accuracy: 0.81250\n",
      "Epoch: 174 Batch:   0 Loss: 0.69107 Accuracy: 0.81250\n",
      "Epoch: 175 Batch:   0 Loss: 0.68960 Accuracy: 0.81250\n",
      "Epoch: 176 Batch:   0 Loss: 0.68823 Accuracy: 0.81250\n",
      "Epoch: 177 Batch:   0 Loss: 0.68677 Accuracy: 0.81250\n",
      "Epoch: 178 Batch:   0 Loss: 0.68533 Accuracy: 0.81250\n",
      "Epoch: 179 Batch:   0 Loss: 0.68391 Accuracy: 0.81250\n",
      "Test Loss: 1.08826 Accuracy: 0.60841\n",
      "Epoch: 180 Batch:   0 Loss: 0.68249 Accuracy: 0.81250\n",
      "Epoch: 181 Batch:   0 Loss: 0.68108 Accuracy: 0.81250\n",
      "Epoch: 182 Batch:   0 Loss: 0.67968 Accuracy: 0.81250\n",
      "Epoch: 183 Batch:   0 Loss: 0.67829 Accuracy: 0.81250\n",
      "Epoch: 184 Batch:   0 Loss: 0.67689 Accuracy: 0.81250\n",
      "Epoch: 185 Batch:   0 Loss: 0.67546 Accuracy: 0.81250\n",
      "Epoch: 186 Batch:   0 Loss: 0.67413 Accuracy: 0.81250\n",
      "Epoch: 187 Batch:   0 Loss: 0.67276 Accuracy: 0.81250\n",
      "Epoch: 188 Batch:   0 Loss: 0.67140 Accuracy: 0.81250\n",
      "Epoch: 189 Batch:   0 Loss: 0.67007 Accuracy: 0.81250\n",
      "Test Loss: 1.07507 Accuracy: 0.61515\n",
      "Epoch: 190 Batch:   0 Loss: 0.67013 Accuracy: 0.81250\n",
      "Epoch: 191 Batch:   0 Loss: 0.66804 Accuracy: 0.81250\n",
      "Epoch: 192 Batch:   0 Loss: 0.66639 Accuracy: 0.81250\n",
      "Epoch: 193 Batch:   0 Loss: 0.66487 Accuracy: 0.81250\n",
      "Epoch: 194 Batch:   0 Loss: 0.66341 Accuracy: 0.81250\n",
      "Epoch: 195 Batch:   0 Loss: 0.66198 Accuracy: 0.81250\n",
      "Epoch: 196 Batch:   0 Loss: 0.66057 Accuracy: 0.81250\n",
      "Epoch: 197 Batch:   0 Loss: 0.65919 Accuracy: 0.84375\n",
      "Epoch: 198 Batch:   0 Loss: 0.65783 Accuracy: 0.84375\n",
      "Epoch: 199 Batch:   0 Loss: 0.65645 Accuracy: 0.84375\n",
      "Test Loss: 1.06040 Accuracy: 0.62409\n",
      "Epoch: 200 Batch:   0 Loss: 0.65508 Accuracy: 0.84375\n",
      "Epoch: 201 Batch:   0 Loss: 0.65374 Accuracy: 0.84375\n",
      "Epoch: 202 Batch:   0 Loss: 0.65239 Accuracy: 0.84375\n",
      "Epoch: 203 Batch:   0 Loss: 0.65106 Accuracy: 0.84375\n",
      "Epoch: 204 Batch:   0 Loss: 0.64972 Accuracy: 0.84375\n",
      "Epoch: 205 Batch:   0 Loss: 0.64842 Accuracy: 0.84375\n",
      "Epoch: 206 Batch:   0 Loss: 0.64707 Accuracy: 0.84375\n",
      "Epoch: 207 Batch:   0 Loss: 0.64573 Accuracy: 0.84375\n",
      "Epoch: 208 Batch:   0 Loss: 0.64438 Accuracy: 0.84375\n",
      "Epoch: 209 Batch:   0 Loss: 0.64308 Accuracy: 0.84375\n",
      "Test Loss: 1.04789 Accuracy: 0.63303\n",
      "Epoch: 210 Batch:   0 Loss: 0.64180 Accuracy: 0.84375\n",
      "Epoch: 211 Batch:   0 Loss: 0.64048 Accuracy: 0.84375\n",
      "Epoch: 212 Batch:   0 Loss: 0.63917 Accuracy: 0.84375\n",
      "Epoch: 213 Batch:   0 Loss: 0.63787 Accuracy: 0.84375\n",
      "Epoch: 214 Batch:   0 Loss: 0.63657 Accuracy: 0.87500\n",
      "Epoch: 215 Batch:   0 Loss: 0.63529 Accuracy: 0.87500\n",
      "Epoch: 216 Batch:   0 Loss: 0.63401 Accuracy: 0.87500\n",
      "Epoch: 217 Batch:   0 Loss: 0.63273 Accuracy: 0.87500\n",
      "Epoch: 218 Batch:   0 Loss: 0.63145 Accuracy: 0.87500\n",
      "Epoch: 219 Batch:   0 Loss: 0.63019 Accuracy: 0.87500\n",
      "Test Loss: 1.03651 Accuracy: 0.64007\n",
      "Epoch: 220 Batch:   0 Loss: 0.62895 Accuracy: 0.87500\n",
      "Epoch: 221 Batch:   0 Loss: 0.62771 Accuracy: 0.87500\n",
      "Epoch: 222 Batch:   0 Loss: 0.62645 Accuracy: 0.87500\n",
      "Epoch: 223 Batch:   0 Loss: 0.62520 Accuracy: 0.87500\n",
      "Epoch: 224 Batch:   0 Loss: 0.62396 Accuracy: 0.87500\n",
      "Epoch: 225 Batch:   0 Loss: 0.62274 Accuracy: 0.87500\n",
      "Epoch: 226 Batch:   0 Loss: 0.62151 Accuracy: 0.87500\n",
      "Epoch: 227 Batch:   0 Loss: 0.62029 Accuracy: 0.87500\n",
      "Epoch: 228 Batch:   0 Loss: 0.61906 Accuracy: 0.87500\n",
      "Epoch: 229 Batch:   0 Loss: 0.61786 Accuracy: 0.87500\n",
      "Test Loss: 1.02642 Accuracy: 0.64680\n",
      "Epoch: 230 Batch:   0 Loss: 0.61661 Accuracy: 0.90625\n",
      "Epoch: 231 Batch:   0 Loss: 0.61540 Accuracy: 0.90625\n",
      "Epoch: 232 Batch:   0 Loss: 0.61414 Accuracy: 0.90625\n",
      "Epoch: 233 Batch:   0 Loss: 0.61291 Accuracy: 0.90625\n",
      "Epoch: 234 Batch:   0 Loss: 0.61166 Accuracy: 0.90625\n",
      "Epoch: 235 Batch:   0 Loss: 0.61038 Accuracy: 0.90625\n",
      "Epoch: 236 Batch:   0 Loss: 0.60915 Accuracy: 0.90625\n",
      "Epoch: 237 Batch:   0 Loss: 0.60793 Accuracy: 0.90625\n",
      "Epoch: 238 Batch:   0 Loss: 0.60673 Accuracy: 0.90625\n",
      "Epoch: 239 Batch:   0 Loss: 0.60555 Accuracy: 0.90625\n",
      "Test Loss: 1.01739 Accuracy: 0.65323\n",
      "Epoch: 240 Batch:   0 Loss: 0.60428 Accuracy: 0.90625\n",
      "Epoch: 241 Batch:   0 Loss: 0.60302 Accuracy: 0.90625\n",
      "Epoch: 242 Batch:   0 Loss: 0.60180 Accuracy: 0.90625\n",
      "Epoch: 243 Batch:   0 Loss: 0.60059 Accuracy: 0.90625\n",
      "Epoch: 244 Batch:   0 Loss: 0.59938 Accuracy: 0.90625\n",
      "Epoch: 245 Batch:   0 Loss: 0.59818 Accuracy: 0.90625\n",
      "Epoch: 246 Batch:   0 Loss: 0.59698 Accuracy: 0.90625\n",
      "Epoch: 247 Batch:   0 Loss: 0.59580 Accuracy: 0.93750\n",
      "Epoch: 248 Batch:   0 Loss: 0.59463 Accuracy: 0.93750\n",
      "Epoch: 249 Batch:   0 Loss: 0.59345 Accuracy: 0.93750\n",
      "Test Loss: 1.00974 Accuracy: 0.65735\n",
      "Epoch: 250 Batch:   0 Loss: 0.59229 Accuracy: 0.93750\n",
      "Epoch: 251 Batch:   0 Loss: 0.59110 Accuracy: 0.93750\n",
      "Epoch: 252 Batch:   0 Loss: 0.58995 Accuracy: 0.93750\n",
      "Epoch: 253 Batch:   0 Loss: 0.58884 Accuracy: 0.93750\n",
      "Epoch: 254 Batch:   0 Loss: 0.58770 Accuracy: 0.93750\n",
      "Epoch: 255 Batch:   0 Loss: 0.58655 Accuracy: 0.93750\n",
      "Epoch: 256 Batch:   0 Loss: 0.58543 Accuracy: 0.93750\n",
      "Epoch: 257 Batch:   0 Loss: 0.58428 Accuracy: 0.93750\n",
      "Epoch: 258 Batch:   0 Loss: 0.58310 Accuracy: 0.93750\n",
      "Epoch: 259 Batch:   0 Loss: 0.58201 Accuracy: 0.93750\n",
      "Test Loss: 1.00306 Accuracy: 0.66127\n",
      "Epoch: 260 Batch:   0 Loss: 0.58092 Accuracy: 0.93750\n",
      "Epoch: 261 Batch:   0 Loss: 0.57983 Accuracy: 0.93750\n",
      "Epoch: 262 Batch:   0 Loss: 0.57869 Accuracy: 0.93750\n",
      "Epoch: 263 Batch:   0 Loss: 0.57755 Accuracy: 0.93750\n",
      "Epoch: 264 Batch:   0 Loss: 0.57644 Accuracy: 0.93750\n",
      "Epoch: 265 Batch:   0 Loss: 0.57534 Accuracy: 0.93750\n",
      "Epoch: 266 Batch:   0 Loss: 0.57423 Accuracy: 0.93750\n",
      "Epoch: 267 Batch:   0 Loss: 0.57311 Accuracy: 0.93750\n",
      "Epoch: 268 Batch:   0 Loss: 0.57198 Accuracy: 0.93750\n",
      "Epoch: 269 Batch:   0 Loss: 0.57084 Accuracy: 0.93750\n",
      "Test Loss: 0.99653 Accuracy: 0.66549\n",
      "Epoch: 270 Batch:   0 Loss: 0.56968 Accuracy: 0.93750\n",
      "Epoch: 271 Batch:   0 Loss: 0.56837 Accuracy: 0.93750\n",
      "Epoch: 272 Batch:   0 Loss: 0.56699 Accuracy: 0.93750\n",
      "Epoch: 273 Batch:   0 Loss: 0.56573 Accuracy: 0.96875\n",
      "Epoch: 274 Batch:   0 Loss: 0.56464 Accuracy: 0.96875\n",
      "Epoch: 275 Batch:   0 Loss: 0.56372 Accuracy: 0.96875\n",
      "Epoch: 276 Batch:   0 Loss: 0.56281 Accuracy: 0.96875\n",
      "Epoch: 277 Batch:   0 Loss: 0.56186 Accuracy: 0.96875\n",
      "Epoch: 278 Batch:   0 Loss: 0.56089 Accuracy: 0.96875\n",
      "Epoch: 279 Batch:   0 Loss: 0.55990 Accuracy: 0.96875\n",
      "Test Loss: 0.98807 Accuracy: 0.66820\n",
      "Epoch: 280 Batch:   0 Loss: 0.55889 Accuracy: 0.96875\n",
      "Epoch: 281 Batch:   0 Loss: 0.55787 Accuracy: 0.96875\n",
      "Epoch: 282 Batch:   0 Loss: 0.55686 Accuracy: 0.96875\n",
      "Epoch: 283 Batch:   0 Loss: 0.55584 Accuracy: 0.96875\n",
      "Epoch: 284 Batch:   0 Loss: 0.55483 Accuracy: 0.96875\n",
      "Epoch: 285 Batch:   0 Loss: 0.55382 Accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.55282 Accuracy: 0.96875\n",
      "Epoch: 287 Batch:   0 Loss: 0.55181 Accuracy: 0.96875\n",
      "Epoch: 288 Batch:   0 Loss: 0.55079 Accuracy: 0.96875\n",
      "Epoch: 289 Batch:   0 Loss: 0.54976 Accuracy: 0.96875\n",
      "Test Loss: 0.98141 Accuracy: 0.67061\n",
      "Epoch: 290 Batch:   0 Loss: 0.54879 Accuracy: 0.96875\n",
      "Epoch: 291 Batch:   0 Loss: 0.54780 Accuracy: 0.96875\n",
      "Epoch: 292 Batch:   0 Loss: 0.54681 Accuracy: 0.96875\n",
      "Epoch: 293 Batch:   0 Loss: 0.54582 Accuracy: 0.96875\n",
      "Epoch: 294 Batch:   0 Loss: 0.54482 Accuracy: 0.96875\n",
      "Epoch: 295 Batch:   0 Loss: 0.54380 Accuracy: 0.96875\n",
      "Epoch: 296 Batch:   0 Loss: 0.54279 Accuracy: 0.96875\n",
      "Epoch: 297 Batch:   0 Loss: 0.54175 Accuracy: 0.96875\n",
      "Epoch: 298 Batch:   0 Loss: 0.54075 Accuracy: 0.96875\n",
      "Epoch: 299 Batch:   0 Loss: 0.53976 Accuracy: 0.96875\n",
      "Test Loss: 0.97507 Accuracy: 0.67352\n",
      "Epoch: 300 Batch:   0 Loss: 0.53876 Accuracy: 0.96875\n",
      "Epoch: 301 Batch:   0 Loss: 0.53777 Accuracy: 0.96875\n",
      "Epoch: 302 Batch:   0 Loss: 0.53678 Accuracy: 0.96875\n",
      "Epoch: 303 Batch:   0 Loss: 0.53579 Accuracy: 0.96875\n",
      "Epoch: 304 Batch:   0 Loss: 0.53481 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.53383 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.53286 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.53188 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.53093 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.52997 Accuracy: 1.00000\n",
      "Test Loss: 0.96921 Accuracy: 0.67593\n",
      "Epoch: 310 Batch:   0 Loss: 0.52901 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.52808 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.52711 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.52614 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.52518 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.52423 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.52326 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.52229 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.52134 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.52041 Accuracy: 1.00000\n",
      "Test Loss: 0.96391 Accuracy: 0.67895\n",
      "Epoch: 320 Batch:   0 Loss: 0.51950 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.51854 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.51760 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.51666 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.51572 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.51480 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.51388 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.51293 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.51198 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.51107 Accuracy: 1.00000\n",
      "Test Loss: 0.95898 Accuracy: 0.68176\n",
      "Epoch: 330 Batch:   0 Loss: 0.51016 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.50926 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.50837 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.50748 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.50657 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.50567 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.50477 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.50388 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.50300 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.50212 Accuracy: 1.00000\n",
      "Test Loss: 0.95441 Accuracy: 0.68377\n",
      "Epoch: 340 Batch:   0 Loss: 0.50124 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.50037 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.49950 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.49863 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.49777 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.49691 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.49607 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.49521 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.49434 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.49351 Accuracy: 1.00000\n",
      "Test Loss: 0.95012 Accuracy: 0.68638\n",
      "Epoch: 350 Batch:   0 Loss: 0.49267 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.49183 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.49100 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.49021 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.48939 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.48858 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.48777 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.48697 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.48618 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.48536 Accuracy: 1.00000\n",
      "Test Loss: 0.94615 Accuracy: 0.68960\n",
      "Epoch: 360 Batch:   0 Loss: 0.48456 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.48373 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.48294 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.48213 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.48132 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.48052 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.47973 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.47896 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.47813 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.47731 Accuracy: 1.00000\n",
      "Test Loss: 0.94224 Accuracy: 0.69151\n",
      "Epoch: 370 Batch:   0 Loss: 0.47650 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.47569 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.47489 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.47409 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.47330 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.47251 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.47172 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.47094 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.47015 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.46937 Accuracy: 1.00000\n",
      "Test Loss: 0.93845 Accuracy: 0.69282\n",
      "Epoch: 380 Batch:   0 Loss: 0.46860 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.46780 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.46700 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.46621 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.46543 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.46465 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.46387 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.46310 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.46232 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.46156 Accuracy: 1.00000\n",
      "Test Loss: 0.93476 Accuracy: 0.69513\n",
      "Epoch: 390 Batch:   0 Loss: 0.46078 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.46002 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.45924 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.45850 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.45775 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.45696 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.45624 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.45551 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.45478 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.45405 Accuracy: 1.00000\n",
      "Test Loss: 0.93126 Accuracy: 0.69663\n",
      "Epoch: 400 Batch:   0 Loss: 0.45332 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.45259 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.45185 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.45111 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.45038 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.44965 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.44891 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.44820 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.44746 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.44676 Accuracy: 1.00000\n",
      "Test Loss: 0.92788 Accuracy: 0.69834\n",
      "Epoch: 410 Batch:   0 Loss: 0.44607 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.44532 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.44458 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.44385 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.44312 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.44240 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.44168 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.44096 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.44025 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.43954 Accuracy: 1.00000\n",
      "Test Loss: 0.92464 Accuracy: 0.69965\n",
      "Epoch: 420 Batch:   0 Loss: 0.43881 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.43811 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.43738 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.43665 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.43593 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.43522 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.43453 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.43381 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.43310 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.43240 Accuracy: 1.00000\n",
      "Test Loss: 0.92155 Accuracy: 0.70135\n",
      "Epoch: 430 Batch:   0 Loss: 0.43171 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.43102 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.43033 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.42965 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.42897 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.42829 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.42762 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.42695 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.42631 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.42567 Accuracy: 1.00000\n",
      "Test Loss: 0.91860 Accuracy: 0.70336\n",
      "Epoch: 440 Batch:   0 Loss: 0.42500 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.42433 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.42368 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.42303 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.42239 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.42174 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.42110 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.42046 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.41982 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.41919 Accuracy: 1.00000\n",
      "Test Loss: 0.91565 Accuracy: 0.70517\n",
      "Epoch: 450 Batch:   0 Loss: 0.41853 Accuracy: 1.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.41788 Accuracy: 1.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.41726 Accuracy: 1.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.41663 Accuracy: 1.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.41599 Accuracy: 1.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.41539 Accuracy: 1.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.41478 Accuracy: 1.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.41417 Accuracy: 1.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.41357 Accuracy: 1.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.41296 Accuracy: 1.00000\n",
      "Test Loss: 0.91275 Accuracy: 0.70557\n",
      "Epoch: 460 Batch:   0 Loss: 0.41232 Accuracy: 1.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.41169 Accuracy: 1.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.41107 Accuracy: 1.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.41045 Accuracy: 1.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.40985 Accuracy: 1.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.40922 Accuracy: 1.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.40859 Accuracy: 1.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.40797 Accuracy: 1.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.40737 Accuracy: 1.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.40677 Accuracy: 1.00000\n",
      "Test Loss: 0.90995 Accuracy: 0.70728\n",
      "Epoch: 470 Batch:   0 Loss: 0.40616 Accuracy: 1.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.40555 Accuracy: 1.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.40495 Accuracy: 1.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.40433 Accuracy: 1.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.40375 Accuracy: 1.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.40317 Accuracy: 1.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.40256 Accuracy: 1.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.40196 Accuracy: 1.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.40137 Accuracy: 1.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.40078 Accuracy: 1.00000\n",
      "Test Loss: 0.90720 Accuracy: 0.70828\n",
      "Epoch: 480 Batch:   0 Loss: 0.40019 Accuracy: 1.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.39960 Accuracy: 1.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.39902 Accuracy: 1.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.39844 Accuracy: 1.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.39788 Accuracy: 1.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.39730 Accuracy: 1.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.39673 Accuracy: 1.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.39615 Accuracy: 1.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.39557 Accuracy: 1.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.39500 Accuracy: 1.00000\n",
      "Test Loss: 0.90452 Accuracy: 0.70888\n",
      "Epoch: 490 Batch:   0 Loss: 0.39441 Accuracy: 1.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.39382 Accuracy: 1.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.39325 Accuracy: 1.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.39269 Accuracy: 1.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.39213 Accuracy: 1.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.39157 Accuracy: 1.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.39101 Accuracy: 1.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.39046 Accuracy: 1.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.38992 Accuracy: 1.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.38938 Accuracy: 1.00000\n",
      "Test Loss: 0.90199 Accuracy: 0.71069\n",
      "Epoch: 500 Batch:   0 Loss: 0.38883 Accuracy: 1.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.38828 Accuracy: 1.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.38775 Accuracy: 1.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.38720 Accuracy: 1.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.38665 Accuracy: 1.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.38610 Accuracy: 1.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.38557 Accuracy: 1.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.38504 Accuracy: 1.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.38450 Accuracy: 1.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.38397 Accuracy: 1.00000\n",
      "Test Loss: 0.89951 Accuracy: 0.71169\n",
      "Epoch: 510 Batch:   0 Loss: 0.38344 Accuracy: 1.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.38290 Accuracy: 1.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.38237 Accuracy: 1.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.38185 Accuracy: 1.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.38132 Accuracy: 1.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.38079 Accuracy: 1.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.38029 Accuracy: 1.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.37977 Accuracy: 1.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.37926 Accuracy: 1.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.37875 Accuracy: 1.00000\n",
      "Test Loss: 0.89700 Accuracy: 0.71290\n",
      "Epoch: 520 Batch:   0 Loss: 0.37823 Accuracy: 1.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.37772 Accuracy: 1.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.37723 Accuracy: 1.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.37673 Accuracy: 1.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.37623 Accuracy: 1.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.37572 Accuracy: 1.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.37524 Accuracy: 1.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.37475 Accuracy: 1.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.37426 Accuracy: 1.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.37378 Accuracy: 1.00000\n",
      "Test Loss: 0.89457 Accuracy: 0.71431\n",
      "Epoch: 530 Batch:   0 Loss: 0.37328 Accuracy: 1.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.37277 Accuracy: 1.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.37229 Accuracy: 1.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.37180 Accuracy: 1.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.37132 Accuracy: 1.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.37083 Accuracy: 1.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.37037 Accuracy: 1.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.36989 Accuracy: 1.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.36942 Accuracy: 1.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.36895 Accuracy: 1.00000\n",
      "Test Loss: 0.89207 Accuracy: 0.71561\n",
      "Epoch: 540 Batch:   0 Loss: 0.36848 Accuracy: 1.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.36802 Accuracy: 1.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.36756 Accuracy: 1.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.36710 Accuracy: 1.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.36666 Accuracy: 1.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.36621 Accuracy: 1.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.36575 Accuracy: 1.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.36530 Accuracy: 1.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.36485 Accuracy: 1.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.36441 Accuracy: 1.00000\n",
      "Test Loss: 0.88952 Accuracy: 0.71611\n",
      "Epoch: 550 Batch:   0 Loss: 0.36396 Accuracy: 1.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.36351 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:37:24,632] Trial 13 finished with value: 0.7160233212706072 and parameters: {'REG_W': 3.11323756630625e-06, 'REG_B': 0.00018466641837387807, 'REG_Z': 3.370459835067725e-05, 'SPAR_W': 0.6947857066796415, 'SPAR_B': 0.7339627145414906, 'SPAR_Z': 0.6210527176469138, 'LEARNING_RATE': 0.0007713727368692295, 'NUM_EPOCHS': 552}. Best is trial 13 with value: 0.7160233212706072.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.02725 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.30922 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.95055 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.42574 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.65662 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.74970 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.77781 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.77682 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.76212 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.74181 Accuracy: 0.00000\n",
      "Test Loss: 0.96706 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.71853 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.69396 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.66957 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.64530 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.62187 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.59948 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.57837 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.55864 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.53997 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.52194 Accuracy: 0.00000\n",
      "Test Loss: 0.95063 Accuracy: 0.50030\n",
      "Epoch:  20 Batch:   0 Loss: 1.50402 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.48637 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.46939 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.45286 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.43646 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.41982 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.40369 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.38745 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.37099 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.35434 Accuracy: 0.00000\n",
      "Test Loss: 0.94051 Accuracy: 0.51306\n",
      "Epoch:  30 Batch:   0 Loss: 1.33839 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.32185 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.30549 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.28952 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.27326 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.25711 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.24101 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.22517 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.20949 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.19385 Accuracy: 0.00000\n",
      "Test Loss: 0.92019 Accuracy: 0.53889\n",
      "Epoch:  40 Batch:   0 Loss: 1.17878 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.16331 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.14812 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.13336 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.11910 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.10466 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.09063 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.07730 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.06414 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.05146 Accuracy: 0.00000\n",
      "Test Loss: 0.89152 Accuracy: 0.54421\n",
      "Epoch:  50 Batch:   0 Loss: 1.03913 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.02704 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.01526 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.00374 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.99250 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.98162 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.97094 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.96054 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.95035 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.94051 Accuracy: 0.00000\n",
      "Test Loss: 0.86465 Accuracy: 0.55345\n",
      "Epoch:  60 Batch:   0 Loss: 0.93079 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.92141 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.91231 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.90339 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.89474 Accuracy: 0.03125\n",
      "Epoch:  65 Batch:   0 Loss: 0.88629 Accuracy: 0.06250\n",
      "Epoch:  66 Batch:   0 Loss: 0.87796 Accuracy: 0.06250\n",
      "Epoch:  67 Batch:   0 Loss: 0.86973 Accuracy: 0.06250\n",
      "Epoch:  68 Batch:   0 Loss: 0.86193 Accuracy: 0.12500\n",
      "Epoch:  69 Batch:   0 Loss: 0.85437 Accuracy: 0.15625\n",
      "Test Loss: 0.84295 Accuracy: 0.56330\n",
      "Epoch:  70 Batch:   0 Loss: 0.84692 Accuracy: 0.15625\n",
      "Epoch:  71 Batch:   0 Loss: 0.83978 Accuracy: 0.18750\n",
      "Epoch:  72 Batch:   0 Loss: 0.83288 Accuracy: 0.21875\n",
      "Epoch:  73 Batch:   0 Loss: 0.82625 Accuracy: 0.21875\n",
      "Epoch:  74 Batch:   0 Loss: 0.81982 Accuracy: 0.21875\n",
      "Epoch:  75 Batch:   0 Loss: 0.81359 Accuracy: 0.25000\n",
      "Epoch:  76 Batch:   0 Loss: 0.80751 Accuracy: 0.28125\n",
      "Epoch:  77 Batch:   0 Loss: 0.80157 Accuracy: 0.28125\n",
      "Epoch:  78 Batch:   0 Loss: 0.79578 Accuracy: 0.31250\n",
      "Epoch:  79 Batch:   0 Loss: 0.79017 Accuracy: 0.34375\n",
      "Test Loss: 0.82703 Accuracy: 0.57867\n",
      "Epoch:  80 Batch:   0 Loss: 0.78469 Accuracy: 0.40625\n",
      "Epoch:  81 Batch:   0 Loss: 0.77938 Accuracy: 0.46875\n",
      "Epoch:  82 Batch:   0 Loss: 0.77423 Accuracy: 0.53125\n",
      "Epoch:  83 Batch:   0 Loss: 0.76924 Accuracy: 0.59375\n",
      "Epoch:  84 Batch:   0 Loss: 0.76433 Accuracy: 0.62500\n",
      "Epoch:  85 Batch:   0 Loss: 0.75963 Accuracy: 0.65625\n",
      "Epoch:  86 Batch:   0 Loss: 0.75506 Accuracy: 0.68750\n",
      "Epoch:  87 Batch:   0 Loss: 0.75059 Accuracy: 0.78125\n",
      "Epoch:  88 Batch:   0 Loss: 0.74628 Accuracy: 0.78125\n",
      "Epoch:  89 Batch:   0 Loss: 0.74205 Accuracy: 0.78125\n",
      "Test Loss: 0.81521 Accuracy: 0.59435\n",
      "Epoch:  90 Batch:   0 Loss: 0.73801 Accuracy: 0.81250\n",
      "Epoch:  91 Batch:   0 Loss: 0.73399 Accuracy: 0.81250\n",
      "Epoch:  92 Batch:   0 Loss: 0.73009 Accuracy: 0.84375\n",
      "Epoch:  93 Batch:   0 Loss: 0.72629 Accuracy: 0.84375\n",
      "Epoch:  94 Batch:   0 Loss: 0.72259 Accuracy: 0.84375\n",
      "Epoch:  95 Batch:   0 Loss: 0.71897 Accuracy: 0.84375\n",
      "Epoch:  96 Batch:   0 Loss: 0.71544 Accuracy: 0.84375\n",
      "Epoch:  97 Batch:   0 Loss: 0.71196 Accuracy: 0.87500\n",
      "Epoch:  98 Batch:   0 Loss: 0.70858 Accuracy: 0.87500\n",
      "Epoch:  99 Batch:   0 Loss: 0.70526 Accuracy: 0.87500\n",
      "Test Loss: 0.80591 Accuracy: 0.60972\n",
      "Epoch: 100 Batch:   0 Loss: 0.70204 Accuracy: 0.87500\n",
      "Epoch: 101 Batch:   0 Loss: 0.69889 Accuracy: 0.87500\n",
      "Epoch: 102 Batch:   0 Loss: 0.69583 Accuracy: 0.90625\n",
      "Epoch: 103 Batch:   0 Loss: 0.69282 Accuracy: 0.90625\n",
      "Epoch: 104 Batch:   0 Loss: 0.68989 Accuracy: 0.90625\n",
      "Epoch: 105 Batch:   0 Loss: 0.68703 Accuracy: 0.90625\n",
      "Epoch: 106 Batch:   0 Loss: 0.68425 Accuracy: 0.90625\n",
      "Epoch: 107 Batch:   0 Loss: 0.68150 Accuracy: 0.90625\n",
      "Epoch: 108 Batch:   0 Loss: 0.67877 Accuracy: 0.90625\n",
      "Epoch: 109 Batch:   0 Loss: 0.67612 Accuracy: 0.90625\n",
      "Test Loss: 0.79802 Accuracy: 0.62730\n",
      "Epoch: 110 Batch:   0 Loss: 0.67355 Accuracy: 0.90625\n",
      "Epoch: 111 Batch:   0 Loss: 0.67108 Accuracy: 0.90625\n",
      "Epoch: 112 Batch:   0 Loss: 0.66869 Accuracy: 0.90625\n",
      "Epoch: 113 Batch:   0 Loss: 0.66628 Accuracy: 0.90625\n",
      "Epoch: 114 Batch:   0 Loss: 0.66392 Accuracy: 0.93750\n",
      "Epoch: 115 Batch:   0 Loss: 0.66155 Accuracy: 0.93750\n",
      "Epoch: 116 Batch:   0 Loss: 0.65929 Accuracy: 0.93750\n",
      "Epoch: 117 Batch:   0 Loss: 0.65706 Accuracy: 0.93750\n",
      "Epoch: 118 Batch:   0 Loss: 0.65489 Accuracy: 0.93750\n",
      "Epoch: 119 Batch:   0 Loss: 0.65275 Accuracy: 0.96875\n",
      "Test Loss: 0.79090 Accuracy: 0.64147\n",
      "Epoch: 120 Batch:   0 Loss: 0.65067 Accuracy: 0.96875\n",
      "Epoch: 121 Batch:   0 Loss: 0.64857 Accuracy: 0.96875\n",
      "Epoch: 122 Batch:   0 Loss: 0.64655 Accuracy: 0.96875\n",
      "Epoch: 123 Batch:   0 Loss: 0.64456 Accuracy: 0.96875\n",
      "Epoch: 124 Batch:   0 Loss: 0.64260 Accuracy: 0.96875\n",
      "Epoch: 125 Batch:   0 Loss: 0.64068 Accuracy: 0.96875\n",
      "Epoch: 126 Batch:   0 Loss: 0.63879 Accuracy: 0.96875\n",
      "Epoch: 127 Batch:   0 Loss: 0.63693 Accuracy: 0.96875\n",
      "Epoch: 128 Batch:   0 Loss: 0.63509 Accuracy: 0.96875\n",
      "Epoch: 129 Batch:   0 Loss: 0.63332 Accuracy: 0.96875\n",
      "Test Loss: 0.78457 Accuracy: 0.65151\n",
      "Epoch: 130 Batch:   0 Loss: 0.63155 Accuracy: 0.96875\n",
      "Epoch: 131 Batch:   0 Loss: 0.62980 Accuracy: 0.96875\n",
      "Epoch: 132 Batch:   0 Loss: 0.62809 Accuracy: 0.96875\n",
      "Epoch: 133 Batch:   0 Loss: 0.62638 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.62469 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.62303 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.62134 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.61971 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.61810 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.61652 Accuracy: 1.00000\n",
      "Test Loss: 0.77852 Accuracy: 0.65885\n",
      "Epoch: 140 Batch:   0 Loss: 0.61497 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.61346 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.61197 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.61052 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.60908 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.60768 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.60631 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.60495 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.60362 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.60229 Accuracy: 1.00000\n",
      "Test Loss: 0.77294 Accuracy: 0.66669\n",
      "Epoch: 150 Batch:   0 Loss: 0.60098 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.59968 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.59840 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.59711 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.59584 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.59462 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.59336 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.59213 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.59092 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.58973 Accuracy: 1.00000\n",
      "Test Loss: 0.76764 Accuracy: 0.67261\n",
      "Epoch: 160 Batch:   0 Loss: 0.58855 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.58738 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.58622 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.58508 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.58395 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.58283 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.58172 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.58063 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.57955 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.57848 Accuracy: 1.00000\n",
      "Test Loss: 0.76261 Accuracy: 0.67764\n",
      "Epoch: 170 Batch:   0 Loss: 0.57742 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.57637 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.57532 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.57429 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.57325 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.57222 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.57121 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.57021 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.56924 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.56828 Accuracy: 1.00000\n",
      "Test Loss: 0.75786 Accuracy: 0.68367\n",
      "Epoch: 180 Batch:   0 Loss: 0.56735 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.56642 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.56548 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.56458 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.56369 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.56280 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.56195 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.56109 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.56024 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.55941 Accuracy: 1.00000\n",
      "Test Loss: 0.75337 Accuracy: 0.68889\n",
      "Epoch: 190 Batch:   0 Loss: 0.55858 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.55774 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.55694 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.55613 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.55532 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.55452 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.55373 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.55294 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.55214 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.55134 Accuracy: 1.00000\n",
      "Test Loss: 0.74901 Accuracy: 0.69201\n",
      "Epoch: 200 Batch:   0 Loss: 0.55056 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.54979 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.54902 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.54826 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.54747 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.54672 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.54599 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.54526 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.54455 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.54386 Accuracy: 1.00000\n",
      "Test Loss: 0.74478 Accuracy: 0.69572\n",
      "Epoch: 210 Batch:   0 Loss: 0.54315 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.54244 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.54173 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.54103 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.54033 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.53965 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.53896 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.53827 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.53758 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.53688 Accuracy: 1.00000\n",
      "Test Loss: 0.74075 Accuracy: 0.70095\n",
      "Epoch: 220 Batch:   0 Loss: 0.53619 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.53550 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.53482 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.53414 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.53345 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.53277 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.53210 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.53143 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.53077 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.53011 Accuracy: 1.00000\n",
      "Test Loss: 0.73694 Accuracy: 0.70567\n",
      "Epoch: 230 Batch:   0 Loss: 0.52944 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.52878 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.52812 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.52747 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.52682 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.52617 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.52552 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.52488 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.52424 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.52360 Accuracy: 1.00000\n",
      "Test Loss: 0.73340 Accuracy: 0.70989\n",
      "Epoch: 240 Batch:   0 Loss: 0.52296 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.52233 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.52171 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.52109 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.52047 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.51983 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.51919 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.51856 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.51793 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.51731 Accuracy: 1.00000\n",
      "Test Loss: 0.73013 Accuracy: 0.71361\n",
      "Epoch: 250 Batch:   0 Loss: 0.51669 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.51608 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.51547 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.51487 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.51426 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.51366 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.51306 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.51246 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.51186 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.51127 Accuracy: 1.00000\n",
      "Test Loss: 0.72698 Accuracy: 0.71682\n",
      "Epoch: 260 Batch:   0 Loss: 0.51068 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.51009 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.50949 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.50889 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.50828 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.50770 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.50711 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.50653 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.50594 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.50535 Accuracy: 1.00000\n",
      "Test Loss: 0.72389 Accuracy: 0.71903\n",
      "Epoch: 270 Batch:   0 Loss: 0.50475 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.50414 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.50355 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.50296 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.50237 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.50177 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.50118 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.50059 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.50000 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.49941 Accuracy: 1.00000\n",
      "Test Loss: 0.72102 Accuracy: 0.72195\n",
      "Epoch: 280 Batch:   0 Loss: 0.49882 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.49823 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.49767 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.49710 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.49653 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.49596 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.49539 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.49482 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.49425 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.49369 Accuracy: 1.00000\n",
      "Test Loss: 0.71839 Accuracy: 0.72506\n",
      "Epoch: 290 Batch:   0 Loss: 0.49313 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.49258 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.49203 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.49148 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.49092 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.49037 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.48981 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.48925 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.48869 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.48814 Accuracy: 1.00000\n",
      "Test Loss: 0.71603 Accuracy: 0.72727\n",
      "Epoch: 300 Batch:   0 Loss: 0.48758 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.48703 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.48651 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.48594 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.48540 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.48486 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.48431 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.48373 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.48318 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.48263 Accuracy: 1.00000\n",
      "Test Loss: 0.71374 Accuracy: 0.72868\n",
      "Epoch: 310 Batch:   0 Loss: 0.48209 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.48156 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.48103 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.48050 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.47998 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.47947 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.47894 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.47843 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.47791 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.47739 Accuracy: 1.00000\n",
      "Test Loss: 0.71160 Accuracy: 0.73119\n",
      "Epoch: 320 Batch:   0 Loss: 0.47686 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.47634 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.47583 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.47531 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.47479 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.47428 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.47376 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.47325 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.47274 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.47223 Accuracy: 1.00000\n",
      "Test Loss: 0.70956 Accuracy: 0.73300\n",
      "Epoch: 330 Batch:   0 Loss: 0.47172 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.47122 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.47070 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.47021 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.46971 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.46921 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.46871 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.46821 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.46770 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.46720 Accuracy: 1.00000\n",
      "Test Loss: 0.70764 Accuracy: 0.73471\n",
      "Epoch: 340 Batch:   0 Loss: 0.46670 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.46620 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.46571 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.46522 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.46472 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.46423 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.46374 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.46325 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.46277 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.46228 Accuracy: 1.00000\n",
      "Test Loss: 0.70587 Accuracy: 0.73631\n",
      "Epoch: 350 Batch:   0 Loss: 0.46180 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.46131 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.46084 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.46035 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.45987 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.45940 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.45892 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.45844 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.45797 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.45749 Accuracy: 1.00000\n",
      "Test Loss: 0.70419 Accuracy: 0.73772\n",
      "Epoch: 360 Batch:   0 Loss: 0.45702 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.45655 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.45608 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.45560 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.45514 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.45466 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.45420 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.45374 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.45327 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.45281 Accuracy: 1.00000\n",
      "Test Loss: 0.70267 Accuracy: 0.73902\n",
      "Epoch: 370 Batch:   0 Loss: 0.45234 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.45188 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.45141 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.45095 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.45049 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.45003 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.44957 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.44911 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.44866 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.44821 Accuracy: 1.00000\n",
      "Test Loss: 0.70130 Accuracy: 0.73993\n",
      "Epoch: 380 Batch:   0 Loss: 0.44776 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.44731 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.44687 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.44643 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.44600 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.44557 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.44516 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.44475 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.44434 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.44393 Accuracy: 1.00000\n",
      "Test Loss: 0.70002 Accuracy: 0.74154\n",
      "Epoch: 390 Batch:   0 Loss: 0.44352 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.44311 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.44269 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.44228 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.44187 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.44146 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.44104 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.44062 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.44021 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.43979 Accuracy: 1.00000\n",
      "Test Loss: 0.69878 Accuracy: 0.74254\n",
      "Epoch: 400 Batch:   0 Loss: 0.43937 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.43895 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.43854 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.43812 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.43772 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.43730 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.43689 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.43647 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.43605 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.43564 Accuracy: 1.00000\n",
      "Test Loss: 0.69763 Accuracy: 0.74335\n",
      "Epoch: 410 Batch:   0 Loss: 0.43523 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.43481 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.43440 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.43399 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.43358 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.43317 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.43276 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.43235 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.43195 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.43154 Accuracy: 1.00000\n",
      "Test Loss: 0.69658 Accuracy: 0.74445\n",
      "Epoch: 420 Batch:   0 Loss: 0.43114 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.43074 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.43034 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.42995 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.42955 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.42915 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.42876 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.42836 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.42796 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.42757 Accuracy: 1.00000\n",
      "Test Loss: 0.69559 Accuracy: 0.74445\n",
      "Epoch: 430 Batch:   0 Loss: 0.42717 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.42678 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.42639 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.42599 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.42560 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.42521 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.42482 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.42443 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.42404 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.42365 Accuracy: 1.00000\n",
      "Test Loss: 0.69465 Accuracy: 0.74575\n",
      "Epoch: 440 Batch:   0 Loss: 0.42326 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.42286 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.42247 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.42207 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.42167 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.42128 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.42089 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.42050 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.42011 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.41972 Accuracy: 1.00000\n",
      "Test Loss: 0.69380 Accuracy: 0.74676\n",
      "Epoch: 450 Batch:   0 Loss: 0.41933 Accuracy: 1.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.41894 Accuracy: 1.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.41856 Accuracy: 1.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.41817 Accuracy: 1.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.41779 Accuracy: 1.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.41740 Accuracy: 1.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.41702 Accuracy: 1.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.41664 Accuracy: 1.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.41626 Accuracy: 1.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.41588 Accuracy: 1.00000\n",
      "Test Loss: 0.69299 Accuracy: 0.74786\n",
      "Epoch: 460 Batch:   0 Loss: 0.41551 Accuracy: 1.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.41514 Accuracy: 1.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.41537 Accuracy: 1.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.41472 Accuracy: 1.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.41423 Accuracy: 1.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.41380 Accuracy: 1.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.41340 Accuracy: 1.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.41301 Accuracy: 1.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.41263 Accuracy: 1.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.41225 Accuracy: 1.00000\n",
      "Test Loss: 0.69237 Accuracy: 0.74796\n",
      "Epoch: 470 Batch:   0 Loss: 0.41188 Accuracy: 1.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.41150 Accuracy: 1.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.41113 Accuracy: 1.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.41076 Accuracy: 1.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.41038 Accuracy: 1.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.41000 Accuracy: 1.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.40962 Accuracy: 1.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.40925 Accuracy: 1.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.40887 Accuracy: 1.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.40849 Accuracy: 1.00000\n",
      "Test Loss: 0.69166 Accuracy: 0.74977\n",
      "Epoch: 480 Batch:   0 Loss: 0.40811 Accuracy: 1.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.40774 Accuracy: 1.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.40736 Accuracy: 1.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.40699 Accuracy: 1.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.40661 Accuracy: 1.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.40624 Accuracy: 1.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.40587 Accuracy: 1.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.40550 Accuracy: 1.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.40513 Accuracy: 1.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.40476 Accuracy: 1.00000\n",
      "Test Loss: 0.69098 Accuracy: 0.75037\n",
      "Epoch: 490 Batch:   0 Loss: 0.40439 Accuracy: 1.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.40403 Accuracy: 1.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.40365 Accuracy: 1.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.40329 Accuracy: 1.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.40293 Accuracy: 1.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.40257 Accuracy: 1.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.40221 Accuracy: 1.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.40185 Accuracy: 1.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.40149 Accuracy: 1.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.40114 Accuracy: 1.00000\n",
      "Test Loss: 0.69031 Accuracy: 0.75098\n",
      "Epoch: 500 Batch:   0 Loss: 0.40077 Accuracy: 1.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.40041 Accuracy: 1.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.40005 Accuracy: 1.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.39969 Accuracy: 1.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.39934 Accuracy: 1.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.39897 Accuracy: 1.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.39861 Accuracy: 1.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.39826 Accuracy: 1.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.39791 Accuracy: 1.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.39756 Accuracy: 1.00000\n",
      "Test Loss: 0.68968 Accuracy: 0.75158\n",
      "Epoch: 510 Batch:   0 Loss: 0.39722 Accuracy: 1.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.39687 Accuracy: 1.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.39652 Accuracy: 1.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.39618 Accuracy: 1.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.39584 Accuracy: 1.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.39550 Accuracy: 1.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.39517 Accuracy: 1.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.39483 Accuracy: 1.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.39449 Accuracy: 1.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.39415 Accuracy: 1.00000\n",
      "Test Loss: 0.68915 Accuracy: 0.75288\n",
      "Epoch: 520 Batch:   0 Loss: 0.39381 Accuracy: 1.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.39348 Accuracy: 1.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.39314 Accuracy: 1.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.39280 Accuracy: 1.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.39247 Accuracy: 1.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.39213 Accuracy: 1.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.39180 Accuracy: 1.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.39147 Accuracy: 1.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.39114 Accuracy: 1.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.39080 Accuracy: 1.00000\n",
      "Test Loss: 0.68866 Accuracy: 0.75299\n",
      "Epoch: 530 Batch:   0 Loss: 0.39047 Accuracy: 1.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.39013 Accuracy: 1.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.38981 Accuracy: 1.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.38948 Accuracy: 1.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.38916 Accuracy: 1.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.38883 Accuracy: 1.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.38850 Accuracy: 1.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.38817 Accuracy: 1.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.38784 Accuracy: 1.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.38751 Accuracy: 1.00000\n",
      "Test Loss: 0.68819 Accuracy: 0.75288\n",
      "Epoch: 540 Batch:   0 Loss: 0.38719 Accuracy: 1.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.38686 Accuracy: 1.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.38652 Accuracy: 1.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.38620 Accuracy: 1.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.38588 Accuracy: 1.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.38555 Accuracy: 1.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.38523 Accuracy: 1.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.38491 Accuracy: 1.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.38460 Accuracy: 1.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.38427 Accuracy: 1.00000\n",
      "Test Loss: 0.68771 Accuracy: 0.75429\n",
      "Epoch: 550 Batch:   0 Loss: 0.38394 Accuracy: 1.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.38361 Accuracy: 1.00000\n",
      "Epoch: 552 Batch:   0 Loss: 0.38328 Accuracy: 1.00000\n",
      "Epoch: 553 Batch:   0 Loss: 0.38296 Accuracy: 1.00000\n",
      "Epoch: 554 Batch:   0 Loss: 0.38263 Accuracy: 1.00000\n",
      "Epoch: 555 Batch:   0 Loss: 0.38231 Accuracy: 1.00000\n",
      "Epoch: 556 Batch:   0 Loss: 0.38199 Accuracy: 1.00000\n",
      "Epoch: 557 Batch:   0 Loss: 0.38166 Accuracy: 1.00000\n",
      "Epoch: 558 Batch:   0 Loss: 0.38134 Accuracy: 1.00000\n",
      "Epoch: 559 Batch:   0 Loss: 0.38101 Accuracy: 1.00000\n",
      "Test Loss: 0.68728 Accuracy: 0.75459\n",
      "Epoch: 560 Batch:   0 Loss: 0.38069 Accuracy: 1.00000\n",
      "Epoch: 561 Batch:   0 Loss: 0.38036 Accuracy: 1.00000\n",
      "Epoch: 562 Batch:   0 Loss: 0.38004 Accuracy: 1.00000\n",
      "Epoch: 563 Batch:   0 Loss: 0.37973 Accuracy: 1.00000\n",
      "Epoch: 564 Batch:   0 Loss: 0.37941 Accuracy: 1.00000\n",
      "Epoch: 565 Batch:   0 Loss: 0.37910 Accuracy: 1.00000\n",
      "Epoch: 566 Batch:   0 Loss: 0.37878 Accuracy: 1.00000\n",
      "Epoch: 567 Batch:   0 Loss: 0.37847 Accuracy: 1.00000\n",
      "Epoch: 568 Batch:   0 Loss: 0.37816 Accuracy: 1.00000\n",
      "Epoch: 569 Batch:   0 Loss: 0.37785 Accuracy: 1.00000\n",
      "Test Loss: 0.68685 Accuracy: 0.75509\n",
      "Epoch: 570 Batch:   0 Loss: 0.37753 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 571 Batch:   0 Loss: 0.37723 Accuracy: 1.00000\n",
      "Epoch: 572 Batch:   0 Loss: 0.37692 Accuracy: 1.00000\n",
      "Epoch: 573 Batch:   0 Loss: 0.37661 Accuracy: 1.00000\n",
      "Epoch: 574 Batch:   0 Loss: 0.37630 Accuracy: 1.00000\n",
      "Epoch: 575 Batch:   0 Loss: 0.37600 Accuracy: 1.00000\n",
      "Epoch: 576 Batch:   0 Loss: 0.37569 Accuracy: 1.00000\n",
      "Epoch: 577 Batch:   0 Loss: 0.37538 Accuracy: 1.00000\n",
      "Epoch: 578 Batch:   0 Loss: 0.37508 Accuracy: 1.00000\n",
      "Epoch: 579 Batch:   0 Loss: 0.37479 Accuracy: 1.00000\n",
      "Test Loss: 0.68646 Accuracy: 0.75559\n",
      "Epoch: 580 Batch:   0 Loss: 0.37449 Accuracy: 1.00000\n",
      "Epoch: 581 Batch:   0 Loss: 0.37419 Accuracy: 1.00000\n",
      "Epoch: 582 Batch:   0 Loss: 0.37389 Accuracy: 1.00000\n",
      "Epoch: 583 Batch:   0 Loss: 0.37358 Accuracy: 1.00000\n",
      "Epoch: 584 Batch:   0 Loss: 0.37329 Accuracy: 1.00000\n",
      "Epoch: 585 Batch:   0 Loss: 0.37299 Accuracy: 1.00000\n",
      "Epoch: 586 Batch:   0 Loss: 0.37269 Accuracy: 1.00000\n",
      "Epoch: 587 Batch:   0 Loss: 0.37239 Accuracy: 1.00000\n",
      "Epoch: 588 Batch:   0 Loss: 0.37209 Accuracy: 1.00000\n",
      "Epoch: 589 Batch:   0 Loss: 0.37179 Accuracy: 1.00000\n",
      "Test Loss: 0.68610 Accuracy: 0.75590\n",
      "Epoch: 590 Batch:   0 Loss: 0.37150 Accuracy: 1.00000\n",
      "Epoch: 591 Batch:   0 Loss: 0.37120 Accuracy: 1.00000\n",
      "Epoch: 592 Batch:   0 Loss: 0.37090 Accuracy: 1.00000\n",
      "Epoch: 593 Batch:   0 Loss: 0.37060 Accuracy: 1.00000\n",
      "Epoch: 594 Batch:   0 Loss: 0.37031 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:42:47,287] Trial 14 finished with value: 0.756031363088058 and parameters: {'REG_W': 3.1545272147130644e-06, 'REG_B': 0.00025738817748430687, 'REG_Z': 3.534809578054365e-05, 'SPAR_W': 0.6622823978261199, 'SPAR_B': 0.651918182305612, 'SPAR_Z': 0.6197401480486052, 'LEARNING_RATE': 0.00029791501581002825, 'NUM_EPOCHS': 595}. Best is trial 14 with value: 0.756031363088058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.01370 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.95344 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 2.26497 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 2.84428 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 3.06146 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 3.13722 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 3.15652 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 3.15042 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 3.13104 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 3.10229 Accuracy: 0.00000\n",
      "Test Loss: 1.51141 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 3.06513 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 3.01950 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 2.96723 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 2.90512 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 2.83923 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 2.76650 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 2.68622 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 2.60254 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 2.51915 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 2.43439 Accuracy: 0.00000\n",
      "Test Loss: 1.48193 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 2.34942 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 2.26350 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 2.17901 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 2.09785 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 2.02026 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.94646 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.87605 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.80951 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.74619 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.68531 Accuracy: 0.00000\n",
      "Test Loss: 1.44355 Accuracy: 0.50060\n",
      "Epoch:  30 Batch:   0 Loss: 1.62882 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.57591 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.52668 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.47970 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.43622 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.39571 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.35805 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.32298 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.29039 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.25995 Accuracy: 0.00000\n",
      "Test Loss: 1.38809 Accuracy: 0.50834\n",
      "Epoch:  40 Batch:   0 Loss: 1.23207 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.20604 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.18196 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.15953 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.13877 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.11929 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.10098 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.08399 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.06815 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.05314 Accuracy: 0.00000\n",
      "Test Loss: 1.34046 Accuracy: 0.51809\n",
      "Epoch:  50 Batch:   0 Loss: 1.03959 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.02670 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.01459 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.00306 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.99225 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.98211 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.97240 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.96326 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.95451 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.94645 Accuracy: 0.00000\n",
      "Test Loss: 1.30377 Accuracy: 0.52542\n",
      "Epoch:  60 Batch:   0 Loss: 0.93875 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.93132 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.92431 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.91762 Accuracy: 0.03125\n",
      "Epoch:  64 Batch:   0 Loss: 0.91128 Accuracy: 0.06250\n",
      "Epoch:  65 Batch:   0 Loss: 0.90523 Accuracy: 0.06250\n",
      "Epoch:  66 Batch:   0 Loss: 0.89942 Accuracy: 0.06250\n",
      "Epoch:  67 Batch:   0 Loss: 0.89375 Accuracy: 0.06250\n",
      "Epoch:  68 Batch:   0 Loss: 0.88819 Accuracy: 0.06250\n",
      "Epoch:  69 Batch:   0 Loss: 0.88300 Accuracy: 0.12500\n",
      "Test Loss: 1.27308 Accuracy: 0.53236\n",
      "Epoch:  70 Batch:   0 Loss: 0.87801 Accuracy: 0.12500\n",
      "Epoch:  71 Batch:   0 Loss: 0.87313 Accuracy: 0.12500\n",
      "Epoch:  72 Batch:   0 Loss: 0.86842 Accuracy: 0.12500\n",
      "Epoch:  73 Batch:   0 Loss: 0.86371 Accuracy: 0.12500\n",
      "Epoch:  74 Batch:   0 Loss: 0.85929 Accuracy: 0.12500\n",
      "Epoch:  75 Batch:   0 Loss: 0.85508 Accuracy: 0.12500\n",
      "Epoch:  76 Batch:   0 Loss: 0.85100 Accuracy: 0.15625\n",
      "Epoch:  77 Batch:   0 Loss: 0.84713 Accuracy: 0.15625\n",
      "Epoch:  78 Batch:   0 Loss: 0.84347 Accuracy: 0.18750\n",
      "Epoch:  79 Batch:   0 Loss: 0.83974 Accuracy: 0.21875\n",
      "Test Loss: 1.24673 Accuracy: 0.53788\n",
      "Epoch:  80 Batch:   0 Loss: 0.83624 Accuracy: 0.25000\n",
      "Epoch:  81 Batch:   0 Loss: 0.83276 Accuracy: 0.25000\n",
      "Epoch:  82 Batch:   0 Loss: 0.82937 Accuracy: 0.25000\n",
      "Epoch:  83 Batch:   0 Loss: 0.82609 Accuracy: 0.25000\n",
      "Epoch:  84 Batch:   0 Loss: 0.82289 Accuracy: 0.31250\n",
      "Epoch:  85 Batch:   0 Loss: 0.81983 Accuracy: 0.34375\n",
      "Epoch:  86 Batch:   0 Loss: 0.81680 Accuracy: 0.37500\n",
      "Epoch:  87 Batch:   0 Loss: 0.81390 Accuracy: 0.37500\n",
      "Epoch:  88 Batch:   0 Loss: 0.81098 Accuracy: 0.37500\n",
      "Epoch:  89 Batch:   0 Loss: 0.80816 Accuracy: 0.37500\n",
      "Test Loss: 1.22353 Accuracy: 0.54351\n",
      "Epoch:  90 Batch:   0 Loss: 0.80543 Accuracy: 0.37500\n",
      "Epoch:  91 Batch:   0 Loss: 0.80265 Accuracy: 0.37500\n",
      "Epoch:  92 Batch:   0 Loss: 0.80003 Accuracy: 0.40625\n",
      "Epoch:  93 Batch:   0 Loss: 0.79745 Accuracy: 0.40625\n",
      "Epoch:  94 Batch:   0 Loss: 0.79491 Accuracy: 0.40625\n",
      "Epoch:  95 Batch:   0 Loss: 0.79246 Accuracy: 0.40625\n",
      "Epoch:  96 Batch:   0 Loss: 0.79000 Accuracy: 0.40625\n",
      "Epoch:  97 Batch:   0 Loss: 0.78752 Accuracy: 0.40625\n",
      "Epoch:  98 Batch:   0 Loss: 0.78511 Accuracy: 0.40625\n",
      "Epoch:  99 Batch:   0 Loss: 0.78273 Accuracy: 0.43750\n",
      "Test Loss: 1.20204 Accuracy: 0.54843\n",
      "Epoch: 100 Batch:   0 Loss: 0.78039 Accuracy: 0.50000\n",
      "Epoch: 101 Batch:   0 Loss: 0.77807 Accuracy: 0.50000\n",
      "Epoch: 102 Batch:   0 Loss: 0.77572 Accuracy: 0.53125\n",
      "Epoch: 103 Batch:   0 Loss: 0.77358 Accuracy: 0.53125\n",
      "Epoch: 104 Batch:   0 Loss: 0.77146 Accuracy: 0.53125\n",
      "Epoch: 105 Batch:   0 Loss: 0.76936 Accuracy: 0.56250\n",
      "Epoch: 106 Batch:   0 Loss: 0.76727 Accuracy: 0.56250\n",
      "Epoch: 107 Batch:   0 Loss: 0.76522 Accuracy: 0.56250\n",
      "Epoch: 108 Batch:   0 Loss: 0.76321 Accuracy: 0.56250\n",
      "Epoch: 109 Batch:   0 Loss: 0.76121 Accuracy: 0.62500\n",
      "Test Loss: 1.18194 Accuracy: 0.55346\n",
      "Epoch: 110 Batch:   0 Loss: 0.75913 Accuracy: 0.65625\n",
      "Epoch: 111 Batch:   0 Loss: 0.75708 Accuracy: 0.71875\n",
      "Epoch: 112 Batch:   0 Loss: 0.75505 Accuracy: 0.71875\n",
      "Epoch: 113 Batch:   0 Loss: 0.75305 Accuracy: 0.71875\n",
      "Epoch: 114 Batch:   0 Loss: 0.75106 Accuracy: 0.71875\n",
      "Epoch: 115 Batch:   0 Loss: 0.74910 Accuracy: 0.75000\n",
      "Epoch: 116 Batch:   0 Loss: 0.74716 Accuracy: 0.75000\n",
      "Epoch: 117 Batch:   0 Loss: 0.74524 Accuracy: 0.75000\n",
      "Epoch: 118 Batch:   0 Loss: 0.74332 Accuracy: 0.75000\n",
      "Epoch: 119 Batch:   0 Loss: 0.74145 Accuracy: 0.75000\n",
      "Test Loss: 1.16305 Accuracy: 0.56089\n",
      "Epoch: 120 Batch:   0 Loss: 0.73961 Accuracy: 0.75000\n",
      "Epoch: 121 Batch:   0 Loss: 0.73777 Accuracy: 0.75000\n",
      "Epoch: 122 Batch:   0 Loss: 0.73593 Accuracy: 0.75000\n",
      "Epoch: 123 Batch:   0 Loss: 0.73414 Accuracy: 0.75000\n",
      "Epoch: 124 Batch:   0 Loss: 0.73234 Accuracy: 0.75000\n",
      "Epoch: 125 Batch:   0 Loss: 0.73050 Accuracy: 0.75000\n",
      "Epoch: 126 Batch:   0 Loss: 0.72869 Accuracy: 0.75000\n",
      "Epoch: 127 Batch:   0 Loss: 0.72695 Accuracy: 0.75000\n",
      "Epoch: 128 Batch:   0 Loss: 0.72512 Accuracy: 0.75000\n",
      "Epoch: 129 Batch:   0 Loss: 0.72329 Accuracy: 0.75000\n",
      "Test Loss: 1.14485 Accuracy: 0.56642\n",
      "Epoch: 130 Batch:   0 Loss: 0.72166 Accuracy: 0.75000\n",
      "Epoch: 131 Batch:   0 Loss: 0.72003 Accuracy: 0.75000\n",
      "Epoch: 132 Batch:   0 Loss: 0.71843 Accuracy: 0.75000\n",
      "Epoch: 133 Batch:   0 Loss: 0.71684 Accuracy: 0.75000\n",
      "Epoch: 134 Batch:   0 Loss: 0.71658 Accuracy: 0.75000\n",
      "Epoch: 135 Batch:   0 Loss: 0.71389 Accuracy: 0.75000\n",
      "Epoch: 136 Batch:   0 Loss: 0.71201 Accuracy: 0.75000\n",
      "Epoch: 137 Batch:   0 Loss: 0.71042 Accuracy: 0.75000\n",
      "Epoch: 138 Batch:   0 Loss: 0.70890 Accuracy: 0.75000\n",
      "Epoch: 139 Batch:   0 Loss: 0.70741 Accuracy: 0.75000\n",
      "Test Loss: 1.12791 Accuracy: 0.57455\n",
      "Epoch: 140 Batch:   0 Loss: 0.70592 Accuracy: 0.75000\n",
      "Epoch: 141 Batch:   0 Loss: 0.70445 Accuracy: 0.75000\n",
      "Epoch: 142 Batch:   0 Loss: 0.70293 Accuracy: 0.75000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.70141 Accuracy: 0.78125\n",
      "Epoch: 144 Batch:   0 Loss: 0.69991 Accuracy: 0.78125\n",
      "Epoch: 145 Batch:   0 Loss: 0.69838 Accuracy: 0.78125\n",
      "Epoch: 146 Batch:   0 Loss: 0.69681 Accuracy: 0.78125\n",
      "Epoch: 147 Batch:   0 Loss: 0.69531 Accuracy: 0.78125\n",
      "Epoch: 148 Batch:   0 Loss: 0.69382 Accuracy: 0.78125\n",
      "Epoch: 149 Batch:   0 Loss: 0.69234 Accuracy: 0.81250\n",
      "Test Loss: 1.11215 Accuracy: 0.58359\n",
      "Epoch: 150 Batch:   0 Loss: 0.69087 Accuracy: 0.81250\n",
      "Epoch: 151 Batch:   0 Loss: 0.68948 Accuracy: 0.81250\n",
      "Epoch: 152 Batch:   0 Loss: 0.68815 Accuracy: 0.81250\n",
      "Epoch: 153 Batch:   0 Loss: 0.68685 Accuracy: 0.81250\n",
      "Epoch: 154 Batch:   0 Loss: 0.68551 Accuracy: 0.81250\n",
      "Epoch: 155 Batch:   0 Loss: 0.68419 Accuracy: 0.81250\n",
      "Epoch: 156 Batch:   0 Loss: 0.68286 Accuracy: 0.81250\n",
      "Epoch: 157 Batch:   0 Loss: 0.68153 Accuracy: 0.81250\n",
      "Epoch: 158 Batch:   0 Loss: 0.68019 Accuracy: 0.81250\n",
      "Epoch: 159 Batch:   0 Loss: 0.67887 Accuracy: 0.81250\n",
      "Test Loss: 1.09718 Accuracy: 0.59193\n",
      "Epoch: 160 Batch:   0 Loss: 0.67758 Accuracy: 0.81250\n",
      "Epoch: 161 Batch:   0 Loss: 0.67630 Accuracy: 0.81250\n",
      "Epoch: 162 Batch:   0 Loss: 0.67505 Accuracy: 0.81250\n",
      "Epoch: 163 Batch:   0 Loss: 0.67380 Accuracy: 0.81250\n",
      "Epoch: 164 Batch:   0 Loss: 0.67256 Accuracy: 0.81250\n",
      "Epoch: 165 Batch:   0 Loss: 0.67128 Accuracy: 0.81250\n",
      "Epoch: 166 Batch:   0 Loss: 0.67003 Accuracy: 0.81250\n",
      "Epoch: 167 Batch:   0 Loss: 0.66879 Accuracy: 0.81250\n",
      "Epoch: 168 Batch:   0 Loss: 0.66755 Accuracy: 0.81250\n",
      "Epoch: 169 Batch:   0 Loss: 0.66631 Accuracy: 0.81250\n",
      "Test Loss: 1.08346 Accuracy: 0.59967\n",
      "Epoch: 170 Batch:   0 Loss: 0.66508 Accuracy: 0.87500\n",
      "Epoch: 171 Batch:   0 Loss: 0.66386 Accuracy: 0.87500\n",
      "Epoch: 172 Batch:   0 Loss: 0.66264 Accuracy: 0.87500\n",
      "Epoch: 173 Batch:   0 Loss: 0.66139 Accuracy: 0.87500\n",
      "Epoch: 174 Batch:   0 Loss: 0.66016 Accuracy: 0.90625\n",
      "Epoch: 175 Batch:   0 Loss: 0.65893 Accuracy: 0.90625\n",
      "Epoch: 176 Batch:   0 Loss: 0.65774 Accuracy: 0.90625\n",
      "Epoch: 177 Batch:   0 Loss: 0.65653 Accuracy: 0.90625\n",
      "Epoch: 178 Batch:   0 Loss: 0.65535 Accuracy: 0.90625\n",
      "Epoch: 179 Batch:   0 Loss: 0.65414 Accuracy: 0.90625\n",
      "Test Loss: 1.07098 Accuracy: 0.60691\n",
      "Epoch: 180 Batch:   0 Loss: 0.65292 Accuracy: 0.90625\n",
      "Epoch: 181 Batch:   0 Loss: 0.65170 Accuracy: 0.90625\n",
      "Epoch: 182 Batch:   0 Loss: 0.65051 Accuracy: 0.90625\n",
      "Epoch: 183 Batch:   0 Loss: 0.64935 Accuracy: 0.90625\n",
      "Epoch: 184 Batch:   0 Loss: 0.64824 Accuracy: 0.90625\n",
      "Epoch: 185 Batch:   0 Loss: 0.64701 Accuracy: 0.93750\n",
      "Epoch: 186 Batch:   0 Loss: 0.64581 Accuracy: 0.93750\n",
      "Epoch: 187 Batch:   0 Loss: 0.64464 Accuracy: 0.93750\n",
      "Epoch: 188 Batch:   0 Loss: 0.64348 Accuracy: 0.96875\n",
      "Epoch: 189 Batch:   0 Loss: 0.64231 Accuracy: 0.96875\n",
      "Test Loss: 1.05979 Accuracy: 0.61555\n",
      "Epoch: 190 Batch:   0 Loss: 0.64120 Accuracy: 0.96875\n",
      "Epoch: 191 Batch:   0 Loss: 0.64001 Accuracy: 0.96875\n",
      "Epoch: 192 Batch:   0 Loss: 0.63887 Accuracy: 0.96875\n",
      "Epoch: 193 Batch:   0 Loss: 0.63774 Accuracy: 0.96875\n",
      "Epoch: 194 Batch:   0 Loss: 0.63662 Accuracy: 0.96875\n",
      "Epoch: 195 Batch:   0 Loss: 0.63550 Accuracy: 0.96875\n",
      "Epoch: 196 Batch:   0 Loss: 0.63438 Accuracy: 0.96875\n",
      "Epoch: 197 Batch:   0 Loss: 0.63330 Accuracy: 0.96875\n",
      "Epoch: 198 Batch:   0 Loss: 0.63224 Accuracy: 0.96875\n",
      "Epoch: 199 Batch:   0 Loss: 0.63115 Accuracy: 0.96875\n",
      "Test Loss: 1.04974 Accuracy: 0.62349\n",
      "Epoch: 200 Batch:   0 Loss: 0.63006 Accuracy: 0.96875\n",
      "Epoch: 201 Batch:   0 Loss: 0.62974 Accuracy: 0.96875\n",
      "Epoch: 202 Batch:   0 Loss: 0.62798 Accuracy: 0.96875\n",
      "Epoch: 203 Batch:   0 Loss: 0.62671 Accuracy: 0.96875\n",
      "Epoch: 204 Batch:   0 Loss: 0.62560 Accuracy: 0.96875\n",
      "Epoch: 205 Batch:   0 Loss: 0.62455 Accuracy: 0.96875\n",
      "Epoch: 206 Batch:   0 Loss: 0.62351 Accuracy: 0.96875\n",
      "Epoch: 207 Batch:   0 Loss: 0.62248 Accuracy: 0.96875\n",
      "Epoch: 208 Batch:   0 Loss: 0.62144 Accuracy: 0.96875\n",
      "Epoch: 209 Batch:   0 Loss: 0.62038 Accuracy: 0.96875\n",
      "Test Loss: 1.04058 Accuracy: 0.62931\n",
      "Epoch: 210 Batch:   0 Loss: 0.61933 Accuracy: 0.96875\n",
      "Epoch: 211 Batch:   0 Loss: 0.61827 Accuracy: 0.96875\n",
      "Epoch: 212 Batch:   0 Loss: 0.61722 Accuracy: 0.96875\n",
      "Epoch: 213 Batch:   0 Loss: 0.61616 Accuracy: 0.96875\n",
      "Epoch: 214 Batch:   0 Loss: 0.61510 Accuracy: 0.96875\n",
      "Epoch: 215 Batch:   0 Loss: 0.61403 Accuracy: 0.96875\n",
      "Epoch: 216 Batch:   0 Loss: 0.61297 Accuracy: 0.96875\n",
      "Epoch: 217 Batch:   0 Loss: 0.61191 Accuracy: 0.96875\n",
      "Epoch: 218 Batch:   0 Loss: 0.61086 Accuracy: 0.96875\n",
      "Epoch: 219 Batch:   0 Loss: 0.60983 Accuracy: 0.96875\n",
      "Test Loss: 1.03190 Accuracy: 0.63544\n",
      "Epoch: 220 Batch:   0 Loss: 0.60880 Accuracy: 0.96875\n",
      "Epoch: 221 Batch:   0 Loss: 0.60776 Accuracy: 0.96875\n",
      "Epoch: 222 Batch:   0 Loss: 0.60676 Accuracy: 0.96875\n",
      "Epoch: 223 Batch:   0 Loss: 0.60570 Accuracy: 0.96875\n",
      "Epoch: 224 Batch:   0 Loss: 0.60467 Accuracy: 0.96875\n",
      "Epoch: 225 Batch:   0 Loss: 0.60365 Accuracy: 0.96875\n",
      "Epoch: 226 Batch:   0 Loss: 0.60259 Accuracy: 0.96875\n",
      "Epoch: 227 Batch:   0 Loss: 0.60154 Accuracy: 0.96875\n",
      "Epoch: 228 Batch:   0 Loss: 0.60049 Accuracy: 0.96875\n",
      "Epoch: 229 Batch:   0 Loss: 0.59944 Accuracy: 0.96875\n",
      "Test Loss: 1.02363 Accuracy: 0.64077\n",
      "Epoch: 230 Batch:   0 Loss: 0.59840 Accuracy: 0.96875\n",
      "Epoch: 231 Batch:   0 Loss: 0.59738 Accuracy: 0.96875\n",
      "Epoch: 232 Batch:   0 Loss: 0.59633 Accuracy: 0.96875\n",
      "Epoch: 233 Batch:   0 Loss: 0.59530 Accuracy: 0.96875\n",
      "Epoch: 234 Batch:   0 Loss: 0.59430 Accuracy: 0.96875\n",
      "Epoch: 235 Batch:   0 Loss: 0.59330 Accuracy: 0.96875\n",
      "Epoch: 236 Batch:   0 Loss: 0.59230 Accuracy: 0.96875\n",
      "Epoch: 237 Batch:   0 Loss: 0.59132 Accuracy: 0.96875\n",
      "Epoch: 238 Batch:   0 Loss: 0.59033 Accuracy: 0.96875\n",
      "Epoch: 239 Batch:   0 Loss: 0.58935 Accuracy: 0.96875\n",
      "Test Loss: 1.01604 Accuracy: 0.64679\n",
      "Epoch: 240 Batch:   0 Loss: 0.58840 Accuracy: 0.96875\n",
      "Epoch: 241 Batch:   0 Loss: 0.58742 Accuracy: 0.96875\n",
      "Epoch: 242 Batch:   0 Loss: 0.58641 Accuracy: 0.96875\n",
      "Epoch: 243 Batch:   0 Loss: 0.58542 Accuracy: 0.96875\n",
      "Epoch: 244 Batch:   0 Loss: 0.58444 Accuracy: 0.96875\n",
      "Epoch: 245 Batch:   0 Loss: 0.58347 Accuracy: 0.96875\n",
      "Epoch: 246 Batch:   0 Loss: 0.58251 Accuracy: 0.96875\n",
      "Epoch: 247 Batch:   0 Loss: 0.58156 Accuracy: 0.96875\n",
      "Epoch: 248 Batch:   0 Loss: 0.58064 Accuracy: 0.96875\n",
      "Epoch: 249 Batch:   0 Loss: 0.57971 Accuracy: 0.96875\n",
      "Test Loss: 1.00905 Accuracy: 0.65091\n",
      "Epoch: 250 Batch:   0 Loss: 0.57877 Accuracy: 0.96875\n",
      "Epoch: 251 Batch:   0 Loss: 0.57779 Accuracy: 0.96875\n",
      "Epoch: 252 Batch:   0 Loss: 0.57684 Accuracy: 0.96875\n",
      "Epoch: 253 Batch:   0 Loss: 0.57591 Accuracy: 0.96875\n",
      "Epoch: 254 Batch:   0 Loss: 0.57497 Accuracy: 0.96875\n",
      "Epoch: 255 Batch:   0 Loss: 0.57403 Accuracy: 0.96875\n",
      "Epoch: 256 Batch:   0 Loss: 0.57310 Accuracy: 0.96875\n",
      "Epoch: 257 Batch:   0 Loss: 0.57217 Accuracy: 0.96875\n",
      "Epoch: 258 Batch:   0 Loss: 0.57122 Accuracy: 0.96875\n",
      "Epoch: 259 Batch:   0 Loss: 0.57032 Accuracy: 0.96875\n",
      "Test Loss: 1.00258 Accuracy: 0.65534\n",
      "Epoch: 260 Batch:   0 Loss: 0.56941 Accuracy: 0.96875\n",
      "Epoch: 261 Batch:   0 Loss: 0.56850 Accuracy: 0.96875\n",
      "Epoch: 262 Batch:   0 Loss: 0.56760 Accuracy: 0.96875\n",
      "Epoch: 263 Batch:   0 Loss: 0.56669 Accuracy: 0.96875\n",
      "Epoch: 264 Batch:   0 Loss: 0.56577 Accuracy: 0.96875\n",
      "Epoch: 265 Batch:   0 Loss: 0.56487 Accuracy: 0.96875\n",
      "Epoch: 266 Batch:   0 Loss: 0.56401 Accuracy: 0.96875\n",
      "Epoch: 267 Batch:   0 Loss: 0.56314 Accuracy: 0.96875\n",
      "Epoch: 268 Batch:   0 Loss: 0.56229 Accuracy: 0.96875\n",
      "Epoch: 269 Batch:   0 Loss: 0.56144 Accuracy: 0.96875\n",
      "Test Loss: 0.99651 Accuracy: 0.65986\n",
      "Epoch: 270 Batch:   0 Loss: 0.56058 Accuracy: 0.96875\n",
      "Epoch: 271 Batch:   0 Loss: 0.55972 Accuracy: 0.96875\n",
      "Epoch: 272 Batch:   0 Loss: 0.55890 Accuracy: 0.96875\n",
      "Epoch: 273 Batch:   0 Loss: 0.55807 Accuracy: 0.96875\n",
      "Epoch: 274 Batch:   0 Loss: 0.55724 Accuracy: 0.96875\n",
      "Epoch: 275 Batch:   0 Loss: 0.55641 Accuracy: 0.96875\n",
      "Epoch: 276 Batch:   0 Loss: 0.55559 Accuracy: 0.96875\n",
      "Epoch: 277 Batch:   0 Loss: 0.55476 Accuracy: 0.96875\n",
      "Epoch: 278 Batch:   0 Loss: 0.55395 Accuracy: 0.96875\n",
      "Epoch: 279 Batch:   0 Loss: 0.55313 Accuracy: 0.96875\n",
      "Test Loss: 0.99085 Accuracy: 0.66327\n",
      "Epoch: 280 Batch:   0 Loss: 0.55232 Accuracy: 0.96875\n",
      "Epoch: 281 Batch:   0 Loss: 0.55151 Accuracy: 0.96875\n",
      "Epoch: 282 Batch:   0 Loss: 0.55069 Accuracy: 0.96875\n",
      "Epoch: 283 Batch:   0 Loss: 0.54990 Accuracy: 0.96875\n",
      "Epoch: 284 Batch:   0 Loss: 0.54910 Accuracy: 0.96875\n",
      "Epoch: 285 Batch:   0 Loss: 0.54831 Accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.54751 Accuracy: 0.96875\n",
      "Epoch: 287 Batch:   0 Loss: 0.54671 Accuracy: 0.96875\n",
      "Epoch: 288 Batch:   0 Loss: 0.54593 Accuracy: 0.96875\n",
      "Epoch: 289 Batch:   0 Loss: 0.54517 Accuracy: 0.96875\n",
      "Test Loss: 0.98558 Accuracy: 0.66569\n",
      "Epoch: 290 Batch:   0 Loss: 0.54437 Accuracy: 0.96875\n",
      "Epoch: 291 Batch:   0 Loss: 0.54358 Accuracy: 0.96875\n",
      "Epoch: 292 Batch:   0 Loss: 0.54280 Accuracy: 0.96875\n",
      "Epoch: 293 Batch:   0 Loss: 0.54202 Accuracy: 0.96875\n",
      "Epoch: 294 Batch:   0 Loss: 0.54124 Accuracy: 0.96875\n",
      "Epoch: 295 Batch:   0 Loss: 0.54047 Accuracy: 0.96875\n",
      "Epoch: 296 Batch:   0 Loss: 0.53969 Accuracy: 0.96875\n",
      "Epoch: 297 Batch:   0 Loss: 0.53892 Accuracy: 0.96875\n",
      "Epoch: 298 Batch:   0 Loss: 0.53815 Accuracy: 0.96875\n",
      "Epoch: 299 Batch:   0 Loss: 0.53738 Accuracy: 0.96875\n",
      "Test Loss: 0.98070 Accuracy: 0.66850\n",
      "Epoch: 300 Batch:   0 Loss: 0.53662 Accuracy: 0.96875\n",
      "Epoch: 301 Batch:   0 Loss: 0.53586 Accuracy: 0.96875\n",
      "Epoch: 302 Batch:   0 Loss: 0.53510 Accuracy: 0.96875\n",
      "Epoch: 303 Batch:   0 Loss: 0.53434 Accuracy: 0.96875\n",
      "Epoch: 304 Batch:   0 Loss: 0.53361 Accuracy: 0.96875\n",
      "Epoch: 305 Batch:   0 Loss: 0.53284 Accuracy: 0.96875\n",
      "Epoch: 306 Batch:   0 Loss: 0.53207 Accuracy: 0.96875\n",
      "Epoch: 307 Batch:   0 Loss: 0.53132 Accuracy: 0.96875\n",
      "Epoch: 308 Batch:   0 Loss: 0.53058 Accuracy: 0.96875\n",
      "Epoch: 309 Batch:   0 Loss: 0.52979 Accuracy: 0.96875\n",
      "Test Loss: 0.97615 Accuracy: 0.67262\n",
      "Epoch: 310 Batch:   0 Loss: 0.52905 Accuracy: 0.96875\n",
      "Epoch: 311 Batch:   0 Loss: 0.52831 Accuracy: 0.96875\n",
      "Epoch: 312 Batch:   0 Loss: 0.52758 Accuracy: 0.96875\n",
      "Epoch: 313 Batch:   0 Loss: 0.52683 Accuracy: 0.96875\n",
      "Epoch: 314 Batch:   0 Loss: 0.52612 Accuracy: 0.96875\n",
      "Epoch: 315 Batch:   0 Loss: 0.52540 Accuracy: 0.96875\n",
      "Epoch: 316 Batch:   0 Loss: 0.52467 Accuracy: 0.96875\n",
      "Epoch: 317 Batch:   0 Loss: 0.52395 Accuracy: 0.96875\n",
      "Epoch: 318 Batch:   0 Loss: 0.52324 Accuracy: 0.96875\n",
      "Epoch: 319 Batch:   0 Loss: 0.52253 Accuracy: 0.96875\n",
      "Test Loss: 0.97196 Accuracy: 0.67503\n",
      "Epoch: 320 Batch:   0 Loss: 0.52182 Accuracy: 0.96875\n",
      "Epoch: 321 Batch:   0 Loss: 0.52111 Accuracy: 0.96875\n",
      "Epoch: 322 Batch:   0 Loss: 0.52041 Accuracy: 0.96875\n",
      "Epoch: 323 Batch:   0 Loss: 0.51971 Accuracy: 0.96875\n",
      "Epoch: 324 Batch:   0 Loss: 0.51901 Accuracy: 0.96875\n",
      "Epoch: 325 Batch:   0 Loss: 0.51833 Accuracy: 0.96875\n",
      "Epoch: 326 Batch:   0 Loss: 0.51764 Accuracy: 0.96875\n",
      "Epoch: 327 Batch:   0 Loss: 0.51692 Accuracy: 0.96875\n",
      "Epoch: 328 Batch:   0 Loss: 0.51621 Accuracy: 0.96875\n",
      "Epoch: 329 Batch:   0 Loss: 0.51552 Accuracy: 0.96875\n",
      "Test Loss: 0.96806 Accuracy: 0.67734\n",
      "Epoch: 330 Batch:   0 Loss: 0.51481 Accuracy: 0.96875\n",
      "Epoch: 331 Batch:   0 Loss: 0.51410 Accuracy: 0.96875\n",
      "Epoch: 332 Batch:   0 Loss: 0.51340 Accuracy: 0.96875\n",
      "Epoch: 333 Batch:   0 Loss: 0.51271 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.51202 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.51133 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.51065 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.50997 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.50930 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.50865 Accuracy: 1.00000\n",
      "Test Loss: 0.96437 Accuracy: 0.67985\n",
      "Epoch: 340 Batch:   0 Loss: 0.50796 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.50727 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.50662 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.50594 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.50530 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.50469 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.50405 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.50341 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.50278 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.50214 Accuracy: 1.00000\n",
      "Test Loss: 0.96082 Accuracy: 0.68247\n",
      "Epoch: 350 Batch:   0 Loss: 0.50151 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.50087 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.50026 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.49964 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.49901 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.49839 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.49779 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.49714 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.49651 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.49588 Accuracy: 1.00000\n",
      "Test Loss: 0.95731 Accuracy: 0.68387\n",
      "Epoch: 360 Batch:   0 Loss: 0.49525 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.49465 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.49406 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.49346 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.49283 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.49291 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.49198 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.49124 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.49058 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.48993 Accuracy: 1.00000\n",
      "Test Loss: 0.95419 Accuracy: 0.68618\n",
      "Epoch: 370 Batch:   0 Loss: 0.48930 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.48867 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.48805 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.48746 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.48687 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.48634 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.48579 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.48522 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.48467 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.48410 Accuracy: 1.00000\n",
      "Test Loss: 0.95084 Accuracy: 0.68819\n",
      "Epoch: 380 Batch:   0 Loss: 0.48352 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.48295 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.48238 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.48181 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.48124 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.48069 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.48012 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.47953 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.47896 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.47840 Accuracy: 1.00000\n",
      "Test Loss: 0.94760 Accuracy: 0.69101\n",
      "Epoch: 390 Batch:   0 Loss: 0.47783 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.47727 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.47670 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.47615 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.47560 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.47508 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.47453 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.47399 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.47345 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.47290 Accuracy: 1.00000\n",
      "Test Loss: 0.94456 Accuracy: 0.69281\n",
      "Epoch: 400 Batch:   0 Loss: 0.47235 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.47179 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.47126 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.47072 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.47018 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.46966 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.46912 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.46859 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.46807 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.46754 Accuracy: 1.00000\n",
      "Test Loss: 0.94154 Accuracy: 0.69462\n",
      "Epoch: 410 Batch:   0 Loss: 0.46701 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.46649 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.46597 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.46544 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.46493 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.46440 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.46386 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.46335 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.46283 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.46232 Accuracy: 1.00000\n",
      "Test Loss: 0.93859 Accuracy: 0.69563\n",
      "Epoch: 420 Batch:   0 Loss: 0.46181 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.46130 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.46079 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.46029 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.45976 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.45926 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.45876 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.45826 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.45776 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.45726 Accuracy: 1.00000\n",
      "Test Loss: 0.93576 Accuracy: 0.69633\n",
      "Epoch: 430 Batch:   0 Loss: 0.45676 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.45626 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.45576 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.45527 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.45478 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.45429 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.45381 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.45332 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.45284 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.45236 Accuracy: 1.00000\n",
      "Test Loss: 0.93299 Accuracy: 0.69754\n",
      "Epoch: 440 Batch:   0 Loss: 0.45188 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.45140 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.45092 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.45044 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.44997 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.44949 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.44902 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.44855 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.44809 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.44763 Accuracy: 1.00000\n",
      "Test Loss: 0.93026 Accuracy: 0.69894\n",
      "Epoch: 450 Batch:   0 Loss: 0.44716 Accuracy: 1.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.44670 Accuracy: 1.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.44623 Accuracy: 1.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.44578 Accuracy: 1.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.44532 Accuracy: 1.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.44487 Accuracy: 1.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.44441 Accuracy: 1.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.44397 Accuracy: 1.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.44351 Accuracy: 1.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.44305 Accuracy: 1.00000\n",
      "Test Loss: 0.92761 Accuracy: 0.69964\n",
      "Epoch: 460 Batch:   0 Loss: 0.44260 Accuracy: 1.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.44215 Accuracy: 1.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.44169 Accuracy: 1.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.44129 Accuracy: 1.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.44086 Accuracy: 1.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.44042 Accuracy: 1.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.43999 Accuracy: 1.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.43956 Accuracy: 1.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.43913 Accuracy: 1.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.43871 Accuracy: 1.00000\n",
      "Test Loss: 0.92499 Accuracy: 0.70055\n",
      "Epoch: 470 Batch:   0 Loss: 0.43828 Accuracy: 1.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.43784 Accuracy: 1.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.43741 Accuracy: 1.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.43698 Accuracy: 1.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.43655 Accuracy: 1.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.43612 Accuracy: 1.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.43567 Accuracy: 1.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.43523 Accuracy: 1.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.43480 Accuracy: 1.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.43436 Accuracy: 1.00000\n",
      "Test Loss: 0.92239 Accuracy: 0.70195\n",
      "Epoch: 480 Batch:   0 Loss: 0.43392 Accuracy: 1.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.43348 Accuracy: 1.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.43306 Accuracy: 1.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.43263 Accuracy: 1.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.43220 Accuracy: 1.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.43177 Accuracy: 1.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.43134 Accuracy: 1.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.43091 Accuracy: 1.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.43048 Accuracy: 1.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.43006 Accuracy: 1.00000\n",
      "Test Loss: 0.91980 Accuracy: 0.70326\n",
      "Epoch: 490 Batch:   0 Loss: 0.42963 Accuracy: 1.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.42921 Accuracy: 1.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.42879 Accuracy: 1.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.42836 Accuracy: 1.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.42794 Accuracy: 1.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.42752 Accuracy: 1.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.42710 Accuracy: 1.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.42667 Accuracy: 1.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.42627 Accuracy: 1.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.42588 Accuracy: 1.00000\n",
      "Test Loss: 0.91722 Accuracy: 0.70497\n",
      "Epoch: 500 Batch:   0 Loss: 0.42546 Accuracy: 1.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.42501 Accuracy: 1.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.42457 Accuracy: 1.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.42414 Accuracy: 1.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.42370 Accuracy: 1.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.42328 Accuracy: 1.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.42285 Accuracy: 1.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.42242 Accuracy: 1.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.42201 Accuracy: 1.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.42158 Accuracy: 1.00000\n",
      "Test Loss: 0.91457 Accuracy: 0.70668\n",
      "Epoch: 510 Batch:   0 Loss: 0.42116 Accuracy: 1.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.42073 Accuracy: 1.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.42030 Accuracy: 1.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.41991 Accuracy: 1.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.41947 Accuracy: 1.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.41904 Accuracy: 1.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.41863 Accuracy: 1.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.41821 Accuracy: 1.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.41780 Accuracy: 1.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.41738 Accuracy: 1.00000\n",
      "Test Loss: 0.91199 Accuracy: 0.70788\n",
      "Epoch: 520 Batch:   0 Loss: 0.41697 Accuracy: 1.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.41655 Accuracy: 1.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.41613 Accuracy: 1.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.41572 Accuracy: 1.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.41532 Accuracy: 1.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.41490 Accuracy: 1.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.41449 Accuracy: 1.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.41409 Accuracy: 1.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.41368 Accuracy: 1.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.41327 Accuracy: 1.00000\n",
      "Test Loss: 0.90941 Accuracy: 0.70979\n",
      "Epoch: 530 Batch:   0 Loss: 0.41287 Accuracy: 1.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.41246 Accuracy: 1.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.41206 Accuracy: 1.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.41167 Accuracy: 1.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.41127 Accuracy: 1.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.41086 Accuracy: 1.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.41046 Accuracy: 1.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.41007 Accuracy: 1.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.40968 Accuracy: 1.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.40929 Accuracy: 1.00000\n",
      "Test Loss: 0.90687 Accuracy: 0.71029\n",
      "Epoch: 540 Batch:   0 Loss: 0.40889 Accuracy: 1.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.40851 Accuracy: 1.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.40811 Accuracy: 1.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.40771 Accuracy: 1.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.40732 Accuracy: 1.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.40693 Accuracy: 1.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.40654 Accuracy: 1.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.40616 Accuracy: 1.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.40576 Accuracy: 1.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.40534 Accuracy: 1.00000\n",
      "Test Loss: 0.90427 Accuracy: 0.71150\n",
      "Epoch: 550 Batch:   0 Loss: 0.40494 Accuracy: 1.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.40454 Accuracy: 1.00000\n",
      "Epoch: 552 Batch:   0 Loss: 0.40413 Accuracy: 1.00000\n",
      "Epoch: 553 Batch:   0 Loss: 0.40373 Accuracy: 1.00000\n",
      "Epoch: 554 Batch:   0 Loss: 0.40333 Accuracy: 1.00000\n",
      "Epoch: 555 Batch:   0 Loss: 0.40293 Accuracy: 1.00000\n",
      "Epoch: 556 Batch:   0 Loss: 0.40254 Accuracy: 1.00000\n",
      "Epoch: 557 Batch:   0 Loss: 0.40216 Accuracy: 1.00000\n",
      "Epoch: 558 Batch:   0 Loss: 0.40179 Accuracy: 1.00000\n",
      "Epoch: 559 Batch:   0 Loss: 0.40139 Accuracy: 1.00000\n",
      "Test Loss: 0.90173 Accuracy: 0.71220\n",
      "Epoch: 560 Batch:   0 Loss: 0.40100 Accuracy: 1.00000\n",
      "Epoch: 561 Batch:   0 Loss: 0.40061 Accuracy: 1.00000\n",
      "Epoch: 562 Batch:   0 Loss: 0.40022 Accuracy: 1.00000\n",
      "Epoch: 563 Batch:   0 Loss: 0.39984 Accuracy: 1.00000\n",
      "Epoch: 564 Batch:   0 Loss: 0.39947 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:47:54,590] Trial 15 finished with value: 0.712605548854041 and parameters: {'REG_W': 3.096750166716164e-06, 'REG_B': 0.00027084498079148574, 'REG_Z': 3.662498911469182e-05, 'SPAR_W': 0.6223364353859038, 'SPAR_B': 0.7503984140113251, 'SPAR_Z': 0.6836677974438338, 'LEARNING_RATE': 0.0007492425529136179, 'NUM_EPOCHS': 565}. Best is trial 14 with value: 0.756031363088058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.05363 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.03570 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.02754 Accuracy: 1.00000\n",
      "Epoch:   3 Batch:   0 Loss: 0.06600 Accuracy: 1.00000\n",
      "Epoch:   4 Batch:   0 Loss: 0.45104 Accuracy: 1.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.07294 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.49025 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.70909 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.81781 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.87126 Accuracy: 0.00000\n",
      "Test Loss: 1.09371 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.89728 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.90888 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.91240 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.91107 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.90652 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.89988 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.89145 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.88173 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.87090 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.85885 Accuracy: 0.00000\n",
      "Test Loss: 1.12690 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.84590 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.83220 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.81700 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.80035 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.78276 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.76404 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.74528 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.72628 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.70667 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.68666 Accuracy: 0.00000\n",
      "Test Loss: 1.12852 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.66502 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.64316 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.62092 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.59770 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.57397 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.54973 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.52482 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.50005 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.47447 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.44865 Accuracy: 0.00000\n",
      "Test Loss: 1.11239 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.42342 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.39792 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.37278 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.34811 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.32341 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.29904 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.27507 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.25145 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.22840 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.20578 Accuracy: 0.00000\n",
      "Test Loss: 1.07348 Accuracy: 0.50030\n",
      "Epoch:  50 Batch:   0 Loss: 1.18402 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.16293 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.14239 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.12222 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.10258 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.08359 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.06530 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.04743 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.03004 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.01353 Accuracy: 0.00000\n",
      "Test Loss: 1.01955 Accuracy: 0.50040\n",
      "Epoch:  60 Batch:   0 Loss: 0.99779 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.98289 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 0.96869 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 0.95525 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 0.94260 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 0.93060 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 0.91917 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 0.90843 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 0.89820 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 0.88855 Accuracy: 0.00000\n",
      "Test Loss: 0.95799 Accuracy: 0.50040\n",
      "Epoch:  70 Batch:   0 Loss: 0.87972 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 0.87144 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 0.86370 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 0.85640 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 0.84962 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 0.84318 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 0.83726 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 0.83172 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 0.82673 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 0.82224 Accuracy: 0.00000\n",
      "Test Loss: 0.88942 Accuracy: 0.50060\n",
      "Epoch:  80 Batch:   0 Loss: 0.81818 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 0.81457 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 0.81140 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.80859 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.80612 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.80382 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.80172 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.80005 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.79882 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.79790 Accuracy: 0.00000\n",
      "Test Loss: 0.83586 Accuracy: 0.50060\n",
      "Epoch:  90 Batch:   0 Loss: 0.79722 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.79667 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.79633 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.79616 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.79614 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.79622 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.79642 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.79667 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.79711 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.79767 Accuracy: 0.00000\n",
      "Test Loss: 0.81046 Accuracy: 0.50060\n",
      "Epoch: 100 Batch:   0 Loss: 0.79820 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.79880 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.79928 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.79973 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.80009 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.80041 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.80061 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.80077 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.80085 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.80086 Accuracy: 0.00000\n",
      "Test Loss: 0.79170 Accuracy: 0.50060\n",
      "Epoch: 110 Batch:   0 Loss: 0.80076 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.80069 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.80057 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.80044 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.80027 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.80013 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.80001 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.79986 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.79967 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.79952 Accuracy: 0.00000\n",
      "Test Loss: 0.77575 Accuracy: 0.50070\n",
      "Epoch: 120 Batch:   0 Loss: 0.79939 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.79926 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.79904 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.79890 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.79872 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.79855 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.79838 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.79824 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.79810 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.79798 Accuracy: 0.00000\n",
      "Test Loss: 0.76304 Accuracy: 0.50070\n",
      "Epoch: 130 Batch:   0 Loss: 0.79786 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.79777 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.79769 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.79763 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.79757 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.79751 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.79749 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.79748 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.79749 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.79746 Accuracy: 0.00000\n",
      "Test Loss: 0.75283 Accuracy: 0.50070\n",
      "Epoch: 140 Batch:   0 Loss: 0.79744 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.79744 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.79745 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.79743 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.79743 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.79745 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.79746 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.79745 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.79745 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.79740 Accuracy: 0.00000\n",
      "Test Loss: 0.74437 Accuracy: 0.50070\n",
      "Epoch: 150 Batch:   0 Loss: 0.79736 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.79729 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.79720 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.79713 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.79707 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.79703 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.79698 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.79694 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.79688 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.79681 Accuracy: 0.00000\n",
      "Test Loss: 0.73711 Accuracy: 0.50070\n",
      "Epoch: 160 Batch:   0 Loss: 0.79675 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.79673 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.79669 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.79665 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.79662 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.79658 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.79654 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.79646 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.79639 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.79629 Accuracy: 0.00000\n",
      "Test Loss: 0.73069 Accuracy: 0.50070\n",
      "Epoch: 170 Batch:   0 Loss: 0.79618 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.79603 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.79589 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.79575 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.79562 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.79550 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.79537 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.79525 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.79513 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.79503 Accuracy: 0.00000\n",
      "Test Loss: 0.72502 Accuracy: 0.50070\n",
      "Epoch: 180 Batch:   0 Loss: 0.79493 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.79486 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.79476 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.79466 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.79456 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.79447 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.79438 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.79430 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.79422 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.79414 Accuracy: 0.00000\n",
      "Test Loss: 0.71991 Accuracy: 0.50070\n",
      "Epoch: 190 Batch:   0 Loss: 0.79406 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.79398 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.79391 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.79383 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.79376 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.79367 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.79357 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.79348 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.79338 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.79327 Accuracy: 0.00000\n",
      "Test Loss: 0.71528 Accuracy: 0.50070\n",
      "Epoch: 200 Batch:   0 Loss: 0.79316 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.79305 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.79294 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.79284 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.79275 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.79264 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.79254 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.79245 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.79236 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.79227 Accuracy: 0.00000\n",
      "Test Loss: 0.71111 Accuracy: 0.50070\n",
      "Epoch: 210 Batch:   0 Loss: 0.79222 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.79216 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.79210 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.79203 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.79197 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.79193 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.79188 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.79184 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.79180 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.79178 Accuracy: 0.00000\n",
      "Test Loss: 0.70736 Accuracy: 0.50060\n",
      "Epoch: 220 Batch:   0 Loss: 0.79173 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.79168 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.79163 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.79159 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.79153 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.79145 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.79138 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.79131 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.79124 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.79116 Accuracy: 0.00000\n",
      "Test Loss: 0.70398 Accuracy: 0.50060\n",
      "Epoch: 230 Batch:   0 Loss: 0.79108 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.79100 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.79094 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.79087 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.79081 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.79073 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.79067 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.79061 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.79056 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.79050 Accuracy: 0.00000\n",
      "Test Loss: 0.70100 Accuracy: 0.50060\n",
      "Epoch: 240 Batch:   0 Loss: 0.79044 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.79037 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.79031 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.79023 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.79018 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.79013 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.79007 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.79002 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.78996 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.78993 Accuracy: 0.00000\n",
      "Test Loss: 0.69835 Accuracy: 0.50070\n",
      "Epoch: 250 Batch:   0 Loss: 0.78990 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.78987 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.78983 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.78979 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.78976 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.78973 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.78969 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.78965 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.78961 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.78957 Accuracy: 0.00000\n",
      "Test Loss: 0.69592 Accuracy: 0.50070\n",
      "Epoch: 260 Batch:   0 Loss: 0.78952 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.78947 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.78942 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.78937 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.78931 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.78926 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.78920 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.78915 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.78910 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.78905 Accuracy: 0.00000\n",
      "Test Loss: 0.69373 Accuracy: 0.50070\n",
      "Epoch: 270 Batch:   0 Loss: 0.78899 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.78894 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.78886 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.78882 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.78877 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.78872 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.78866 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.78860 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.78854 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.78848 Accuracy: 0.00000\n",
      "Test Loss: 0.69175 Accuracy: 0.50070\n",
      "Epoch: 280 Batch:   0 Loss: 0.78842 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.78834 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.78826 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.78819 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.78812 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.78806 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.78800 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.78794 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.78788 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.78783 Accuracy: 0.00000\n",
      "Test Loss: 0.68990 Accuracy: 0.50070\n",
      "Epoch: 290 Batch:   0 Loss: 0.78777 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.78772 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.78766 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.78758 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.78751 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.78741 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.78732 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.78723 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.78713 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.78704 Accuracy: 0.00000\n",
      "Test Loss: 0.68830 Accuracy: 0.50070\n",
      "Epoch: 300 Batch:   0 Loss: 0.78695 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.78686 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.78677 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.78669 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.78661 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.78654 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.78646 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.78639 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.78630 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.78623 Accuracy: 0.00000\n",
      "Test Loss: 0.68697 Accuracy: 0.50070\n",
      "Epoch: 310 Batch:   0 Loss: 0.78615 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.78607 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.78598 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.78592 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.78583 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.78575 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.78566 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.78558 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.78549 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.78541 Accuracy: 0.00000\n",
      "Test Loss: 0.68583 Accuracy: 0.50070\n",
      "Epoch: 320 Batch:   0 Loss: 0.78530 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.78521 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.78511 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.78500 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.78489 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.78478 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.78467 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.78456 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.78444 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.78434 Accuracy: 0.00000\n",
      "Test Loss: 0.68488 Accuracy: 0.50070\n",
      "Epoch: 330 Batch:   0 Loss: 0.78422 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.78410 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.78397 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.78387 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.78376 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.78365 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.78352 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.78341 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.78329 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.78317 Accuracy: 0.00000\n",
      "Test Loss: 0.68402 Accuracy: 0.50070\n",
      "Epoch: 340 Batch:   0 Loss: 0.78305 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.78294 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.78283 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.78272 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.78262 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.78252 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.78243 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.78233 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.78225 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.78217 Accuracy: 0.00000\n",
      "Test Loss: 0.68327 Accuracy: 0.50070\n",
      "Epoch: 350 Batch:   0 Loss: 0.78209 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.78200 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.78193 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.78186 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.78180 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.78174 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.78169 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.78164 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.78160 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.78156 Accuracy: 0.00000\n",
      "Test Loss: 0.68271 Accuracy: 0.50070\n",
      "Epoch: 360 Batch:   0 Loss: 0.78154 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.78152 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.78150 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.78149 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.78149 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.78149 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.78151 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.78153 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.78156 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.78160 Accuracy: 0.00000\n",
      "Test Loss: 0.68231 Accuracy: 0.50070\n",
      "Epoch: 370 Batch:   0 Loss: 0.78165 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.78172 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.78180 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.78189 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.78199 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.78210 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.78221 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.78233 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.78244 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.78256 Accuracy: 0.00000\n",
      "Test Loss: 0.68211 Accuracy: 0.50070\n",
      "Epoch: 380 Batch:   0 Loss: 0.78266 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.78276 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.78283 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.78289 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.78292 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.78291 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.78288 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.78281 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.78272 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.78260 Accuracy: 0.00000\n",
      "Test Loss: 0.68136 Accuracy: 0.50070\n",
      "Epoch: 390 Batch:   0 Loss: 0.78245 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.78228 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.78208 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.78187 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.78165 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.78143 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.78118 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.78091 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.78064 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.78037 Accuracy: 0.00000\n",
      "Test Loss: 0.68027 Accuracy: 0.50070\n",
      "Epoch: 400 Batch:   0 Loss: 0.78010 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.77984 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.77958 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.77933 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.77909 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.77886 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.77864 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.77843 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.77822 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.77803 Accuracy: 0.00000\n",
      "Test Loss: 0.67922 Accuracy: 0.50070\n",
      "Epoch: 410 Batch:   0 Loss: 0.77786 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.77770 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.77758 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.77746 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.77735 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.77724 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.77713 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.77704 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.77695 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.77685 Accuracy: 0.00000\n",
      "Test Loss: 0.67807 Accuracy: 0.50060\n",
      "Epoch: 420 Batch:   0 Loss: 0.77674 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.77661 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.77646 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.77630 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.77613 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.77595 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.77577 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.77559 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.77540 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.77521 Accuracy: 0.00000\n",
      "Test Loss: 0.67677 Accuracy: 0.50060\n",
      "Epoch: 430 Batch:   0 Loss: 0.77503 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.77485 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.77468 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.77453 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.77438 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.77425 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.77413 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.77403 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.77394 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.77387 Accuracy: 0.00000\n",
      "Test Loss: 0.67588 Accuracy: 0.50060\n",
      "Epoch: 440 Batch:   0 Loss: 0.77381 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.77376 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.77373 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.77370 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.77368 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.77368 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.77367 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.77365 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.77364 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.77359 Accuracy: 0.00000\n",
      "Test Loss: 0.67522 Accuracy: 0.50060\n",
      "Epoch: 450 Batch:   0 Loss: 0.77355 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.77349 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.77340 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.77331 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.77319 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.77306 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.77291 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.77274 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.77256 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.77234 Accuracy: 0.00000\n",
      "Test Loss: 0.67448 Accuracy: 0.50060\n",
      "Epoch: 460 Batch:   0 Loss: 0.77212 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.77187 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.77159 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.77130 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.77100 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.77069 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.77036 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.77004 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.76969 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.76934 Accuracy: 0.00000\n",
      "Test Loss: 0.67431 Accuracy: 0.50060\n",
      "Epoch: 470 Batch:   0 Loss: 0.76899 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.76864 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.76829 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.76793 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.76757 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.76722 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.76687 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.76651 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.76615 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.76577 Accuracy: 0.00000\n",
      "Test Loss: 0.67483 Accuracy: 0.50060\n",
      "Epoch: 480 Batch:   0 Loss: 0.76541 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.76505 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.76470 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.76436 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.76402 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.76369 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.76338 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.76307 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.76277 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.76247 Accuracy: 0.00000\n",
      "Test Loss: 0.67573 Accuracy: 0.50060\n",
      "Epoch: 490 Batch:   0 Loss: 0.76218 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.76190 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.76162 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.76135 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.76109 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.76085 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.76060 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.76037 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.76014 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.75991 Accuracy: 0.00000\n",
      "Test Loss: 0.67670 Accuracy: 0.50060\n",
      "Epoch: 500 Batch:   0 Loss: 0.75970 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.75949 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.75930 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.75910 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.75892 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.75873 Accuracy: 0.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.75855 Accuracy: 0.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.75838 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.75820 Accuracy: 0.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.75804 Accuracy: 0.00000\n",
      "Test Loss: 0.67763 Accuracy: 0.50060\n",
      "Epoch: 510 Batch:   0 Loss: 0.75787 Accuracy: 0.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.75771 Accuracy: 0.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.75756 Accuracy: 0.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.75741 Accuracy: 0.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.75726 Accuracy: 0.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.75711 Accuracy: 0.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.75697 Accuracy: 0.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.75683 Accuracy: 0.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.75670 Accuracy: 0.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.75656 Accuracy: 0.00000\n",
      "Test Loss: 0.67848 Accuracy: 0.50060\n",
      "Epoch: 520 Batch:   0 Loss: 0.75643 Accuracy: 0.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.75630 Accuracy: 0.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.75617 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.75605 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.75594 Accuracy: 0.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.75582 Accuracy: 0.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.75570 Accuracy: 0.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.75559 Accuracy: 0.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.75548 Accuracy: 0.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.75536 Accuracy: 0.00000\n",
      "Test Loss: 0.67936 Accuracy: 0.50070\n",
      "Epoch: 530 Batch:   0 Loss: 0.75525 Accuracy: 0.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.75514 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.75504 Accuracy: 0.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.75494 Accuracy: 0.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.75483 Accuracy: 0.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.75474 Accuracy: 0.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.75464 Accuracy: 0.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.75454 Accuracy: 0.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.75445 Accuracy: 0.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.75436 Accuracy: 0.00000\n",
      "Test Loss: 0.68020 Accuracy: 0.50080\n",
      "Epoch: 540 Batch:   0 Loss: 0.75427 Accuracy: 0.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.75419 Accuracy: 0.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.75410 Accuracy: 0.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.75402 Accuracy: 0.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.75394 Accuracy: 0.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.75387 Accuracy: 0.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.75379 Accuracy: 0.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.75372 Accuracy: 0.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.75365 Accuracy: 0.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.75358 Accuracy: 0.00000\n",
      "Test Loss: 0.68104 Accuracy: 0.50080\n",
      "Epoch: 550 Batch:   0 Loss: 0.75351 Accuracy: 0.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.75344 Accuracy: 0.00000\n",
      "Epoch: 552 Batch:   0 Loss: 0.75337 Accuracy: 0.00000\n",
      "Epoch: 553 Batch:   0 Loss: 0.75330 Accuracy: 0.00000\n",
      "Epoch: 554 Batch:   0 Loss: 0.75324 Accuracy: 0.00000\n",
      "Epoch: 555 Batch:   0 Loss: 0.75317 Accuracy: 0.00000\n",
      "Epoch: 556 Batch:   0 Loss: 0.75311 Accuracy: 0.00000\n",
      "Epoch: 557 Batch:   0 Loss: 0.75305 Accuracy: 0.00000\n",
      "Epoch: 558 Batch:   0 Loss: 0.75298 Accuracy: 0.00000\n",
      "Epoch: 559 Batch:   0 Loss: 0.75291 Accuracy: 0.00000\n",
      "Test Loss: 0.68188 Accuracy: 0.50080\n",
      "Epoch: 560 Batch:   0 Loss: 0.75284 Accuracy: 0.00000\n",
      "Epoch: 561 Batch:   0 Loss: 0.75278 Accuracy: 0.00000\n",
      "Epoch: 562 Batch:   0 Loss: 0.75271 Accuracy: 0.00000\n",
      "Epoch: 563 Batch:   0 Loss: 0.75265 Accuracy: 0.00000\n",
      "Epoch: 564 Batch:   0 Loss: 0.75259 Accuracy: 0.00000\n",
      "Epoch: 565 Batch:   0 Loss: 0.75253 Accuracy: 0.00000\n",
      "Epoch: 566 Batch:   0 Loss: 0.75247 Accuracy: 0.00000\n",
      "Epoch: 567 Batch:   0 Loss: 0.75241 Accuracy: 0.00000\n",
      "Epoch: 568 Batch:   0 Loss: 0.75235 Accuracy: 0.00000\n",
      "Epoch: 569 Batch:   0 Loss: 0.75229 Accuracy: 0.00000\n",
      "Test Loss: 0.68261 Accuracy: 0.50080\n",
      "Epoch: 570 Batch:   0 Loss: 0.75222 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 571 Batch:   0 Loss: 0.75216 Accuracy: 0.00000\n",
      "Epoch: 572 Batch:   0 Loss: 0.75210 Accuracy: 0.00000\n",
      "Epoch: 573 Batch:   0 Loss: 0.75204 Accuracy: 0.00000\n",
      "Epoch: 574 Batch:   0 Loss: 0.75198 Accuracy: 0.00000\n",
      "Epoch: 575 Batch:   0 Loss: 0.75193 Accuracy: 0.00000\n",
      "Epoch: 576 Batch:   0 Loss: 0.75187 Accuracy: 0.00000\n",
      "Epoch: 577 Batch:   0 Loss: 0.75181 Accuracy: 0.00000\n",
      "Epoch: 578 Batch:   0 Loss: 0.75176 Accuracy: 0.00000\n",
      "Epoch: 579 Batch:   0 Loss: 0.75171 Accuracy: 0.00000\n",
      "Test Loss: 0.68335 Accuracy: 0.50080\n",
      "Epoch: 580 Batch:   0 Loss: 0.75165 Accuracy: 0.00000\n",
      "Epoch: 581 Batch:   0 Loss: 0.75160 Accuracy: 0.00000\n",
      "Epoch: 582 Batch:   0 Loss: 0.75155 Accuracy: 0.00000\n",
      "Epoch: 583 Batch:   0 Loss: 0.75150 Accuracy: 0.00000\n",
      "Epoch: 584 Batch:   0 Loss: 0.75145 Accuracy: 0.00000\n",
      "Epoch: 585 Batch:   0 Loss: 0.75141 Accuracy: 0.00000\n",
      "Epoch: 586 Batch:   0 Loss: 0.75136 Accuracy: 0.00000\n",
      "Epoch: 587 Batch:   0 Loss: 0.75131 Accuracy: 0.00000\n",
      "Epoch: 588 Batch:   0 Loss: 0.75126 Accuracy: 0.00000\n",
      "Epoch: 589 Batch:   0 Loss: 0.75122 Accuracy: 0.00000\n",
      "Test Loss: 0.68408 Accuracy: 0.50080\n",
      "Epoch: 590 Batch:   0 Loss: 0.75118 Accuracy: 0.00000\n",
      "Epoch: 591 Batch:   0 Loss: 0.75113 Accuracy: 0.00000\n",
      "Epoch: 592 Batch:   0 Loss: 0.75109 Accuracy: 0.00000\n",
      "Epoch: 593 Batch:   0 Loss: 0.75105 Accuracy: 0.00000\n",
      "Epoch: 594 Batch:   0 Loss: 0.75101 Accuracy: 0.00000\n",
      "Epoch: 595 Batch:   0 Loss: 0.75098 Accuracy: 0.00000\n",
      "Epoch: 596 Batch:   0 Loss: 0.75094 Accuracy: 0.00000\n",
      "Epoch: 597 Batch:   0 Loss: 0.75090 Accuracy: 0.00000\n",
      "Epoch: 598 Batch:   0 Loss: 0.75086 Accuracy: 0.00000\n",
      "Epoch: 599 Batch:   0 Loss: 0.75083 Accuracy: 0.00000\n",
      "Test Loss: 0.68475 Accuracy: 0.50080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:53:20,668] Trial 16 finished with value: 0.5006031363088058 and parameters: {'REG_W': 2.9921967736687803e-06, 'REG_B': 0.0017399308847832016, 'REG_Z': 3.73477848815666e-05, 'SPAR_W': 0.6251354755252909, 'SPAR_B': 0.6131562427040257, 'SPAR_Z': 0.6032833747352059, 'LEARNING_RATE': 0.00042360329673525035, 'NUM_EPOCHS': 600}. Best is trial 14 with value: 0.756031363088058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 1.76903 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.85262 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 1.89864 Accuracy: 0.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.91419 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.91487 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.90810 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.89684 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.88228 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.86532 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.84615 Accuracy: 0.00000\n",
      "Test Loss: 0.98552 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.82486 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.80212 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.77745 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.75155 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.72473 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.69662 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.66896 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.64190 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.61415 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.58673 Accuracy: 0.00000\n",
      "Test Loss: 0.94355 Accuracy: 0.50050\n",
      "Epoch:  20 Batch:   0 Loss: 1.56038 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.53486 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.50927 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.48406 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.45925 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.43480 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.41103 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.38802 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.36543 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.34300 Accuracy: 0.00000\n",
      "Test Loss: 0.92824 Accuracy: 0.51638\n",
      "Epoch:  30 Batch:   0 Loss: 1.32079 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.29904 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.27725 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.25566 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.23444 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.21399 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.19413 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.17486 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.15618 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.13792 Accuracy: 0.00000\n",
      "Test Loss: 0.91083 Accuracy: 0.52783\n",
      "Epoch:  40 Batch:   0 Loss: 1.12019 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.10331 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.08712 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.07136 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.05603 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.04136 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.02698 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.01295 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 0.99924 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 0.98630 Accuracy: 0.00000\n",
      "Test Loss: 0.88410 Accuracy: 0.53889\n",
      "Epoch:  50 Batch:   0 Loss: 0.97371 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 0.96141 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 0.94951 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 0.93791 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 0.92653 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 0.91561 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 0.90502 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 0.89448 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 0.88419 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 0.87413 Accuracy: 0.00000\n",
      "Test Loss: 0.85707 Accuracy: 0.54923\n",
      "Epoch:  60 Batch:   0 Loss: 0.86428 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 0.85497 Accuracy: 0.03125\n",
      "Epoch:  62 Batch:   0 Loss: 0.84597 Accuracy: 0.06250\n",
      "Epoch:  63 Batch:   0 Loss: 0.83721 Accuracy: 0.06250\n",
      "Epoch:  64 Batch:   0 Loss: 0.82867 Accuracy: 0.06250\n",
      "Epoch:  65 Batch:   0 Loss: 0.82053 Accuracy: 0.09375\n",
      "Epoch:  66 Batch:   0 Loss: 0.81262 Accuracy: 0.15625\n",
      "Epoch:  67 Batch:   0 Loss: 0.80496 Accuracy: 0.25000\n",
      "Epoch:  68 Batch:   0 Loss: 0.79758 Accuracy: 0.25000\n",
      "Epoch:  69 Batch:   0 Loss: 0.79036 Accuracy: 0.31250\n",
      "Test Loss: 0.83682 Accuracy: 0.56631\n",
      "Epoch:  70 Batch:   0 Loss: 0.78339 Accuracy: 0.34375\n",
      "Epoch:  71 Batch:   0 Loss: 0.77660 Accuracy: 0.46875\n",
      "Epoch:  72 Batch:   0 Loss: 0.77016 Accuracy: 0.53125\n",
      "Epoch:  73 Batch:   0 Loss: 0.76396 Accuracy: 0.56250\n",
      "Epoch:  74 Batch:   0 Loss: 0.75790 Accuracy: 0.59375\n",
      "Epoch:  75 Batch:   0 Loss: 0.75214 Accuracy: 0.59375\n",
      "Epoch:  76 Batch:   0 Loss: 0.74658 Accuracy: 0.65625\n",
      "Epoch:  77 Batch:   0 Loss: 0.74119 Accuracy: 0.68750\n",
      "Epoch:  78 Batch:   0 Loss: 0.73583 Accuracy: 0.75000\n",
      "Epoch:  79 Batch:   0 Loss: 0.73068 Accuracy: 0.78125\n",
      "Test Loss: 0.82203 Accuracy: 0.59063\n",
      "Epoch:  80 Batch:   0 Loss: 0.72570 Accuracy: 0.78125\n",
      "Epoch:  81 Batch:   0 Loss: 0.72089 Accuracy: 0.78125\n",
      "Epoch:  82 Batch:   0 Loss: 0.71620 Accuracy: 0.78125\n",
      "Epoch:  83 Batch:   0 Loss: 0.71162 Accuracy: 0.84375\n",
      "Epoch:  84 Batch:   0 Loss: 0.70722 Accuracy: 0.87500\n",
      "Epoch:  85 Batch:   0 Loss: 0.70295 Accuracy: 0.90625\n",
      "Epoch:  86 Batch:   0 Loss: 0.69875 Accuracy: 0.90625\n",
      "Epoch:  87 Batch:   0 Loss: 0.69472 Accuracy: 0.93750\n",
      "Epoch:  88 Batch:   0 Loss: 0.69087 Accuracy: 0.93750\n",
      "Epoch:  89 Batch:   0 Loss: 0.68711 Accuracy: 0.96875\n",
      "Test Loss: 0.81084 Accuracy: 0.61042\n",
      "Epoch:  90 Batch:   0 Loss: 0.68348 Accuracy: 0.96875\n",
      "Epoch:  91 Batch:   0 Loss: 0.67998 Accuracy: 0.96875\n",
      "Epoch:  92 Batch:   0 Loss: 0.67653 Accuracy: 0.96875\n",
      "Epoch:  93 Batch:   0 Loss: 0.67317 Accuracy: 0.96875\n",
      "Epoch:  94 Batch:   0 Loss: 0.66991 Accuracy: 0.96875\n",
      "Epoch:  95 Batch:   0 Loss: 0.66672 Accuracy: 0.96875\n",
      "Epoch:  96 Batch:   0 Loss: 0.66362 Accuracy: 1.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.66058 Accuracy: 1.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.65762 Accuracy: 1.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.65474 Accuracy: 1.00000\n",
      "Test Loss: 0.80190 Accuracy: 0.62700\n",
      "Epoch: 100 Batch:   0 Loss: 0.65195 Accuracy: 1.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.64921 Accuracy: 1.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.64649 Accuracy: 1.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.64382 Accuracy: 1.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.64121 Accuracy: 1.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.63856 Accuracy: 1.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.63607 Accuracy: 1.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.63362 Accuracy: 1.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.63122 Accuracy: 1.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.62892 Accuracy: 1.00000\n",
      "Test Loss: 0.79397 Accuracy: 0.64066\n",
      "Epoch: 110 Batch:   0 Loss: 0.62660 Accuracy: 1.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.62430 Accuracy: 1.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.62205 Accuracy: 1.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.61982 Accuracy: 1.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.61763 Accuracy: 1.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.61546 Accuracy: 1.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.61340 Accuracy: 1.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.61132 Accuracy: 1.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.60930 Accuracy: 1.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.60731 Accuracy: 1.00000\n",
      "Test Loss: 0.78689 Accuracy: 0.65432\n",
      "Epoch: 120 Batch:   0 Loss: 0.60536 Accuracy: 1.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.60345 Accuracy: 1.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.60153 Accuracy: 1.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.59969 Accuracy: 1.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.59785 Accuracy: 1.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.59602 Accuracy: 1.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.59421 Accuracy: 1.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.59240 Accuracy: 1.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.59065 Accuracy: 1.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.58894 Accuracy: 1.00000\n",
      "Test Loss: 0.78053 Accuracy: 0.66366\n",
      "Epoch: 130 Batch:   0 Loss: 0.58727 Accuracy: 1.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.58559 Accuracy: 1.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.58393 Accuracy: 1.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.58227 Accuracy: 1.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.58065 Accuracy: 1.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.57905 Accuracy: 1.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.57747 Accuracy: 1.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.57590 Accuracy: 1.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.57432 Accuracy: 1.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.57279 Accuracy: 1.00000\n",
      "Test Loss: 0.77486 Accuracy: 0.67291\n",
      "Epoch: 140 Batch:   0 Loss: 0.57128 Accuracy: 1.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.56979 Accuracy: 1.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.56833 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.56690 Accuracy: 1.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.56548 Accuracy: 1.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.56408 Accuracy: 1.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.56270 Accuracy: 1.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.56132 Accuracy: 1.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.55997 Accuracy: 1.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.55863 Accuracy: 1.00000\n",
      "Test Loss: 0.76969 Accuracy: 0.68024\n",
      "Epoch: 150 Batch:   0 Loss: 0.55730 Accuracy: 1.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.55599 Accuracy: 1.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.55467 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.55334 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.55202 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.55071 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.54941 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.54808 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.54682 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.54557 Accuracy: 1.00000\n",
      "Test Loss: 0.76477 Accuracy: 0.68657\n",
      "Epoch: 160 Batch:   0 Loss: 0.54429 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.54310 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.54191 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.54074 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.53956 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.53841 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.53727 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.53612 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.53499 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.53385 Accuracy: 1.00000\n",
      "Test Loss: 0.76016 Accuracy: 0.69210\n",
      "Epoch: 170 Batch:   0 Loss: 0.53273 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.53163 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.53052 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.52941 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.52833 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.52721 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.52612 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.52503 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.52395 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.52288 Accuracy: 1.00000\n",
      "Test Loss: 0.75603 Accuracy: 0.69591\n",
      "Epoch: 180 Batch:   0 Loss: 0.52182 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.52078 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.51975 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.51870 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.51767 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.51662 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.51559 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.51457 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.51357 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.51258 Accuracy: 1.00000\n",
      "Test Loss: 0.75227 Accuracy: 0.70024\n",
      "Epoch: 190 Batch:   0 Loss: 0.51158 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.51062 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.50965 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.50869 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.50773 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.50677 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.50583 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.50491 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.50394 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.50298 Accuracy: 1.00000\n",
      "Test Loss: 0.74881 Accuracy: 0.70446\n",
      "Epoch: 200 Batch:   0 Loss: 0.50202 Accuracy: 1.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.50105 Accuracy: 1.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.50012 Accuracy: 1.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.49920 Accuracy: 1.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.49828 Accuracy: 1.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.49737 Accuracy: 1.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.49647 Accuracy: 1.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.49554 Accuracy: 1.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.49463 Accuracy: 1.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.49373 Accuracy: 1.00000\n",
      "Test Loss: 0.74549 Accuracy: 0.70847\n",
      "Epoch: 210 Batch:   0 Loss: 0.49285 Accuracy: 1.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.49197 Accuracy: 1.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.49109 Accuracy: 1.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.49023 Accuracy: 1.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.48938 Accuracy: 1.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.48852 Accuracy: 1.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.48768 Accuracy: 1.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.48683 Accuracy: 1.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.48598 Accuracy: 1.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.48514 Accuracy: 1.00000\n",
      "Test Loss: 0.74240 Accuracy: 0.71169\n",
      "Epoch: 220 Batch:   0 Loss: 0.48430 Accuracy: 1.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.48342 Accuracy: 1.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.48257 Accuracy: 1.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.48175 Accuracy: 1.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.48093 Accuracy: 1.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.48010 Accuracy: 1.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.47928 Accuracy: 1.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.47846 Accuracy: 1.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.47765 Accuracy: 1.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.47685 Accuracy: 1.00000\n",
      "Test Loss: 0.73954 Accuracy: 0.71410\n",
      "Epoch: 230 Batch:   0 Loss: 0.47605 Accuracy: 1.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.47523 Accuracy: 1.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.47442 Accuracy: 1.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.47364 Accuracy: 1.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.47286 Accuracy: 1.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.47207 Accuracy: 1.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.47127 Accuracy: 1.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.47049 Accuracy: 1.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.46967 Accuracy: 1.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.46891 Accuracy: 1.00000\n",
      "Test Loss: 0.73681 Accuracy: 0.71812\n",
      "Epoch: 240 Batch:   0 Loss: 0.46813 Accuracy: 1.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.46737 Accuracy: 1.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.46660 Accuracy: 1.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.46583 Accuracy: 1.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.46507 Accuracy: 1.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.46430 Accuracy: 1.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.46355 Accuracy: 1.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.46279 Accuracy: 1.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.46203 Accuracy: 1.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.46129 Accuracy: 1.00000\n",
      "Test Loss: 0.73419 Accuracy: 0.72144\n",
      "Epoch: 250 Batch:   0 Loss: 0.46053 Accuracy: 1.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.45979 Accuracy: 1.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.45904 Accuracy: 1.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.45832 Accuracy: 1.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.45762 Accuracy: 1.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.45690 Accuracy: 1.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.45619 Accuracy: 1.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.45548 Accuracy: 1.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.45478 Accuracy: 1.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.45407 Accuracy: 1.00000\n",
      "Test Loss: 0.73191 Accuracy: 0.72455\n",
      "Epoch: 260 Batch:   0 Loss: 0.45338 Accuracy: 1.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.45273 Accuracy: 1.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.45204 Accuracy: 1.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.45136 Accuracy: 1.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.45067 Accuracy: 1.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.45000 Accuracy: 1.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.44932 Accuracy: 1.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.44865 Accuracy: 1.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.44799 Accuracy: 1.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.44733 Accuracy: 1.00000\n",
      "Test Loss: 0.72991 Accuracy: 0.72676\n",
      "Epoch: 270 Batch:   0 Loss: 0.44667 Accuracy: 1.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.44601 Accuracy: 1.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.44535 Accuracy: 1.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.44469 Accuracy: 1.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.44405 Accuracy: 1.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.44226 Accuracy: 1.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.44196 Accuracy: 1.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.44138 Accuracy: 1.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.44072 Accuracy: 1.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.44004 Accuracy: 1.00000\n",
      "Test Loss: 0.72767 Accuracy: 0.72917\n",
      "Epoch: 280 Batch:   0 Loss: 0.43936 Accuracy: 1.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.43868 Accuracy: 1.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.43800 Accuracy: 1.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.43734 Accuracy: 1.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.43668 Accuracy: 1.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.43603 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.43538 Accuracy: 1.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.43474 Accuracy: 1.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.43412 Accuracy: 1.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.43348 Accuracy: 1.00000\n",
      "Test Loss: 0.72597 Accuracy: 0.73138\n",
      "Epoch: 290 Batch:   0 Loss: 0.43283 Accuracy: 1.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.43220 Accuracy: 1.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.43156 Accuracy: 1.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.43092 Accuracy: 1.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.43029 Accuracy: 1.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.42966 Accuracy: 1.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.42904 Accuracy: 1.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.42841 Accuracy: 1.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.42778 Accuracy: 1.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.42717 Accuracy: 1.00000\n",
      "Test Loss: 0.72438 Accuracy: 0.73329\n",
      "Epoch: 300 Batch:   0 Loss: 0.42655 Accuracy: 1.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.42593 Accuracy: 1.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.42531 Accuracy: 1.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.42471 Accuracy: 1.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.42410 Accuracy: 1.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.42349 Accuracy: 1.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.42288 Accuracy: 1.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.42203 Accuracy: 1.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.42062 Accuracy: 1.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.41986 Accuracy: 1.00000\n",
      "Test Loss: 0.72201 Accuracy: 0.73460\n",
      "Epoch: 310 Batch:   0 Loss: 0.41929 Accuracy: 1.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.41879 Accuracy: 1.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.41825 Accuracy: 1.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.41772 Accuracy: 1.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.41719 Accuracy: 1.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.41665 Accuracy: 1.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.41612 Accuracy: 1.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.41558 Accuracy: 1.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.41504 Accuracy: 1.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.41451 Accuracy: 1.00000\n",
      "Test Loss: 0.72068 Accuracy: 0.73620\n",
      "Epoch: 320 Batch:   0 Loss: 0.41397 Accuracy: 1.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.41344 Accuracy: 1.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.41291 Accuracy: 1.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.41238 Accuracy: 1.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.41185 Accuracy: 1.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.41133 Accuracy: 1.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.41080 Accuracy: 1.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.41028 Accuracy: 1.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.40977 Accuracy: 1.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.40924 Accuracy: 1.00000\n",
      "Test Loss: 0.71941 Accuracy: 0.73771\n",
      "Epoch: 330 Batch:   0 Loss: 0.40872 Accuracy: 1.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.40821 Accuracy: 1.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.40769 Accuracy: 1.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.40718 Accuracy: 1.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.40668 Accuracy: 1.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.40615 Accuracy: 1.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.40565 Accuracy: 1.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.40516 Accuracy: 1.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.40465 Accuracy: 1.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.40414 Accuracy: 1.00000\n",
      "Test Loss: 0.71815 Accuracy: 0.73932\n",
      "Epoch: 340 Batch:   0 Loss: 0.40364 Accuracy: 1.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.40314 Accuracy: 1.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.40264 Accuracy: 1.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.40214 Accuracy: 1.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.40166 Accuracy: 1.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.40118 Accuracy: 1.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.40070 Accuracy: 1.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.40022 Accuracy: 1.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.39974 Accuracy: 1.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.39926 Accuracy: 1.00000\n",
      "Test Loss: 0.71691 Accuracy: 0.73992\n",
      "Epoch: 350 Batch:   0 Loss: 0.39879 Accuracy: 1.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.39831 Accuracy: 1.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.39784 Accuracy: 1.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.39737 Accuracy: 1.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.39752 Accuracy: 1.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.39716 Accuracy: 1.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.39666 Accuracy: 1.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.39614 Accuracy: 1.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.39561 Accuracy: 1.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.39509 Accuracy: 1.00000\n",
      "Test Loss: 0.71627 Accuracy: 0.74062\n",
      "Epoch: 360 Batch:   0 Loss: 0.39458 Accuracy: 1.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.39407 Accuracy: 1.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.39358 Accuracy: 1.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.39307 Accuracy: 1.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.39257 Accuracy: 1.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.39207 Accuracy: 1.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.39157 Accuracy: 1.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.39108 Accuracy: 1.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.39059 Accuracy: 1.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.39011 Accuracy: 1.00000\n",
      "Test Loss: 0.71507 Accuracy: 0.74153\n",
      "Epoch: 370 Batch:   0 Loss: 0.38962 Accuracy: 1.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.38914 Accuracy: 1.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.38867 Accuracy: 1.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.38819 Accuracy: 1.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.38772 Accuracy: 1.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.38725 Accuracy: 1.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.38678 Accuracy: 1.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.38631 Accuracy: 1.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.38584 Accuracy: 1.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.38538 Accuracy: 1.00000\n",
      "Test Loss: 0.71388 Accuracy: 0.74183\n",
      "Epoch: 380 Batch:   0 Loss: 0.38492 Accuracy: 1.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.38447 Accuracy: 1.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.38401 Accuracy: 1.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.38356 Accuracy: 1.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.38311 Accuracy: 1.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.38266 Accuracy: 1.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.38222 Accuracy: 1.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.38177 Accuracy: 1.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.38133 Accuracy: 1.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.38090 Accuracy: 1.00000\n",
      "Test Loss: 0.71271 Accuracy: 0.74303\n",
      "Epoch: 390 Batch:   0 Loss: 0.38045 Accuracy: 1.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.38001 Accuracy: 1.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.37956 Accuracy: 1.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.37912 Accuracy: 1.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.37868 Accuracy: 1.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.37824 Accuracy: 1.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.37781 Accuracy: 1.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.37739 Accuracy: 1.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.37696 Accuracy: 1.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.37654 Accuracy: 1.00000\n",
      "Test Loss: 0.71158 Accuracy: 0.74474\n",
      "Epoch: 400 Batch:   0 Loss: 0.37612 Accuracy: 1.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.37570 Accuracy: 1.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.37528 Accuracy: 1.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.37486 Accuracy: 1.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.37446 Accuracy: 1.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.37406 Accuracy: 1.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.37366 Accuracy: 1.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.37326 Accuracy: 1.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.37286 Accuracy: 1.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.37245 Accuracy: 1.00000\n",
      "Test Loss: 0.71051 Accuracy: 0.74585\n",
      "Epoch: 410 Batch:   0 Loss: 0.37204 Accuracy: 1.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.37164 Accuracy: 1.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.37124 Accuracy: 1.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.37131 Accuracy: 1.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.37101 Accuracy: 1.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.37061 Accuracy: 1.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.37019 Accuracy: 1.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.36977 Accuracy: 1.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.36936 Accuracy: 1.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.36893 Accuracy: 1.00000\n",
      "Test Loss: 0.70989 Accuracy: 0.74625\n",
      "Epoch: 420 Batch:   0 Loss: 0.36851 Accuracy: 1.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.36809 Accuracy: 1.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.36768 Accuracy: 1.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.36726 Accuracy: 1.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.36685 Accuracy: 1.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.36645 Accuracy: 1.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.36604 Accuracy: 1.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.36565 Accuracy: 1.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.36524 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.36484 Accuracy: 1.00000\n",
      "Test Loss: 0.70891 Accuracy: 0.74725\n",
      "Epoch: 430 Batch:   0 Loss: 0.36445 Accuracy: 1.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.36405 Accuracy: 1.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.36366 Accuracy: 1.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.36326 Accuracy: 1.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.36287 Accuracy: 1.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.36248 Accuracy: 1.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.36209 Accuracy: 1.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.36171 Accuracy: 1.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.36132 Accuracy: 1.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.36094 Accuracy: 1.00000\n",
      "Test Loss: 0.70797 Accuracy: 0.74826\n",
      "Epoch: 440 Batch:   0 Loss: 0.36056 Accuracy: 1.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.36018 Accuracy: 1.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.35980 Accuracy: 1.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.35943 Accuracy: 1.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.35904 Accuracy: 1.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.35897 Accuracy: 1.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.35866 Accuracy: 1.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.35829 Accuracy: 1.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.35791 Accuracy: 1.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.35752 Accuracy: 1.00000\n",
      "Test Loss: 0.70735 Accuracy: 0.74886\n",
      "Epoch: 450 Batch:   0 Loss: 0.35715 Accuracy: 1.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.35677 Accuracy: 1.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.35639 Accuracy: 1.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.35602 Accuracy: 1.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.35565 Accuracy: 1.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.35528 Accuracy: 1.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.35491 Accuracy: 1.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.35455 Accuracy: 1.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.35418 Accuracy: 1.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.35382 Accuracy: 1.00000\n",
      "Test Loss: 0.70648 Accuracy: 0.74997\n",
      "Epoch: 460 Batch:   0 Loss: 0.35347 Accuracy: 1.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.35312 Accuracy: 1.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.35276 Accuracy: 1.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.35240 Accuracy: 1.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.35203 Accuracy: 1.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.35167 Accuracy: 1.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.35132 Accuracy: 1.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.35096 Accuracy: 1.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.35061 Accuracy: 1.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.35025 Accuracy: 1.00000\n",
      "Test Loss: 0.70568 Accuracy: 0.75117\n",
      "Epoch: 470 Batch:   0 Loss: 0.34990 Accuracy: 1.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.34955 Accuracy: 1.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.34921 Accuracy: 1.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.34886 Accuracy: 1.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.34852 Accuracy: 1.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.34818 Accuracy: 1.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.34784 Accuracy: 1.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.34750 Accuracy: 1.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.34716 Accuracy: 1.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.34682 Accuracy: 1.00000\n",
      "Test Loss: 0.70495 Accuracy: 0.75168\n",
      "Epoch: 480 Batch:   0 Loss: 0.34649 Accuracy: 1.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.34616 Accuracy: 1.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.34582 Accuracy: 1.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.34548 Accuracy: 1.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.34515 Accuracy: 1.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.34482 Accuracy: 1.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.34449 Accuracy: 1.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.34416 Accuracy: 1.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.34383 Accuracy: 1.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.34351 Accuracy: 1.00000\n",
      "Test Loss: 0.70427 Accuracy: 0.75198\n",
      "Epoch: 490 Batch:   0 Loss: 0.34318 Accuracy: 1.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.34286 Accuracy: 1.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.34254 Accuracy: 1.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.34222 Accuracy: 1.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.34190 Accuracy: 1.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.34158 Accuracy: 1.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.34126 Accuracy: 1.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.34095 Accuracy: 1.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.34063 Accuracy: 1.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.34031 Accuracy: 1.00000\n",
      "Test Loss: 0.70363 Accuracy: 0.75208\n",
      "Epoch: 500 Batch:   0 Loss: 0.34000 Accuracy: 1.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.33968 Accuracy: 1.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.33937 Accuracy: 1.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.33906 Accuracy: 1.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.33875 Accuracy: 1.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.33844 Accuracy: 1.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.33813 Accuracy: 1.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.33783 Accuracy: 1.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.33752 Accuracy: 1.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.33721 Accuracy: 1.00000\n",
      "Test Loss: 0.70297 Accuracy: 0.75278\n",
      "Epoch: 510 Batch:   0 Loss: 0.33691 Accuracy: 1.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.33660 Accuracy: 1.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.33630 Accuracy: 1.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.33599 Accuracy: 1.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.33569 Accuracy: 1.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.33538 Accuracy: 1.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.33508 Accuracy: 1.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.33478 Accuracy: 1.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.33448 Accuracy: 1.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.33418 Accuracy: 1.00000\n",
      "Test Loss: 0.70234 Accuracy: 0.75288\n",
      "Epoch: 520 Batch:   0 Loss: 0.33388 Accuracy: 1.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.33358 Accuracy: 1.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.33329 Accuracy: 1.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.33299 Accuracy: 1.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.33270 Accuracy: 1.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.33240 Accuracy: 1.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.33211 Accuracy: 1.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.33182 Accuracy: 1.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.33153 Accuracy: 1.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.33124 Accuracy: 1.00000\n",
      "Test Loss: 0.70173 Accuracy: 0.75379\n",
      "Epoch: 530 Batch:   0 Loss: 0.33095 Accuracy: 1.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.33066 Accuracy: 1.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.33037 Accuracy: 1.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.33008 Accuracy: 1.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.32980 Accuracy: 1.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.32951 Accuracy: 1.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.32922 Accuracy: 1.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.32893 Accuracy: 1.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.32865 Accuracy: 1.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.32837 Accuracy: 1.00000\n",
      "Test Loss: 0.70115 Accuracy: 0.75429\n",
      "Epoch: 540 Batch:   0 Loss: 0.32808 Accuracy: 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 10:58:06,766] Trial 17 finished with value: 0.7543224768797748 and parameters: {'REG_W': 3.5406815975622515e-06, 'REG_B': 0.00016864863899221193, 'REG_Z': 3.381830624969882e-05, 'SPAR_W': 0.6256238933757005, 'SPAR_B': 0.7487258140054214, 'SPAR_Z': 0.7340778613007167, 'LEARNING_RATE': 0.00031638933153247143, 'NUM_EPOCHS': 541}. Best is trial 14 with value: 0.756031363088058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.12972 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.12719 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.67977 Accuracy: 1.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.41454 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.72430 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.82880 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.86169 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.86994 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.86907 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.86433 Accuracy: 0.00000\n",
      "Test Loss: 1.00016 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.85754 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.84953 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.84067 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.83124 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.82150 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.81160 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.80164 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.79168 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.78177 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.77191 Accuracy: 0.00000\n",
      "Test Loss: 0.96824 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.76212 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.75235 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.74264 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.73293 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.72322 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.71348 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.70369 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.69386 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.68398 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.67401 Accuracy: 0.00000\n",
      "Test Loss: 0.94529 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.66396 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.65381 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.64356 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.63304 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.62227 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.61137 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.60071 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.58999 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.57907 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.56803 Accuracy: 0.00000\n",
      "Test Loss: 0.92824 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.55639 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.54502 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.53349 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.52167 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.50998 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.49837 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.48640 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.47407 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.46166 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.44897 Accuracy: 0.00000\n",
      "Test Loss: 0.91359 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.43593 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.42277 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.40945 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.39584 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.38223 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.36831 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.35421 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.33980 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.32536 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.31093 Accuracy: 0.00000\n",
      "Test Loss: 0.89929 Accuracy: 0.50020\n",
      "Epoch:  60 Batch:   0 Loss: 1.29653 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.28200 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.26734 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.25289 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 1.23815 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 1.22362 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 1.20933 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 1.19532 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 1.18147 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 1.16760 Accuracy: 0.00000\n",
      "Test Loss: 0.88413 Accuracy: 0.50020\n",
      "Epoch:  70 Batch:   0 Loss: 1.15419 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 1.14090 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 1.12778 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 1.11494 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 1.10236 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 1.08998 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 1.07782 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 1.06583 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 1.05425 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 1.04282 Accuracy: 0.00000\n",
      "Test Loss: 0.86949 Accuracy: 0.50020\n",
      "Epoch:  80 Batch:   0 Loss: 1.03165 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 1.02085 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 1.01032 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 0.99994 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 0.99003 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 0.98021 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 0.97102 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.96211 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.95352 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.94525 Accuracy: 0.00000\n",
      "Test Loss: 0.85671 Accuracy: 0.50030\n",
      "Epoch:  90 Batch:   0 Loss: 0.93725 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.92946 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.92198 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.91476 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.90773 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.90093 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.89445 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.88811 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.88213 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.87637 Accuracy: 0.00000\n",
      "Test Loss: 0.84657 Accuracy: 0.50030\n",
      "Epoch: 100 Batch:   0 Loss: 0.87091 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.86570 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.86064 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.85574 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.85102 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.84652 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.84221 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.83804 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.83403 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.83016 Accuracy: 0.00000\n",
      "Test Loss: 0.83742 Accuracy: 0.50030\n",
      "Epoch: 110 Batch:   0 Loss: 0.82639 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.82293 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.81950 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.81624 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.81317 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.81029 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.80751 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.80494 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.80249 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.80026 Accuracy: 0.00000\n",
      "Test Loss: 0.82854 Accuracy: 0.50040\n",
      "Epoch: 120 Batch:   0 Loss: 0.79820 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.79634 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.79467 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.79308 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.79173 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.79047 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.78943 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.78847 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.78770 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.78705 Accuracy: 0.00000\n",
      "Test Loss: 0.81797 Accuracy: 0.50040\n",
      "Epoch: 130 Batch:   0 Loss: 0.78647 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.78601 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.78563 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.78536 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.78517 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.78512 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.78509 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.78513 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.78521 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.78540 Accuracy: 0.00000\n",
      "Test Loss: 0.80413 Accuracy: 0.50060\n",
      "Epoch: 140 Batch:   0 Loss: 0.78558 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.78576 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.78601 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.78629 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.78659 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.78694 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.78732 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.78770 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.78811 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.78847 Accuracy: 0.00000\n",
      "Test Loss: 0.78890 Accuracy: 0.50060\n",
      "Epoch: 150 Batch:   0 Loss: 0.78888 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.78933 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.78975 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.79019 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.79064 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.79107 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.79150 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.79192 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.79235 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.79278 Accuracy: 0.00000\n",
      "Test Loss: 0.77564 Accuracy: 0.50060\n",
      "Epoch: 160 Batch:   0 Loss: 0.79317 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.79355 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.79393 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.79432 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.79469 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.79507 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.79542 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.79579 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.79615 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.79647 Accuracy: 0.00000\n",
      "Test Loss: 0.76481 Accuracy: 0.50060\n",
      "Epoch: 170 Batch:   0 Loss: 0.79677 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.79706 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.79734 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.79761 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.79789 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.79820 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.79852 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.79881 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.79912 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.79944 Accuracy: 0.00000\n",
      "Test Loss: 0.75584 Accuracy: 0.50060\n",
      "Epoch: 180 Batch:   0 Loss: 0.79973 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.80001 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.80030 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.80059 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.80089 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.80119 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.80150 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.80181 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.80215 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.80245 Accuracy: 0.00000\n",
      "Test Loss: 0.74826 Accuracy: 0.50060\n",
      "Epoch: 190 Batch:   0 Loss: 0.80274 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.80302 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.80327 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.80352 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.80381 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.80409 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.80440 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.80467 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.80499 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.80533 Accuracy: 0.00000\n",
      "Test Loss: 0.74140 Accuracy: 0.50050\n",
      "Epoch: 200 Batch:   0 Loss: 0.80567 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.80601 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.80632 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.80664 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.80696 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.80726 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.80752 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.80782 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.80808 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.80831 Accuracy: 0.00000\n",
      "Test Loss: 0.73510 Accuracy: 0.50050\n",
      "Epoch: 210 Batch:   0 Loss: 0.80855 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.80875 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.80895 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.80910 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.80923 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.80935 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.80944 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.80950 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.80955 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.80956 Accuracy: 0.00000\n",
      "Test Loss: 0.72955 Accuracy: 0.50050\n",
      "Epoch: 220 Batch:   0 Loss: 0.80960 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.80963 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.80966 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.80968 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.80969 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.80969 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.80970 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.80968 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.80967 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.80965 Accuracy: 0.00000\n",
      "Test Loss: 0.72457 Accuracy: 0.50050\n",
      "Epoch: 230 Batch:   0 Loss: 0.80962 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.80958 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.80954 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.80951 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.80944 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.80936 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.80927 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.80919 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.80912 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.80905 Accuracy: 0.00000\n",
      "Test Loss: 0.72012 Accuracy: 0.50050\n",
      "Epoch: 240 Batch:   0 Loss: 0.80895 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.80884 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.80874 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.80864 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.80851 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.80839 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.80823 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.80801 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.80780 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.80757 Accuracy: 0.00000\n",
      "Test Loss: 0.71622 Accuracy: 0.50050\n",
      "Epoch: 250 Batch:   0 Loss: 0.80735 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.80713 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.80690 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.80666 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.80644 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.80622 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.80600 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.80578 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.80557 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.80536 Accuracy: 0.00000\n",
      "Test Loss: 0.71279 Accuracy: 0.50050\n",
      "Epoch: 260 Batch:   0 Loss: 0.80515 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.80493 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.80472 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.80451 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.80430 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.80410 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.80390 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.80369 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.80349 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.80329 Accuracy: 0.00000\n",
      "Test Loss: 0.70980 Accuracy: 0.50050\n",
      "Epoch: 270 Batch:   0 Loss: 0.80309 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.80289 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.80268 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.80247 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.80226 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.80205 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.80184 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.80166 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.80146 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.80127 Accuracy: 0.00000\n",
      "Test Loss: 0.70706 Accuracy: 0.50050\n",
      "Epoch: 280 Batch:   0 Loss: 0.80108 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.80088 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.80070 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.80053 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.80037 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.80019 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.80002 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.79985 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.79967 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.79950 Accuracy: 0.00000\n",
      "Test Loss: 0.70459 Accuracy: 0.50050\n",
      "Epoch: 290 Batch:   0 Loss: 0.79933 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.79917 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.79902 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.79889 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.79876 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.79862 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.79849 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.79835 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.79823 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.79812 Accuracy: 0.00000\n",
      "Test Loss: 0.70226 Accuracy: 0.50050\n",
      "Epoch: 300 Batch:   0 Loss: 0.79798 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.79782 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.79769 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.79756 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.79743 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.79731 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.79717 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.79704 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.79692 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.79679 Accuracy: 0.00000\n",
      "Test Loss: 0.70009 Accuracy: 0.50050\n",
      "Epoch: 310 Batch:   0 Loss: 0.79665 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.79652 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.79640 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.79627 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.79614 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.79602 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.79590 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.79578 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.79566 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.79555 Accuracy: 0.00000\n",
      "Test Loss: 0.69792 Accuracy: 0.50050\n",
      "Epoch: 320 Batch:   0 Loss: 0.79544 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.79531 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.79519 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.79507 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.79495 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.79483 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.79471 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.79460 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.79449 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.79438 Accuracy: 0.00000\n",
      "Test Loss: 0.69591 Accuracy: 0.50050\n",
      "Epoch: 330 Batch:   0 Loss: 0.79426 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.79417 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.79406 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.79395 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.79384 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.79373 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.79362 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.79351 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.79340 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.79329 Accuracy: 0.00000\n",
      "Test Loss: 0.69412 Accuracy: 0.50050\n",
      "Epoch: 340 Batch:   0 Loss: 0.79318 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.79306 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.79296 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.79284 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.79273 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.79262 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.79250 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.79240 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.79230 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.79220 Accuracy: 0.00000\n",
      "Test Loss: 0.69241 Accuracy: 0.50050\n",
      "Epoch: 350 Batch:   0 Loss: 0.79211 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.79201 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.79192 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.79183 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.79173 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.79166 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.79156 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.79146 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.79137 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.79127 Accuracy: 0.00000\n",
      "Test Loss: 0.69085 Accuracy: 0.50050\n",
      "Epoch: 360 Batch:   0 Loss: 0.79118 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.79109 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.79101 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.79092 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.79084 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.79075 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.79067 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.79060 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.79052 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.79045 Accuracy: 0.00000\n",
      "Test Loss: 0.68936 Accuracy: 0.50050\n",
      "Epoch: 370 Batch:   0 Loss: 0.79037 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.79030 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.79024 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.79018 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.79011 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.79005 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.79000 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.78994 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.78989 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.78982 Accuracy: 0.00000\n",
      "Test Loss: 0.68791 Accuracy: 0.50050\n",
      "Epoch: 380 Batch:   0 Loss: 0.78977 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.78970 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.78966 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.78961 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.78956 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.78952 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.78949 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.78945 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.78941 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.78937 Accuracy: 0.00000\n",
      "Test Loss: 0.68662 Accuracy: 0.50050\n",
      "Epoch: 390 Batch:   0 Loss: 0.78933 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.78930 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.78928 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.78926 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.78924 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.78922 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.78920 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.78920 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.78918 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.78918 Accuracy: 0.00000\n",
      "Test Loss: 0.68545 Accuracy: 0.50050\n",
      "Epoch: 400 Batch:   0 Loss: 0.78916 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.78915 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.78914 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.78915 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.78916 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.78918 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.78919 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.78921 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.78923 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.78926 Accuracy: 0.00000\n",
      "Test Loss: 0.68431 Accuracy: 0.50050\n",
      "Epoch: 410 Batch:   0 Loss: 0.78928 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.78932 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.78936 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.78940 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.78945 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.78949 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.78954 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.78960 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.78965 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.78971 Accuracy: 0.00000\n",
      "Test Loss: 0.68318 Accuracy: 0.50050\n",
      "Epoch: 420 Batch:   0 Loss: 0.78977 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.78982 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.78988 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.78993 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.78998 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.79003 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.79008 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.79012 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.79016 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.79020 Accuracy: 0.00000\n",
      "Test Loss: 0.68198 Accuracy: 0.50050\n",
      "Epoch: 430 Batch:   0 Loss: 0.79023 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.79026 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.79028 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.79027 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.79027 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.79025 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.79024 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.79022 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.79018 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.79015 Accuracy: 0.00000\n",
      "Test Loss: 0.68072 Accuracy: 0.50050\n",
      "Epoch: 440 Batch:   0 Loss: 0.79010 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.79005 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.79000 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.78995 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.78989 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.78983 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.78977 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.78973 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.78965 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.78959 Accuracy: 0.00000\n",
      "Test Loss: 0.67953 Accuracy: 0.50050\n",
      "Epoch: 450 Batch:   0 Loss: 0.78952 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.78945 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.78941 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.78938 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.78935 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.78933 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.78931 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.78929 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.78928 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.78927 Accuracy: 0.00000\n",
      "Test Loss: 0.67848 Accuracy: 0.50050\n",
      "Epoch: 460 Batch:   0 Loss: 0.78927 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.78928 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.78930 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.78932 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.78934 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.78938 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.78942 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.78949 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.78958 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.78966 Accuracy: 0.00000\n",
      "Test Loss: 0.67740 Accuracy: 0.50050\n",
      "Epoch: 470 Batch:   0 Loss: 0.78975 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.78985 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.78995 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.79006 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.79017 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.79028 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.79039 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.79050 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.79059 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.79069 Accuracy: 0.00000\n",
      "Test Loss: 0.67628 Accuracy: 0.50050\n",
      "Epoch: 480 Batch:   0 Loss: 0.79076 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.79082 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.79086 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.79090 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.79096 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.79098 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.79098 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.79098 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.79098 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.79095 Accuracy: 0.00000\n",
      "Test Loss: 0.67519 Accuracy: 0.50050\n",
      "Epoch: 490 Batch:   0 Loss: 0.79092 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.79088 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.79083 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.79077 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.79068 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.79057 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.79046 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.79032 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.79017 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.78999 Accuracy: 0.00000\n",
      "Test Loss: 0.67433 Accuracy: 0.50050\n",
      "Epoch: 500 Batch:   0 Loss: 0.78979 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.78958 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.78937 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.78914 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.78890 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.78864 Accuracy: 0.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.78836 Accuracy: 0.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.78808 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.78778 Accuracy: 0.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.78748 Accuracy: 0.00000\n",
      "Test Loss: 0.67372 Accuracy: 0.50050\n",
      "Epoch: 510 Batch:   0 Loss: 0.78718 Accuracy: 0.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.78688 Accuracy: 0.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.78656 Accuracy: 0.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.78622 Accuracy: 0.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.78589 Accuracy: 0.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.78555 Accuracy: 0.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.78521 Accuracy: 0.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.78487 Accuracy: 0.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.78454 Accuracy: 0.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.78420 Accuracy: 0.00000\n",
      "Test Loss: 0.67346 Accuracy: 0.50040\n",
      "Epoch: 520 Batch:   0 Loss: 0.78387 Accuracy: 0.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.78354 Accuracy: 0.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.78321 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.78286 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.78253 Accuracy: 0.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.78220 Accuracy: 0.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.78188 Accuracy: 0.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.78157 Accuracy: 0.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.78125 Accuracy: 0.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.78093 Accuracy: 0.00000\n",
      "Test Loss: 0.67338 Accuracy: 0.50040\n",
      "Epoch: 530 Batch:   0 Loss: 0.78062 Accuracy: 0.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.78032 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.78002 Accuracy: 0.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.77972 Accuracy: 0.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.77943 Accuracy: 0.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.77914 Accuracy: 0.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.77886 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 11:03:01,976] Trial 18 finished with value: 0.5002010454362686 and parameters: {'REG_W': 3.582384022396309e-06, 'REG_B': 0.004066284365854493, 'REG_Z': 4.028592909037885e-05, 'SPAR_W': 0.5073628275195186, 'SPAR_B': 0.7855526698024307, 'SPAR_Z': 0.7414618993232829, 'LEARNING_RATE': 0.00032117831832901276, 'NUM_EPOCHS': 537}. Best is trial 14 with value: 0.756031363088058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 0.07572 Accuracy: 1.00000\n",
      "Epoch:   1 Batch:   0 Loss: 0.10939 Accuracy: 1.00000\n",
      "Epoch:   2 Batch:   0 Loss: 0.67295 Accuracy: 1.00000\n",
      "Epoch:   3 Batch:   0 Loss: 1.33738 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 1.61726 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 1.71323 Accuracy: 0.00000\n",
      "Epoch:   6 Batch:   0 Loss: 1.74384 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 1.75130 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 1.74954 Accuracy: 0.00000\n",
      "Epoch:   9 Batch:   0 Loss: 1.74347 Accuracy: 0.00000\n",
      "Test Loss: 0.94540 Accuracy: 0.50020\n",
      "Epoch:  10 Batch:   0 Loss: 1.73490 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 1.72466 Accuracy: 0.00000\n",
      "Epoch:  12 Batch:   0 Loss: 1.71330 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 1.70128 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 1.68896 Accuracy: 0.00000\n",
      "Epoch:  15 Batch:   0 Loss: 1.67651 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 1.66414 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 1.65205 Accuracy: 0.00000\n",
      "Epoch:  18 Batch:   0 Loss: 1.64027 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 1.62885 Accuracy: 0.00000\n",
      "Test Loss: 0.92829 Accuracy: 0.50020\n",
      "Epoch:  20 Batch:   0 Loss: 1.61782 Accuracy: 0.00000\n",
      "Epoch:  21 Batch:   0 Loss: 1.60702 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 1.59669 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 1.58666 Accuracy: 0.00000\n",
      "Epoch:  24 Batch:   0 Loss: 1.57703 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 1.56741 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 1.55832 Accuracy: 0.00000\n",
      "Epoch:  27 Batch:   0 Loss: 1.54939 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 1.54058 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 1.53182 Accuracy: 0.00000\n",
      "Test Loss: 0.92462 Accuracy: 0.50020\n",
      "Epoch:  30 Batch:   0 Loss: 1.52317 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 1.51466 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 1.50648 Accuracy: 0.00000\n",
      "Epoch:  33 Batch:   0 Loss: 1.49824 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 1.49026 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 1.48240 Accuracy: 0.00000\n",
      "Epoch:  36 Batch:   0 Loss: 1.47453 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 1.46658 Accuracy: 0.00000\n",
      "Epoch:  38 Batch:   0 Loss: 1.45858 Accuracy: 0.00000\n",
      "Epoch:  39 Batch:   0 Loss: 1.45038 Accuracy: 0.00000\n",
      "Test Loss: 0.92320 Accuracy: 0.50020\n",
      "Epoch:  40 Batch:   0 Loss: 1.44229 Accuracy: 0.00000\n",
      "Epoch:  41 Batch:   0 Loss: 1.43410 Accuracy: 0.00000\n",
      "Epoch:  42 Batch:   0 Loss: 1.42579 Accuracy: 0.00000\n",
      "Epoch:  43 Batch:   0 Loss: 1.41745 Accuracy: 0.00000\n",
      "Epoch:  44 Batch:   0 Loss: 1.40910 Accuracy: 0.00000\n",
      "Epoch:  45 Batch:   0 Loss: 1.40042 Accuracy: 0.00000\n",
      "Epoch:  46 Batch:   0 Loss: 1.39175 Accuracy: 0.00000\n",
      "Epoch:  47 Batch:   0 Loss: 1.38296 Accuracy: 0.00000\n",
      "Epoch:  48 Batch:   0 Loss: 1.37367 Accuracy: 0.00000\n",
      "Epoch:  49 Batch:   0 Loss: 1.36440 Accuracy: 0.00000\n",
      "Test Loss: 0.91883 Accuracy: 0.50020\n",
      "Epoch:  50 Batch:   0 Loss: 1.35502 Accuracy: 0.00000\n",
      "Epoch:  51 Batch:   0 Loss: 1.34556 Accuracy: 0.00000\n",
      "Epoch:  52 Batch:   0 Loss: 1.33601 Accuracy: 0.00000\n",
      "Epoch:  53 Batch:   0 Loss: 1.32640 Accuracy: 0.00000\n",
      "Epoch:  54 Batch:   0 Loss: 1.31643 Accuracy: 0.00000\n",
      "Epoch:  55 Batch:   0 Loss: 1.30655 Accuracy: 0.00000\n",
      "Epoch:  56 Batch:   0 Loss: 1.29640 Accuracy: 0.00000\n",
      "Epoch:  57 Batch:   0 Loss: 1.28621 Accuracy: 0.00000\n",
      "Epoch:  58 Batch:   0 Loss: 1.27609 Accuracy: 0.00000\n",
      "Epoch:  59 Batch:   0 Loss: 1.26596 Accuracy: 0.00000\n",
      "Test Loss: 0.91141 Accuracy: 0.50020\n",
      "Epoch:  60 Batch:   0 Loss: 1.25578 Accuracy: 0.00000\n",
      "Epoch:  61 Batch:   0 Loss: 1.24546 Accuracy: 0.00000\n",
      "Epoch:  62 Batch:   0 Loss: 1.23516 Accuracy: 0.00000\n",
      "Epoch:  63 Batch:   0 Loss: 1.22486 Accuracy: 0.00000\n",
      "Epoch:  64 Batch:   0 Loss: 1.21472 Accuracy: 0.00000\n",
      "Epoch:  65 Batch:   0 Loss: 1.20460 Accuracy: 0.00000\n",
      "Epoch:  66 Batch:   0 Loss: 1.19444 Accuracy: 0.00000\n",
      "Epoch:  67 Batch:   0 Loss: 1.18426 Accuracy: 0.00000\n",
      "Epoch:  68 Batch:   0 Loss: 1.17409 Accuracy: 0.00000\n",
      "Epoch:  69 Batch:   0 Loss: 1.16400 Accuracy: 0.00000\n",
      "Test Loss: 0.90309 Accuracy: 0.50020\n",
      "Epoch:  70 Batch:   0 Loss: 1.15398 Accuracy: 0.00000\n",
      "Epoch:  71 Batch:   0 Loss: 1.14392 Accuracy: 0.00000\n",
      "Epoch:  72 Batch:   0 Loss: 1.13389 Accuracy: 0.00000\n",
      "Epoch:  73 Batch:   0 Loss: 1.12394 Accuracy: 0.00000\n",
      "Epoch:  74 Batch:   0 Loss: 1.11398 Accuracy: 0.00000\n",
      "Epoch:  75 Batch:   0 Loss: 1.10420 Accuracy: 0.00000\n",
      "Epoch:  76 Batch:   0 Loss: 1.09451 Accuracy: 0.00000\n",
      "Epoch:  77 Batch:   0 Loss: 1.08492 Accuracy: 0.00000\n",
      "Epoch:  78 Batch:   0 Loss: 1.07557 Accuracy: 0.00000\n",
      "Epoch:  79 Batch:   0 Loss: 1.06635 Accuracy: 0.00000\n",
      "Test Loss: 0.89416 Accuracy: 0.50020\n",
      "Epoch:  80 Batch:   0 Loss: 1.05719 Accuracy: 0.00000\n",
      "Epoch:  81 Batch:   0 Loss: 1.04808 Accuracy: 0.00000\n",
      "Epoch:  82 Batch:   0 Loss: 1.03911 Accuracy: 0.00000\n",
      "Epoch:  83 Batch:   0 Loss: 1.03044 Accuracy: 0.00000\n",
      "Epoch:  84 Batch:   0 Loss: 1.02178 Accuracy: 0.00000\n",
      "Epoch:  85 Batch:   0 Loss: 1.01332 Accuracy: 0.00000\n",
      "Epoch:  86 Batch:   0 Loss: 1.00504 Accuracy: 0.00000\n",
      "Epoch:  87 Batch:   0 Loss: 0.99695 Accuracy: 0.00000\n",
      "Epoch:  88 Batch:   0 Loss: 0.98904 Accuracy: 0.00000\n",
      "Epoch:  89 Batch:   0 Loss: 0.98124 Accuracy: 0.00000\n",
      "Test Loss: 0.88451 Accuracy: 0.50020\n",
      "Epoch:  90 Batch:   0 Loss: 0.97361 Accuracy: 0.00000\n",
      "Epoch:  91 Batch:   0 Loss: 0.96615 Accuracy: 0.00000\n",
      "Epoch:  92 Batch:   0 Loss: 0.95890 Accuracy: 0.00000\n",
      "Epoch:  93 Batch:   0 Loss: 0.95179 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 0.94486 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 0.93802 Accuracy: 0.00000\n",
      "Epoch:  96 Batch:   0 Loss: 0.93135 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 0.92494 Accuracy: 0.00000\n",
      "Epoch:  98 Batch:   0 Loss: 0.91867 Accuracy: 0.00000\n",
      "Epoch:  99 Batch:   0 Loss: 0.91259 Accuracy: 0.00000\n",
      "Test Loss: 0.87465 Accuracy: 0.50020\n",
      "Epoch: 100 Batch:   0 Loss: 0.90669 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 0.90096 Accuracy: 0.00000\n",
      "Epoch: 102 Batch:   0 Loss: 0.89538 Accuracy: 0.00000\n",
      "Epoch: 103 Batch:   0 Loss: 0.88997 Accuracy: 0.00000\n",
      "Epoch: 104 Batch:   0 Loss: 0.88467 Accuracy: 0.00000\n",
      "Epoch: 105 Batch:   0 Loss: 0.87951 Accuracy: 0.00000\n",
      "Epoch: 106 Batch:   0 Loss: 0.87457 Accuracy: 0.00000\n",
      "Epoch: 107 Batch:   0 Loss: 0.86979 Accuracy: 0.00000\n",
      "Epoch: 108 Batch:   0 Loss: 0.86515 Accuracy: 0.00000\n",
      "Epoch: 109 Batch:   0 Loss: 0.86065 Accuracy: 0.00000\n",
      "Test Loss: 0.86440 Accuracy: 0.50020\n",
      "Epoch: 110 Batch:   0 Loss: 0.85629 Accuracy: 0.00000\n",
      "Epoch: 111 Batch:   0 Loss: 0.85197 Accuracy: 0.00000\n",
      "Epoch: 112 Batch:   0 Loss: 0.84797 Accuracy: 0.00000\n",
      "Epoch: 113 Batch:   0 Loss: 0.84411 Accuracy: 0.00000\n",
      "Epoch: 114 Batch:   0 Loss: 0.84035 Accuracy: 0.00000\n",
      "Epoch: 115 Batch:   0 Loss: 0.83671 Accuracy: 0.00000\n",
      "Epoch: 116 Batch:   0 Loss: 0.83323 Accuracy: 0.00000\n",
      "Epoch: 117 Batch:   0 Loss: 0.82989 Accuracy: 0.00000\n",
      "Epoch: 118 Batch:   0 Loss: 0.82669 Accuracy: 0.00000\n",
      "Epoch: 119 Batch:   0 Loss: 0.82359 Accuracy: 0.00000\n",
      "Test Loss: 0.85323 Accuracy: 0.50030\n",
      "Epoch: 120 Batch:   0 Loss: 0.82057 Accuracy: 0.00000\n",
      "Epoch: 121 Batch:   0 Loss: 0.81772 Accuracy: 0.00000\n",
      "Epoch: 122 Batch:   0 Loss: 0.81500 Accuracy: 0.00000\n",
      "Epoch: 123 Batch:   0 Loss: 0.81234 Accuracy: 0.00000\n",
      "Epoch: 124 Batch:   0 Loss: 0.80984 Accuracy: 0.00000\n",
      "Epoch: 125 Batch:   0 Loss: 0.80748 Accuracy: 0.00000\n",
      "Epoch: 126 Batch:   0 Loss: 0.80522 Accuracy: 0.00000\n",
      "Epoch: 127 Batch:   0 Loss: 0.80309 Accuracy: 0.00000\n",
      "Epoch: 128 Batch:   0 Loss: 0.80107 Accuracy: 0.00000\n",
      "Epoch: 129 Batch:   0 Loss: 0.79918 Accuracy: 0.00000\n",
      "Test Loss: 0.83983 Accuracy: 0.50040\n",
      "Epoch: 130 Batch:   0 Loss: 0.79743 Accuracy: 0.00000\n",
      "Epoch: 131 Batch:   0 Loss: 0.79577 Accuracy: 0.00000\n",
      "Epoch: 132 Batch:   0 Loss: 0.79428 Accuracy: 0.00000\n",
      "Epoch: 133 Batch:   0 Loss: 0.79296 Accuracy: 0.00000\n",
      "Epoch: 134 Batch:   0 Loss: 0.79179 Accuracy: 0.00000\n",
      "Epoch: 135 Batch:   0 Loss: 0.79073 Accuracy: 0.00000\n",
      "Epoch: 136 Batch:   0 Loss: 0.78978 Accuracy: 0.00000\n",
      "Epoch: 137 Batch:   0 Loss: 0.78890 Accuracy: 0.00000\n",
      "Epoch: 138 Batch:   0 Loss: 0.78823 Accuracy: 0.00000\n",
      "Epoch: 139 Batch:   0 Loss: 0.78764 Accuracy: 0.00000\n",
      "Test Loss: 0.82197 Accuracy: 0.50040\n",
      "Epoch: 140 Batch:   0 Loss: 0.78716 Accuracy: 0.00000\n",
      "Epoch: 141 Batch:   0 Loss: 0.78672 Accuracy: 0.00000\n",
      "Epoch: 142 Batch:   0 Loss: 0.78645 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.78622 Accuracy: 0.00000\n",
      "Epoch: 144 Batch:   0 Loss: 0.78607 Accuracy: 0.00000\n",
      "Epoch: 145 Batch:   0 Loss: 0.78599 Accuracy: 0.00000\n",
      "Epoch: 146 Batch:   0 Loss: 0.78597 Accuracy: 0.00000\n",
      "Epoch: 147 Batch:   0 Loss: 0.78600 Accuracy: 0.00000\n",
      "Epoch: 148 Batch:   0 Loss: 0.78605 Accuracy: 0.00000\n",
      "Epoch: 149 Batch:   0 Loss: 0.78617 Accuracy: 0.00000\n",
      "Test Loss: 0.80368 Accuracy: 0.50050\n",
      "Epoch: 150 Batch:   0 Loss: 0.78633 Accuracy: 0.00000\n",
      "Epoch: 151 Batch:   0 Loss: 0.78646 Accuracy: 0.00000\n",
      "Epoch: 152 Batch:   0 Loss: 0.78658 Accuracy: 0.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.78670 Accuracy: 0.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.78686 Accuracy: 0.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.78697 Accuracy: 0.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.78706 Accuracy: 0.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.78714 Accuracy: 0.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.78722 Accuracy: 0.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.78734 Accuracy: 0.00000\n",
      "Test Loss: 0.78680 Accuracy: 0.50060\n",
      "Epoch: 160 Batch:   0 Loss: 0.78744 Accuracy: 0.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.78755 Accuracy: 0.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.78763 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.78770 Accuracy: 0.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.78778 Accuracy: 0.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.78784 Accuracy: 0.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.78784 Accuracy: 0.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.78788 Accuracy: 0.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.78793 Accuracy: 0.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.78796 Accuracy: 0.00000\n",
      "Test Loss: 0.77112 Accuracy: 0.50060\n",
      "Epoch: 170 Batch:   0 Loss: 0.78797 Accuracy: 0.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.78797 Accuracy: 0.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.78795 Accuracy: 0.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.78793 Accuracy: 0.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.78792 Accuracy: 0.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.78792 Accuracy: 0.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.78790 Accuracy: 0.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.78788 Accuracy: 0.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.78788 Accuracy: 0.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.78787 Accuracy: 0.00000\n",
      "Test Loss: 0.75729 Accuracy: 0.50060\n",
      "Epoch: 180 Batch:   0 Loss: 0.78787 Accuracy: 0.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.78788 Accuracy: 0.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.78790 Accuracy: 0.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.78796 Accuracy: 0.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.78799 Accuracy: 0.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.78808 Accuracy: 0.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.78817 Accuracy: 0.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.78827 Accuracy: 0.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.78837 Accuracy: 0.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.78846 Accuracy: 0.00000\n",
      "Test Loss: 0.74567 Accuracy: 0.50060\n",
      "Epoch: 190 Batch:   0 Loss: 0.78861 Accuracy: 0.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.78876 Accuracy: 0.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.78894 Accuracy: 0.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.78912 Accuracy: 0.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.78932 Accuracy: 0.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.78955 Accuracy: 0.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.78977 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.78998 Accuracy: 0.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.79018 Accuracy: 0.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.79041 Accuracy: 0.00000\n",
      "Test Loss: 0.73604 Accuracy: 0.50070\n",
      "Epoch: 200 Batch:   0 Loss: 0.79065 Accuracy: 0.00000\n",
      "Epoch: 201 Batch:   0 Loss: 0.79089 Accuracy: 0.00000\n",
      "Epoch: 202 Batch:   0 Loss: 0.79114 Accuracy: 0.00000\n",
      "Epoch: 203 Batch:   0 Loss: 0.79140 Accuracy: 0.00000\n",
      "Epoch: 204 Batch:   0 Loss: 0.79169 Accuracy: 0.00000\n",
      "Epoch: 205 Batch:   0 Loss: 0.79199 Accuracy: 0.00000\n",
      "Epoch: 206 Batch:   0 Loss: 0.79229 Accuracy: 0.00000\n",
      "Epoch: 207 Batch:   0 Loss: 0.79259 Accuracy: 0.00000\n",
      "Epoch: 208 Batch:   0 Loss: 0.79289 Accuracy: 0.00000\n",
      "Epoch: 209 Batch:   0 Loss: 0.79318 Accuracy: 0.00000\n",
      "Test Loss: 0.72810 Accuracy: 0.50070\n",
      "Epoch: 210 Batch:   0 Loss: 0.79347 Accuracy: 0.00000\n",
      "Epoch: 211 Batch:   0 Loss: 0.79377 Accuracy: 0.00000\n",
      "Epoch: 212 Batch:   0 Loss: 0.79410 Accuracy: 0.00000\n",
      "Epoch: 213 Batch:   0 Loss: 0.79441 Accuracy: 0.00000\n",
      "Epoch: 214 Batch:   0 Loss: 0.79473 Accuracy: 0.00000\n",
      "Epoch: 215 Batch:   0 Loss: 0.79505 Accuracy: 0.00000\n",
      "Epoch: 216 Batch:   0 Loss: 0.79539 Accuracy: 0.00000\n",
      "Epoch: 217 Batch:   0 Loss: 0.79573 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 0.79606 Accuracy: 0.00000\n",
      "Epoch: 219 Batch:   0 Loss: 0.79639 Accuracy: 0.00000\n",
      "Test Loss: 0.72150 Accuracy: 0.50070\n",
      "Epoch: 220 Batch:   0 Loss: 0.79674 Accuracy: 0.00000\n",
      "Epoch: 221 Batch:   0 Loss: 0.79709 Accuracy: 0.00000\n",
      "Epoch: 222 Batch:   0 Loss: 0.79744 Accuracy: 0.00000\n",
      "Epoch: 223 Batch:   0 Loss: 0.79778 Accuracy: 0.00000\n",
      "Epoch: 224 Batch:   0 Loss: 0.79814 Accuracy: 0.00000\n",
      "Epoch: 225 Batch:   0 Loss: 0.79850 Accuracy: 0.00000\n",
      "Epoch: 226 Batch:   0 Loss: 0.79886 Accuracy: 0.00000\n",
      "Epoch: 227 Batch:   0 Loss: 0.79921 Accuracy: 0.00000\n",
      "Epoch: 228 Batch:   0 Loss: 0.79956 Accuracy: 0.00000\n",
      "Epoch: 229 Batch:   0 Loss: 0.79989 Accuracy: 0.00000\n",
      "Test Loss: 0.71591 Accuracy: 0.50070\n",
      "Epoch: 230 Batch:   0 Loss: 0.80021 Accuracy: 0.00000\n",
      "Epoch: 231 Batch:   0 Loss: 0.80054 Accuracy: 0.00000\n",
      "Epoch: 232 Batch:   0 Loss: 0.80089 Accuracy: 0.00000\n",
      "Epoch: 233 Batch:   0 Loss: 0.80123 Accuracy: 0.00000\n",
      "Epoch: 234 Batch:   0 Loss: 0.80157 Accuracy: 0.00000\n",
      "Epoch: 235 Batch:   0 Loss: 0.80190 Accuracy: 0.00000\n",
      "Epoch: 236 Batch:   0 Loss: 0.80223 Accuracy: 0.00000\n",
      "Epoch: 237 Batch:   0 Loss: 0.80254 Accuracy: 0.00000\n",
      "Epoch: 238 Batch:   0 Loss: 0.80283 Accuracy: 0.00000\n",
      "Epoch: 239 Batch:   0 Loss: 0.80312 Accuracy: 0.00000\n",
      "Test Loss: 0.71118 Accuracy: 0.50070\n",
      "Epoch: 240 Batch:   0 Loss: 0.80340 Accuracy: 0.00000\n",
      "Epoch: 241 Batch:   0 Loss: 0.80368 Accuracy: 0.00000\n",
      "Epoch: 242 Batch:   0 Loss: 0.80395 Accuracy: 0.00000\n",
      "Epoch: 243 Batch:   0 Loss: 0.80422 Accuracy: 0.00000\n",
      "Epoch: 244 Batch:   0 Loss: 0.80449 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 0.80473 Accuracy: 0.00000\n",
      "Epoch: 246 Batch:   0 Loss: 0.80496 Accuracy: 0.00000\n",
      "Epoch: 247 Batch:   0 Loss: 0.80519 Accuracy: 0.00000\n",
      "Epoch: 248 Batch:   0 Loss: 0.80542 Accuracy: 0.00000\n",
      "Epoch: 249 Batch:   0 Loss: 0.80566 Accuracy: 0.00000\n",
      "Test Loss: 0.70712 Accuracy: 0.50070\n",
      "Epoch: 250 Batch:   0 Loss: 0.80588 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 0.80609 Accuracy: 0.00000\n",
      "Epoch: 252 Batch:   0 Loss: 0.80630 Accuracy: 0.00000\n",
      "Epoch: 253 Batch:   0 Loss: 0.80652 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 0.80674 Accuracy: 0.00000\n",
      "Epoch: 255 Batch:   0 Loss: 0.80696 Accuracy: 0.00000\n",
      "Epoch: 256 Batch:   0 Loss: 0.80718 Accuracy: 0.00000\n",
      "Epoch: 257 Batch:   0 Loss: 0.80740 Accuracy: 0.00000\n",
      "Epoch: 258 Batch:   0 Loss: 0.80759 Accuracy: 0.00000\n",
      "Epoch: 259 Batch:   0 Loss: 0.80778 Accuracy: 0.00000\n",
      "Test Loss: 0.70353 Accuracy: 0.50070\n",
      "Epoch: 260 Batch:   0 Loss: 0.80797 Accuracy: 0.00000\n",
      "Epoch: 261 Batch:   0 Loss: 0.80814 Accuracy: 0.00000\n",
      "Epoch: 262 Batch:   0 Loss: 0.80831 Accuracy: 0.00000\n",
      "Epoch: 263 Batch:   0 Loss: 0.80849 Accuracy: 0.00000\n",
      "Epoch: 264 Batch:   0 Loss: 0.80867 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 0.80884 Accuracy: 0.00000\n",
      "Epoch: 266 Batch:   0 Loss: 0.80900 Accuracy: 0.00000\n",
      "Epoch: 267 Batch:   0 Loss: 0.80915 Accuracy: 0.00000\n",
      "Epoch: 268 Batch:   0 Loss: 0.80931 Accuracy: 0.00000\n",
      "Epoch: 269 Batch:   0 Loss: 0.80945 Accuracy: 0.00000\n",
      "Test Loss: 0.70033 Accuracy: 0.50070\n",
      "Epoch: 270 Batch:   0 Loss: 0.80958 Accuracy: 0.00000\n",
      "Epoch: 271 Batch:   0 Loss: 0.80966 Accuracy: 0.00000\n",
      "Epoch: 272 Batch:   0 Loss: 0.80972 Accuracy: 0.00000\n",
      "Epoch: 273 Batch:   0 Loss: 0.80978 Accuracy: 0.00000\n",
      "Epoch: 274 Batch:   0 Loss: 0.80985 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 0.80989 Accuracy: 0.00000\n",
      "Epoch: 276 Batch:   0 Loss: 0.80994 Accuracy: 0.00000\n",
      "Epoch: 277 Batch:   0 Loss: 0.80998 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 0.81001 Accuracy: 0.00000\n",
      "Epoch: 279 Batch:   0 Loss: 0.81005 Accuracy: 0.00000\n",
      "Test Loss: 0.69749 Accuracy: 0.50070\n",
      "Epoch: 280 Batch:   0 Loss: 0.81008 Accuracy: 0.00000\n",
      "Epoch: 281 Batch:   0 Loss: 0.81012 Accuracy: 0.00000\n",
      "Epoch: 282 Batch:   0 Loss: 0.81015 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 0.81017 Accuracy: 0.00000\n",
      "Epoch: 284 Batch:   0 Loss: 0.81017 Accuracy: 0.00000\n",
      "Epoch: 285 Batch:   0 Loss: 0.81017 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286 Batch:   0 Loss: 0.81015 Accuracy: 0.00000\n",
      "Epoch: 287 Batch:   0 Loss: 0.81013 Accuracy: 0.00000\n",
      "Epoch: 288 Batch:   0 Loss: 0.81008 Accuracy: 0.00000\n",
      "Epoch: 289 Batch:   0 Loss: 0.81005 Accuracy: 0.00000\n",
      "Test Loss: 0.69496 Accuracy: 0.50070\n",
      "Epoch: 290 Batch:   0 Loss: 0.81002 Accuracy: 0.00000\n",
      "Epoch: 291 Batch:   0 Loss: 0.80997 Accuracy: 0.00000\n",
      "Epoch: 292 Batch:   0 Loss: 0.80992 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 0.80987 Accuracy: 0.00000\n",
      "Epoch: 294 Batch:   0 Loss: 0.80982 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 0.80976 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 0.80969 Accuracy: 0.00000\n",
      "Epoch: 297 Batch:   0 Loss: 0.80962 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 0.80955 Accuracy: 0.00000\n",
      "Epoch: 299 Batch:   0 Loss: 0.80947 Accuracy: 0.00000\n",
      "Test Loss: 0.69268 Accuracy: 0.50070\n",
      "Epoch: 300 Batch:   0 Loss: 0.80939 Accuracy: 0.00000\n",
      "Epoch: 301 Batch:   0 Loss: 0.80932 Accuracy: 0.00000\n",
      "Epoch: 302 Batch:   0 Loss: 0.80923 Accuracy: 0.00000\n",
      "Epoch: 303 Batch:   0 Loss: 0.80914 Accuracy: 0.00000\n",
      "Epoch: 304 Batch:   0 Loss: 0.80905 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 0.80896 Accuracy: 0.00000\n",
      "Epoch: 306 Batch:   0 Loss: 0.80887 Accuracy: 0.00000\n",
      "Epoch: 307 Batch:   0 Loss: 0.80877 Accuracy: 0.00000\n",
      "Epoch: 308 Batch:   0 Loss: 0.80866 Accuracy: 0.00000\n",
      "Epoch: 309 Batch:   0 Loss: 0.80855 Accuracy: 0.00000\n",
      "Test Loss: 0.69063 Accuracy: 0.50070\n",
      "Epoch: 310 Batch:   0 Loss: 0.80844 Accuracy: 0.00000\n",
      "Epoch: 311 Batch:   0 Loss: 0.80832 Accuracy: 0.00000\n",
      "Epoch: 312 Batch:   0 Loss: 0.80820 Accuracy: 0.00000\n",
      "Epoch: 313 Batch:   0 Loss: 0.80809 Accuracy: 0.00000\n",
      "Epoch: 314 Batch:   0 Loss: 0.80797 Accuracy: 0.00000\n",
      "Epoch: 315 Batch:   0 Loss: 0.80786 Accuracy: 0.00000\n",
      "Epoch: 316 Batch:   0 Loss: 0.80774 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 0.80763 Accuracy: 0.00000\n",
      "Epoch: 318 Batch:   0 Loss: 0.80752 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 0.80740 Accuracy: 0.00000\n",
      "Test Loss: 0.68881 Accuracy: 0.50070\n",
      "Epoch: 320 Batch:   0 Loss: 0.80729 Accuracy: 0.00000\n",
      "Epoch: 321 Batch:   0 Loss: 0.80717 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 0.80704 Accuracy: 0.00000\n",
      "Epoch: 323 Batch:   0 Loss: 0.80690 Accuracy: 0.00000\n",
      "Epoch: 324 Batch:   0 Loss: 0.80677 Accuracy: 0.00000\n",
      "Epoch: 325 Batch:   0 Loss: 0.80663 Accuracy: 0.00000\n",
      "Epoch: 326 Batch:   0 Loss: 0.80647 Accuracy: 0.00000\n",
      "Epoch: 327 Batch:   0 Loss: 0.80633 Accuracy: 0.00000\n",
      "Epoch: 328 Batch:   0 Loss: 0.80619 Accuracy: 0.00000\n",
      "Epoch: 329 Batch:   0 Loss: 0.80604 Accuracy: 0.00000\n",
      "Test Loss: 0.68711 Accuracy: 0.50070\n",
      "Epoch: 330 Batch:   0 Loss: 0.80589 Accuracy: 0.00000\n",
      "Epoch: 331 Batch:   0 Loss: 0.80575 Accuracy: 0.00000\n",
      "Epoch: 332 Batch:   0 Loss: 0.80560 Accuracy: 0.00000\n",
      "Epoch: 333 Batch:   0 Loss: 0.80546 Accuracy: 0.00000\n",
      "Epoch: 334 Batch:   0 Loss: 0.80531 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 0.80516 Accuracy: 0.00000\n",
      "Epoch: 336 Batch:   0 Loss: 0.80501 Accuracy: 0.00000\n",
      "Epoch: 337 Batch:   0 Loss: 0.80486 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 0.80471 Accuracy: 0.00000\n",
      "Epoch: 339 Batch:   0 Loss: 0.80456 Accuracy: 0.00000\n",
      "Test Loss: 0.68558 Accuracy: 0.50070\n",
      "Epoch: 340 Batch:   0 Loss: 0.80441 Accuracy: 0.00000\n",
      "Epoch: 341 Batch:   0 Loss: 0.80426 Accuracy: 0.00000\n",
      "Epoch: 342 Batch:   0 Loss: 0.80411 Accuracy: 0.00000\n",
      "Epoch: 343 Batch:   0 Loss: 0.80397 Accuracy: 0.00000\n",
      "Epoch: 344 Batch:   0 Loss: 0.80382 Accuracy: 0.00000\n",
      "Epoch: 345 Batch:   0 Loss: 0.80367 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 0.80352 Accuracy: 0.00000\n",
      "Epoch: 347 Batch:   0 Loss: 0.80337 Accuracy: 0.00000\n",
      "Epoch: 348 Batch:   0 Loss: 0.80322 Accuracy: 0.00000\n",
      "Epoch: 349 Batch:   0 Loss: 0.80307 Accuracy: 0.00000\n",
      "Test Loss: 0.68428 Accuracy: 0.50070\n",
      "Epoch: 350 Batch:   0 Loss: 0.80293 Accuracy: 0.00000\n",
      "Epoch: 351 Batch:   0 Loss: 0.80277 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 0.80262 Accuracy: 0.00000\n",
      "Epoch: 353 Batch:   0 Loss: 0.80248 Accuracy: 0.00000\n",
      "Epoch: 354 Batch:   0 Loss: 0.80233 Accuracy: 0.00000\n",
      "Epoch: 355 Batch:   0 Loss: 0.80218 Accuracy: 0.00000\n",
      "Epoch: 356 Batch:   0 Loss: 0.80202 Accuracy: 0.00000\n",
      "Epoch: 357 Batch:   0 Loss: 0.80188 Accuracy: 0.00000\n",
      "Epoch: 358 Batch:   0 Loss: 0.80172 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 0.80156 Accuracy: 0.00000\n",
      "Test Loss: 0.68315 Accuracy: 0.50070\n",
      "Epoch: 360 Batch:   0 Loss: 0.80139 Accuracy: 0.00000\n",
      "Epoch: 361 Batch:   0 Loss: 0.80123 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 0.80107 Accuracy: 0.00000\n",
      "Epoch: 363 Batch:   0 Loss: 0.80091 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 0.80075 Accuracy: 0.00000\n",
      "Epoch: 365 Batch:   0 Loss: 0.80059 Accuracy: 0.00000\n",
      "Epoch: 366 Batch:   0 Loss: 0.80044 Accuracy: 0.00000\n",
      "Epoch: 367 Batch:   0 Loss: 0.80028 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 0.80012 Accuracy: 0.00000\n",
      "Epoch: 369 Batch:   0 Loss: 0.79997 Accuracy: 0.00000\n",
      "Test Loss: 0.68218 Accuracy: 0.50070\n",
      "Epoch: 370 Batch:   0 Loss: 0.79982 Accuracy: 0.00000\n",
      "Epoch: 371 Batch:   0 Loss: 0.79967 Accuracy: 0.00000\n",
      "Epoch: 372 Batch:   0 Loss: 0.79951 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 0.79935 Accuracy: 0.00000\n",
      "Epoch: 374 Batch:   0 Loss: 0.79919 Accuracy: 0.00000\n",
      "Epoch: 375 Batch:   0 Loss: 0.79904 Accuracy: 0.00000\n",
      "Epoch: 376 Batch:   0 Loss: 0.79888 Accuracy: 0.00000\n",
      "Epoch: 377 Batch:   0 Loss: 0.79873 Accuracy: 0.00000\n",
      "Epoch: 378 Batch:   0 Loss: 0.79857 Accuracy: 0.00000\n",
      "Epoch: 379 Batch:   0 Loss: 0.79842 Accuracy: 0.00000\n",
      "Test Loss: 0.68128 Accuracy: 0.50070\n",
      "Epoch: 380 Batch:   0 Loss: 0.79826 Accuracy: 0.00000\n",
      "Epoch: 381 Batch:   0 Loss: 0.79811 Accuracy: 0.00000\n",
      "Epoch: 382 Batch:   0 Loss: 0.79796 Accuracy: 0.00000\n",
      "Epoch: 383 Batch:   0 Loss: 0.79781 Accuracy: 0.00000\n",
      "Epoch: 384 Batch:   0 Loss: 0.79766 Accuracy: 0.00000\n",
      "Epoch: 385 Batch:   0 Loss: 0.79751 Accuracy: 0.00000\n",
      "Epoch: 386 Batch:   0 Loss: 0.79736 Accuracy: 0.00000\n",
      "Epoch: 387 Batch:   0 Loss: 0.79721 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 0.79707 Accuracy: 0.00000\n",
      "Epoch: 389 Batch:   0 Loss: 0.79692 Accuracy: 0.00000\n",
      "Test Loss: 0.68051 Accuracy: 0.50070\n",
      "Epoch: 390 Batch:   0 Loss: 0.79677 Accuracy: 0.00000\n",
      "Epoch: 391 Batch:   0 Loss: 0.79663 Accuracy: 0.00000\n",
      "Epoch: 392 Batch:   0 Loss: 0.79649 Accuracy: 0.00000\n",
      "Epoch: 393 Batch:   0 Loss: 0.79635 Accuracy: 0.00000\n",
      "Epoch: 394 Batch:   0 Loss: 0.79621 Accuracy: 0.00000\n",
      "Epoch: 395 Batch:   0 Loss: 0.79607 Accuracy: 0.00000\n",
      "Epoch: 396 Batch:   0 Loss: 0.79593 Accuracy: 0.00000\n",
      "Epoch: 397 Batch:   0 Loss: 0.79579 Accuracy: 0.00000\n",
      "Epoch: 398 Batch:   0 Loss: 0.79565 Accuracy: 0.00000\n",
      "Epoch: 399 Batch:   0 Loss: 0.79552 Accuracy: 0.00000\n",
      "Test Loss: 0.67984 Accuracy: 0.50070\n",
      "Epoch: 400 Batch:   0 Loss: 0.79538 Accuracy: 0.00000\n",
      "Epoch: 401 Batch:   0 Loss: 0.79526 Accuracy: 0.00000\n",
      "Epoch: 402 Batch:   0 Loss: 0.79512 Accuracy: 0.00000\n",
      "Epoch: 403 Batch:   0 Loss: 0.79501 Accuracy: 0.00000\n",
      "Epoch: 404 Batch:   0 Loss: 0.79488 Accuracy: 0.00000\n",
      "Epoch: 405 Batch:   0 Loss: 0.79476 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 0.79464 Accuracy: 0.00000\n",
      "Epoch: 407 Batch:   0 Loss: 0.79452 Accuracy: 0.00000\n",
      "Epoch: 408 Batch:   0 Loss: 0.79440 Accuracy: 0.00000\n",
      "Epoch: 409 Batch:   0 Loss: 0.79429 Accuracy: 0.00000\n",
      "Test Loss: 0.67928 Accuracy: 0.50070\n",
      "Epoch: 410 Batch:   0 Loss: 0.79416 Accuracy: 0.00000\n",
      "Epoch: 411 Batch:   0 Loss: 0.79402 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 0.79391 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 0.79379 Accuracy: 0.00000\n",
      "Epoch: 414 Batch:   0 Loss: 0.79368 Accuracy: 0.00000\n",
      "Epoch: 415 Batch:   0 Loss: 0.79357 Accuracy: 0.00000\n",
      "Epoch: 416 Batch:   0 Loss: 0.79344 Accuracy: 0.00000\n",
      "Epoch: 417 Batch:   0 Loss: 0.79331 Accuracy: 0.00000\n",
      "Epoch: 418 Batch:   0 Loss: 0.79319 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 0.79306 Accuracy: 0.00000\n",
      "Test Loss: 0.67886 Accuracy: 0.50070\n",
      "Epoch: 420 Batch:   0 Loss: 0.79294 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 0.79282 Accuracy: 0.00000\n",
      "Epoch: 422 Batch:   0 Loss: 0.79269 Accuracy: 0.00000\n",
      "Epoch: 423 Batch:   0 Loss: 0.79256 Accuracy: 0.00000\n",
      "Epoch: 424 Batch:   0 Loss: 0.79241 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 0.79227 Accuracy: 0.00000\n",
      "Epoch: 426 Batch:   0 Loss: 0.79212 Accuracy: 0.00000\n",
      "Epoch: 427 Batch:   0 Loss: 0.79198 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 0.79185 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Batch:   0 Loss: 0.79171 Accuracy: 0.00000\n",
      "Test Loss: 0.67857 Accuracy: 0.50070\n",
      "Epoch: 430 Batch:   0 Loss: 0.79158 Accuracy: 0.00000\n",
      "Epoch: 431 Batch:   0 Loss: 0.79145 Accuracy: 0.00000\n",
      "Epoch: 432 Batch:   0 Loss: 0.79132 Accuracy: 0.00000\n",
      "Epoch: 433 Batch:   0 Loss: 0.79120 Accuracy: 0.00000\n",
      "Epoch: 434 Batch:   0 Loss: 0.79107 Accuracy: 0.00000\n",
      "Epoch: 435 Batch:   0 Loss: 0.79096 Accuracy: 0.00000\n",
      "Epoch: 436 Batch:   0 Loss: 0.79084 Accuracy: 0.00000\n",
      "Epoch: 437 Batch:   0 Loss: 0.79073 Accuracy: 0.00000\n",
      "Epoch: 438 Batch:   0 Loss: 0.79061 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 0.79050 Accuracy: 0.00000\n",
      "Test Loss: 0.67838 Accuracy: 0.50070\n",
      "Epoch: 440 Batch:   0 Loss: 0.79039 Accuracy: 0.00000\n",
      "Epoch: 441 Batch:   0 Loss: 0.79027 Accuracy: 0.00000\n",
      "Epoch: 442 Batch:   0 Loss: 0.79017 Accuracy: 0.00000\n",
      "Epoch: 443 Batch:   0 Loss: 0.79006 Accuracy: 0.00000\n",
      "Epoch: 444 Batch:   0 Loss: 0.78996 Accuracy: 0.00000\n",
      "Epoch: 445 Batch:   0 Loss: 0.78985 Accuracy: 0.00000\n",
      "Epoch: 446 Batch:   0 Loss: 0.78974 Accuracy: 0.00000\n",
      "Epoch: 447 Batch:   0 Loss: 0.78963 Accuracy: 0.00000\n",
      "Epoch: 448 Batch:   0 Loss: 0.78952 Accuracy: 0.00000\n",
      "Epoch: 449 Batch:   0 Loss: 0.78941 Accuracy: 0.00000\n",
      "Test Loss: 0.67826 Accuracy: 0.50070\n",
      "Epoch: 450 Batch:   0 Loss: 0.78931 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 0.78921 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 0.78912 Accuracy: 0.00000\n",
      "Epoch: 453 Batch:   0 Loss: 0.78902 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 0.78893 Accuracy: 0.00000\n",
      "Epoch: 455 Batch:   0 Loss: 0.78884 Accuracy: 0.00000\n",
      "Epoch: 456 Batch:   0 Loss: 0.78876 Accuracy: 0.00000\n",
      "Epoch: 457 Batch:   0 Loss: 0.78867 Accuracy: 0.00000\n",
      "Epoch: 458 Batch:   0 Loss: 0.78859 Accuracy: 0.00000\n",
      "Epoch: 459 Batch:   0 Loss: 0.78851 Accuracy: 0.00000\n",
      "Test Loss: 0.67817 Accuracy: 0.50070\n",
      "Epoch: 460 Batch:   0 Loss: 0.78845 Accuracy: 0.00000\n",
      "Epoch: 461 Batch:   0 Loss: 0.78838 Accuracy: 0.00000\n",
      "Epoch: 462 Batch:   0 Loss: 0.78832 Accuracy: 0.00000\n",
      "Epoch: 463 Batch:   0 Loss: 0.78826 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 0.78820 Accuracy: 0.00000\n",
      "Epoch: 465 Batch:   0 Loss: 0.78814 Accuracy: 0.00000\n",
      "Epoch: 466 Batch:   0 Loss: 0.78809 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 0.78803 Accuracy: 0.00000\n",
      "Epoch: 468 Batch:   0 Loss: 0.78798 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 0.78794 Accuracy: 0.00000\n",
      "Test Loss: 0.67810 Accuracy: 0.50070\n",
      "Epoch: 470 Batch:   0 Loss: 0.78789 Accuracy: 0.00000\n",
      "Epoch: 471 Batch:   0 Loss: 0.78786 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 0.78783 Accuracy: 0.00000\n",
      "Epoch: 473 Batch:   0 Loss: 0.78780 Accuracy: 0.00000\n",
      "Epoch: 474 Batch:   0 Loss: 0.78778 Accuracy: 0.00000\n",
      "Epoch: 475 Batch:   0 Loss: 0.78777 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 0.78777 Accuracy: 0.00000\n",
      "Epoch: 477 Batch:   0 Loss: 0.78776 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 0.78775 Accuracy: 0.00000\n",
      "Epoch: 479 Batch:   0 Loss: 0.78775 Accuracy: 0.00000\n",
      "Test Loss: 0.67800 Accuracy: 0.50070\n",
      "Epoch: 480 Batch:   0 Loss: 0.78776 Accuracy: 0.00000\n",
      "Epoch: 481 Batch:   0 Loss: 0.78776 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 0.78778 Accuracy: 0.00000\n",
      "Epoch: 483 Batch:   0 Loss: 0.78781 Accuracy: 0.00000\n",
      "Epoch: 484 Batch:   0 Loss: 0.78784 Accuracy: 0.00000\n",
      "Epoch: 485 Batch:   0 Loss: 0.78788 Accuracy: 0.00000\n",
      "Epoch: 486 Batch:   0 Loss: 0.78792 Accuracy: 0.00000\n",
      "Epoch: 487 Batch:   0 Loss: 0.78796 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 0.78802 Accuracy: 0.00000\n",
      "Epoch: 489 Batch:   0 Loss: 0.78809 Accuracy: 0.00000\n",
      "Test Loss: 0.67783 Accuracy: 0.50070\n",
      "Epoch: 490 Batch:   0 Loss: 0.78816 Accuracy: 0.00000\n",
      "Epoch: 491 Batch:   0 Loss: 0.78824 Accuracy: 0.00000\n",
      "Epoch: 492 Batch:   0 Loss: 0.78833 Accuracy: 0.00000\n",
      "Epoch: 493 Batch:   0 Loss: 0.78842 Accuracy: 0.00000\n",
      "Epoch: 494 Batch:   0 Loss: 0.78852 Accuracy: 0.00000\n",
      "Epoch: 495 Batch:   0 Loss: 0.78863 Accuracy: 0.00000\n",
      "Epoch: 496 Batch:   0 Loss: 0.78874 Accuracy: 0.00000\n",
      "Epoch: 497 Batch:   0 Loss: 0.78886 Accuracy: 0.00000\n",
      "Epoch: 498 Batch:   0 Loss: 0.78899 Accuracy: 0.00000\n",
      "Epoch: 499 Batch:   0 Loss: 0.78912 Accuracy: 0.00000\n",
      "Test Loss: 0.67761 Accuracy: 0.50070\n",
      "Epoch: 500 Batch:   0 Loss: 0.78926 Accuracy: 0.00000\n",
      "Epoch: 501 Batch:   0 Loss: 0.78940 Accuracy: 0.00000\n",
      "Epoch: 502 Batch:   0 Loss: 0.78954 Accuracy: 0.00000\n",
      "Epoch: 503 Batch:   0 Loss: 0.78968 Accuracy: 0.00000\n",
      "Epoch: 504 Batch:   0 Loss: 0.78984 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 0.78997 Accuracy: 0.00000\n",
      "Epoch: 506 Batch:   0 Loss: 0.79010 Accuracy: 0.00000\n",
      "Epoch: 507 Batch:   0 Loss: 0.79021 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 0.79032 Accuracy: 0.00000\n",
      "Epoch: 509 Batch:   0 Loss: 0.79042 Accuracy: 0.00000\n",
      "Test Loss: 0.67722 Accuracy: 0.50070\n",
      "Epoch: 510 Batch:   0 Loss: 0.79051 Accuracy: 0.00000\n",
      "Epoch: 511 Batch:   0 Loss: 0.79059 Accuracy: 0.00000\n",
      "Epoch: 512 Batch:   0 Loss: 0.79065 Accuracy: 0.00000\n",
      "Epoch: 513 Batch:   0 Loss: 0.79070 Accuracy: 0.00000\n",
      "Epoch: 514 Batch:   0 Loss: 0.79074 Accuracy: 0.00000\n",
      "Epoch: 515 Batch:   0 Loss: 0.79075 Accuracy: 0.00000\n",
      "Epoch: 516 Batch:   0 Loss: 0.79075 Accuracy: 0.00000\n",
      "Epoch: 517 Batch:   0 Loss: 0.79073 Accuracy: 0.00000\n",
      "Epoch: 518 Batch:   0 Loss: 0.79069 Accuracy: 0.00000\n",
      "Epoch: 519 Batch:   0 Loss: 0.79064 Accuracy: 0.00000\n",
      "Test Loss: 0.67630 Accuracy: 0.50060\n",
      "Epoch: 520 Batch:   0 Loss: 0.79057 Accuracy: 0.00000\n",
      "Epoch: 521 Batch:   0 Loss: 0.79051 Accuracy: 0.00000\n",
      "Epoch: 522 Batch:   0 Loss: 0.79044 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 0.79036 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 0.79026 Accuracy: 0.00000\n",
      "Epoch: 525 Batch:   0 Loss: 0.79015 Accuracy: 0.00000\n",
      "Epoch: 526 Batch:   0 Loss: 0.79002 Accuracy: 0.00000\n",
      "Epoch: 527 Batch:   0 Loss: 0.78989 Accuracy: 0.00000\n",
      "Epoch: 528 Batch:   0 Loss: 0.78975 Accuracy: 0.00000\n",
      "Epoch: 529 Batch:   0 Loss: 0.78960 Accuracy: 0.00000\n",
      "Test Loss: 0.67525 Accuracy: 0.50060\n",
      "Epoch: 530 Batch:   0 Loss: 0.78944 Accuracy: 0.00000\n",
      "Epoch: 531 Batch:   0 Loss: 0.78927 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 0.78910 Accuracy: 0.00000\n",
      "Epoch: 533 Batch:   0 Loss: 0.78893 Accuracy: 0.00000\n",
      "Epoch: 534 Batch:   0 Loss: 0.78875 Accuracy: 0.00000\n",
      "Epoch: 535 Batch:   0 Loss: 0.78858 Accuracy: 0.00000\n",
      "Epoch: 536 Batch:   0 Loss: 0.78840 Accuracy: 0.00000\n",
      "Epoch: 537 Batch:   0 Loss: 0.78821 Accuracy: 0.00000\n",
      "Epoch: 538 Batch:   0 Loss: 0.78802 Accuracy: 0.00000\n",
      "Epoch: 539 Batch:   0 Loss: 0.78784 Accuracy: 0.00000\n",
      "Test Loss: 0.67433 Accuracy: 0.50050\n",
      "Epoch: 540 Batch:   0 Loss: 0.78764 Accuracy: 0.00000\n",
      "Epoch: 541 Batch:   0 Loss: 0.78744 Accuracy: 0.00000\n",
      "Epoch: 542 Batch:   0 Loss: 0.78726 Accuracy: 0.00000\n",
      "Epoch: 543 Batch:   0 Loss: 0.78707 Accuracy: 0.00000\n",
      "Epoch: 544 Batch:   0 Loss: 0.78687 Accuracy: 0.00000\n",
      "Epoch: 545 Batch:   0 Loss: 0.78669 Accuracy: 0.00000\n",
      "Epoch: 546 Batch:   0 Loss: 0.78650 Accuracy: 0.00000\n",
      "Epoch: 547 Batch:   0 Loss: 0.78631 Accuracy: 0.00000\n",
      "Epoch: 548 Batch:   0 Loss: 0.78613 Accuracy: 0.00000\n",
      "Epoch: 549 Batch:   0 Loss: 0.78595 Accuracy: 0.00000\n",
      "Test Loss: 0.67354 Accuracy: 0.50050\n",
      "Epoch: 550 Batch:   0 Loss: 0.78577 Accuracy: 0.00000\n",
      "Epoch: 551 Batch:   0 Loss: 0.78559 Accuracy: 0.00000\n",
      "Epoch: 552 Batch:   0 Loss: 0.78542 Accuracy: 0.00000\n",
      "Epoch: 553 Batch:   0 Loss: 0.78525 Accuracy: 0.00000\n",
      "Epoch: 554 Batch:   0 Loss: 0.78509 Accuracy: 0.00000\n",
      "Epoch: 555 Batch:   0 Loss: 0.78493 Accuracy: 0.00000\n",
      "Epoch: 556 Batch:   0 Loss: 0.78477 Accuracy: 0.00000\n",
      "Epoch: 557 Batch:   0 Loss: 0.78461 Accuracy: 0.00000\n",
      "Epoch: 558 Batch:   0 Loss: 0.78446 Accuracy: 0.00000\n",
      "Epoch: 559 Batch:   0 Loss: 0.78431 Accuracy: 0.00000\n",
      "Test Loss: 0.67291 Accuracy: 0.50050\n",
      "Epoch: 560 Batch:   0 Loss: 0.78417 Accuracy: 0.00000\n",
      "Epoch: 561 Batch:   0 Loss: 0.78404 Accuracy: 0.00000\n",
      "Epoch: 562 Batch:   0 Loss: 0.78391 Accuracy: 0.00000\n",
      "Epoch: 563 Batch:   0 Loss: 0.78379 Accuracy: 0.00000\n",
      "Epoch: 564 Batch:   0 Loss: 0.78368 Accuracy: 0.00000\n",
      "Epoch: 565 Batch:   0 Loss: 0.78358 Accuracy: 0.00000\n",
      "Epoch: 566 Batch:   0 Loss: 0.78348 Accuracy: 0.00000\n",
      "Epoch: 567 Batch:   0 Loss: 0.78339 Accuracy: 0.00000\n",
      "Epoch: 568 Batch:   0 Loss: 0.78331 Accuracy: 0.00000\n",
      "Epoch: 569 Batch:   0 Loss: 0.78324 Accuracy: 0.00000\n",
      "Test Loss: 0.67245 Accuracy: 0.50050\n",
      "Epoch: 570 Batch:   0 Loss: 0.78316 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 571 Batch:   0 Loss: 0.78310 Accuracy: 0.00000\n",
      "Epoch: 572 Batch:   0 Loss: 0.78304 Accuracy: 0.00000\n",
      "Epoch: 573 Batch:   0 Loss: 0.78299 Accuracy: 0.00000\n",
      "Epoch: 574 Batch:   0 Loss: 0.78295 Accuracy: 0.00000\n",
      "Epoch: 575 Batch:   0 Loss: 0.78291 Accuracy: 0.00000\n",
      "Epoch: 576 Batch:   0 Loss: 0.78287 Accuracy: 0.00000\n",
      "Epoch: 577 Batch:   0 Loss: 0.78284 Accuracy: 0.00000\n",
      "Epoch: 578 Batch:   0 Loss: 0.78281 Accuracy: 0.00000\n",
      "Epoch: 579 Batch:   0 Loss: 0.78278 Accuracy: 0.00000\n",
      "Test Loss: 0.67207 Accuracy: 0.50050\n",
      "Epoch: 580 Batch:   0 Loss: 0.78275 Accuracy: 0.00000\n",
      "Epoch: 581 Batch:   0 Loss: 0.78273 Accuracy: 0.00000\n",
      "Epoch: 582 Batch:   0 Loss: 0.78270 Accuracy: 0.00000\n",
      "Epoch: 583 Batch:   0 Loss: 0.78268 Accuracy: 0.00000\n",
      "Epoch: 584 Batch:   0 Loss: 0.78265 Accuracy: 0.00000\n",
      "Epoch: 585 Batch:   0 Loss: 0.78261 Accuracy: 0.00000\n",
      "Epoch: 586 Batch:   0 Loss: 0.78257 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 11:12:19,738] Trial 19 finished with value: 0.5003015681544029 and parameters: {'REG_W': 3.5816754063519616e-06, 'REG_B': 0.0019308848784722011, 'REG_Z': 3.2192243443148886e-05, 'SPAR_W': 0.6279903470101106, 'SPAR_B': 0.8571723793461878, 'SPAR_Z': 0.759147611268914, 'LEARNING_RATE': 0.0002724335761200872, 'NUM_EPOCHS': 587}. Best is trial 14 with value: 0.756031363088058.\n"
     ]
    }
   ],
   "source": [
    "op_fun = partial(objective,x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)\n",
    "study.optimize(op_fun,n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=14, state=TrialState.COMPLETE, values=[0.756031363088058], datetime_start=datetime.datetime(2023, 11, 17, 10, 37, 24, 632687), datetime_complete=datetime.datetime(2023, 11, 17, 10, 42, 47, 287661), params={'REG_W': 3.1545272147130644e-06, 'REG_B': 0.00025738817748430687, 'REG_Z': 3.534809578054365e-05, 'SPAR_W': 0.6622823978261199, 'SPAR_B': 0.651918182305612, 'SPAR_Z': 0.6197401480486052, 'LEARNING_RATE': 0.00029791501581002825, 'NUM_EPOCHS': 595}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'REG_W': FloatDistribution(high=5e-06, log=False, low=2e-06, step=None), 'REG_B': FloatDistribution(high=0.01, log=False, low=0.0, step=None), 'REG_Z': FloatDistribution(high=5e-05, log=False, low=2e-05, step=None), 'SPAR_W': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'SPAR_B': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'SPAR_Z': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'LEARNING_RATE': FloatDistribution(high=0.001, log=False, low=0.0001, step=None), 'NUM_EPOCHS': IntDistribution(high=600, log=False, low=200, step=1)}, trial_id=14, value=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJwO4MXatk9G"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:07:22.641991Z",
     "start_time": "2018-08-15T13:06:10.309353Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 98358,
     "status": "ok",
     "timestamp": 1567154584840,
     "user": {
      "displayName": "Gokul Hari",
      "photoUrl": "",
      "userId": "16159457985484250305"
     },
     "user_tz": -330
    },
    "id": "MrKAP5_RQJ2b",
    "outputId": "2fb982af-47ae-4867-c5e5-b2ecc2b9dfc4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setup input and train protoNN\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                  NUM_PROTOTYPES, numClasses,\n",
    "                  gamma, W=W, B=B)\n",
    "trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
    "                         SPAR_W, SPAR_B, SPAR_Z,\n",
    "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
    "sess = tf.Session()\n",
    "\n",
    "trainer.train(BATCH_SIZE, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,\n",
    "              printStep=600, valStep=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uypXmz1QJ2h"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:07:22.671507Z",
     "start_time": "2018-08-15T13:07:22.645050Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 96103,
     "status": "ok",
     "timestamp": 1567154584845,
     "user": {
      "displayName": "Gokul Hari",
      "photoUrl": "",
      "userId": "16159457985484250305"
     },
     "user_tz": -330
    },
    "id": "VYxefAD3QJ2j",
    "outputId": "f8b711a1-bae4-4bf5-9a62-935838844601"
   },
   "outputs": [],
   "source": [
    "acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "pred = sess.run(protoNN.predictions, feed_dict={X: x_test, Y: y_test})\n",
    "# W, B, Z are tensorflow graph nodes\n",
    "W, B, Z, _ = protoNN.getModelMatrices()\n",
    "matrixList = sess.run([W, B, Z])\n",
    "sparcityList = [SPAR_W, SPAR_B, SPAR_Z]                       \n",
    "nnz, size, sparse = getModelSize(matrixList, sparcityList)\n",
    "print(\"Final test accuracy\", acc)\n",
    "print(\"Model size constraint (Bytes): \", size)\n",
    "print(\"Number of non-zeros: \", nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 91542,
     "status": "ok",
     "timestamp": 1567154584848,
     "user": {
      "displayName": "Gokul Hari",
      "photoUrl": "",
      "userId": "16159457985484250305"
     },
     "user_tz": -330
    },
    "id": "yJM9puhcQJ2t",
    "outputId": "d8e743e0-1068-4681-e3bc-3b650ab66a3c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "y_test = np.argmax(y_test,axis=1)\n",
    "print (confusion_matrix(y_test,pred))\n",
    "print (classification_report(y_test,pred,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = confusion_matrix(y_test,pred)[1][1]/(confusion_matrix(y_test,pred)[1][1] + confusion_matrix(y_test,pred)[1][0])\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = confusion_matrix(y_test,pred)[0][0]/(confusion_matrix(y_test,pred)[0][0] + confusion_matrix(y_test,pred)[0][1])\n",
    "specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = (TP + TN) / (TP + TN + FP + FN) \n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)\n",
    "# sensitivity = TP / (TP + FN) \n",
    "# specificity = TN / (TN + FP) \n",
    "# positive predictive value (PPV) = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "protoNN_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ProtoNN",
   "language": "python",
   "name": "protonn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
